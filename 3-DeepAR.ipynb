{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker/DeepAR demo on Stores Daily Sales\n",
    "\n",
    "In this lab, we will use Amazon SageMaker build-in algorithm DeepAR to forecast 1604 stores daily sales.\n",
    "\n",
    "In particular, we will see how to:\n",
    "* Use the SageMaker Python SDK to train a DeepAR model and deploy it\n",
    "* Make requests to the deployed model to obtain forecasts interactively\n",
    "* Illustrate advanced features of DeepAR: additional time features and category information\n",
    "\n",
    "Running this notebook takes around 40 min on a ml.c4.2xlarge for the training, and inference is done on a ml.m4.xlarge (the usage time will depend on how long you leave your served model running).\n",
    "\n",
    "For more information see the DeepAR [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html) or [paper](https://arxiv.org/abs/1704.04110), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "from dateutil.parser import parse\n",
    "import json\n",
    "from random import shuffle\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "import s3fs\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import IntSlider, FloatSlider, Checkbox\n",
    "\n",
    "from decouple import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, we can override the default values for the following:\n",
    "- The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = sagemaker.Session().default_bucket()  # replace with an existing bucket if needed\n",
    "s3_prefix = 'tko-ts-workshop'    # prefix used for all data stored within the bucket\n",
    "\n",
    "role = sagemaker.get_execution_role()             # IAM role to use by SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "s3_data_path = \"s3://{}/{}/data\".format(s3_bucket, s3_prefix)\n",
    "s3_output_path = \"s3://{}/{}/output\".format(s3_bucket, s3_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we configure the container image to be used for the region that we are running in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = sagemaker.amazon.amazon_estimator.get_image_uri(region, \"forecasting-deepar\", \"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset and upload it to S3 to make it available for Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already has pre-processed the data we will use, it is under the same folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = 'data/timeseries_raw.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we load and parse the dataset and convert it to a collection of Pandas time series, which makes common time series operations such as indexing by time periods or resampling much easier. The data has been processed, and the frequency is 1 day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(FILE_NAME, sep=\",\", index_col=0, parse_dates=True, decimal=',')\n",
    "data.index = pd.DatetimeIndex(data.index,freq=\"1D\")\n",
    "\n",
    "num_timeseries = data.shape[1]\n",
    "\n",
    "timeseries = []\n",
    "for i in range(num_timeseries):\n",
    "    timeseries.append(np.trim_zeros(data.iloc[:,i], trim='f').astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the resulting time series for the first ten stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019-07-10 00:00:00 to 2019-10-09 23:59:59\n",
    "\n",
    "DATETIME_START_OF_TRAIN = config('DATETIME_START_OF_TRAIN')\n",
    "DATETIME_END_OF_TRAIN = config('DATETIME_END_OF_TRAIN')\n",
    "DATETIME_START_OF_TEST = config('DATETIME_START_OF_TEST')\n",
    "DATETIME_END_OF_TEST = config('DATETIME_END_OF_TEST')\n",
    "DATETIME_START_OF_PREDICT = config('DATETIME_START_OF_PREDICT')\n",
    "DATETIME_END_OF_PREDICT = config('DATETIME_END_OF_PREDICT')\n",
    "\n",
    "# we use 1 day frequency for the time series\n",
    "freq = config('freq')\n",
    "\n",
    "# we predict for 7 days\n",
    "prediction_length = config('prediction_length', cast=int)\n",
    "\n",
    "# we also use 14 days as context length, this is the number of state updates accomplished before making predictions\n",
    "context_length = config('context_length', cast=int)\n",
    "\n",
    "sample_sites = config('sample_sites', cast=lambda v: [int(s.strip()) for s in v.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(len(sample_sites), 1, figsize=(15, 10), sharex=True)\n",
    "axx = axs.ravel()\n",
    "for i, site in enumerate(sample_sites):\n",
    "    timeseries[site].loc[DATETIME_START_OF_TRAIN:DATETIME_END_OF_PREDICT].astype(float).plot(ax=axx[i])\n",
    "    axx[i].set_xlabel(\"date\")    \n",
    "    axx[i].set_ylabel(\"sales RMB\")   \n",
    "    axx[i].grid(which='minor', axis='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test splits\n",
    "\n",
    "Often times one is interested in evaluating the model or tuning its hyperparameters by looking at error metrics on a hold-out test set. Here we split the available data into train and test sets for evaluating the trained model. For standard machine learning tasks such as classification and regression, one typically obtains this split by randomly separating examples into train and test sets. However, in forecasting it is important to do this train/test split based on time rather than by time series.\n",
    "\n",
    "In this example, we will reserve the last section of each of the time series for evalutation purpose and use only the first part as training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify here the portion of the data that is used for training: the model sees data from 2019-07-10 to 2019-09-16 for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dataset = pd.Timestamp(DATETIME_START_OF_TRAIN, freq=freq)\n",
    "end_training = pd.Timestamp(DATETIME_END_OF_TRAIN, freq=freq)\n",
    "end_test = pd.Timestamp(DATETIME_END_OF_TEST, freq=freq)\n",
    "start_predict = pd.Timestamp(DATETIME_START_OF_PREDICT, freq=freq)\n",
    "end_predict = pd.Timestamp(DATETIME_END_OF_PREDICT, freq=freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DeepAR JSON input format represents each time series as a JSON object. In the simplest case each time series just consists of a start time stamp (``start``) and a list of values (``target``). For more complex cases, DeepAR also supports the fields ``dynamic_feat`` for time-series features and ``cat`` for categorical features, which we will use  later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:6: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n"
     ]
    }
   ],
   "source": [
    "training_data = [\n",
    "    {\n",
    "        \"start\": str(start_dataset),\n",
    "        \"target\": ts[start_dataset:end_training - 1].tolist()  # We use -1, because pandas indexing includes the upper bound \n",
    "    }\n",
    "    for ts in timeseries\n",
    "]\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As test data, we will consider time series extending beyond the training range: these will be used for computing test scores, by using the trained model to forecast their trailing 7 days, and comparing predictions with actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-09-24 00:00:00', freq='D')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:6: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1604\n"
     ]
    }
   ],
   "source": [
    "test_data = [\n",
    "    {\n",
    "        \"start\": str(start_dataset),\n",
    "        \"target\": ts[start_dataset:end_test - 1].tolist()\n",
    "    }\n",
    "    for ts in timeseries\n",
    "]\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now write the dictionary to the `jsonlines` file format that DeepAR understands (it also supports gzipped jsonlines and parquet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dicts_to_file(path, data):\n",
    "    with open(path, 'wb') as fp:\n",
    "        for d in data:\n",
    "            fp.write(json.dumps(d).encode(\"utf-8\"))\n",
    "            fp.write(\"\\n\".encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 84.8 ms, sys: 21 µs, total: 84.8 ms\n",
      "Wall time: 83.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_dicts_to_file(\"data/train.json\", training_data)\n",
    "write_dicts_to_file(\"data/test.json\", test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data files locally, let us copy them to S3 where DeepAR can access them. Depending on your connection, this may take a couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "def copy_to_s3(local_file, s3_path, override=False):\n",
    "    assert s3_path.startswith('s3://')\n",
    "    split = s3_path.split('/')\n",
    "    bucket = split[2]\n",
    "    path = '/'.join(split[3:])\n",
    "    buk = s3.Bucket(bucket)\n",
    "    \n",
    "    if len(list(buk.objects.filter(Prefix=path))) > 0:\n",
    "        if not override:\n",
    "            print('File s3://{}/{} already exists.\\nSet override to upload anyway.\\n'.format(s3_bucket, s3_path))\n",
    "            return\n",
    "        else:\n",
    "            print('Overwriting existing file')\n",
    "    with open(local_file, 'rb') as data:\n",
    "        print('Uploading file to {}'.format(s3_path))\n",
    "        buk.put_object(Key=path, Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file to s3://sagemaker-ap-northeast-2-169088282855/tko-ts-workshop/data/train/train.json\n",
      "Uploading file to s3://sagemaker-ap-northeast-2-169088282855/tko-ts-workshop/data/test/test.json\n",
      "CPU times: user 35.8 ms, sys: 4 ms, total: 39.8 ms\n",
      "Wall time: 272 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "copy_to_s3(\"data/train.json\", s3_data_path + \"/train/train.json\")\n",
    "copy_to_s3(\"data/test.json\", s3_data_path + \"/test/test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look to what we just wrote to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"start\": \"2019-07-10 00:00:00\", \"target\": [14.0, 18.0, 22.4, 28.5, 25.0, 7.3, 31.1, 0.0, 27.6, 46.1...\n"
     ]
    }
   ],
   "source": [
    "s3filesystem = s3fs.S3FileSystem()\n",
    "with s3filesystem.open(s3_data_path + \"/train/train.json\", 'rb') as fp:\n",
    "    print(fp.readline().decode(\"utf-8\")[:100] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are all set with our dataset processing, we can now call DeepAR to train a model and generate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model\n",
    "\n",
    "Here we define the estimator that will launch the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "image_name = sagemaker.amazon.amazon_estimator.get_image_uri(region, \"forecasting-deepar\", \"latest\")\n",
    "\n",
    "role = sagemaker.get_execution_role()             # IAM role to use by SageMaker\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.2xlarge',\n",
    "    base_job_name='deepar-stores-sales-demo',\n",
    "    output_path=s3_output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to set the hyperparameters for the training job. For example frequency of the time series used, number of data points the model will look at in the past, number of predicted data points. The other hyperparameters concern the model to train (number of layers, number of cells per layer, likelihood function) and the training options (number of epochs, batch size, learning rate...). We use default parameters for every optional parameter in this case (you can always use [Sagemaker Automated Model Tuning](https://aws.amazon.com/blogs/aws/sagemaker-automatic-model-tuning/) to tune them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"mini_batch_size\": \"32\",\n",
    "    \"learning_rate\": \"5E-4\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to launch the training job. SageMaker will start an EC2 instance, download the data from S3, start training the model and save the trained model.\n",
    "\n",
    "If you provide the `test` data channel as we do in this example, DeepAR will also calculate accuracy metrics for the trained model on this test. This is done by predicting the last `prediction_length` points of each time-series in the test set and comparing this to the actual value of the time-series. \n",
    "\n",
    "**Note:** the next cell may take a few minutes to complete, depending on data size, model complexity, training options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-08 08:16:06 Starting - Starting the training job...\n",
      "2020-01-08 08:16:08 Starting - Launching requested ML instances......\n",
      "2020-01-08 08:17:09 Starting - Preparing the instances for training...\n",
      "2020-01-08 08:17:58 Downloading - Downloading input data...\n",
      "2020-01-08 08:18:28 Training - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:50 INFO 139919921551168] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:50 INFO 139919921551168] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'5E-4', u'prediction_length': u'7', u'epochs': u'400', u'time_freq': u'1D', u'context_length': u'14', u'mini_batch_size': u'32', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:50 INFO 139919921551168] Final configuration: {u'dropout_rate': u'0.10', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'5E-4', u'num_layers': u'2', u'epochs': u'400', u'embedding_dimension': u'10', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'32', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'7', u'time_freq': u'1D', u'context_length': u'14', u'_kvstore': u'auto', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:50 INFO 139919921551168] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] Using early stopping with patience 40\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] [num_dynamic_feat=auto] `dynamic_feat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] Training set statistics:\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] Real time series\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] number of time series: 1604\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] number of observations: 110676\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] mean target length: 69\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] min/mean/max target: 0.0/21018.1296408/1653507.875\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] mean abs(target): 21018.1296408\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] contains missing values: no\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] Test set statistics:\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] Real time series\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] number of time series: 1604\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] number of observations: 121904\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] mean target length: 76\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] min/mean/max target: 0.0/20798.7399189/1653507.875\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] mean abs(target): 20798.7399189\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] contains missing values: no\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] nvidia-smi took: 0.0251679420471 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 49.97086524963379, \"sum\": 49.97086524963379, \"min\": 49.97086524963379}}, \"EndTime\": 1578471531.500429, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471531.449647}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 142.84610748291016, \"sum\": 142.84610748291016, \"min\": 142.84610748291016}}, \"EndTime\": 1578471531.592619, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471531.500504}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] Epoch[0] Batch[0] avg_epoch_loss=11.783336\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=11.7833356857\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] Epoch[0] Batch[5] avg_epoch_loss=10.608825\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=10.6088253657\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:51 INFO 139919921551168] Epoch[0] Batch [5]#011Speed: 1767.98 samples/sec#011loss=10.608825\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] Epoch[0] Batch[10] avg_epoch_loss=9.957854\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=9.17668781281\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] Epoch[0] Batch [10]#011Speed: 898.81 samples/sec#011loss=9.176688\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] Epoch[0] Batch[15] avg_epoch_loss=9.705494\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=0, batch=15 train loss <loss>=9.15030097961\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] Epoch[0] Batch [15]#011Speed: 1638.24 samples/sec#011loss=9.150301\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] Epoch[0] Batch[20] avg_epoch_loss=9.598764\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=0, batch=20 train loss <loss>=9.25722827911\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] Epoch[0] Batch [20]#011Speed: 985.25 samples/sec#011loss=9.257228\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] Epoch[0] Batch[25] avg_epoch_loss=9.409865\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=0, batch=25 train loss <loss>=8.61648921967\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] Epoch[0] Batch [25]#011Speed: 2006.17 samples/sec#011loss=8.616489\u001b[0m\n",
      "\n",
      "2020-01-08 08:18:47 Training - Training image download completed. Training in progress.\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] Epoch[0] Batch[30] avg_epoch_loss=9.288206\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=0, batch=30 train loss <loss>=8.6555814743\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] Epoch[0] Batch [30]#011Speed: 869.04 samples/sec#011loss=8.655581\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] Epoch[0] Batch[35] avg_epoch_loss=9.134467\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=0, batch=35 train loss <loss>=8.18128614426\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] Epoch[0] Batch [35]#011Speed: 2131.26 samples/sec#011loss=8.181286\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] Epoch[0] Batch[40] avg_epoch_loss=9.036790\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=0, batch=40 train loss <loss>=8.33351345062\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] Epoch[0] Batch [40]#011Speed: 1029.20 samples/sec#011loss=8.333513\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] Epoch[0] Batch[45] avg_epoch_loss=8.999250\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=0, batch=45 train loss <loss>=8.69141921997\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:52 INFO 139919921551168] Epoch[0] Batch [45]#011Speed: 1683.98 samples/sec#011loss=8.691419\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] Epoch[0] Batch[50] avg_epoch_loss=8.896456\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=0, batch=50 train loss <loss>=7.95075330734\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] Epoch[0] Batch [50]#011Speed: 1341.25 samples/sec#011loss=7.950753\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] processed a total of 1655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 400, \"sum\": 400.0, \"min\": 400}, \"update.time\": {\"count\": 1, \"max\": 1466.0909175872803, \"sum\": 1466.0909175872803, \"min\": 1466.0909175872803}}, \"EndTime\": 1578471533.058852, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471531.592678}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1128.75439123 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=0, train loss <loss>=8.87059814196\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] Saved checkpoint to \"/opt/ml/model/state_4a29cfd6-4a27-456c-bd6e-67015d761960-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.581037521362305, \"sum\": 13.581037521362305, \"min\": 13.581037521362305}}, \"EndTime\": 1578471533.073098, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471533.058939}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] Epoch[1] Batch[0] avg_epoch_loss=8.843451\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=8.84345054626\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] Epoch[1] Batch[5] avg_epoch_loss=8.912348\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=8.91234763463\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] Epoch[1] Batch [5]#011Speed: 2087.25 samples/sec#011loss=8.912348\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] Epoch[1] Batch[10] avg_epoch_loss=8.805604\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=8.67751216888\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] Epoch[1] Batch [10]#011Speed: 943.20 samples/sec#011loss=8.677512\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] Epoch[1] Batch[15] avg_epoch_loss=8.918338\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=1, batch=15 train loss <loss>=9.16635169983\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] Epoch[1] Batch [15]#011Speed: 1636.49 samples/sec#011loss=9.166352\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] Epoch[1] Batch[20] avg_epoch_loss=8.906831\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=1, batch=20 train loss <loss>=8.87000923157\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] Epoch[1] Batch [20]#011Speed: 981.82 samples/sec#011loss=8.870009\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] Epoch[1] Batch[25] avg_epoch_loss=8.806893\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=1, batch=25 train loss <loss>=8.38715257645\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] Epoch[1] Batch [25]#011Speed: 1991.34 samples/sec#011loss=8.387153\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] Epoch[1] Batch[30] avg_epoch_loss=8.735829\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=1, batch=30 train loss <loss>=8.3662940979\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:53 INFO 139919921551168] Epoch[1] Batch [30]#011Speed: 951.87 samples/sec#011loss=8.366294\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] Epoch[1] Batch[35] avg_epoch_loss=8.657957\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=1, batch=35 train loss <loss>=8.17515583038\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] Epoch[1] Batch [35]#011Speed: 1758.61 samples/sec#011loss=8.175156\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] Epoch[1] Batch[40] avg_epoch_loss=8.612335\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=1, batch=40 train loss <loss>=8.28385477066\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] Epoch[1] Batch [40]#011Speed: 996.47 samples/sec#011loss=8.283855\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] Epoch[1] Batch[45] avg_epoch_loss=8.581281\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=1, batch=45 train loss <loss>=8.32664022446\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] Epoch[1] Batch [45]#011Speed: 1850.89 samples/sec#011loss=8.326640\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] processed a total of 1590 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1274.8332023620605, \"sum\": 1274.8332023620605, \"min\": 1274.8332023620605}}, \"EndTime\": 1578471534.348049, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471533.073161}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1247.11166747 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=1, train loss <loss>=8.48082932472\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] Saved checkpoint to \"/opt/ml/model/state_f1ab22ad-3511-4a00-a09f-424def241fc4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 15.91801643371582, \"sum\": 15.91801643371582, \"min\": 15.91801643371582}}, \"EndTime\": 1578471534.364537, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471534.348127}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] Epoch[2] Batch[0] avg_epoch_loss=8.629896\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=8.62989616394\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] Epoch[2] Batch[5] avg_epoch_loss=8.584908\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=8.58490832647\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] Epoch[2] Batch [5]#011Speed: 1585.49 samples/sec#011loss=8.584908\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] Epoch[2] Batch[10] avg_epoch_loss=8.564617\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=8.54026660919\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] Epoch[2] Batch [10]#011Speed: 788.50 samples/sec#011loss=8.540267\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] Epoch[2] Batch[15] avg_epoch_loss=8.666932\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=2, batch=15 train loss <loss>=8.89202537537\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:54 INFO 139919921551168] Epoch[2] Batch [15]#011Speed: 1493.29 samples/sec#011loss=8.892025\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] Epoch[2] Batch[20] avg_epoch_loss=8.653830\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=2, batch=20 train loss <loss>=8.6119020462\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] Epoch[2] Batch [20]#011Speed: 820.85 samples/sec#011loss=8.611902\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] Epoch[2] Batch[25] avg_epoch_loss=8.650271\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=2, batch=25 train loss <loss>=8.63532524109\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] Epoch[2] Batch [25]#011Speed: 1581.29 samples/sec#011loss=8.635325\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] Epoch[2] Batch[30] avg_epoch_loss=8.606961\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=2, batch=30 train loss <loss>=8.38175010681\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] Epoch[2] Batch [30]#011Speed: 950.83 samples/sec#011loss=8.381750\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] Epoch[2] Batch[35] avg_epoch_loss=8.564595\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=2, batch=35 train loss <loss>=8.30192565918\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] Epoch[2] Batch [35]#011Speed: 1751.08 samples/sec#011loss=8.301926\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] Epoch[2] Batch[40] avg_epoch_loss=8.517323\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=2, batch=40 train loss <loss>=8.17696352005\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] Epoch[2] Batch [40]#011Speed: 850.82 samples/sec#011loss=8.176964\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] Epoch[2] Batch[45] avg_epoch_loss=8.458604\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=2, batch=45 train loss <loss>=7.97710428238\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] Epoch[2] Batch [45]#011Speed: 2072.14 samples/sec#011loss=7.977104\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] processed a total of 1553 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1441.979169845581, \"sum\": 1441.979169845581, \"min\": 1441.979169845581}}, \"EndTime\": 1578471535.80664, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471534.364603}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1076.87998402 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=2, train loss <loss>=8.42974635533\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] Saved checkpoint to \"/opt/ml/model/state_acdd4382-8b08-470d-995d-e775ff833369-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 15.318870544433594, \"sum\": 15.318870544433594, \"min\": 15.318870544433594}}, \"EndTime\": 1578471535.822563, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471535.806755}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] Epoch[3] Batch[0] avg_epoch_loss=8.231645\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=8.23164463043\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] Epoch[3] Batch[5] avg_epoch_loss=8.190007\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=8.1900071303\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:55 INFO 139919921551168] Epoch[3] Batch [5]#011Speed: 1916.54 samples/sec#011loss=8.190007\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:56 INFO 139919921551168] Epoch[3] Batch[10] avg_epoch_loss=8.356471\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=8.55622692108\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:56 INFO 139919921551168] Epoch[3] Batch [10]#011Speed: 841.75 samples/sec#011loss=8.556227\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:56 INFO 139919921551168] Epoch[3] Batch[15] avg_epoch_loss=8.458588\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=3, batch=15 train loss <loss>=8.68324756622\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:56 INFO 139919921551168] Epoch[3] Batch [15]#011Speed: 2050.39 samples/sec#011loss=8.683248\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:56 INFO 139919921551168] Epoch[3] Batch[20] avg_epoch_loss=8.514540\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=3, batch=20 train loss <loss>=8.69358463287\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:56 INFO 139919921551168] Epoch[3] Batch [20]#011Speed: 894.60 samples/sec#011loss=8.693585\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:56 INFO 139919921551168] Epoch[3] Batch[25] avg_epoch_loss=8.513165\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=3, batch=25 train loss <loss>=8.50738859177\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:56 INFO 139919921551168] Epoch[3] Batch [25]#011Speed: 1743.77 samples/sec#011loss=8.507389\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:56 INFO 139919921551168] Epoch[3] Batch[30] avg_epoch_loss=8.454308\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=3, batch=30 train loss <loss>=8.14825286865\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:56 INFO 139919921551168] Epoch[3] Batch [30]#011Speed: 1001.73 samples/sec#011loss=8.148253\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:56 INFO 139919921551168] Epoch[3] Batch[35] avg_epoch_loss=8.340837\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=3, batch=35 train loss <loss>=7.63731651306\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:56 INFO 139919921551168] Epoch[3] Batch [35]#011Speed: 2005.82 samples/sec#011loss=7.637317\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:56 INFO 139919921551168] Epoch[3] Batch[40] avg_epoch_loss=8.274331\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=3, batch=40 train loss <loss>=7.79548625946\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:56 INFO 139919921551168] Epoch[3] Batch [40]#011Speed: 963.08 samples/sec#011loss=7.795486\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] Epoch[3] Batch[45] avg_epoch_loss=8.276575\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=3, batch=45 train loss <loss>=8.29497966766\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] Epoch[3] Batch [45]#011Speed: 2061.99 samples/sec#011loss=8.294980\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] Epoch[3] Batch[50] avg_epoch_loss=8.262300\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=3, batch=50 train loss <loss>=8.130971241\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] Epoch[3] Batch [50]#011Speed: 1833.37 samples/sec#011loss=8.130971\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] processed a total of 1643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1308.9299201965332, \"sum\": 1308.9299201965332, \"min\": 1308.9299201965332}}, \"EndTime\": 1578471537.131596, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471535.822621}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1255.11635911 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=3, train loss <loss>=8.18875585153\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] Saved checkpoint to \"/opt/ml/model/state_80421595-27a4-404d-b679-d3e0c360290f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.44011116027832, \"sum\": 10.44011116027832, \"min\": 10.44011116027832}}, \"EndTime\": 1578471537.142639, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471537.131681}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] Epoch[4] Batch[0] avg_epoch_loss=8.756257\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=8.75625705719\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] Epoch[4] Batch[5] avg_epoch_loss=8.471559\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=8.47155857086\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] Epoch[4] Batch [5]#011Speed: 1638.81 samples/sec#011loss=8.471559\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] Epoch[4] Batch[10] avg_epoch_loss=8.476041\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=8.48141946793\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] Epoch[4] Batch [10]#011Speed: 853.30 samples/sec#011loss=8.481419\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] Epoch[4] Batch[15] avg_epoch_loss=8.479500\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=4, batch=15 train loss <loss>=8.48711090088\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] Epoch[4] Batch [15]#011Speed: 1636.68 samples/sec#011loss=8.487111\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] Epoch[4] Batch[20] avg_epoch_loss=8.557992\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=4, batch=20 train loss <loss>=8.80916461945\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] Epoch[4] Batch [20]#011Speed: 985.53 samples/sec#011loss=8.809165\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] Epoch[4] Batch[25] avg_epoch_loss=8.488757\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=4, batch=25 train loss <loss>=8.19796972275\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:57 INFO 139919921551168] Epoch[4] Batch [25]#011Speed: 1912.23 samples/sec#011loss=8.197970\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] Epoch[4] Batch[30] avg_epoch_loss=8.443236\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=4, batch=30 train loss <loss>=8.20652866364\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] Epoch[4] Batch [30]#011Speed: 762.85 samples/sec#011loss=8.206529\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] Epoch[4] Batch[35] avg_epoch_loss=8.384551\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=4, batch=35 train loss <loss>=8.02070178986\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] Epoch[4] Batch [35]#011Speed: 2050.65 samples/sec#011loss=8.020702\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] Epoch[4] Batch[40] avg_epoch_loss=8.358144\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=4, batch=40 train loss <loss>=8.16801605225\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] Epoch[4] Batch [40]#011Speed: 970.58 samples/sec#011loss=8.168016\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] Epoch[4] Batch[45] avg_epoch_loss=8.332961\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=4, batch=45 train loss <loss>=8.1264629364\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] Epoch[4] Batch [45]#011Speed: 1750.39 samples/sec#011loss=8.126463\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] processed a total of 1580 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1344.7279930114746, \"sum\": 1344.7279930114746, \"min\": 1344.7279930114746}}, \"EndTime\": 1578471538.487473, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471537.1427}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1174.88194361 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=4, train loss <loss>=8.27354966164\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] Epoch[5] Batch[0] avg_epoch_loss=8.470086\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=8.47008609772\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] Epoch[5] Batch[5] avg_epoch_loss=8.286094\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=8.28609402974\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] Epoch[5] Batch [5]#011Speed: 2044.65 samples/sec#011loss=8.286094\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] Epoch[5] Batch[10] avg_epoch_loss=8.374381\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=8.48032646179\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] Epoch[5] Batch [10]#011Speed: 1058.40 samples/sec#011loss=8.480326\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] Epoch[5] Batch[15] avg_epoch_loss=8.506427\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=5, batch=15 train loss <loss>=8.79692745209\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:58 INFO 139919921551168] Epoch[5] Batch [15]#011Speed: 1630.34 samples/sec#011loss=8.796927\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] Epoch[5] Batch[20] avg_epoch_loss=8.518829\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=5, batch=20 train loss <loss>=8.55851478577\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] Epoch[5] Batch [20]#011Speed: 954.34 samples/sec#011loss=8.558515\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] Epoch[5] Batch[25] avg_epoch_loss=8.497306\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=5, batch=25 train loss <loss>=8.40691051483\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] Epoch[5] Batch [25]#011Speed: 2067.50 samples/sec#011loss=8.406911\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] Epoch[5] Batch[30] avg_epoch_loss=8.441824\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=5, batch=30 train loss <loss>=8.15331707001\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] Epoch[5] Batch [30]#011Speed: 1007.93 samples/sec#011loss=8.153317\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] Epoch[5] Batch[35] avg_epoch_loss=8.348830\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=5, batch=35 train loss <loss>=7.77226495743\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] Epoch[5] Batch [35]#011Speed: 1913.03 samples/sec#011loss=7.772265\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] Epoch[5] Batch[40] avg_epoch_loss=8.298454\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=5, batch=40 train loss <loss>=7.93575162888\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] Epoch[5] Batch [40]#011Speed: 1041.41 samples/sec#011loss=7.935752\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] Epoch[5] Batch[45] avg_epoch_loss=8.304467\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=5, batch=45 train loss <loss>=8.35377483368\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] Epoch[5] Batch [45]#011Speed: 1724.83 samples/sec#011loss=8.353775\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] Epoch[5] Batch[50] avg_epoch_loss=8.269170\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=5, batch=50 train loss <loss>=7.94443435669\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] Epoch[5] Batch [50]#011Speed: 1759.81 samples/sec#011loss=7.944434\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] processed a total of 1619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1254.1859149932861, \"sum\": 1254.1859149932861, \"min\": 1254.1859149932861}}, \"EndTime\": 1578471539.742073, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471538.487535}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1290.76800734 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=5, train loss <loss>=8.26917008793\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] Epoch[6] Batch[0] avg_epoch_loss=8.023699\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=8.02369880676\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] Epoch[6] Batch[5] avg_epoch_loss=8.002058\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=8.00205818812\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:18:59 INFO 139919921551168] Epoch[6] Batch [5]#011Speed: 2061.46 samples/sec#011loss=8.002058\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] Epoch[6] Batch[10] avg_epoch_loss=8.331116\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=8.72598609924\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] Epoch[6] Batch [10]#011Speed: 929.51 samples/sec#011loss=8.725986\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] Epoch[6] Batch[15] avg_epoch_loss=8.467821\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=6, batch=15 train loss <loss>=8.76856975555\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] Epoch[6] Batch [15]#011Speed: 1946.54 samples/sec#011loss=8.768570\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] Epoch[6] Batch[20] avg_epoch_loss=8.546338\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=6, batch=20 train loss <loss>=8.79759464264\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] Epoch[6] Batch [20]#011Speed: 975.81 samples/sec#011loss=8.797595\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] Epoch[6] Batch[25] avg_epoch_loss=8.484202\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=6, batch=25 train loss <loss>=8.22322998047\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] Epoch[6] Batch [25]#011Speed: 1877.39 samples/sec#011loss=8.223230\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] Epoch[6] Batch[30] avg_epoch_loss=8.406645\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=6, batch=30 train loss <loss>=8.00334568024\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] Epoch[6] Batch [30]#011Speed: 975.90 samples/sec#011loss=8.003346\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] Epoch[6] Batch[35] avg_epoch_loss=8.324308\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=6, batch=35 train loss <loss>=7.81382427216\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] Epoch[6] Batch [35]#011Speed: 2152.62 samples/sec#011loss=7.813824\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] Epoch[6] Batch[40] avg_epoch_loss=8.291283\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=6, batch=40 train loss <loss>=8.05350246429\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] Epoch[6] Batch [40]#011Speed: 996.59 samples/sec#011loss=8.053502\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] Epoch[6] Batch[45] avg_epoch_loss=8.255118\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=6, batch=45 train loss <loss>=7.95855884552\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:00 INFO 139919921551168] Epoch[6] Batch [45]#011Speed: 1922.48 samples/sec#011loss=7.958559\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] Epoch[6] Batch[50] avg_epoch_loss=8.186010\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=6, batch=50 train loss <loss>=7.55021781921\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] Epoch[6] Batch [50]#011Speed: 1486.81 samples/sec#011loss=7.550218\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] processed a total of 1628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1267.0888900756836, \"sum\": 1267.0888900756836, \"min\": 1267.0888900756836}}, \"EndTime\": 1578471541.009648, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471539.742147}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1284.72609664 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=6, train loss <loss>=8.18600974363\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] Saved checkpoint to \"/opt/ml/model/state_ba77aeae-07f2-4d02-bbe9-10514365f3cd-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 15.700817108154297, \"sum\": 15.700817108154297, \"min\": 15.700817108154297}}, \"EndTime\": 1578471541.025905, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471541.00972}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] Epoch[7] Batch[0] avg_epoch_loss=8.073824\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=8.07382392883\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] Epoch[7] Batch[5] avg_epoch_loss=8.103023\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=8.10302313169\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] Epoch[7] Batch [5]#011Speed: 1970.86 samples/sec#011loss=8.103023\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] Epoch[7] Batch[10] avg_epoch_loss=8.238132\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=8.40026321411\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] Epoch[7] Batch [10]#011Speed: 975.15 samples/sec#011loss=8.400263\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] Epoch[7] Batch[15] avg_epoch_loss=8.384552\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=7, batch=15 train loss <loss>=8.70667514801\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] Epoch[7] Batch [15]#011Speed: 1847.11 samples/sec#011loss=8.706675\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] Epoch[7] Batch[20] avg_epoch_loss=8.396367\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=7, batch=20 train loss <loss>=8.43417367935\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] Epoch[7] Batch [20]#011Speed: 1012.70 samples/sec#011loss=8.434174\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] Epoch[7] Batch[25] avg_epoch_loss=8.336909\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=7, batch=25 train loss <loss>=8.08718795776\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] Epoch[7] Batch [25]#011Speed: 2007.78 samples/sec#011loss=8.087188\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] Epoch[7] Batch[30] avg_epoch_loss=8.323053\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=7, batch=30 train loss <loss>=8.25100164413\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] Epoch[7] Batch [30]#011Speed: 1049.54 samples/sec#011loss=8.251002\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] Epoch[7] Batch[35] avg_epoch_loss=8.296008\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=7, batch=35 train loss <loss>=8.12832841873\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:01 INFO 139919921551168] Epoch[7] Batch [35]#011Speed: 1623.31 samples/sec#011loss=8.128328\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] Epoch[7] Batch[40] avg_epoch_loss=8.279252\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=7, batch=40 train loss <loss>=8.15860481262\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] Epoch[7] Batch [40]#011Speed: 931.28 samples/sec#011loss=8.158605\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] Epoch[7] Batch[45] avg_epoch_loss=8.259738\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=7, batch=45 train loss <loss>=8.09972829819\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] Epoch[7] Batch [45]#011Speed: 1702.11 samples/sec#011loss=8.099728\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] Epoch[7] Batch[50] avg_epoch_loss=8.173809\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=7, batch=50 train loss <loss>=7.38325901031\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] Epoch[7] Batch [50]#011Speed: 1526.57 samples/sec#011loss=7.383259\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] processed a total of 1625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1292.1991348266602, \"sum\": 1292.1991348266602, \"min\": 1292.1991348266602}}, \"EndTime\": 1578471542.31823, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471541.025976}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1257.44101511 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=7, train loss <loss>=8.17380881777\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] Saved checkpoint to \"/opt/ml/model/state_6bce83de-2d1c-44a3-b464-516667d2c93f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 15.686988830566406, \"sum\": 15.686988830566406, \"min\": 15.686988830566406}}, \"EndTime\": 1578471542.334464, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471542.318305}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] Epoch[8] Batch[0] avg_epoch_loss=8.267259\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=8.2672586441\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] Epoch[8] Batch[5] avg_epoch_loss=8.446677\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=8.44667657216\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] Epoch[8] Batch [5]#011Speed: 2007.88 samples/sec#011loss=8.446677\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] Epoch[8] Batch[10] avg_epoch_loss=8.568971\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=8.71572360992\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] Epoch[8] Batch [10]#011Speed: 892.46 samples/sec#011loss=8.715724\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] Epoch[8] Batch[15] avg_epoch_loss=8.559558\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=8, batch=15 train loss <loss>=8.53884878159\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] Epoch[8] Batch [15]#011Speed: 2149.44 samples/sec#011loss=8.538849\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] Epoch[8] Batch[20] avg_epoch_loss=8.550273\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=8, batch=20 train loss <loss>=8.520561409\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:02 INFO 139919921551168] Epoch[8] Batch [20]#011Speed: 952.13 samples/sec#011loss=8.520561\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] Epoch[8] Batch[25] avg_epoch_loss=8.526054\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=8, batch=25 train loss <loss>=8.42433319092\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] Epoch[8] Batch [25]#011Speed: 1800.60 samples/sec#011loss=8.424333\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] Epoch[8] Batch[30] avg_epoch_loss=8.469380\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=8, batch=30 train loss <loss>=8.17467937469\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] Epoch[8] Batch [30]#011Speed: 875.70 samples/sec#011loss=8.174679\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] Epoch[8] Batch[35] avg_epoch_loss=8.392395\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=8, batch=35 train loss <loss>=7.91508846283\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] Epoch[8] Batch [35]#011Speed: 2099.76 samples/sec#011loss=7.915088\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] Epoch[8] Batch[40] avg_epoch_loss=8.371401\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=8, batch=40 train loss <loss>=8.22024488449\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] Epoch[8] Batch [40]#011Speed: 980.22 samples/sec#011loss=8.220245\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] Epoch[8] Batch[45] avg_epoch_loss=8.370550\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=8, batch=45 train loss <loss>=8.36356449127\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] Epoch[8] Batch [45]#011Speed: 2118.42 samples/sec#011loss=8.363564\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] Epoch[8] Batch[50] avg_epoch_loss=8.311135\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=8, batch=50 train loss <loss>=7.76452074051\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] Epoch[8] Batch [50]#011Speed: 1439.96 samples/sec#011loss=7.764521\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] processed a total of 1617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1313.169002532959, \"sum\": 1313.169002532959, \"min\": 1313.169002532959}}, \"EndTime\": 1578471543.647744, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471542.334527}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1231.27398766 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=8, train loss <loss>=8.31113498351\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] Epoch[9] Batch[0] avg_epoch_loss=8.482673\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=8.48267269135\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] Epoch[9] Batch[5] avg_epoch_loss=8.611871\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=8.61187060674\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] Epoch[9] Batch [5]#011Speed: 2106.32 samples/sec#011loss=8.611871\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] Epoch[9] Batch[10] avg_epoch_loss=8.560196\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=8.49818706512\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:03 INFO 139919921551168] Epoch[9] Batch [10]#011Speed: 962.69 samples/sec#011loss=8.498187\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] Epoch[9] Batch[15] avg_epoch_loss=8.632438\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=9, batch=15 train loss <loss>=8.79136924744\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] Epoch[9] Batch [15]#011Speed: 2001.62 samples/sec#011loss=8.791369\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] Epoch[9] Batch[20] avg_epoch_loss=8.653011\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=9, batch=20 train loss <loss>=8.71884651184\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] Epoch[9] Batch [20]#011Speed: 1061.42 samples/sec#011loss=8.718847\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] Epoch[9] Batch[25] avg_epoch_loss=8.615248\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=9, batch=25 train loss <loss>=8.45664348602\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] Epoch[9] Batch [25]#011Speed: 2007.15 samples/sec#011loss=8.456643\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] Epoch[9] Batch[30] avg_epoch_loss=8.511251\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=9, batch=30 train loss <loss>=7.97046518326\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] Epoch[9] Batch [30]#011Speed: 1012.05 samples/sec#011loss=7.970465\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] Epoch[9] Batch[35] avg_epoch_loss=8.418843\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=9, batch=35 train loss <loss>=7.84591112137\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] Epoch[9] Batch [35]#011Speed: 1664.11 samples/sec#011loss=7.845911\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] Epoch[9] Batch[40] avg_epoch_loss=8.361400\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=9, batch=40 train loss <loss>=7.94781312943\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] Epoch[9] Batch [40]#011Speed: 1061.70 samples/sec#011loss=7.947813\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] Epoch[9] Batch[45] avg_epoch_loss=8.344691\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=9, batch=45 train loss <loss>=8.20767421722\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] Epoch[9] Batch [45]#011Speed: 2076.41 samples/sec#011loss=8.207674\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] processed a total of 1584 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1216.4490222930908, \"sum\": 1216.4490222930908, \"min\": 1216.4490222930908}}, \"EndTime\": 1578471544.864718, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471543.64782}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1302.02136296 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=9, train loss <loss>=8.28757289886\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] Epoch[10] Batch[0] avg_epoch_loss=8.014524\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=8.01452350616\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] Epoch[10] Batch[5] avg_epoch_loss=8.213472\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=8.21347204844\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] Epoch[10] Batch [5]#011Speed: 1990.60 samples/sec#011loss=8.213472\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] Epoch[10] Batch[10] avg_epoch_loss=8.291878\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=8.38596553802\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] Epoch[10] Batch [10]#011Speed: 996.18 samples/sec#011loss=8.385966\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] Epoch[10] Batch[15] avg_epoch_loss=8.438305\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=10, batch=15 train loss <loss>=8.76044311523\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] Epoch[10] Batch [15]#011Speed: 1884.82 samples/sec#011loss=8.760443\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] Epoch[10] Batch[20] avg_epoch_loss=8.428132\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=10, batch=20 train loss <loss>=8.3955780983\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] Epoch[10] Batch [20]#011Speed: 950.43 samples/sec#011loss=8.395578\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] Epoch[10] Batch[25] avg_epoch_loss=8.379191\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=10, batch=25 train loss <loss>=8.17364082336\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] Epoch[10] Batch [25]#011Speed: 2078.32 samples/sec#011loss=8.173641\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] Epoch[10] Batch[30] avg_epoch_loss=8.329371\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=10, batch=30 train loss <loss>=8.07030849457\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] Epoch[10] Batch [30]#011Speed: 908.42 samples/sec#011loss=8.070308\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] Epoch[10] Batch[35] avg_epoch_loss=8.308888\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=10, batch=35 train loss <loss>=8.18189144135\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] Epoch[10] Batch [35]#011Speed: 1981.82 samples/sec#011loss=8.181891\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] Epoch[10] Batch[40] avg_epoch_loss=8.325321\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=10, batch=40 train loss <loss>=8.44363822937\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:05 INFO 139919921551168] Epoch[10] Batch [40]#011Speed: 916.46 samples/sec#011loss=8.443638\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] Epoch[10] Batch[45] avg_epoch_loss=8.288776\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=10, batch=45 train loss <loss>=7.98910713196\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] Epoch[10] Batch [45]#011Speed: 1550.22 samples/sec#011loss=7.989107\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] processed a total of 1518 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1235.4109287261963, \"sum\": 1235.4109287261963, \"min\": 1235.4109287261963}}, \"EndTime\": 1578471546.100705, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471544.864799}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1228.63543706 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=10, train loss <loss>=8.22145896157\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] Epoch[11] Batch[0] avg_epoch_loss=8.342934\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=8.34293365479\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] Epoch[11] Batch[5] avg_epoch_loss=7.995686\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=7.99568557739\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] Epoch[11] Batch [5]#011Speed: 2005.61 samples/sec#011loss=7.995686\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] Epoch[11] Batch[10] avg_epoch_loss=8.226890\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=8.50433559418\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] Epoch[11] Batch [10]#011Speed: 1033.91 samples/sec#011loss=8.504336\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] Epoch[11] Batch[15] avg_epoch_loss=8.361985\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=11, batch=15 train loss <loss>=8.659192276\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] Epoch[11] Batch [15]#011Speed: 2117.75 samples/sec#011loss=8.659192\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] Epoch[11] Batch[20] avg_epoch_loss=8.345014\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=11, batch=20 train loss <loss>=8.29070825577\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] Epoch[11] Batch [20]#011Speed: 1007.04 samples/sec#011loss=8.290708\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] Epoch[11] Batch[25] avg_epoch_loss=8.302497\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=11, batch=25 train loss <loss>=8.1239238739\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] Epoch[11] Batch [25]#011Speed: 1741.74 samples/sec#011loss=8.123924\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] Epoch[11] Batch[30] avg_epoch_loss=8.249386\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=11, batch=30 train loss <loss>=7.97321338654\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:06 INFO 139919921551168] Epoch[11] Batch [30]#011Speed: 973.23 samples/sec#011loss=7.973213\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] Epoch[11] Batch[35] avg_epoch_loss=8.184973\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=11, batch=35 train loss <loss>=7.78561229706\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] Epoch[11] Batch [35]#011Speed: 1669.24 samples/sec#011loss=7.785612\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] Epoch[11] Batch[40] avg_epoch_loss=8.144369\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=11, batch=40 train loss <loss>=7.85201759338\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] Epoch[11] Batch [40]#011Speed: 1066.82 samples/sec#011loss=7.852018\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] Epoch[11] Batch[45] avg_epoch_loss=8.113084\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=11, batch=45 train loss <loss>=7.85654764175\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] Epoch[11] Batch [45]#011Speed: 1740.57 samples/sec#011loss=7.856548\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] Epoch[11] Batch[50] avg_epoch_loss=8.064028\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=11, batch=50 train loss <loss>=7.61271190643\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] Epoch[11] Batch [50]#011Speed: 1439.99 samples/sec#011loss=7.612712\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] processed a total of 1675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1301.9680976867676, \"sum\": 1301.9680976867676, \"min\": 1301.9680976867676}}, \"EndTime\": 1578471547.403234, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471546.100774}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1286.40337618 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=11, train loss <loss>=8.04281078195\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] Saved checkpoint to \"/opt/ml/model/state_dd6ed508-3a88-4521-b964-dc6f46f8129e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 14.941930770874023, \"sum\": 14.941930770874023, \"min\": 14.941930770874023}}, \"EndTime\": 1578471547.418713, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471547.403312}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] Epoch[12] Batch[0] avg_epoch_loss=8.080626\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=8.08062553406\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] Epoch[12] Batch[5] avg_epoch_loss=8.398358\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=8.3983575503\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] Epoch[12] Batch [5]#011Speed: 1617.27 samples/sec#011loss=8.398358\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] Epoch[12] Batch[10] avg_epoch_loss=8.389109\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=8.37801122665\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] Epoch[12] Batch [10]#011Speed: 840.39 samples/sec#011loss=8.378011\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] Epoch[12] Batch[15] avg_epoch_loss=8.445832\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=12, batch=15 train loss <loss>=8.57062282562\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:07 INFO 139919921551168] Epoch[12] Batch [15]#011Speed: 2065.05 samples/sec#011loss=8.570623\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] Epoch[12] Batch[20] avg_epoch_loss=8.421345\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=12, batch=20 train loss <loss>=8.34298725128\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] Epoch[12] Batch [20]#011Speed: 999.86 samples/sec#011loss=8.342987\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] Epoch[12] Batch[25] avg_epoch_loss=8.385883\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=12, batch=25 train loss <loss>=8.23694076538\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] Epoch[12] Batch [25]#011Speed: 1564.78 samples/sec#011loss=8.236941\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] Epoch[12] Batch[30] avg_epoch_loss=8.347753\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=12, batch=30 train loss <loss>=8.14947910309\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] Epoch[12] Batch [30]#011Speed: 960.98 samples/sec#011loss=8.149479\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] Epoch[12] Batch[35] avg_epoch_loss=8.309740\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=12, batch=35 train loss <loss>=8.07405767441\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] Epoch[12] Batch [35]#011Speed: 1547.34 samples/sec#011loss=8.074058\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] Epoch[12] Batch[40] avg_epoch_loss=8.283172\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=12, batch=40 train loss <loss>=8.0918847084\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] Epoch[12] Batch [40]#011Speed: 906.77 samples/sec#011loss=8.091885\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] Epoch[12] Batch[45] avg_epoch_loss=8.291863\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=12, batch=45 train loss <loss>=8.36312599182\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] Epoch[12] Batch [45]#011Speed: 1620.78 samples/sec#011loss=8.363126\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] Epoch[12] Batch[50] avg_epoch_loss=8.240932\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=12, batch=50 train loss <loss>=7.77236757278\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] Epoch[12] Batch [50]#011Speed: 1391.17 samples/sec#011loss=7.772368\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] processed a total of 1621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1391.667127609253, \"sum\": 1391.667127609253, \"min\": 1391.667127609253}}, \"EndTime\": 1578471548.810492, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471547.418776}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1164.69804794 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=12, train loss <loss>=8.24093197841\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] Epoch[13] Batch[0] avg_epoch_loss=7.906531\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=7.90653133392\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] Epoch[13] Batch[5] avg_epoch_loss=8.439504\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=8.43950430552\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:08 INFO 139919921551168] Epoch[13] Batch [5]#011Speed: 1943.99 samples/sec#011loss=8.439504\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] Epoch[13] Batch[10] avg_epoch_loss=8.432221\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=8.42348136902\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] Epoch[13] Batch [10]#011Speed: 1060.97 samples/sec#011loss=8.423481\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] Epoch[13] Batch[15] avg_epoch_loss=8.506978\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=13, batch=15 train loss <loss>=8.67144260406\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] Epoch[13] Batch [15]#011Speed: 1938.62 samples/sec#011loss=8.671443\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] Epoch[13] Batch[20] avg_epoch_loss=8.479641\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=13, batch=20 train loss <loss>=8.39216213226\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] Epoch[13] Batch [20]#011Speed: 1063.35 samples/sec#011loss=8.392162\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] Epoch[13] Batch[25] avg_epoch_loss=8.400488\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=13, batch=25 train loss <loss>=8.06804876328\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] Epoch[13] Batch [25]#011Speed: 2042.17 samples/sec#011loss=8.068049\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] Epoch[13] Batch[30] avg_epoch_loss=8.296827\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=13, batch=30 train loss <loss>=7.75778694153\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] Epoch[13] Batch [30]#011Speed: 1027.12 samples/sec#011loss=7.757787\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] Epoch[13] Batch[35] avg_epoch_loss=8.226782\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=13, batch=35 train loss <loss>=7.79250221252\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] Epoch[13] Batch [35]#011Speed: 1859.47 samples/sec#011loss=7.792502\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] Epoch[13] Batch[40] avg_epoch_loss=8.212192\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=13, batch=40 train loss <loss>=8.10714359283\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] Epoch[13] Batch [40]#011Speed: 992.60 samples/sec#011loss=8.107144\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] Epoch[13] Batch[45] avg_epoch_loss=8.203404\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=13, batch=45 train loss <loss>=8.13134632111\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:09 INFO 139919921551168] Epoch[13] Batch [45]#011Speed: 1809.07 samples/sec#011loss=8.131346\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] processed a total of 1584 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1230.1650047302246, \"sum\": 1230.1650047302246, \"min\": 1230.1650047302246}}, \"EndTime\": 1578471550.041169, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471548.810569}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1287.54630031 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=13, train loss <loss>=8.15639399529\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] Epoch[14] Batch[0] avg_epoch_loss=8.808747\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=8.80874729156\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] Epoch[14] Batch[5] avg_epoch_loss=8.432826\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=8.43282612165\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] Epoch[14] Batch [5]#011Speed: 1641.77 samples/sec#011loss=8.432826\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] Epoch[14] Batch[10] avg_epoch_loss=8.305212\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=8.1520740509\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] Epoch[14] Batch [10]#011Speed: 893.09 samples/sec#011loss=8.152074\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] Epoch[14] Batch[15] avg_epoch_loss=8.436197\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=14, batch=15 train loss <loss>=8.72436523438\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] Epoch[14] Batch [15]#011Speed: 1937.05 samples/sec#011loss=8.724365\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] Epoch[14] Batch[20] avg_epoch_loss=8.398831\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=14, batch=20 train loss <loss>=8.27926015854\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] Epoch[14] Batch [20]#011Speed: 996.55 samples/sec#011loss=8.279260\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] Epoch[14] Batch[25] avg_epoch_loss=8.349528\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=14, batch=25 train loss <loss>=8.14245405197\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] Epoch[14] Batch [25]#011Speed: 1881.78 samples/sec#011loss=8.142454\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] Epoch[14] Batch[30] avg_epoch_loss=8.317298\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=14, batch=30 train loss <loss>=8.14970417023\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:10 INFO 139919921551168] Epoch[14] Batch [30]#011Speed: 926.26 samples/sec#011loss=8.149704\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] Epoch[14] Batch[35] avg_epoch_loss=8.288778\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=14, batch=35 train loss <loss>=8.1119553566\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] Epoch[14] Batch [35]#011Speed: 1873.87 samples/sec#011loss=8.111955\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] Epoch[14] Batch[40] avg_epoch_loss=8.256890\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=14, batch=40 train loss <loss>=8.02729444504\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] Epoch[14] Batch [40]#011Speed: 1015.25 samples/sec#011loss=8.027294\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] Epoch[14] Batch[45] avg_epoch_loss=8.205736\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=14, batch=45 train loss <loss>=7.78626966476\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] Epoch[14] Batch [45]#011Speed: 1889.31 samples/sec#011loss=7.786270\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] Epoch[14] Batch[50] avg_epoch_loss=8.165838\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=14, batch=50 train loss <loss>=7.79878053665\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] Epoch[14] Batch [50]#011Speed: 1626.31 samples/sec#011loss=7.798781\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] processed a total of 1657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1322.1750259399414, \"sum\": 1322.1750259399414, \"min\": 1322.1750259399414}}, \"EndTime\": 1578471551.363964, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471550.041221}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1253.12231623 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=14, train loss <loss>=8.15163972745\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] Epoch[15] Batch[0] avg_epoch_loss=8.105204\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=8.10520362854\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] Epoch[15] Batch[5] avg_epoch_loss=8.494780\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=8.49478022257\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] Epoch[15] Batch [5]#011Speed: 1655.77 samples/sec#011loss=8.494780\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] Epoch[15] Batch[10] avg_epoch_loss=8.570205\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=8.66071567535\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] Epoch[15] Batch [10]#011Speed: 914.38 samples/sec#011loss=8.660716\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] Epoch[15] Batch[15] avg_epoch_loss=8.668595\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=15, batch=15 train loss <loss>=8.88505210876\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] Epoch[15] Batch [15]#011Speed: 2142.70 samples/sec#011loss=8.885052\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] Epoch[15] Batch[20] avg_epoch_loss=8.616994\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=15, batch=20 train loss <loss>=8.45187072754\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:11 INFO 139919921551168] Epoch[15] Batch [20]#011Speed: 1008.26 samples/sec#011loss=8.451871\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] Epoch[15] Batch[25] avg_epoch_loss=8.540982\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=15, batch=25 train loss <loss>=8.22173175812\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] Epoch[15] Batch [25]#011Speed: 1867.33 samples/sec#011loss=8.221732\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] Epoch[15] Batch[30] avg_epoch_loss=8.470446\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=15, batch=30 train loss <loss>=8.10365753174\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] Epoch[15] Batch [30]#011Speed: 1002.96 samples/sec#011loss=8.103658\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] Epoch[15] Batch[35] avg_epoch_loss=8.401762\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=15, batch=35 train loss <loss>=7.97592191696\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] Epoch[15] Batch [35]#011Speed: 2047.34 samples/sec#011loss=7.975922\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] Epoch[15] Batch[40] avg_epoch_loss=8.358043\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=15, batch=40 train loss <loss>=8.04326534271\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] Epoch[15] Batch [40]#011Speed: 982.16 samples/sec#011loss=8.043265\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] Epoch[15] Batch[45] avg_epoch_loss=8.339276\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=15, batch=45 train loss <loss>=8.18538379669\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] Epoch[15] Batch [45]#011Speed: 1998.45 samples/sec#011loss=8.185384\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] Epoch[15] Batch[50] avg_epoch_loss=8.206086\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=15, batch=50 train loss <loss>=6.98074235916\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] Epoch[15] Batch [50]#011Speed: 1374.10 samples/sec#011loss=6.980742\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] processed a total of 1604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1300.8570671081543, \"sum\": 1300.8570671081543, \"min\": 1300.8570671081543}}, \"EndTime\": 1578471552.665337, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471551.36405}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1232.92612776 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=15, train loss <loss>=8.20608602786\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] Epoch[16] Batch[0] avg_epoch_loss=8.108580\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=8.10857963562\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] Epoch[16] Batch[5] avg_epoch_loss=8.182597\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=8.18259684245\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:12 INFO 139919921551168] Epoch[16] Batch [5]#011Speed: 1775.94 samples/sec#011loss=8.182597\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] Epoch[16] Batch[10] avg_epoch_loss=8.434381\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=8.73652133942\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] Epoch[16] Batch [10]#011Speed: 1012.84 samples/sec#011loss=8.736521\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] Epoch[16] Batch[15] avg_epoch_loss=8.425785\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=16, batch=15 train loss <loss>=8.40687532425\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] Epoch[16] Batch [15]#011Speed: 1754.08 samples/sec#011loss=8.406875\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] Epoch[16] Batch[20] avg_epoch_loss=8.454214\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=16, batch=20 train loss <loss>=8.5451874733\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] Epoch[16] Batch [20]#011Speed: 942.03 samples/sec#011loss=8.545187\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] Epoch[16] Batch[25] avg_epoch_loss=8.409580\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=16, batch=25 train loss <loss>=8.22211418152\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] Epoch[16] Batch [25]#011Speed: 1881.71 samples/sec#011loss=8.222114\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] Epoch[16] Batch[30] avg_epoch_loss=8.323777\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=16, batch=30 train loss <loss>=7.87760105133\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] Epoch[16] Batch [30]#011Speed: 967.93 samples/sec#011loss=7.877601\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] Epoch[16] Batch[35] avg_epoch_loss=8.259934\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=16, batch=35 train loss <loss>=7.86410732269\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] Epoch[16] Batch [35]#011Speed: 1763.49 samples/sec#011loss=7.864107\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] Epoch[16] Batch[40] avg_epoch_loss=8.288899\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=16, batch=40 train loss <loss>=8.49744815826\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] Epoch[16] Batch [40]#011Speed: 1033.36 samples/sec#011loss=8.497448\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] Epoch[16] Batch[45] avg_epoch_loss=8.251464\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=16, batch=45 train loss <loss>=7.94449558258\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] Epoch[16] Batch [45]#011Speed: 1829.96 samples/sec#011loss=7.944496\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] processed a total of 1511 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1243.38698387146, \"sum\": 1243.38698387146, \"min\": 1243.38698387146}}, \"EndTime\": 1578471553.909225, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471552.665417}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1215.11675859 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=16, train loss <loss>=8.206535091\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:13 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:14 INFO 139919921551168] Epoch[17] Batch[0] avg_epoch_loss=8.390304\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=8.39030361176\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:14 INFO 139919921551168] Epoch[17] Batch[5] avg_epoch_loss=8.219318\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=8.219318072\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:14 INFO 139919921551168] Epoch[17] Batch [5]#011Speed: 2036.29 samples/sec#011loss=8.219318\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:14 INFO 139919921551168] Epoch[17] Batch[10] avg_epoch_loss=8.173358\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=8.11820678711\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:14 INFO 139919921551168] Epoch[17] Batch [10]#011Speed: 1077.44 samples/sec#011loss=8.118207\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:14 INFO 139919921551168] Epoch[17] Batch[15] avg_epoch_loss=8.288729\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=17, batch=15 train loss <loss>=8.54254283905\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:14 INFO 139919921551168] Epoch[17] Batch [15]#011Speed: 1990.94 samples/sec#011loss=8.542543\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:14 INFO 139919921551168] Epoch[17] Batch[20] avg_epoch_loss=8.310425\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=17, batch=20 train loss <loss>=8.37985572815\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:14 INFO 139919921551168] Epoch[17] Batch [20]#011Speed: 797.23 samples/sec#011loss=8.379856\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:14 INFO 139919921551168] Epoch[17] Batch[25] avg_epoch_loss=8.260519\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=17, batch=25 train loss <loss>=8.05091352463\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:14 INFO 139919921551168] Epoch[17] Batch [25]#011Speed: 1762.75 samples/sec#011loss=8.050914\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:14 INFO 139919921551168] Epoch[17] Batch[30] avg_epoch_loss=8.243314\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=17, batch=30 train loss <loss>=8.15384883881\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:14 INFO 139919921551168] Epoch[17] Batch [30]#011Speed: 933.08 samples/sec#011loss=8.153849\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:14 INFO 139919921551168] Epoch[17] Batch[35] avg_epoch_loss=8.197407\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=17, batch=35 train loss <loss>=7.91277980804\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:14 INFO 139919921551168] Epoch[17] Batch [35]#011Speed: 2110.24 samples/sec#011loss=7.912780\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] Epoch[17] Batch[40] avg_epoch_loss=8.172512\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=17, batch=40 train loss <loss>=7.99326543808\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] Epoch[17] Batch [40]#011Speed: 1017.28 samples/sec#011loss=7.993265\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] Epoch[17] Batch[45] avg_epoch_loss=8.133013\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=17, batch=45 train loss <loss>=7.80912656784\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] Epoch[17] Batch [45]#011Speed: 1624.35 samples/sec#011loss=7.809127\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] Epoch[17] Batch[50] avg_epoch_loss=8.102968\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=17, batch=50 train loss <loss>=7.82655086517\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] Epoch[17] Batch [50]#011Speed: 1342.35 samples/sec#011loss=7.826551\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] processed a total of 1670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1352.189064025879, \"sum\": 1352.189064025879, \"min\": 1352.189064025879}}, \"EndTime\": 1578471555.261932, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471553.909306}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1234.9329244 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=17, train loss <loss>=8.0428282\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] Epoch[18] Batch[0] avg_epoch_loss=8.039865\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=8.0398645401\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] Epoch[18] Batch[5] avg_epoch_loss=8.217002\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=8.21700151761\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] Epoch[18] Batch [5]#011Speed: 2052.86 samples/sec#011loss=8.217002\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] Epoch[18] Batch[10] avg_epoch_loss=8.191259\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=8.1603685379\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] Epoch[18] Batch [10]#011Speed: 1052.53 samples/sec#011loss=8.160369\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] Epoch[18] Batch[15] avg_epoch_loss=8.320810\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=18, batch=15 train loss <loss>=8.60582027435\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] Epoch[18] Batch [15]#011Speed: 2027.45 samples/sec#011loss=8.605820\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] Epoch[18] Batch[20] avg_epoch_loss=8.292847\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=18, batch=20 train loss <loss>=8.20336494446\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] Epoch[18] Batch [20]#011Speed: 895.74 samples/sec#011loss=8.203365\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] Epoch[18] Batch[25] avg_epoch_loss=8.238841\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=18, batch=25 train loss <loss>=8.01201972961\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:15 INFO 139919921551168] Epoch[18] Batch [25]#011Speed: 1927.06 samples/sec#011loss=8.012020\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] Epoch[18] Batch[30] avg_epoch_loss=8.207803\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=18, batch=30 train loss <loss>=8.04640455246\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] Epoch[18] Batch [30]#011Speed: 1076.67 samples/sec#011loss=8.046405\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] Epoch[18] Batch[35] avg_epoch_loss=8.148789\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=18, batch=35 train loss <loss>=7.78289966583\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] Epoch[18] Batch [35]#011Speed: 2054.15 samples/sec#011loss=7.782900\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] Epoch[18] Batch[40] avg_epoch_loss=8.109793\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=18, batch=40 train loss <loss>=7.82902374268\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] Epoch[18] Batch [40]#011Speed: 988.53 samples/sec#011loss=7.829024\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] Epoch[18] Batch[45] avg_epoch_loss=8.129221\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=18, batch=45 train loss <loss>=8.28852539063\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] Epoch[18] Batch [45]#011Speed: 1993.00 samples/sec#011loss=8.288525\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] Epoch[18] Batch[50] avg_epoch_loss=8.144029\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=18, batch=50 train loss <loss>=8.28027191162\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] Epoch[18] Batch [50]#011Speed: 1265.78 samples/sec#011loss=8.280272\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] processed a total of 1611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1262.6121044158936, \"sum\": 1262.6121044158936, \"min\": 1262.6121044158936}}, \"EndTime\": 1578471556.525084, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471555.262005}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1275.81524704 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=18, train loss <loss>=8.14402946771\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] Epoch[19] Batch[0] avg_epoch_loss=8.393535\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=8.39353466034\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] Epoch[19] Batch[5] avg_epoch_loss=8.217080\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=8.21708035469\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] Epoch[19] Batch [5]#011Speed: 1854.75 samples/sec#011loss=8.217080\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] Epoch[19] Batch[10] avg_epoch_loss=8.125321\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=8.01520996094\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] Epoch[19] Batch [10]#011Speed: 950.40 samples/sec#011loss=8.015210\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] Epoch[19] Batch[15] avg_epoch_loss=8.240841\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=19, batch=15 train loss <loss>=8.49498634338\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:16 INFO 139919921551168] Epoch[19] Batch [15]#011Speed: 1955.27 samples/sec#011loss=8.494986\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] Epoch[19] Batch[20] avg_epoch_loss=8.234279\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=19, batch=20 train loss <loss>=8.21327905655\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] Epoch[19] Batch [20]#011Speed: 941.85 samples/sec#011loss=8.213279\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] Epoch[19] Batch[25] avg_epoch_loss=8.209709\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=19, batch=25 train loss <loss>=8.10651245117\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] Epoch[19] Batch [25]#011Speed: 2071.47 samples/sec#011loss=8.106512\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] Epoch[19] Batch[30] avg_epoch_loss=8.185669\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=19, batch=30 train loss <loss>=8.06066350937\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] Epoch[19] Batch [30]#011Speed: 846.96 samples/sec#011loss=8.060664\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] Epoch[19] Batch[35] avg_epoch_loss=8.124234\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=19, batch=35 train loss <loss>=7.74334039688\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] Epoch[19] Batch [35]#011Speed: 2062.52 samples/sec#011loss=7.743340\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] Epoch[19] Batch[40] avg_epoch_loss=8.078768\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=19, batch=40 train loss <loss>=7.75140895844\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] Epoch[19] Batch [40]#011Speed: 954.35 samples/sec#011loss=7.751409\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] Epoch[19] Batch[45] avg_epoch_loss=8.084506\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=19, batch=45 train loss <loss>=8.13156080246\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] Epoch[19] Batch [45]#011Speed: 2068.82 samples/sec#011loss=8.131561\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] Epoch[19] Batch[50] avg_epoch_loss=8.047629\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=19, batch=50 train loss <loss>=7.7083533287\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] Epoch[19] Batch [50]#011Speed: 1224.03 samples/sec#011loss=7.708353\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] processed a total of 1625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1330.4011821746826, \"sum\": 1330.4011821746826, \"min\": 1330.4011821746826}}, \"EndTime\": 1578471557.855963, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471556.52516}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1221.33342508 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=19, train loss <loss>=8.04762855231\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] Epoch[20] Batch[0] avg_epoch_loss=8.302907\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=8.30290699005\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] Epoch[20] Batch[5] avg_epoch_loss=8.513969\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=8.51396862666\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] Epoch[20] Batch [5]#011Speed: 2061.32 samples/sec#011loss=8.513969\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] Epoch[20] Batch[10] avg_epoch_loss=8.541300\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=8.5740983963\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] Epoch[20] Batch [10]#011Speed: 2005.72 samples/sec#011loss=8.574098\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] Epoch[20] Batch[15] avg_epoch_loss=8.541515\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=20, batch=15 train loss <loss>=8.5419883728\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] Epoch[20] Batch [15]#011Speed: 984.34 samples/sec#011loss=8.541988\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] Epoch[20] Batch[20] avg_epoch_loss=8.560158\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=20, batch=20 train loss <loss>=8.61981487274\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] Epoch[20] Batch [20]#011Speed: 984.40 samples/sec#011loss=8.619815\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] Epoch[20] Batch[25] avg_epoch_loss=8.422761\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=20, batch=25 train loss <loss>=7.84569101334\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] Epoch[20] Batch [25]#011Speed: 1946.66 samples/sec#011loss=7.845691\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] Epoch[20] Batch[30] avg_epoch_loss=8.368784\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=20, batch=30 train loss <loss>=8.08810310364\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] Epoch[20] Batch [30]#011Speed: 980.76 samples/sec#011loss=8.088103\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] Epoch[20] Batch[35] avg_epoch_loss=8.312396\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=20, batch=35 train loss <loss>=7.96279315948\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] Epoch[20] Batch [35]#011Speed: 1974.99 samples/sec#011loss=7.962793\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] Epoch[20] Batch[40] avg_epoch_loss=8.260381\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=20, batch=40 train loss <loss>=7.88587017059\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:18 INFO 139919921551168] Epoch[20] Batch [40]#011Speed: 1008.46 samples/sec#011loss=7.885870\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] Epoch[20] Batch[45] avg_epoch_loss=8.223441\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=20, batch=45 train loss <loss>=7.92053594589\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] Epoch[20] Batch [45]#011Speed: 1688.85 samples/sec#011loss=7.920536\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] Epoch[20] Batch[50] avg_epoch_loss=8.177635\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=20, batch=50 train loss <loss>=7.7562169075\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] Epoch[20] Batch [50]#011Speed: 1521.62 samples/sec#011loss=7.756217\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] processed a total of 1618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1272.7279663085938, \"sum\": 1272.7279663085938, \"min\": 1272.7279663085938}}, \"EndTime\": 1578471559.129185, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471557.856041}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1271.18500708 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=20, train loss <loss>=8.17763473473\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] Epoch[21] Batch[0] avg_epoch_loss=8.142057\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=8.14205741882\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] Epoch[21] Batch[5] avg_epoch_loss=8.188282\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=8.18828209241\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] Epoch[21] Batch [5]#011Speed: 2074.50 samples/sec#011loss=8.188282\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] Epoch[21] Batch[10] avg_epoch_loss=8.230765\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=8.28174409866\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] Epoch[21] Batch [10]#011Speed: 994.86 samples/sec#011loss=8.281744\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] Epoch[21] Batch[15] avg_epoch_loss=8.367622\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=21, batch=15 train loss <loss>=8.66870670319\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] Epoch[21] Batch [15]#011Speed: 2154.50 samples/sec#011loss=8.668707\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] Epoch[21] Batch[20] avg_epoch_loss=8.448036\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=21, batch=20 train loss <loss>=8.70536136627\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] Epoch[21] Batch [20]#011Speed: 1022.20 samples/sec#011loss=8.705361\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] Epoch[21] Batch[25] avg_epoch_loss=8.424297\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=21, batch=25 train loss <loss>=8.3245923996\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] Epoch[21] Batch [25]#011Speed: 1858.22 samples/sec#011loss=8.324592\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] Epoch[21] Batch[30] avg_epoch_loss=8.348908\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=21, batch=30 train loss <loss>=7.95688486099\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:19 INFO 139919921551168] Epoch[21] Batch [30]#011Speed: 880.86 samples/sec#011loss=7.956885\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] Epoch[21] Batch[35] avg_epoch_loss=8.271868\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=21, batch=35 train loss <loss>=7.79422206879\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] Epoch[21] Batch [35]#011Speed: 2058.46 samples/sec#011loss=7.794222\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] Epoch[21] Batch[40] avg_epoch_loss=8.253299\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=21, batch=40 train loss <loss>=8.11960306168\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] Epoch[21] Batch [40]#011Speed: 922.89 samples/sec#011loss=8.119603\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] Epoch[21] Batch[45] avg_epoch_loss=8.261657\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=21, batch=45 train loss <loss>=8.33018779755\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] Epoch[21] Batch [45]#011Speed: 2086.46 samples/sec#011loss=8.330188\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] Epoch[21] Batch[50] avg_epoch_loss=8.188341\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=21, batch=50 train loss <loss>=7.51383447647\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] Epoch[21] Batch [50]#011Speed: 1571.75 samples/sec#011loss=7.513834\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] processed a total of 1635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1276.7181396484375, \"sum\": 1276.7181396484375, \"min\": 1276.7181396484375}}, \"EndTime\": 1578471560.406406, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471559.129249}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1280.50598166 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=21, train loss <loss>=8.18098696379\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] Epoch[22] Batch[0] avg_epoch_loss=8.330955\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=8.3309545517\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] Epoch[22] Batch[5] avg_epoch_loss=8.466281\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=8.46628069878\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] Epoch[22] Batch [5]#011Speed: 1639.81 samples/sec#011loss=8.466281\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] Epoch[22] Batch[10] avg_epoch_loss=8.374473\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=8.26430330276\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] Epoch[22] Batch [10]#011Speed: 1008.64 samples/sec#011loss=8.264303\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] Epoch[22] Batch[15] avg_epoch_loss=8.452230\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=22, batch=15 train loss <loss>=8.62329559326\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] Epoch[22] Batch [15]#011Speed: 1839.10 samples/sec#011loss=8.623296\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] Epoch[22] Batch[20] avg_epoch_loss=8.395941\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=22, batch=20 train loss <loss>=8.21581802368\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:20 INFO 139919921551168] Epoch[22] Batch [20]#011Speed: 1050.12 samples/sec#011loss=8.215818\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] Epoch[22] Batch[25] avg_epoch_loss=8.339484\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=22, batch=25 train loss <loss>=8.10236234665\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] Epoch[22] Batch [25]#011Speed: 1792.32 samples/sec#011loss=8.102362\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] Epoch[22] Batch[30] avg_epoch_loss=8.246418\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=22, batch=30 train loss <loss>=7.76247406006\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] Epoch[22] Batch [30]#011Speed: 1018.93 samples/sec#011loss=7.762474\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] Epoch[22] Batch[35] avg_epoch_loss=8.163248\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=22, batch=35 train loss <loss>=7.64759721756\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] Epoch[22] Batch [35]#011Speed: 2103.24 samples/sec#011loss=7.647597\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] Epoch[22] Batch[40] avg_epoch_loss=8.122977\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=22, batch=40 train loss <loss>=7.83302154541\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] Epoch[22] Batch [40]#011Speed: 873.84 samples/sec#011loss=7.833022\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] Epoch[22] Batch[45] avg_epoch_loss=8.105709\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=22, batch=45 train loss <loss>=7.96411523819\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] Epoch[22] Batch [45]#011Speed: 2169.34 samples/sec#011loss=7.964115\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] processed a total of 1581 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1269.6239948272705, \"sum\": 1269.6239948272705, \"min\": 1269.6239948272705}}, \"EndTime\": 1578471561.676543, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471560.406492}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1245.1289817 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=22, train loss <loss>=8.06708878517\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] Epoch[23] Batch[0] avg_epoch_loss=8.280897\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=8.2808971405\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] Epoch[23] Batch[5] avg_epoch_loss=8.393298\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=8.39329783122\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:21 INFO 139919921551168] Epoch[23] Batch [5]#011Speed: 2117.02 samples/sec#011loss=8.393298\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] Epoch[23] Batch[10] avg_epoch_loss=8.281851\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=8.14811429977\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] Epoch[23] Batch [10]#011Speed: 971.60 samples/sec#011loss=8.148114\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] Epoch[23] Batch[15] avg_epoch_loss=8.377577\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=23, batch=15 train loss <loss>=8.58817310333\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] Epoch[23] Batch [15]#011Speed: 1901.26 samples/sec#011loss=8.588173\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] Epoch[23] Batch[20] avg_epoch_loss=8.379254\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=23, batch=20 train loss <loss>=8.3846200943\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] Epoch[23] Batch [20]#011Speed: 972.93 samples/sec#011loss=8.384620\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] Epoch[23] Batch[25] avg_epoch_loss=8.331896\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=23, batch=25 train loss <loss>=8.13299322128\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] Epoch[23] Batch [25]#011Speed: 1980.37 samples/sec#011loss=8.132993\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] Epoch[23] Batch[30] avg_epoch_loss=8.278452\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=23, batch=30 train loss <loss>=8.00054368973\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] Epoch[23] Batch [30]#011Speed: 894.56 samples/sec#011loss=8.000544\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] Epoch[23] Batch[35] avg_epoch_loss=8.220584\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=23, batch=35 train loss <loss>=7.86180391312\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] Epoch[23] Batch [35]#011Speed: 2167.91 samples/sec#011loss=7.861804\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] Epoch[23] Batch[40] avg_epoch_loss=8.172774\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=23, batch=40 train loss <loss>=7.82854385376\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] Epoch[23] Batch [40]#011Speed: 922.10 samples/sec#011loss=7.828544\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] Epoch[23] Batch[45] avg_epoch_loss=8.189447\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=23, batch=45 train loss <loss>=8.32616357803\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] Epoch[23] Batch [45]#011Speed: 2047.79 samples/sec#011loss=8.326164\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] Epoch[23] Batch[50] avg_epoch_loss=8.149613\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=23, batch=50 train loss <loss>=7.78313922882\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] Epoch[23] Batch [50]#011Speed: 1791.29 samples/sec#011loss=7.783139\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] processed a total of 1634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1281.5680503845215, \"sum\": 1281.5680503845215, \"min\": 1281.5680503845215}}, \"EndTime\": 1578471562.958639, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471561.676632}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1274.88815274 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=23, train loss <loss>=8.11235147256\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:22 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:23 INFO 139919921551168] Epoch[24] Batch[0] avg_epoch_loss=8.648560\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=8.64855957031\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:23 INFO 139919921551168] Epoch[24] Batch[5] avg_epoch_loss=8.314441\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=8.31444136302\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:23 INFO 139919921551168] Epoch[24] Batch [5]#011Speed: 2058.22 samples/sec#011loss=8.314441\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:23 INFO 139919921551168] Epoch[24] Batch[10] avg_epoch_loss=8.425368\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=8.55848054886\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:23 INFO 139919921551168] Epoch[24] Batch [10]#011Speed: 1011.37 samples/sec#011loss=8.558481\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:23 INFO 139919921551168] Epoch[24] Batch[15] avg_epoch_loss=8.365734\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=24, batch=15 train loss <loss>=8.23454017639\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:23 INFO 139919921551168] Epoch[24] Batch [15]#011Speed: 2075.84 samples/sec#011loss=8.234540\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:23 INFO 139919921551168] Epoch[24] Batch[20] avg_epoch_loss=8.378754\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=24, batch=20 train loss <loss>=8.42041568756\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:23 INFO 139919921551168] Epoch[24] Batch [20]#011Speed: 1058.92 samples/sec#011loss=8.420416\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:23 INFO 139919921551168] Epoch[24] Batch[25] avg_epoch_loss=8.335934\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=24, batch=25 train loss <loss>=8.15609025955\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:23 INFO 139919921551168] Epoch[24] Batch [25]#011Speed: 1853.33 samples/sec#011loss=8.156090\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:23 INFO 139919921551168] Epoch[24] Batch[30] avg_epoch_loss=8.317462\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=24, batch=30 train loss <loss>=8.22140684128\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:23 INFO 139919921551168] Epoch[24] Batch [30]#011Speed: 926.33 samples/sec#011loss=8.221407\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:23 INFO 139919921551168] Epoch[24] Batch[35] avg_epoch_loss=8.228072\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=24, batch=35 train loss <loss>=7.67385311127\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:23 INFO 139919921551168] Epoch[24] Batch [35]#011Speed: 2101.78 samples/sec#011loss=7.673853\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] Epoch[24] Batch[40] avg_epoch_loss=8.190761\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=24, batch=40 train loss <loss>=7.92212514877\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] Epoch[24] Batch [40]#011Speed: 1002.37 samples/sec#011loss=7.922125\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] Epoch[24] Batch[45] avg_epoch_loss=8.171415\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=24, batch=45 train loss <loss>=8.01277313232\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] Epoch[24] Batch [45]#011Speed: 1437.65 samples/sec#011loss=8.012773\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] processed a total of 1531 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1190.5090808868408, \"sum\": 1190.5090808868408, \"min\": 1190.5090808868408}}, \"EndTime\": 1578471564.149685, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471562.958723}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1285.89116137 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=24, train loss <loss>=8.13513623675\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] Epoch[25] Batch[0] avg_epoch_loss=7.957086\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=7.95708560944\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] Epoch[25] Batch[5] avg_epoch_loss=8.240294\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=8.24029445648\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] Epoch[25] Batch [5]#011Speed: 1975.21 samples/sec#011loss=8.240294\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] Epoch[25] Batch[10] avg_epoch_loss=8.289961\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=8.34955997467\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] Epoch[25] Batch [10]#011Speed: 993.45 samples/sec#011loss=8.349560\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] Epoch[25] Batch[15] avg_epoch_loss=8.462947\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=25, batch=15 train loss <loss>=8.84351558685\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] Epoch[25] Batch [15]#011Speed: 2129.70 samples/sec#011loss=8.843516\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] Epoch[25] Batch[20] avg_epoch_loss=8.505555\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=25, batch=20 train loss <loss>=8.6419008255\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] Epoch[25] Batch [20]#011Speed: 936.59 samples/sec#011loss=8.641901\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] Epoch[25] Batch[25] avg_epoch_loss=8.438620\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=25, batch=25 train loss <loss>=8.1574921608\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] Epoch[25] Batch [25]#011Speed: 1999.97 samples/sec#011loss=8.157492\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] Epoch[25] Batch[30] avg_epoch_loss=8.336357\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=25, batch=30 train loss <loss>=7.80459041595\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:24 INFO 139919921551168] Epoch[25] Batch [30]#011Speed: 868.29 samples/sec#011loss=7.804590\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] Epoch[25] Batch[35] avg_epoch_loss=8.248568\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=25, batch=35 train loss <loss>=7.70428009033\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] Epoch[25] Batch [35]#011Speed: 2013.92 samples/sec#011loss=7.704280\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] Epoch[25] Batch[40] avg_epoch_loss=8.199404\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=25, batch=40 train loss <loss>=7.84542303085\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] Epoch[25] Batch [40]#011Speed: 926.18 samples/sec#011loss=7.845423\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] Epoch[25] Batch[45] avg_epoch_loss=8.198455\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=25, batch=45 train loss <loss>=8.19066925049\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] Epoch[25] Batch [45]#011Speed: 1901.52 samples/sec#011loss=8.190669\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] processed a total of 1533 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1232.6269149780273, \"sum\": 1232.6269149780273, \"min\": 1232.6269149780273}}, \"EndTime\": 1578471565.382843, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471564.149755}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1243.56433199 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=25, train loss <loss>=8.15098382036\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] Epoch[26] Batch[0] avg_epoch_loss=8.476774\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=8.4767742157\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] Epoch[26] Batch[5] avg_epoch_loss=8.053768\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=8.05376815796\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] Epoch[26] Batch [5]#011Speed: 2053.15 samples/sec#011loss=8.053768\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] Epoch[26] Batch[10] avg_epoch_loss=8.171974\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=8.31382083893\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] Epoch[26] Batch [10]#011Speed: 1871.80 samples/sec#011loss=8.313821\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] Epoch[26] Batch[15] avg_epoch_loss=8.312464\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=26, batch=15 train loss <loss>=8.62154273987\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] Epoch[26] Batch [15]#011Speed: 951.71 samples/sec#011loss=8.621543\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] Epoch[26] Batch[20] avg_epoch_loss=8.381967\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=26, batch=20 train loss <loss>=8.60437726974\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:25 INFO 139919921551168] Epoch[26] Batch [20]#011Speed: 2089.21 samples/sec#011loss=8.604377\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] Epoch[26] Batch[25] avg_epoch_loss=8.337293\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=26, batch=25 train loss <loss>=8.14966249466\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] Epoch[26] Batch [25]#011Speed: 1004.67 samples/sec#011loss=8.149662\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] Epoch[26] Batch[30] avg_epoch_loss=8.235731\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=26, batch=30 train loss <loss>=7.70760622025\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] Epoch[26] Batch [30]#011Speed: 1018.81 samples/sec#011loss=7.707606\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] Epoch[26] Batch[35] avg_epoch_loss=8.202193\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=26, batch=35 train loss <loss>=7.99425840378\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] Epoch[26] Batch [35]#011Speed: 1862.63 samples/sec#011loss=7.994258\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] Epoch[26] Batch[40] avg_epoch_loss=8.153997\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=26, batch=40 train loss <loss>=7.80698270798\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] Epoch[26] Batch [40]#011Speed: 1016.59 samples/sec#011loss=7.806983\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] Epoch[26] Batch[45] avg_epoch_loss=8.146585\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=26, batch=45 train loss <loss>=8.08580856323\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] Epoch[26] Batch [45]#011Speed: 2071.89 samples/sec#011loss=8.085809\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] Epoch[26] Batch[50] avg_epoch_loss=8.095827\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=26, batch=50 train loss <loss>=7.62885866165\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] Epoch[26] Batch [50]#011Speed: 1623.16 samples/sec#011loss=7.628859\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] processed a total of 1626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1249.3650913238525, \"sum\": 1249.3650913238525, \"min\": 1249.3650913238525}}, \"EndTime\": 1578471566.632735, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471565.382926}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1301.34432833 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=26, train loss <loss>=8.09582742055\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] Epoch[27] Batch[0] avg_epoch_loss=8.321051\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=8.32105064392\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] Epoch[27] Batch[5] avg_epoch_loss=8.138974\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=8.13897403081\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] Epoch[27] Batch [5]#011Speed: 1896.41 samples/sec#011loss=8.138974\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] Epoch[27] Batch[10] avg_epoch_loss=8.188842\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=8.24868268967\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:26 INFO 139919921551168] Epoch[27] Batch [10]#011Speed: 1026.42 samples/sec#011loss=8.248683\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] Epoch[27] Batch[15] avg_epoch_loss=8.319024\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=27, batch=15 train loss <loss>=8.60542564392\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] Epoch[27] Batch [15]#011Speed: 1894.92 samples/sec#011loss=8.605426\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] Epoch[27] Batch[20] avg_epoch_loss=8.324582\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=27, batch=20 train loss <loss>=8.34236927032\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] Epoch[27] Batch [20]#011Speed: 1052.83 samples/sec#011loss=8.342369\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] Epoch[27] Batch[25] avg_epoch_loss=8.277310\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=27, batch=25 train loss <loss>=8.07876729965\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] Epoch[27] Batch [25]#011Speed: 1662.86 samples/sec#011loss=8.078767\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] Epoch[27] Batch[30] avg_epoch_loss=8.234632\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=27, batch=30 train loss <loss>=8.01270465851\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] Epoch[27] Batch [30]#011Speed: 856.56 samples/sec#011loss=8.012705\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] Epoch[27] Batch[35] avg_epoch_loss=8.178851\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=27, batch=35 train loss <loss>=7.8330072403\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] Epoch[27] Batch [35]#011Speed: 2149.99 samples/sec#011loss=7.833007\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] Epoch[27] Batch[40] avg_epoch_loss=8.151867\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=27, batch=40 train loss <loss>=7.95758714676\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] Epoch[27] Batch [40]#011Speed: 1003.80 samples/sec#011loss=7.957587\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] Epoch[27] Batch[45] avg_epoch_loss=8.152290\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=27, batch=45 train loss <loss>=8.1557554245\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] Epoch[27] Batch [45]#011Speed: 1695.13 samples/sec#011loss=8.155755\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] Epoch[27] Batch[50] avg_epoch_loss=8.044134\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=27, batch=50 train loss <loss>=7.04910125732\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] Epoch[27] Batch [50]#011Speed: 1530.31 samples/sec#011loss=7.049101\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] processed a total of 1604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1281.231164932251, \"sum\": 1281.231164932251, \"min\": 1281.231164932251}}, \"EndTime\": 1578471567.914501, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471566.632816}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1251.81135927 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=27, train loss <loss>=8.04413426156\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:27 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] Epoch[28] Batch[0] avg_epoch_loss=7.973803\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=7.97380304337\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] Epoch[28] Batch[5] avg_epoch_loss=8.125581\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=8.12558086713\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] Epoch[28] Batch [5]#011Speed: 2035.24 samples/sec#011loss=8.125581\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] Epoch[28] Batch[10] avg_epoch_loss=8.260851\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=8.4231754303\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] Epoch[28] Batch [10]#011Speed: 1034.89 samples/sec#011loss=8.423175\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] Epoch[28] Batch[15] avg_epoch_loss=8.324664\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=28, batch=15 train loss <loss>=8.46505336761\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] Epoch[28] Batch [15]#011Speed: 2008.31 samples/sec#011loss=8.465053\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] Epoch[28] Batch[20] avg_epoch_loss=8.394140\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=28, batch=20 train loss <loss>=8.61646080017\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] Epoch[28] Batch [20]#011Speed: 1042.81 samples/sec#011loss=8.616461\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] Epoch[28] Batch[25] avg_epoch_loss=8.304893\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=28, batch=25 train loss <loss>=7.93005933762\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] Epoch[28] Batch [25]#011Speed: 1650.64 samples/sec#011loss=7.930059\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] Epoch[28] Batch[30] avg_epoch_loss=8.267449\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=28, batch=30 train loss <loss>=8.07273521423\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] Epoch[28] Batch [30]#011Speed: 953.08 samples/sec#011loss=8.072735\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] Epoch[28] Batch[35] avg_epoch_loss=8.222041\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=28, batch=35 train loss <loss>=7.94051055908\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] Epoch[28] Batch [35]#011Speed: 2074.58 samples/sec#011loss=7.940511\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] Epoch[28] Batch[40] avg_epoch_loss=8.195064\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=28, batch=40 train loss <loss>=8.00083694458\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:28 INFO 139919921551168] Epoch[28] Batch [40]#011Speed: 1012.02 samples/sec#011loss=8.000837\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] Epoch[28] Batch[45] avg_epoch_loss=8.155228\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=28, batch=45 train loss <loss>=7.82856845856\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] Epoch[28] Batch [45]#011Speed: 1764.72 samples/sec#011loss=7.828568\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] processed a total of 1597 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1259.7410678863525, \"sum\": 1259.7410678863525, \"min\": 1259.7410678863525}}, \"EndTime\": 1578471569.174749, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471567.91458}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1267.63254856 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=28, train loss <loss>=8.14520267487\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] Epoch[29] Batch[0] avg_epoch_loss=8.477863\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=8.47786331177\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] Epoch[29] Batch[5] avg_epoch_loss=8.327208\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=8.32720772425\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] Epoch[29] Batch [5]#011Speed: 1885.19 samples/sec#011loss=8.327208\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] Epoch[29] Batch[10] avg_epoch_loss=8.407872\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=8.50466938019\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] Epoch[29] Batch [10]#011Speed: 1097.40 samples/sec#011loss=8.504669\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] Epoch[29] Batch[15] avg_epoch_loss=8.457318\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=29, batch=15 train loss <loss>=8.5660982132\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] Epoch[29] Batch [15]#011Speed: 1844.15 samples/sec#011loss=8.566098\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] Epoch[29] Batch[20] avg_epoch_loss=8.452649\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=29, batch=20 train loss <loss>=8.43770914078\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] Epoch[29] Batch [20]#011Speed: 960.56 samples/sec#011loss=8.437709\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] Epoch[29] Batch[25] avg_epoch_loss=8.379014\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=29, batch=25 train loss <loss>=8.06974544525\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] Epoch[29] Batch [25]#011Speed: 2102.99 samples/sec#011loss=8.069745\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] Epoch[29] Batch[30] avg_epoch_loss=8.333815\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=29, batch=30 train loss <loss>=8.09878082275\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:29 INFO 139919921551168] Epoch[29] Batch [30]#011Speed: 998.45 samples/sec#011loss=8.098781\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] Epoch[29] Batch[35] avg_epoch_loss=8.269915\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=29, batch=35 train loss <loss>=7.8737326622\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] Epoch[29] Batch [35]#011Speed: 1727.95 samples/sec#011loss=7.873733\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] Epoch[29] Batch[40] avg_epoch_loss=8.221459\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=29, batch=40 train loss <loss>=7.87257843018\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] Epoch[29] Batch [40]#011Speed: 897.03 samples/sec#011loss=7.872578\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] Epoch[29] Batch[45] avg_epoch_loss=8.208105\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=29, batch=45 train loss <loss>=8.09860334396\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] Epoch[29] Batch [45]#011Speed: 1983.24 samples/sec#011loss=8.098603\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] processed a total of 1590 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1265.6848430633545, \"sum\": 1265.6848430633545, \"min\": 1265.6848430633545}}, \"EndTime\": 1578471570.440917, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471569.174805}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1256.12048161 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=29, train loss <loss>=8.14744970322\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] Epoch[30] Batch[0] avg_epoch_loss=8.064699\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=8.06469917297\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] Epoch[30] Batch[5] avg_epoch_loss=8.286605\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=8.2866054376\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] Epoch[30] Batch [5]#011Speed: 1734.94 samples/sec#011loss=8.286605\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] Epoch[30] Batch[10] avg_epoch_loss=8.285789\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=8.28480911255\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] Epoch[30] Batch [10]#011Speed: 992.56 samples/sec#011loss=8.284809\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] Epoch[30] Batch[15] avg_epoch_loss=8.332702\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=30, batch=15 train loss <loss>=8.43591051102\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:30 INFO 139919921551168] Epoch[30] Batch [15]#011Speed: 1908.42 samples/sec#011loss=8.435911\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] Epoch[30] Batch[20] avg_epoch_loss=8.446673\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=30, batch=20 train loss <loss>=8.81137886047\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] Epoch[30] Batch [20]#011Speed: 1038.54 samples/sec#011loss=8.811379\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] Epoch[30] Batch[25] avg_epoch_loss=8.378414\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=30, batch=25 train loss <loss>=8.0917298317\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] Epoch[30] Batch [25]#011Speed: 1822.82 samples/sec#011loss=8.091730\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] Epoch[30] Batch[30] avg_epoch_loss=8.299485\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=30, batch=30 train loss <loss>=7.88905363083\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] Epoch[30] Batch [30]#011Speed: 1010.78 samples/sec#011loss=7.889054\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] Epoch[30] Batch[35] avg_epoch_loss=8.214525\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=30, batch=35 train loss <loss>=7.68777418137\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] Epoch[30] Batch [35]#011Speed: 1894.14 samples/sec#011loss=7.687774\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] Epoch[30] Batch[40] avg_epoch_loss=8.155616\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=30, batch=40 train loss <loss>=7.73146924973\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] Epoch[30] Batch [40]#011Speed: 1072.30 samples/sec#011loss=7.731469\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] Epoch[30] Batch[45] avg_epoch_loss=8.178679\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=30, batch=45 train loss <loss>=8.36779918671\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] Epoch[30] Batch [45]#011Speed: 1967.70 samples/sec#011loss=8.367799\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] Epoch[30] Batch[50] avg_epoch_loss=8.126899\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=30, batch=50 train loss <loss>=7.65052375793\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] Epoch[30] Batch [50]#011Speed: 1466.30 samples/sec#011loss=7.650524\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] processed a total of 1612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1263.5271549224854, \"sum\": 1263.5271549224854, \"min\": 1263.5271549224854}}, \"EndTime\": 1578471571.704977, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471570.440997}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1275.68370706 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=30, train loss <loss>=8.12689949484\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] Epoch[31] Batch[0] avg_epoch_loss=8.491398\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=8.49139785767\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] Epoch[31] Batch[5] avg_epoch_loss=8.132885\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=8.13288545609\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] Epoch[31] Batch [5]#011Speed: 2022.04 samples/sec#011loss=8.132885\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] Epoch[31] Batch[10] avg_epoch_loss=8.115379\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=8.09437208176\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:31 INFO 139919921551168] Epoch[31] Batch [10]#011Speed: 2149.01 samples/sec#011loss=8.094372\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] Epoch[31] Batch[15] avg_epoch_loss=8.322037\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=31, batch=15 train loss <loss>=8.77668304443\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] Epoch[31] Batch [15]#011Speed: 1003.74 samples/sec#011loss=8.776683\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] Epoch[31] Batch[20] avg_epoch_loss=8.319902\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=31, batch=20 train loss <loss>=8.31307048798\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] Epoch[31] Batch [20]#011Speed: 1872.90 samples/sec#011loss=8.313070\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] Epoch[31] Batch[25] avg_epoch_loss=8.296679\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=31, batch=25 train loss <loss>=8.19914302826\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] Epoch[31] Batch [25]#011Speed: 893.53 samples/sec#011loss=8.199143\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] Epoch[31] Batch[30] avg_epoch_loss=8.263727\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=31, batch=30 train loss <loss>=8.092374897\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] Epoch[31] Batch [30]#011Speed: 1047.64 samples/sec#011loss=8.092375\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] Epoch[31] Batch[35] avg_epoch_loss=8.179726\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=31, batch=35 train loss <loss>=7.65892066956\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] Epoch[31] Batch [35]#011Speed: 1702.45 samples/sec#011loss=7.658921\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] Epoch[31] Batch[40] avg_epoch_loss=8.168344\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=31, batch=40 train loss <loss>=8.08639411926\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] Epoch[31] Batch [40]#011Speed: 1010.16 samples/sec#011loss=8.086394\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] Epoch[31] Batch[45] avg_epoch_loss=8.193209\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=31, batch=45 train loss <loss>=8.39710140228\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] Epoch[31] Batch [45]#011Speed: 1863.54 samples/sec#011loss=8.397101\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] Epoch[31] Batch[50] avg_epoch_loss=8.111247\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=31, batch=50 train loss <loss>=7.35720205307\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:32 INFO 139919921551168] Epoch[31] Batch [50]#011Speed: 1661.93 samples/sec#011loss=7.357202\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] processed a total of 1642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1310.8539581298828, \"sum\": 1310.8539581298828, \"min\": 1310.8539581298828}}, \"EndTime\": 1578471573.016317, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471571.705052}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1252.51536499 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=31, train loss <loss>=8.04668662181\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] Epoch[32] Batch[0] avg_epoch_loss=9.069385\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=9.06938457489\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] Epoch[32] Batch[5] avg_epoch_loss=8.307626\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=8.30762624741\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] Epoch[32] Batch [5]#011Speed: 2156.77 samples/sec#011loss=8.307626\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] Epoch[32] Batch[10] avg_epoch_loss=8.380685\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=8.46835632324\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] Epoch[32] Batch [10]#011Speed: 862.75 samples/sec#011loss=8.468356\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] Epoch[32] Batch[15] avg_epoch_loss=8.460724\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=32, batch=15 train loss <loss>=8.63680973053\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] Epoch[32] Batch [15]#011Speed: 1514.48 samples/sec#011loss=8.636810\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] Epoch[32] Batch[20] avg_epoch_loss=8.438527\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=32, batch=20 train loss <loss>=8.36749620438\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] Epoch[32] Batch [20]#011Speed: 906.22 samples/sec#011loss=8.367496\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] Epoch[32] Batch[25] avg_epoch_loss=8.348602\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=32, batch=25 train loss <loss>=7.97091760635\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] Epoch[32] Batch [25]#011Speed: 2081.44 samples/sec#011loss=7.970918\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] Epoch[32] Batch[30] avg_epoch_loss=8.263518\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=32, batch=30 train loss <loss>=7.82107744217\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] Epoch[32] Batch [30]#011Speed: 1078.09 samples/sec#011loss=7.821077\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] Epoch[32] Batch[35] avg_epoch_loss=8.218962\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=32, batch=35 train loss <loss>=7.94271888733\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:33 INFO 139919921551168] Epoch[32] Batch [35]#011Speed: 1946.28 samples/sec#011loss=7.942719\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] Epoch[32] Batch[40] avg_epoch_loss=8.186395\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=32, batch=40 train loss <loss>=7.9519115448\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] Epoch[32] Batch [40]#011Speed: 962.95 samples/sec#011loss=7.951912\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] Epoch[32] Batch[45] avg_epoch_loss=8.155495\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=32, batch=45 train loss <loss>=7.90211019516\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] Epoch[32] Batch [45]#011Speed: 1894.12 samples/sec#011loss=7.902110\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] processed a total of 1596 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1295.280933380127, \"sum\": 1295.280933380127, \"min\": 1295.280933380127}}, \"EndTime\": 1578471574.312145, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471573.016387}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1232.04539095 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=32, train loss <loss>=8.10986310959\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] Epoch[33] Batch[0] avg_epoch_loss=7.816115\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=7.8161149025\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] Epoch[33] Batch[5] avg_epoch_loss=8.248173\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=8.24817331632\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] Epoch[33] Batch [5]#011Speed: 2144.03 samples/sec#011loss=8.248173\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] Epoch[33] Batch[10] avg_epoch_loss=8.239705\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=33, batch=10 train loss <loss>=8.22954311371\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] Epoch[33] Batch [10]#011Speed: 1104.99 samples/sec#011loss=8.229543\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] Epoch[33] Batch[15] avg_epoch_loss=8.300132\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=33, batch=15 train loss <loss>=8.43306999207\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] Epoch[33] Batch [15]#011Speed: 2082.28 samples/sec#011loss=8.433070\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] Epoch[33] Batch[20] avg_epoch_loss=8.344683\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=33, batch=20 train loss <loss>=8.48724918365\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] Epoch[33] Batch [20]#011Speed: 1089.62 samples/sec#011loss=8.487249\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] Epoch[33] Batch[25] avg_epoch_loss=8.285784\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=33, batch=25 train loss <loss>=8.0384054184\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:34 INFO 139919921551168] Epoch[33] Batch [25]#011Speed: 1894.23 samples/sec#011loss=8.038405\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] Epoch[33] Batch[30] avg_epoch_loss=8.259176\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=33, batch=30 train loss <loss>=8.1208158493\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] Epoch[33] Batch [30]#011Speed: 920.67 samples/sec#011loss=8.120816\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] Epoch[33] Batch[35] avg_epoch_loss=8.215474\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=33, batch=35 train loss <loss>=7.94452285767\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] Epoch[33] Batch [35]#011Speed: 2115.62 samples/sec#011loss=7.944523\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] Epoch[33] Batch[40] avg_epoch_loss=8.191788\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=33, batch=40 train loss <loss>=8.02124910355\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] Epoch[33] Batch [40]#011Speed: 946.23 samples/sec#011loss=8.021249\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] Epoch[33] Batch[45] avg_epoch_loss=8.194485\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=33, batch=45 train loss <loss>=8.21660137177\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] Epoch[33] Batch [45]#011Speed: 2150.45 samples/sec#011loss=8.216601\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] Epoch[33] Batch[50] avg_epoch_loss=8.057266\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=33, batch=50 train loss <loss>=6.79484820366\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] Epoch[33] Batch [50]#011Speed: 1678.96 samples/sec#011loss=6.794848\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] processed a total of 1603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1213.8769626617432, \"sum\": 1213.8769626617432, \"min\": 1213.8769626617432}}, \"EndTime\": 1578471575.526586, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471574.312223}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1320.43483364 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=33, train loss <loss>=8.05726598758\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] Epoch[34] Batch[0] avg_epoch_loss=8.346840\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=8.34683990479\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] Epoch[34] Batch[5] avg_epoch_loss=8.170280\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=8.17028013865\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] Epoch[34] Batch [5]#011Speed: 2081.95 samples/sec#011loss=8.170280\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] Epoch[34] Batch[10] avg_epoch_loss=8.195607\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=8.22599916458\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] Epoch[34] Batch [10]#011Speed: 1126.00 samples/sec#011loss=8.225999\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] Epoch[34] Batch[15] avg_epoch_loss=8.295871\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=34, batch=15 train loss <loss>=8.51645030975\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:35 INFO 139919921551168] Epoch[34] Batch [15]#011Speed: 1993.75 samples/sec#011loss=8.516450\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] Epoch[34] Batch[20] avg_epoch_loss=8.288555\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=34, batch=20 train loss <loss>=8.26514415741\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] Epoch[34] Batch [20]#011Speed: 1096.85 samples/sec#011loss=8.265144\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] Epoch[34] Batch[25] avg_epoch_loss=8.234502\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=34, batch=25 train loss <loss>=8.0074804306\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] Epoch[34] Batch [25]#011Speed: 1982.09 samples/sec#011loss=8.007480\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] Epoch[34] Batch[30] avg_epoch_loss=8.180411\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=34, batch=30 train loss <loss>=7.89913883209\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] Epoch[34] Batch [30]#011Speed: 908.12 samples/sec#011loss=7.899139\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] Epoch[34] Batch[35] avg_epoch_loss=8.146190\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=34, batch=35 train loss <loss>=7.93401994705\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] Epoch[34] Batch [35]#011Speed: 2098.00 samples/sec#011loss=7.934020\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] Epoch[34] Batch[40] avg_epoch_loss=8.112119\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=34, batch=40 train loss <loss>=7.8668050766\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] Epoch[34] Batch [40]#011Speed: 1042.99 samples/sec#011loss=7.866805\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] Epoch[34] Batch[45] avg_epoch_loss=8.108647\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=34, batch=45 train loss <loss>=8.08017997742\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] Epoch[34] Batch [45]#011Speed: 2086.56 samples/sec#011loss=8.080180\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] processed a total of 1569 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1169.593095779419, \"sum\": 1169.593095779419, \"min\": 1169.593095779419}}, \"EndTime\": 1578471576.696711, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471575.526665}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1341.35929875 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=34, train loss <loss>=7.9836066246\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] Saved checkpoint to \"/opt/ml/model/state_c8290741-3b19-4cc7-9df1-d517847e22c5-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 11.45315170288086, \"sum\": 11.45315170288086, \"min\": 11.45315170288086}}, \"EndTime\": 1578471576.708753, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471576.696789}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] Epoch[35] Batch[0] avg_epoch_loss=8.779332\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=8.77933216095\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] Epoch[35] Batch[5] avg_epoch_loss=8.332682\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=8.33268157641\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:36 INFO 139919921551168] Epoch[35] Batch [5]#011Speed: 2084.31 samples/sec#011loss=8.332682\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] Epoch[35] Batch[10] avg_epoch_loss=8.335930\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=8.33982772827\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] Epoch[35] Batch [10]#011Speed: 988.86 samples/sec#011loss=8.339828\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] Epoch[35] Batch[15] avg_epoch_loss=8.375552\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=35, batch=15 train loss <loss>=8.46271982193\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] Epoch[35] Batch [15]#011Speed: 2099.68 samples/sec#011loss=8.462720\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] Epoch[35] Batch[20] avg_epoch_loss=8.391010\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=35, batch=20 train loss <loss>=8.44047832489\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] Epoch[35] Batch [20]#011Speed: 950.67 samples/sec#011loss=8.440478\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] Epoch[35] Batch[25] avg_epoch_loss=8.311339\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=35, batch=25 train loss <loss>=7.97671852112\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] Epoch[35] Batch [25]#011Speed: 2006.42 samples/sec#011loss=7.976719\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] Epoch[35] Batch[30] avg_epoch_loss=8.279056\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=35, batch=30 train loss <loss>=8.11118755341\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] Epoch[35] Batch [30]#011Speed: 936.65 samples/sec#011loss=8.111188\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] Epoch[35] Batch[35] avg_epoch_loss=8.207687\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=35, batch=35 train loss <loss>=7.76519641876\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] Epoch[35] Batch [35]#011Speed: 1923.58 samples/sec#011loss=7.765196\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] Epoch[35] Batch[40] avg_epoch_loss=8.172676\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=35, batch=40 train loss <loss>=7.92059593201\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] Epoch[35] Batch [40]#011Speed: 1002.24 samples/sec#011loss=7.920596\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] Epoch[35] Batch[45] avg_epoch_loss=8.142564\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=35, batch=45 train loss <loss>=7.89564990997\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] Epoch[35] Batch [45]#011Speed: 1905.47 samples/sec#011loss=7.895650\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] Epoch[35] Batch[50] avg_epoch_loss=8.072700\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=35, batch=50 train loss <loss>=7.42995033264\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] Epoch[35] Batch [50]#011Speed: 1427.37 samples/sec#011loss=7.429950\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] processed a total of 1630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1263.2880210876465, \"sum\": 1263.2880210876465, \"min\": 1263.2880210876465}}, \"EndTime\": 1578471577.972147, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471576.70881}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1290.17953056 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=35, train loss <loss>=8.0727002387\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:37 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:38 INFO 139919921551168] Epoch[36] Batch[0] avg_epoch_loss=7.956136\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=7.95613622665\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:38 INFO 139919921551168] Epoch[36] Batch[5] avg_epoch_loss=8.078199\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=8.07819930712\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:38 INFO 139919921551168] Epoch[36] Batch [5]#011Speed: 1993.45 samples/sec#011loss=8.078199\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:38 INFO 139919921551168] Epoch[36] Batch[10] avg_epoch_loss=8.300678\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=8.56765184402\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:38 INFO 139919921551168] Epoch[36] Batch [10]#011Speed: 979.08 samples/sec#011loss=8.567652\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:38 INFO 139919921551168] Epoch[36] Batch[15] avg_epoch_loss=8.448583\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=36, batch=15 train loss <loss>=8.7739730835\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:38 INFO 139919921551168] Epoch[36] Batch [15]#011Speed: 1671.35 samples/sec#011loss=8.773973\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:38 INFO 139919921551168] Epoch[36] Batch[20] avg_epoch_loss=8.372497\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=36, batch=20 train loss <loss>=8.12902431488\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:38 INFO 139919921551168] Epoch[36] Batch [20]#011Speed: 960.27 samples/sec#011loss=8.129024\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:38 INFO 139919921551168] Epoch[36] Batch[25] avg_epoch_loss=8.335060\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=36, batch=25 train loss <loss>=8.17782344818\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:38 INFO 139919921551168] Epoch[36] Batch [25]#011Speed: 1865.25 samples/sec#011loss=8.177823\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:38 INFO 139919921551168] Epoch[36] Batch[30] avg_epoch_loss=8.259145\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=36, batch=30 train loss <loss>=7.86438465118\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:38 INFO 139919921551168] Epoch[36] Batch [30]#011Speed: 1053.87 samples/sec#011loss=7.864385\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:38 INFO 139919921551168] Epoch[36] Batch[35] avg_epoch_loss=8.210402\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=36, batch=35 train loss <loss>=7.90819807053\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:38 INFO 139919921551168] Epoch[36] Batch [35]#011Speed: 1931.48 samples/sec#011loss=7.908198\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] Epoch[36] Batch[40] avg_epoch_loss=8.155817\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=36, batch=40 train loss <loss>=7.76280269623\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] Epoch[36] Batch [40]#011Speed: 1066.84 samples/sec#011loss=7.762803\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] Epoch[36] Batch[45] avg_epoch_loss=8.158708\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=36, batch=45 train loss <loss>=8.1824174881\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] Epoch[36] Batch [45]#011Speed: 2086.67 samples/sec#011loss=8.182417\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] Epoch[36] Batch[50] avg_epoch_loss=8.098494\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=36, batch=50 train loss <loss>=7.54452667236\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] Epoch[36] Batch [50]#011Speed: 1487.54 samples/sec#011loss=7.544527\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] processed a total of 1623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1278.9690494537354, \"sum\": 1278.9690494537354, \"min\": 1278.9690494537354}}, \"EndTime\": 1578471579.251622, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471577.972218}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1268.85388085 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=36, train loss <loss>=8.09849425858\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] Epoch[37] Batch[0] avg_epoch_loss=8.742522\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=8.74252223969\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] Epoch[37] Batch[5] avg_epoch_loss=8.235671\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=8.23567096392\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] Epoch[37] Batch [5]#011Speed: 1831.44 samples/sec#011loss=8.235671\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] Epoch[37] Batch[10] avg_epoch_loss=8.360241\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=8.50972423553\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] Epoch[37] Batch [10]#011Speed: 1022.71 samples/sec#011loss=8.509724\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] Epoch[37] Batch[15] avg_epoch_loss=8.383812\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=37, batch=15 train loss <loss>=8.4356675148\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] Epoch[37] Batch [15]#011Speed: 2081.77 samples/sec#011loss=8.435668\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] Epoch[37] Batch[20] avg_epoch_loss=8.334869\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=37, batch=20 train loss <loss>=8.17825174332\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] Epoch[37] Batch [20]#011Speed: 1071.23 samples/sec#011loss=8.178252\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] Epoch[37] Batch[25] avg_epoch_loss=8.271536\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=37, batch=25 train loss <loss>=8.00553922653\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:39 INFO 139919921551168] Epoch[37] Batch [25]#011Speed: 1670.56 samples/sec#011loss=8.005539\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] Epoch[37] Batch[30] avg_epoch_loss=8.220930\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=37, batch=30 train loss <loss>=7.95777826309\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] Epoch[37] Batch [30]#011Speed: 1043.61 samples/sec#011loss=7.957778\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] Epoch[37] Batch[35] avg_epoch_loss=8.121869\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=37, batch=35 train loss <loss>=7.50768823624\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] Epoch[37] Batch [35]#011Speed: 1846.04 samples/sec#011loss=7.507688\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] Epoch[37] Batch[40] avg_epoch_loss=8.123984\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=37, batch=40 train loss <loss>=8.13921785355\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] Epoch[37] Batch [40]#011Speed: 994.24 samples/sec#011loss=8.139218\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] Epoch[37] Batch[45] avg_epoch_loss=8.137222\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=37, batch=45 train loss <loss>=8.24576663971\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] Epoch[37] Batch [45]#011Speed: 1811.39 samples/sec#011loss=8.245767\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] processed a total of 1549 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1242.5270080566406, \"sum\": 1242.5270080566406, \"min\": 1242.5270080566406}}, \"EndTime\": 1578471580.494671, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471579.251726}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1246.53578014 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=37, train loss <loss>=8.07035383886\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] Epoch[38] Batch[0] avg_epoch_loss=8.197736\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=8.19773578644\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] Epoch[38] Batch[5] avg_epoch_loss=8.189032\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=8.18903199832\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] Epoch[38] Batch [5]#011Speed: 1909.17 samples/sec#011loss=8.189032\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] Epoch[38] Batch[10] avg_epoch_loss=8.317736\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=8.47218112946\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] Epoch[38] Batch [10]#011Speed: 962.84 samples/sec#011loss=8.472181\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] Epoch[38] Batch[15] avg_epoch_loss=8.440931\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=38, batch=15 train loss <loss>=8.71196060181\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:40 INFO 139919921551168] Epoch[38] Batch [15]#011Speed: 1701.80 samples/sec#011loss=8.711961\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] Epoch[38] Batch[20] avg_epoch_loss=8.413716\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=38, batch=20 train loss <loss>=8.326628685\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] Epoch[38] Batch [20]#011Speed: 1046.00 samples/sec#011loss=8.326629\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] Epoch[38] Batch[25] avg_epoch_loss=8.362636\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=38, batch=25 train loss <loss>=8.14809970856\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] Epoch[38] Batch [25]#011Speed: 2098.08 samples/sec#011loss=8.148100\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] Epoch[38] Batch[30] avg_epoch_loss=8.294000\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=38, batch=30 train loss <loss>=7.93709287643\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] Epoch[38] Batch [30]#011Speed: 1067.59 samples/sec#011loss=7.937093\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] Epoch[38] Batch[35] avg_epoch_loss=8.224130\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=38, batch=35 train loss <loss>=7.79093637466\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] Epoch[38] Batch [35]#011Speed: 2034.58 samples/sec#011loss=7.790936\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] Epoch[38] Batch[40] avg_epoch_loss=8.167279\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=38, batch=40 train loss <loss>=7.7579498291\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] Epoch[38] Batch [40]#011Speed: 976.34 samples/sec#011loss=7.757950\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] Epoch[38] Batch[45] avg_epoch_loss=8.146779\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=38, batch=45 train loss <loss>=7.97868118286\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] Epoch[38] Batch [45]#011Speed: 1628.40 samples/sec#011loss=7.978681\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] Epoch[38] Batch[50] avg_epoch_loss=8.103299\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=38, batch=50 train loss <loss>=7.70327682495\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] Epoch[38] Batch [50]#011Speed: 1416.35 samples/sec#011loss=7.703277\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] processed a total of 1629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1272.6809978485107, \"sum\": 1272.6809978485107, \"min\": 1272.6809978485107}}, \"EndTime\": 1578471581.767869, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471580.49475}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1279.87464779 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=38, train loss <loss>=8.1032985893\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] Epoch[39] Batch[0] avg_epoch_loss=8.607573\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=8.60757255554\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] Epoch[39] Batch[5] avg_epoch_loss=8.199830\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=8.19982973735\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:41 INFO 139919921551168] Epoch[39] Batch [5]#011Speed: 1636.73 samples/sec#011loss=8.199830\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] Epoch[39] Batch[10] avg_epoch_loss=8.232516\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=8.27173948288\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] Epoch[39] Batch [10]#011Speed: 968.46 samples/sec#011loss=8.271739\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] Epoch[39] Batch[15] avg_epoch_loss=8.338162\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=39, batch=15 train loss <loss>=8.57058258057\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] Epoch[39] Batch [15]#011Speed: 1804.56 samples/sec#011loss=8.570583\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] Epoch[39] Batch[20] avg_epoch_loss=8.345447\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=39, batch=20 train loss <loss>=8.36875762939\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] Epoch[39] Batch [20]#011Speed: 950.63 samples/sec#011loss=8.368758\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] Epoch[39] Batch[25] avg_epoch_loss=8.306602\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=39, batch=25 train loss <loss>=8.14345407486\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] Epoch[39] Batch [25]#011Speed: 2058.00 samples/sec#011loss=8.143454\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] Epoch[39] Batch[30] avg_epoch_loss=8.234456\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=39, batch=30 train loss <loss>=7.8592997551\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] Epoch[39] Batch [30]#011Speed: 1096.43 samples/sec#011loss=7.859300\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] Epoch[39] Batch[35] avg_epoch_loss=8.209137\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=39, batch=35 train loss <loss>=8.05215597153\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] Epoch[39] Batch [35]#011Speed: 2089.75 samples/sec#011loss=8.052156\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] Epoch[39] Batch[40] avg_epoch_loss=8.149159\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=39, batch=40 train loss <loss>=7.71732187271\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] Epoch[39] Batch [40]#011Speed: 947.44 samples/sec#011loss=7.717322\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] Epoch[39] Batch[45] avg_epoch_loss=8.108483\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=39, batch=45 train loss <loss>=7.77494068146\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:42 INFO 139919921551168] Epoch[39] Batch [45]#011Speed: 2008.54 samples/sec#011loss=7.774941\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] Epoch[39] Batch[50] avg_epoch_loss=8.068627\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=39, batch=50 train loss <loss>=7.70194702148\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] Epoch[39] Batch [50]#011Speed: 1331.08 samples/sec#011loss=7.701947\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] processed a total of 1607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1283.0429077148438, \"sum\": 1283.0429077148438, \"min\": 1283.0429077148438}}, \"EndTime\": 1578471583.051404, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471581.76793}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1252.38092839 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=39, train loss <loss>=8.06862693674\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] Epoch[40] Batch[0] avg_epoch_loss=8.454877\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=8.45487689972\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] Epoch[40] Batch[5] avg_epoch_loss=8.493482\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=8.49348211288\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] Epoch[40] Batch [5]#011Speed: 1659.43 samples/sec#011loss=8.493482\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] Epoch[40] Batch[10] avg_epoch_loss=8.375300\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=8.23348045349\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] Epoch[40] Batch [10]#011Speed: 912.83 samples/sec#011loss=8.233480\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] Epoch[40] Batch[15] avg_epoch_loss=8.522873\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=40, batch=15 train loss <loss>=8.84753494263\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] Epoch[40] Batch [15]#011Speed: 1894.48 samples/sec#011loss=8.847535\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] Epoch[40] Batch[20] avg_epoch_loss=8.447001\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=40, batch=20 train loss <loss>=8.20421152115\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] Epoch[40] Batch [20]#011Speed: 986.16 samples/sec#011loss=8.204212\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] Epoch[40] Batch[25] avg_epoch_loss=8.398100\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=40, batch=25 train loss <loss>=8.19271373749\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] Epoch[40] Batch [25]#011Speed: 2165.70 samples/sec#011loss=8.192714\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] Epoch[40] Batch[30] avg_epoch_loss=8.325270\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=40, batch=30 train loss <loss>=7.94655704498\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] Epoch[40] Batch [30]#011Speed: 1017.70 samples/sec#011loss=7.946557\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] Epoch[40] Batch[35] avg_epoch_loss=8.238875\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=40, batch=35 train loss <loss>=7.70322132111\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:43 INFO 139919921551168] Epoch[40] Batch [35]#011Speed: 1859.88 samples/sec#011loss=7.703221\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] Epoch[40] Batch[40] avg_epoch_loss=8.224007\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=40, batch=40 train loss <loss>=8.11695899963\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] Epoch[40] Batch [40]#011Speed: 959.07 samples/sec#011loss=8.116959\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] Epoch[40] Batch[45] avg_epoch_loss=8.240942\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=40, batch=45 train loss <loss>=8.37980670929\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] Epoch[40] Batch [45]#011Speed: 1640.49 samples/sec#011loss=8.379807\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] processed a total of 1593 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1299.9448776245117, \"sum\": 1299.9448776245117, \"min\": 1299.9448776245117}}, \"EndTime\": 1578471584.351874, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471583.051481}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1225.33746796 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=40, train loss <loss>=8.20600186348\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] Epoch[41] Batch[0] avg_epoch_loss=8.021523\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=8.02152347565\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] Epoch[41] Batch[5] avg_epoch_loss=8.244828\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=8.2448284626\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] Epoch[41] Batch [5]#011Speed: 1603.03 samples/sec#011loss=8.244828\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] Epoch[41] Batch[10] avg_epoch_loss=8.409656\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=8.60744934082\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] Epoch[41] Batch [10]#011Speed: 921.62 samples/sec#011loss=8.607449\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] Epoch[41] Batch[15] avg_epoch_loss=8.477098\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=41, batch=15 train loss <loss>=8.62547035217\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] Epoch[41] Batch [15]#011Speed: 1910.28 samples/sec#011loss=8.625470\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] Epoch[41] Batch[20] avg_epoch_loss=8.487455\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=41, batch=20 train loss <loss>=8.52059783936\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:44 INFO 139919921551168] Epoch[41] Batch [20]#011Speed: 988.23 samples/sec#011loss=8.520598\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] Epoch[41] Batch[25] avg_epoch_loss=8.405276\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=41, batch=25 train loss <loss>=8.06012134552\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] Epoch[41] Batch [25]#011Speed: 1933.12 samples/sec#011loss=8.060121\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] Epoch[41] Batch[30] avg_epoch_loss=8.317586\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=41, batch=30 train loss <loss>=7.86160306931\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] Epoch[41] Batch [30]#011Speed: 910.36 samples/sec#011loss=7.861603\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] Epoch[41] Batch[35] avg_epoch_loss=8.237539\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=41, batch=35 train loss <loss>=7.74124641418\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] Epoch[41] Batch [35]#011Speed: 2169.72 samples/sec#011loss=7.741246\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] Epoch[41] Batch[40] avg_epoch_loss=8.207164\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=41, batch=40 train loss <loss>=7.98846578598\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] Epoch[41] Batch [40]#011Speed: 986.99 samples/sec#011loss=7.988466\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] Epoch[41] Batch[45] avg_epoch_loss=8.158003\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=41, batch=45 train loss <loss>=7.75488014221\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] Epoch[41] Batch [45]#011Speed: 2076.38 samples/sec#011loss=7.754880\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] processed a total of 1590 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1278.8679599761963, \"sum\": 1278.8679599761963, \"min\": 1278.8679599761963}}, \"EndTime\": 1578471585.631317, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471584.35194}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1243.17698263 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=41, train loss <loss>=8.09800440788\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] Epoch[42] Batch[0] avg_epoch_loss=8.688790\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=8.68879032135\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] Epoch[42] Batch[5] avg_epoch_loss=8.082769\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=8.08276851972\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] Epoch[42] Batch [5]#011Speed: 1974.04 samples/sec#011loss=8.082769\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] Epoch[42] Batch[10] avg_epoch_loss=8.089884\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=8.09842348099\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:45 INFO 139919921551168] Epoch[42] Batch [10]#011Speed: 1068.39 samples/sec#011loss=8.098423\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] Epoch[42] Batch[15] avg_epoch_loss=8.293949\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=42, batch=15 train loss <loss>=8.74289016724\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] Epoch[42] Batch [15]#011Speed: 1820.41 samples/sec#011loss=8.742890\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] Epoch[42] Batch[20] avg_epoch_loss=8.330210\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=42, batch=20 train loss <loss>=8.4462474823\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] Epoch[42] Batch [20]#011Speed: 969.91 samples/sec#011loss=8.446247\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] Epoch[42] Batch[25] avg_epoch_loss=8.282907\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=42, batch=25 train loss <loss>=8.084233284\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] Epoch[42] Batch [25]#011Speed: 1657.69 samples/sec#011loss=8.084233\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] Epoch[42] Batch[30] avg_epoch_loss=8.245761\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=42, batch=30 train loss <loss>=8.05260190964\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] Epoch[42] Batch [30]#011Speed: 963.42 samples/sec#011loss=8.052602\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] Epoch[42] Batch[35] avg_epoch_loss=8.174813\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=42, batch=35 train loss <loss>=7.73493785858\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] Epoch[42] Batch [35]#011Speed: 1652.24 samples/sec#011loss=7.734938\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] Epoch[42] Batch[40] avg_epoch_loss=8.143164\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=42, batch=40 train loss <loss>=7.91529111862\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] Epoch[42] Batch [40]#011Speed: 976.53 samples/sec#011loss=7.915291\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] Epoch[42] Batch[45] avg_epoch_loss=8.100251\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=42, batch=45 train loss <loss>=7.74836626053\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] Epoch[42] Batch [45]#011Speed: 1848.66 samples/sec#011loss=7.748366\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] Epoch[42] Batch[50] avg_epoch_loss=8.097861\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=42, batch=50 train loss <loss>=8.07586860657\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] Epoch[42] Batch [50]#011Speed: 1558.07 samples/sec#011loss=8.075869\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] processed a total of 1634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1324.295997619629, \"sum\": 1324.295997619629, \"min\": 1324.295997619629}}, \"EndTime\": 1578471586.956143, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471585.631394}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1233.76805892 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=42, train loss <loss>=8.06909796825\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:46 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:47 INFO 139919921551168] Epoch[43] Batch[0] avg_epoch_loss=8.111388\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=8.11138820648\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:47 INFO 139919921551168] Epoch[43] Batch[5] avg_epoch_loss=8.070900\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=8.07090036074\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:47 INFO 139919921551168] Epoch[43] Batch [5]#011Speed: 2038.55 samples/sec#011loss=8.070900\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:47 INFO 139919921551168] Epoch[43] Batch[10] avg_epoch_loss=8.274802\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=8.51948451996\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:47 INFO 139919921551168] Epoch[43] Batch [10]#011Speed: 996.54 samples/sec#011loss=8.519485\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:47 INFO 139919921551168] Epoch[43] Batch[15] avg_epoch_loss=8.256009\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=43, batch=15 train loss <loss>=8.21466331482\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:47 INFO 139919921551168] Epoch[43] Batch [15]#011Speed: 1853.40 samples/sec#011loss=8.214663\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:47 INFO 139919921551168] Epoch[43] Batch[20] avg_epoch_loss=8.294902\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=43, batch=20 train loss <loss>=8.41935892105\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:47 INFO 139919921551168] Epoch[43] Batch [20]#011Speed: 980.43 samples/sec#011loss=8.419359\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:47 INFO 139919921551168] Epoch[43] Batch[25] avg_epoch_loss=8.248214\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=43, batch=25 train loss <loss>=8.05212726593\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:47 INFO 139919921551168] Epoch[43] Batch [25]#011Speed: 1810.07 samples/sec#011loss=8.052127\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:47 INFO 139919921551168] Epoch[43] Batch[30] avg_epoch_loss=8.166807\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=43, batch=30 train loss <loss>=7.74348745346\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:47 INFO 139919921551168] Epoch[43] Batch [30]#011Speed: 1014.49 samples/sec#011loss=7.743487\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:47 INFO 139919921551168] Epoch[43] Batch[35] avg_epoch_loss=8.087571\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=43, batch=35 train loss <loss>=7.59630708694\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:47 INFO 139919921551168] Epoch[43] Batch [35]#011Speed: 1678.91 samples/sec#011loss=7.596307\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] Epoch[43] Batch[40] avg_epoch_loss=8.076429\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=43, batch=40 train loss <loss>=7.99621248245\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] Epoch[43] Batch [40]#011Speed: 926.76 samples/sec#011loss=7.996212\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] Epoch[43] Batch[45] avg_epoch_loss=8.102649\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=43, batch=45 train loss <loss>=8.31764726639\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] Epoch[43] Batch [45]#011Speed: 2074.82 samples/sec#011loss=8.317647\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] processed a total of 1591 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1250.101089477539, \"sum\": 1250.101089477539, \"min\": 1250.101089477539}}, \"EndTime\": 1578471588.206775, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471586.956207}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1272.57305302 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=43, train loss <loss>=8.06725369453\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] Epoch[44] Batch[0] avg_epoch_loss=7.742014\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=7.74201393127\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] Epoch[44] Batch[5] avg_epoch_loss=8.033438\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=8.03343844414\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] Epoch[44] Batch [5]#011Speed: 1657.84 samples/sec#011loss=8.033438\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] Epoch[44] Batch[10] avg_epoch_loss=8.019184\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=8.0020781517\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] Epoch[44] Batch [10]#011Speed: 924.94 samples/sec#011loss=8.002078\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] Epoch[44] Batch[15] avg_epoch_loss=8.209106\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=44, batch=15 train loss <loss>=8.62693386078\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] Epoch[44] Batch [15]#011Speed: 1658.24 samples/sec#011loss=8.626934\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] Epoch[44] Batch[20] avg_epoch_loss=8.314512\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=44, batch=20 train loss <loss>=8.65181350708\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] Epoch[44] Batch [20]#011Speed: 985.46 samples/sec#011loss=8.651814\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] Epoch[44] Batch[25] avg_epoch_loss=8.267934\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=44, batch=25 train loss <loss>=8.07230606079\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:48 INFO 139919921551168] Epoch[44] Batch [25]#011Speed: 1720.25 samples/sec#011loss=8.072306\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] Epoch[44] Batch[30] avg_epoch_loss=8.198953\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=44, batch=30 train loss <loss>=7.84024925232\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] Epoch[44] Batch [30]#011Speed: 938.88 samples/sec#011loss=7.840249\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] Epoch[44] Batch[35] avg_epoch_loss=8.168895\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=44, batch=35 train loss <loss>=7.98254041672\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] Epoch[44] Batch [35]#011Speed: 2088.97 samples/sec#011loss=7.982540\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] Epoch[44] Batch[40] avg_epoch_loss=8.121693\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=44, batch=40 train loss <loss>=7.78183279037\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] Epoch[44] Batch [40]#011Speed: 1023.69 samples/sec#011loss=7.781833\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] Epoch[44] Batch[45] avg_epoch_loss=8.115396\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=44, batch=45 train loss <loss>=8.06376638412\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] Epoch[44] Batch [45]#011Speed: 2078.65 samples/sec#011loss=8.063766\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] processed a total of 1594 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1320.8119869232178, \"sum\": 1320.8119869232178, \"min\": 1320.8119869232178}}, \"EndTime\": 1578471589.528115, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471588.206862}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1206.7290457 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=44, train loss <loss>=8.06733415604\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] Epoch[45] Batch[0] avg_epoch_loss=8.290821\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=8.29082107544\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] Epoch[45] Batch[5] avg_epoch_loss=8.330203\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=8.33020305634\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] Epoch[45] Batch [5]#011Speed: 2081.30 samples/sec#011loss=8.330203\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] Epoch[45] Batch[10] avg_epoch_loss=8.227617\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=8.10451469421\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] Epoch[45] Batch [10]#011Speed: 1091.74 samples/sec#011loss=8.104515\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] Epoch[45] Batch[15] avg_epoch_loss=8.320901\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=45, batch=15 train loss <loss>=8.52612361908\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:49 INFO 139919921551168] Epoch[45] Batch [15]#011Speed: 2088.91 samples/sec#011loss=8.526124\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] Epoch[45] Batch[20] avg_epoch_loss=8.289544\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=45, batch=20 train loss <loss>=8.18920078278\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] Epoch[45] Batch [20]#011Speed: 1093.61 samples/sec#011loss=8.189201\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] Epoch[45] Batch[25] avg_epoch_loss=8.209363\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=45, batch=25 train loss <loss>=7.87260522842\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] Epoch[45] Batch [25]#011Speed: 1965.31 samples/sec#011loss=7.872605\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] Epoch[45] Batch[30] avg_epoch_loss=8.167033\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=45, batch=30 train loss <loss>=7.94691610336\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] Epoch[45] Batch [30]#011Speed: 988.24 samples/sec#011loss=7.946916\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] Epoch[45] Batch[35] avg_epoch_loss=8.074412\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=45, batch=35 train loss <loss>=7.50015993118\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] Epoch[45] Batch [35]#011Speed: 1797.91 samples/sec#011loss=7.500160\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] Epoch[45] Batch[40] avg_epoch_loss=8.053126\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=45, batch=40 train loss <loss>=7.89986581802\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] Epoch[45] Batch [40]#011Speed: 985.11 samples/sec#011loss=7.899866\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] Epoch[45] Batch[45] avg_epoch_loss=8.052575\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=45, batch=45 train loss <loss>=8.04806365967\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] Epoch[45] Batch [45]#011Speed: 2031.10 samples/sec#011loss=8.048064\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] processed a total of 1582 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1200.6850242614746, \"sum\": 1200.6850242614746, \"min\": 1200.6850242614746}}, \"EndTime\": 1578471590.729338, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471589.528194}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1317.44410731 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=45, train loss <loss>=7.96955925941\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] Saved checkpoint to \"/opt/ml/model/state_f8e55df0-cf2f-4604-b4b2-e9b9a24e6aae-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 11.268138885498047, \"sum\": 11.268138885498047, \"min\": 11.268138885498047}}, \"EndTime\": 1578471590.741206, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471590.729417}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] Epoch[46] Batch[0] avg_epoch_loss=8.529244\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=8.52924442291\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] Epoch[46] Batch[5] avg_epoch_loss=8.290623\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=8.29062310855\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:50 INFO 139919921551168] Epoch[46] Batch [5]#011Speed: 2037.39 samples/sec#011loss=8.290623\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] Epoch[46] Batch[10] avg_epoch_loss=8.262682\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=8.22915287018\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] Epoch[46] Batch [10]#011Speed: 909.80 samples/sec#011loss=8.229153\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] Epoch[46] Batch[15] avg_epoch_loss=8.360262\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=46, batch=15 train loss <loss>=8.57493934631\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] Epoch[46] Batch [15]#011Speed: 1938.22 samples/sec#011loss=8.574939\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] Epoch[46] Batch[20] avg_epoch_loss=8.358837\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=46, batch=20 train loss <loss>=8.35427570343\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] Epoch[46] Batch [20]#011Speed: 988.44 samples/sec#011loss=8.354276\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] Epoch[46] Batch[25] avg_epoch_loss=8.295691\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=46, batch=25 train loss <loss>=8.03047504425\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] Epoch[46] Batch [25]#011Speed: 2142.42 samples/sec#011loss=8.030475\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] Epoch[46] Batch[30] avg_epoch_loss=8.208789\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=46, batch=30 train loss <loss>=7.75689935684\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] Epoch[46] Batch [30]#011Speed: 998.51 samples/sec#011loss=7.756899\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] Epoch[46] Batch[35] avg_epoch_loss=8.148186\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=46, batch=35 train loss <loss>=7.7724486351\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] Epoch[46] Batch [35]#011Speed: 2170.78 samples/sec#011loss=7.772449\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] Epoch[46] Batch[40] avg_epoch_loss=8.153426\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=46, batch=40 train loss <loss>=8.19115142822\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] Epoch[46] Batch [40]#011Speed: 1009.37 samples/sec#011loss=8.191151\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] Epoch[46] Batch[45] avg_epoch_loss=8.128773\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=46, batch=45 train loss <loss>=7.92661800385\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] Epoch[46] Batch [45]#011Speed: 2042.04 samples/sec#011loss=7.926618\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] Epoch[46] Batch[50] avg_epoch_loss=8.043004\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=46, batch=50 train loss <loss>=7.25393638611\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] Epoch[46] Batch [50]#011Speed: 1665.07 samples/sec#011loss=7.253936\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] processed a total of 1610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1228.6579608917236, \"sum\": 1228.6579608917236, \"min\": 1228.6579608917236}}, \"EndTime\": 1578471591.969965, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471590.741255}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1310.25662896 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=46, train loss <loss>=8.04300436319\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:51 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:52 INFO 139919921551168] Epoch[47] Batch[0] avg_epoch_loss=8.256888\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=8.25688838959\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:52 INFO 139919921551168] Epoch[47] Batch[5] avg_epoch_loss=8.453274\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=8.45327393214\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:52 INFO 139919921551168] Epoch[47] Batch [5]#011Speed: 2001.18 samples/sec#011loss=8.453274\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:52 INFO 139919921551168] Epoch[47] Batch[10] avg_epoch_loss=8.339250\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=8.20242023468\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:52 INFO 139919921551168] Epoch[47] Batch [10]#011Speed: 953.08 samples/sec#011loss=8.202420\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:52 INFO 139919921551168] Epoch[47] Batch[15] avg_epoch_loss=8.374691\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=47, batch=15 train loss <loss>=8.4526638031\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:52 INFO 139919921551168] Epoch[47] Batch [15]#011Speed: 1912.71 samples/sec#011loss=8.452664\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:52 INFO 139919921551168] Epoch[47] Batch[20] avg_epoch_loss=8.381829\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=47, batch=20 train loss <loss>=8.40466880798\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:52 INFO 139919921551168] Epoch[47] Batch [20]#011Speed: 1031.45 samples/sec#011loss=8.404669\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:19:52 INFO 139919921551168] Epoch[47] Batch[25] avg_epoch_loss=8.308875\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=47, batch=25 train loss <loss>=8.00246744156\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:52 INFO 139919921551168] Epoch[47] Batch [25]#011Speed: 2085.04 samples/sec#011loss=8.002467\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:52 INFO 139919921551168] Epoch[47] Batch[30] avg_epoch_loss=8.242702\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=47, batch=30 train loss <loss>=7.89860067368\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:52 INFO 139919921551168] Epoch[47] Batch [30]#011Speed: 1074.14 samples/sec#011loss=7.898601\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:52 INFO 139919921551168] Epoch[47] Batch[35] avg_epoch_loss=8.185433\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=47, batch=35 train loss <loss>=7.83036680222\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:52 INFO 139919921551168] Epoch[47] Batch [35]#011Speed: 1653.68 samples/sec#011loss=7.830367\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] Epoch[47] Batch[40] avg_epoch_loss=8.154354\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=47, batch=40 train loss <loss>=7.93058462143\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] Epoch[47] Batch [40]#011Speed: 900.74 samples/sec#011loss=7.930585\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] Epoch[47] Batch[45] avg_epoch_loss=8.158454\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=47, batch=45 train loss <loss>=8.19207410812\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] Epoch[47] Batch [45]#011Speed: 2075.17 samples/sec#011loss=8.192074\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] Epoch[47] Batch[50] avg_epoch_loss=8.119196\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=47, batch=50 train loss <loss>=7.75802736282\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] Epoch[47] Batch [50]#011Speed: 1591.39 samples/sec#011loss=7.758027\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] processed a total of 1636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1312.3500347137451, \"sum\": 1312.3500347137451, \"min\": 1312.3500347137451}}, \"EndTime\": 1578471593.282804, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471591.970042}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1246.50200348 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=47, train loss <loss>=8.10945327465\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] Epoch[48] Batch[0] avg_epoch_loss=8.062908\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=8.06290817261\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] Epoch[48] Batch[5] avg_epoch_loss=8.205492\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=8.2054921786\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] Epoch[48] Batch [5]#011Speed: 1569.10 samples/sec#011loss=8.205492\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] Epoch[48] Batch[10] avg_epoch_loss=8.146307\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=8.07528400421\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] Epoch[48] Batch [10]#011Speed: 961.42 samples/sec#011loss=8.075284\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] Epoch[48] Batch[15] avg_epoch_loss=8.269713\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=48, batch=15 train loss <loss>=8.54120769501\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] Epoch[48] Batch [15]#011Speed: 1920.75 samples/sec#011loss=8.541208\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] Epoch[48] Batch[20] avg_epoch_loss=8.316805\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=48, batch=20 train loss <loss>=8.46749916077\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] Epoch[48] Batch [20]#011Speed: 951.31 samples/sec#011loss=8.467499\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] Epoch[48] Batch[25] avg_epoch_loss=8.249974\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=48, batch=25 train loss <loss>=7.96928443909\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:53 INFO 139919921551168] Epoch[48] Batch [25]#011Speed: 2002.48 samples/sec#011loss=7.969284\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] Epoch[48] Batch[30] avg_epoch_loss=8.118678\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=48, batch=30 train loss <loss>=7.43593559265\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] Epoch[48] Batch [30]#011Speed: 881.77 samples/sec#011loss=7.435936\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] Epoch[48] Batch[35] avg_epoch_loss=8.052188\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=48, batch=35 train loss <loss>=7.63995246887\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] Epoch[48] Batch [35]#011Speed: 2036.30 samples/sec#011loss=7.639952\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] Epoch[48] Batch[40] avg_epoch_loss=8.045364\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=48, batch=40 train loss <loss>=7.9962313652\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] Epoch[48] Batch [40]#011Speed: 1034.53 samples/sec#011loss=7.996231\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] Epoch[48] Batch[45] avg_epoch_loss=8.025044\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=48, batch=45 train loss <loss>=7.85842132568\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] Epoch[48] Batch [45]#011Speed: 2088.97 samples/sec#011loss=7.858421\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] processed a total of 1573 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1257.7950954437256, \"sum\": 1257.7950954437256, \"min\": 1257.7950954437256}}, \"EndTime\": 1578471594.541139, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471593.282883}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1250.48690566 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=48, train loss <loss>=7.97237789154\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] Epoch[49] Batch[0] avg_epoch_loss=8.118739\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=8.11873912811\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] Epoch[49] Batch[5] avg_epoch_loss=8.356175\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=8.3561753432\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] Epoch[49] Batch [5]#011Speed: 2060.08 samples/sec#011loss=8.356175\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] Epoch[49] Batch[10] avg_epoch_loss=8.346597\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=8.33510398865\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] Epoch[49] Batch [10]#011Speed: 1028.36 samples/sec#011loss=8.335104\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] Epoch[49] Batch[15] avg_epoch_loss=8.434902\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=49, batch=15 train loss <loss>=8.62917346954\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:54 INFO 139919921551168] Epoch[49] Batch [15]#011Speed: 2067.24 samples/sec#011loss=8.629173\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] Epoch[49] Batch[20] avg_epoch_loss=8.394291\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=49, batch=20 train loss <loss>=8.26433591843\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] Epoch[49] Batch [20]#011Speed: 954.59 samples/sec#011loss=8.264336\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] Epoch[49] Batch[25] avg_epoch_loss=8.309771\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=49, batch=25 train loss <loss>=7.95478773117\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] Epoch[49] Batch [25]#011Speed: 2061.99 samples/sec#011loss=7.954788\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] Epoch[49] Batch[30] avg_epoch_loss=8.246874\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=49, batch=30 train loss <loss>=7.9198056221\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] Epoch[49] Batch [30]#011Speed: 901.25 samples/sec#011loss=7.919806\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] Epoch[49] Batch[35] avg_epoch_loss=8.197219\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=49, batch=35 train loss <loss>=7.88936223984\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] Epoch[49] Batch [35]#011Speed: 1926.18 samples/sec#011loss=7.889362\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] Epoch[49] Batch[40] avg_epoch_loss=8.149520\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=49, batch=40 train loss <loss>=7.80608301163\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] Epoch[49] Batch [40]#011Speed: 962.86 samples/sec#011loss=7.806083\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] Epoch[49] Batch[45] avg_epoch_loss=8.184606\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=49, batch=45 train loss <loss>=8.47231712341\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] Epoch[49] Batch [45]#011Speed: 1718.57 samples/sec#011loss=8.472317\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] Epoch[49] Batch[50] avg_epoch_loss=8.171057\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=49, batch=50 train loss <loss>=8.04639930725\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] Epoch[49] Batch [50]#011Speed: 1665.45 samples/sec#011loss=8.046399\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] processed a total of 1662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1285.893201828003, \"sum\": 1285.893201828003, \"min\": 1285.893201828003}}, \"EndTime\": 1578471595.827551, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471594.541218}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1292.37346781 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=49, train loss <loss>=8.1597571373\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] Epoch[50] Batch[0] avg_epoch_loss=8.106805\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=8.10680484772\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] Epoch[50] Batch[5] avg_epoch_loss=8.202025\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=8.20202549299\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] Epoch[50] Batch [5]#011Speed: 1690.40 samples/sec#011loss=8.202025\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] Epoch[50] Batch[10] avg_epoch_loss=8.280479\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=8.37462406158\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] Epoch[50] Batch [10]#011Speed: 941.24 samples/sec#011loss=8.374624\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] Epoch[50] Batch[15] avg_epoch_loss=8.391168\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=50, batch=15 train loss <loss>=8.63468151093\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] Epoch[50] Batch [15]#011Speed: 1550.64 samples/sec#011loss=8.634682\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] Epoch[50] Batch[20] avg_epoch_loss=8.355193\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=50, batch=20 train loss <loss>=8.24007349014\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] Epoch[50] Batch [20]#011Speed: 1066.86 samples/sec#011loss=8.240073\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] Epoch[50] Batch[25] avg_epoch_loss=8.240254\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=50, batch=25 train loss <loss>=7.75751199722\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] Epoch[50] Batch [25]#011Speed: 1658.26 samples/sec#011loss=7.757512\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] Epoch[50] Batch[30] avg_epoch_loss=8.159426\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=50, batch=30 train loss <loss>=7.73911952972\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] Epoch[50] Batch [30]#011Speed: 1033.67 samples/sec#011loss=7.739120\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] Epoch[50] Batch[35] avg_epoch_loss=8.124338\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=50, batch=35 train loss <loss>=7.90678911209\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] Epoch[50] Batch [35]#011Speed: 1664.86 samples/sec#011loss=7.906789\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] Epoch[50] Batch[40] avg_epoch_loss=8.105729\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=50, batch=40 train loss <loss>=7.97174396515\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:56 INFO 139919921551168] Epoch[50] Batch [40]#011Speed: 1066.07 samples/sec#011loss=7.971744\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] Epoch[50] Batch[45] avg_epoch_loss=8.099853\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=50, batch=45 train loss <loss>=8.05167379379\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] Epoch[50] Batch [45]#011Speed: 1670.69 samples/sec#011loss=8.051674\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] Epoch[50] Batch[50] avg_epoch_loss=8.041311\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=50, batch=50 train loss <loss>=7.50272035599\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] Epoch[50] Batch [50]#011Speed: 1472.56 samples/sec#011loss=7.502720\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] processed a total of 1656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1329.7309875488281, \"sum\": 1329.7309875488281, \"min\": 1329.7309875488281}}, \"EndTime\": 1578471597.157888, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471595.827625}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1245.25303973 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=50, train loss <loss>=8.01865175137\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] Epoch[51] Batch[0] avg_epoch_loss=8.480044\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=8.48004436493\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] Epoch[51] Batch[5] avg_epoch_loss=8.313951\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=8.31395053864\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] Epoch[51] Batch [5]#011Speed: 2052.02 samples/sec#011loss=8.313951\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] Epoch[51] Batch[10] avg_epoch_loss=8.374293\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=8.44670305252\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] Epoch[51] Batch [10]#011Speed: 1076.01 samples/sec#011loss=8.446703\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] Epoch[51] Batch[15] avg_epoch_loss=8.252455\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=51, batch=15 train loss <loss>=7.98441133499\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] Epoch[51] Batch [15]#011Speed: 2080.90 samples/sec#011loss=7.984411\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] Epoch[51] Batch[20] avg_epoch_loss=8.262238\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=51, batch=20 train loss <loss>=8.29354639053\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] Epoch[51] Batch [20]#011Speed: 903.05 samples/sec#011loss=8.293546\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] Epoch[51] Batch[25] avg_epoch_loss=8.209051\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=51, batch=25 train loss <loss>=7.98566141129\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:57 INFO 139919921551168] Epoch[51] Batch [25]#011Speed: 1863.44 samples/sec#011loss=7.985661\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] Epoch[51] Batch[30] avg_epoch_loss=8.196553\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=51, batch=30 train loss <loss>=8.13156347275\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] Epoch[51] Batch [30]#011Speed: 886.94 samples/sec#011loss=8.131563\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] Epoch[51] Batch[35] avg_epoch_loss=8.170660\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=51, batch=35 train loss <loss>=8.01012525558\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] Epoch[51] Batch [35]#011Speed: 1863.26 samples/sec#011loss=8.010125\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] Epoch[51] Batch[40] avg_epoch_loss=8.125498\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=51, batch=40 train loss <loss>=7.80033502579\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] Epoch[51] Batch [40]#011Speed: 1013.08 samples/sec#011loss=7.800335\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] Epoch[51] Batch[45] avg_epoch_loss=8.123216\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=51, batch=45 train loss <loss>=8.10450153351\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] Epoch[51] Batch [45]#011Speed: 1795.01 samples/sec#011loss=8.104502\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] processed a total of 1592 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1257.4620246887207, \"sum\": 1257.4620246887207, \"min\": 1257.4620246887207}}, \"EndTime\": 1578471598.41588, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471597.157971}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1265.9205181 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=51, train loss <loss>=8.07301988602\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] Epoch[52] Batch[0] avg_epoch_loss=7.933792\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=7.93379163742\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] Epoch[52] Batch[5] avg_epoch_loss=8.402704\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=8.40270431836\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] Epoch[52] Batch [5]#011Speed: 2007.53 samples/sec#011loss=8.402704\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] Epoch[52] Batch[10] avg_epoch_loss=8.380725\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=8.35435085297\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] Epoch[52] Batch [10]#011Speed: 1084.41 samples/sec#011loss=8.354351\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] Epoch[52] Batch[15] avg_epoch_loss=8.457503\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=52, batch=15 train loss <loss>=8.62641448975\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:58 INFO 139919921551168] Epoch[52] Batch [15]#011Speed: 2009.77 samples/sec#011loss=8.626414\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] Epoch[52] Batch[20] avg_epoch_loss=8.421338\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=52, batch=20 train loss <loss>=8.30560874939\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] Epoch[52] Batch [20]#011Speed: 890.61 samples/sec#011loss=8.305609\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] Epoch[52] Batch[25] avg_epoch_loss=8.372045\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=52, batch=25 train loss <loss>=8.16501636505\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] Epoch[52] Batch [25]#011Speed: 1921.16 samples/sec#011loss=8.165016\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] Epoch[52] Batch[30] avg_epoch_loss=8.284524\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=52, batch=30 train loss <loss>=7.82941617966\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] Epoch[52] Batch [30]#011Speed: 874.82 samples/sec#011loss=7.829416\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] Epoch[52] Batch[35] avg_epoch_loss=8.204223\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=52, batch=35 train loss <loss>=7.70635347366\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] Epoch[52] Batch [35]#011Speed: 1976.16 samples/sec#011loss=7.706353\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] Epoch[52] Batch[40] avg_epoch_loss=8.189635\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=52, batch=40 train loss <loss>=8.08460006714\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] Epoch[52] Batch [40]#011Speed: 1058.32 samples/sec#011loss=8.084600\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] Epoch[52] Batch[45] avg_epoch_loss=8.182837\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=52, batch=45 train loss <loss>=8.12709589005\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] Epoch[52] Batch [45]#011Speed: 1945.34 samples/sec#011loss=8.127096\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] Epoch[52] Batch[50] avg_epoch_loss=8.107645\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=52, batch=50 train loss <loss>=7.41587266922\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] Epoch[52] Batch [50]#011Speed: 1495.57 samples/sec#011loss=7.415873\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] processed a total of 1630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1274.4641304016113, \"sum\": 1274.4641304016113, \"min\": 1274.4641304016113}}, \"EndTime\": 1578471599.690891, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471598.415967}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1278.87177753 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=52, train loss <loss>=8.10764450185\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] Epoch[53] Batch[0] avg_epoch_loss=7.909995\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=7.90999507904\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] Epoch[53] Batch[5] avg_epoch_loss=8.114756\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=8.11475563049\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:19:59 INFO 139919921551168] Epoch[53] Batch [5]#011Speed: 2082.57 samples/sec#011loss=8.114756\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] Epoch[53] Batch[10] avg_epoch_loss=8.271866\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=8.46039867401\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] Epoch[53] Batch [10]#011Speed: 927.62 samples/sec#011loss=8.460399\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] Epoch[53] Batch[15] avg_epoch_loss=8.306461\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=53, batch=15 train loss <loss>=8.38257055283\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] Epoch[53] Batch [15]#011Speed: 1762.60 samples/sec#011loss=8.382571\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] Epoch[53] Batch[20] avg_epoch_loss=8.307832\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=53, batch=20 train loss <loss>=8.31221637726\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] Epoch[53] Batch [20]#011Speed: 916.44 samples/sec#011loss=8.312216\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] Epoch[53] Batch[25] avg_epoch_loss=8.233459\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=53, batch=25 train loss <loss>=7.92109556198\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] Epoch[53] Batch [25]#011Speed: 2043.24 samples/sec#011loss=7.921096\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] Epoch[53] Batch[30] avg_epoch_loss=8.165009\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=53, batch=30 train loss <loss>=7.80906534195\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] Epoch[53] Batch [30]#011Speed: 935.02 samples/sec#011loss=7.809065\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] Epoch[53] Batch[35] avg_epoch_loss=8.118994\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=53, batch=35 train loss <loss>=7.83370695114\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] Epoch[53] Batch [35]#011Speed: 1781.44 samples/sec#011loss=7.833707\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] Epoch[53] Batch[40] avg_epoch_loss=8.084752\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=53, batch=40 train loss <loss>=7.83820571899\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] Epoch[53] Batch [40]#011Speed: 934.97 samples/sec#011loss=7.838206\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] Epoch[53] Batch[45] avg_epoch_loss=8.035773\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=53, batch=45 train loss <loss>=7.63414573669\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:00 INFO 139919921551168] Epoch[53] Batch [45]#011Speed: 1760.58 samples/sec#011loss=7.634146\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] Epoch[53] Batch[50] avg_epoch_loss=8.013169\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=53, batch=50 train loss <loss>=7.80520868301\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] Epoch[53] Batch [50]#011Speed: 1383.89 samples/sec#011loss=7.805209\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] processed a total of 1637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1346.7628955841064, \"sum\": 1346.7628955841064, \"min\": 1346.7628955841064}}, \"EndTime\": 1578471601.038156, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471599.690955}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1215.40349376 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=53, train loss <loss>=8.00400817394\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] Epoch[54] Batch[0] avg_epoch_loss=8.208475\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=8.20847511292\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] Epoch[54] Batch[5] avg_epoch_loss=8.280498\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=8.2804980278\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] Epoch[54] Batch [5]#011Speed: 1647.46 samples/sec#011loss=8.280498\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] Epoch[54] Batch[10] avg_epoch_loss=8.198368\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=8.09981184006\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] Epoch[54] Batch [10]#011Speed: 990.44 samples/sec#011loss=8.099812\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] Epoch[54] Batch[15] avg_epoch_loss=8.276840\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=54, batch=15 train loss <loss>=8.449477005\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] Epoch[54] Batch [15]#011Speed: 2063.58 samples/sec#011loss=8.449477\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] Epoch[54] Batch[20] avg_epoch_loss=8.245207\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=54, batch=20 train loss <loss>=8.14398212433\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] Epoch[54] Batch [20]#011Speed: 1094.69 samples/sec#011loss=8.143982\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] Epoch[54] Batch[25] avg_epoch_loss=8.214668\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=54, batch=25 train loss <loss>=8.08640518188\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] Epoch[54] Batch [25]#011Speed: 2051.89 samples/sec#011loss=8.086405\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] Epoch[54] Batch[30] avg_epoch_loss=8.142273\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=54, batch=30 train loss <loss>=7.76582164764\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] Epoch[54] Batch [30]#011Speed: 1109.92 samples/sec#011loss=7.765822\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] Epoch[54] Batch[35] avg_epoch_loss=8.108626\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=54, batch=35 train loss <loss>=7.90000953674\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:01 INFO 139919921551168] Epoch[54] Batch [35]#011Speed: 1989.55 samples/sec#011loss=7.900010\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] Epoch[54] Batch[40] avg_epoch_loss=8.070964\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=54, batch=40 train loss <loss>=7.79979581833\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] Epoch[54] Batch [40]#011Speed: 1049.11 samples/sec#011loss=7.799796\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] Epoch[54] Batch[45] avg_epoch_loss=8.024727\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=54, batch=45 train loss <loss>=7.64558973312\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] Epoch[54] Batch [45]#011Speed: 1977.51 samples/sec#011loss=7.645590\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] processed a total of 1578 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1200.3021240234375, \"sum\": 1200.3021240234375, \"min\": 1200.3021240234375}}, \"EndTime\": 1578471602.239012, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471601.03824}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1314.54315049 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=54, train loss <loss>=7.99077312469\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] Epoch[55] Batch[0] avg_epoch_loss=7.821479\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=7.82147884369\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] Epoch[55] Batch[5] avg_epoch_loss=8.155522\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=8.15552186966\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] Epoch[55] Batch [5]#011Speed: 1693.14 samples/sec#011loss=8.155522\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] Epoch[55] Batch[10] avg_epoch_loss=8.178257\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=8.20553836823\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] Epoch[55] Batch [10]#011Speed: 1041.84 samples/sec#011loss=8.205538\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] Epoch[55] Batch[15] avg_epoch_loss=8.270493\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=55, batch=15 train loss <loss>=8.473412323\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] Epoch[55] Batch [15]#011Speed: 1881.00 samples/sec#011loss=8.473412\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] Epoch[55] Batch[20] avg_epoch_loss=8.202855\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=55, batch=20 train loss <loss>=7.9864159584\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] Epoch[55] Batch [20]#011Speed: 1033.20 samples/sec#011loss=7.986416\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] Epoch[55] Batch[25] avg_epoch_loss=8.184005\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=55, batch=25 train loss <loss>=8.10483551025\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:02 INFO 139919921551168] Epoch[55] Batch [25]#011Speed: 1655.75 samples/sec#011loss=8.104836\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] Epoch[55] Batch[30] avg_epoch_loss=8.155659\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=55, batch=30 train loss <loss>=8.00825920105\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] Epoch[55] Batch [30]#011Speed: 931.68 samples/sec#011loss=8.008259\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] Epoch[55] Batch[35] avg_epoch_loss=8.122369\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=55, batch=35 train loss <loss>=7.91596632004\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] Epoch[55] Batch [35]#011Speed: 1742.54 samples/sec#011loss=7.915966\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] Epoch[55] Batch[40] avg_epoch_loss=8.106240\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=55, batch=40 train loss <loss>=7.99011669159\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] Epoch[55] Batch [40]#011Speed: 965.87 samples/sec#011loss=7.990117\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] Epoch[55] Batch[45] avg_epoch_loss=8.146003\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=55, batch=45 train loss <loss>=8.47205791473\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] Epoch[55] Batch [45]#011Speed: 1974.28 samples/sec#011loss=8.472058\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] processed a total of 1600 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1286.4019870758057, \"sum\": 1286.4019870758057, \"min\": 1286.4019870758057}}, \"EndTime\": 1578471603.525922, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471602.239092}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1243.66507686 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=55, train loss <loss>=8.06622473717\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] Epoch[56] Batch[0] avg_epoch_loss=8.347116\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=8.34711647034\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] Epoch[56] Batch[5] avg_epoch_loss=8.192360\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=8.19235984484\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] Epoch[56] Batch [5]#011Speed: 1631.27 samples/sec#011loss=8.192360\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] Epoch[56] Batch[10] avg_epoch_loss=8.145657\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=56, batch=10 train loss <loss>=8.08961410522\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] Epoch[56] Batch [10]#011Speed: 933.17 samples/sec#011loss=8.089614\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] Epoch[56] Batch[15] avg_epoch_loss=8.181595\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=56, batch=15 train loss <loss>=8.26065950394\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:03 INFO 139919921551168] Epoch[56] Batch [15]#011Speed: 1910.06 samples/sec#011loss=8.260660\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] Epoch[56] Batch[20] avg_epoch_loss=8.231549\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=56, batch=20 train loss <loss>=8.39140090942\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] Epoch[56] Batch [20]#011Speed: 999.89 samples/sec#011loss=8.391401\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] Epoch[56] Batch[25] avg_epoch_loss=8.213732\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=56, batch=25 train loss <loss>=8.13889818192\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] Epoch[56] Batch [25]#011Speed: 1846.19 samples/sec#011loss=8.138898\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] Epoch[56] Batch[30] avg_epoch_loss=8.154520\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=56, batch=30 train loss <loss>=7.84661741257\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] Epoch[56] Batch [30]#011Speed: 1034.15 samples/sec#011loss=7.846617\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] Epoch[56] Batch[35] avg_epoch_loss=8.114065\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=56, batch=35 train loss <loss>=7.86324501038\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] Epoch[56] Batch [35]#011Speed: 1939.56 samples/sec#011loss=7.863245\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] Epoch[56] Batch[40] avg_epoch_loss=8.074308\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=56, batch=40 train loss <loss>=7.78805484772\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] Epoch[56] Batch [40]#011Speed: 1054.32 samples/sec#011loss=7.788055\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] Epoch[56] Batch[45] avg_epoch_loss=8.065143\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=56, batch=45 train loss <loss>=7.98999128342\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] Epoch[56] Batch [45]#011Speed: 1896.27 samples/sec#011loss=7.989991\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] Epoch[56] Batch[50] avg_epoch_loss=8.028348\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=56, batch=50 train loss <loss>=7.68983182907\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] Epoch[56] Batch [50]#011Speed: 1749.42 samples/sec#011loss=7.689832\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] processed a total of 1611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1282.5829982757568, \"sum\": 1282.5829982757568, \"min\": 1282.5829982757568}}, \"EndTime\": 1578471604.809037, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471603.526004}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1255.95213532 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=56, train loss <loss>=8.02834753897\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] Epoch[57] Batch[0] avg_epoch_loss=7.649591\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=7.64959144592\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] Epoch[57] Batch[5] avg_epoch_loss=8.119497\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=8.11949666341\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:04 INFO 139919921551168] Epoch[57] Batch [5]#011Speed: 1728.67 samples/sec#011loss=8.119497\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:05 INFO 139919921551168] Epoch[57] Batch[10] avg_epoch_loss=8.238019\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=8.38024625778\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:05 INFO 139919921551168] Epoch[57] Batch [10]#011Speed: 938.33 samples/sec#011loss=8.380246\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:05 INFO 139919921551168] Epoch[57] Batch[15] avg_epoch_loss=8.274038\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=57, batch=15 train loss <loss>=8.35327777863\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:05 INFO 139919921551168] Epoch[57] Batch [15]#011Speed: 2143.79 samples/sec#011loss=8.353278\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:05 INFO 139919921551168] Epoch[57] Batch[20] avg_epoch_loss=8.356004\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=57, batch=20 train loss <loss>=8.61829624176\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:05 INFO 139919921551168] Epoch[57] Batch [20]#011Speed: 856.58 samples/sec#011loss=8.618296\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:05 INFO 139919921551168] Epoch[57] Batch[25] avg_epoch_loss=8.348279\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=57, batch=25 train loss <loss>=8.31583433151\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:05 INFO 139919921551168] Epoch[57] Batch [25]#011Speed: 1728.08 samples/sec#011loss=8.315834\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:05 INFO 139919921551168] Epoch[57] Batch[30] avg_epoch_loss=8.247970\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=57, batch=30 train loss <loss>=7.72636098862\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:05 INFO 139919921551168] Epoch[57] Batch [30]#011Speed: 980.52 samples/sec#011loss=7.726361\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:05 INFO 139919921551168] Epoch[57] Batch[35] avg_epoch_loss=8.175976\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=57, batch=35 train loss <loss>=7.72961893082\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:05 INFO 139919921551168] Epoch[57] Batch [35]#011Speed: 1874.83 samples/sec#011loss=7.729619\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:05 INFO 139919921551168] Epoch[57] Batch[40] avg_epoch_loss=8.141802\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=57, batch=40 train loss <loss>=7.89574728012\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:05 INFO 139919921551168] Epoch[57] Batch [40]#011Speed: 957.01 samples/sec#011loss=7.895747\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] Epoch[57] Batch[45] avg_epoch_loss=8.132615\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=57, batch=45 train loss <loss>=8.05728111267\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] Epoch[57] Batch [45]#011Speed: 2018.67 samples/sec#011loss=8.057281\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] processed a total of 1593 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1291.7799949645996, \"sum\": 1291.7799949645996, \"min\": 1291.7799949645996}}, \"EndTime\": 1578471606.101303, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471604.809111}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1233.07516128 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=57, train loss <loss>=8.11979301453\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] Epoch[58] Batch[0] avg_epoch_loss=7.690566\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=7.69056606293\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] Epoch[58] Batch[5] avg_epoch_loss=8.042214\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=8.04221423467\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] Epoch[58] Batch [5]#011Speed: 1879.41 samples/sec#011loss=8.042214\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] Epoch[58] Batch[10] avg_epoch_loss=8.159136\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=8.29944257736\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] Epoch[58] Batch [10]#011Speed: 1076.62 samples/sec#011loss=8.299443\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] Epoch[58] Batch[15] avg_epoch_loss=8.158633\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=58, batch=15 train loss <loss>=8.15752687454\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] Epoch[58] Batch [15]#011Speed: 1763.85 samples/sec#011loss=8.157527\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] Epoch[58] Batch[20] avg_epoch_loss=8.136348\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=58, batch=20 train loss <loss>=8.0650346756\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] Epoch[58] Batch [20]#011Speed: 954.50 samples/sec#011loss=8.065035\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] Epoch[58] Batch[25] avg_epoch_loss=8.052894\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=58, batch=25 train loss <loss>=7.70238733292\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] Epoch[58] Batch [25]#011Speed: 1789.88 samples/sec#011loss=7.702387\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] Epoch[58] Batch[30] avg_epoch_loss=8.000026\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=58, batch=30 train loss <loss>=7.72511072159\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:06 INFO 139919921551168] Epoch[58] Batch [30]#011Speed: 968.65 samples/sec#011loss=7.725111\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] Epoch[58] Batch[35] avg_epoch_loss=7.956478\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=58, batch=35 train loss <loss>=7.68648033142\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] Epoch[58] Batch [35]#011Speed: 1629.91 samples/sec#011loss=7.686480\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] Epoch[58] Batch[40] avg_epoch_loss=7.956414\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=58, batch=40 train loss <loss>=7.95595655441\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] Epoch[58] Batch [40]#011Speed: 962.01 samples/sec#011loss=7.955957\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] Epoch[58] Batch[45] avg_epoch_loss=7.976547\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=58, batch=45 train loss <loss>=8.1416352272\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] Epoch[58] Batch [45]#011Speed: 1659.08 samples/sec#011loss=8.141635\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] processed a total of 1559 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1284.153938293457, \"sum\": 1284.153938293457, \"min\": 1284.153938293457}}, \"EndTime\": 1578471607.385989, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471606.10138}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1213.9344705 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=58, train loss <loss>=7.95438241959\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] Saved checkpoint to \"/opt/ml/model/state_06fd1318-feb2-4129-a4be-04639cd6fa68-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.113000869750977, \"sum\": 10.113000869750977, \"min\": 10.113000869750977}}, \"EndTime\": 1578471607.396681, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471607.386051}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] Epoch[59] Batch[0] avg_epoch_loss=8.307021\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=8.30702114105\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] Epoch[59] Batch[5] avg_epoch_loss=8.455705\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=8.45570500692\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] Epoch[59] Batch [5]#011Speed: 1657.03 samples/sec#011loss=8.455705\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] Epoch[59] Batch[10] avg_epoch_loss=8.498091\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=8.54895496368\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] Epoch[59] Batch [10]#011Speed: 838.18 samples/sec#011loss=8.548955\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] Epoch[59] Batch[15] avg_epoch_loss=8.540388\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=59, batch=15 train loss <loss>=8.63344135284\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:07 INFO 139919921551168] Epoch[59] Batch [15]#011Speed: 1893.22 samples/sec#011loss=8.633441\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] Epoch[59] Batch[20] avg_epoch_loss=8.467516\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=59, batch=20 train loss <loss>=8.2343252182\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] Epoch[59] Batch [20]#011Speed: 929.08 samples/sec#011loss=8.234325\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] Epoch[59] Batch[25] avg_epoch_loss=8.322642\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=59, batch=25 train loss <loss>=7.71417045593\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] Epoch[59] Batch [25]#011Speed: 1882.11 samples/sec#011loss=7.714170\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] Epoch[59] Batch[30] avg_epoch_loss=8.235322\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=59, batch=30 train loss <loss>=7.78125543594\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] Epoch[59] Batch [30]#011Speed: 867.17 samples/sec#011loss=7.781255\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] Epoch[59] Batch[35] avg_epoch_loss=8.174723\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=59, batch=35 train loss <loss>=7.79901237488\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] Epoch[59] Batch [35]#011Speed: 2098.31 samples/sec#011loss=7.799012\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] Epoch[59] Batch[40] avg_epoch_loss=8.127826\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=59, batch=40 train loss <loss>=7.79016590118\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] Epoch[59] Batch [40]#011Speed: 996.13 samples/sec#011loss=7.790166\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] Epoch[59] Batch[45] avg_epoch_loss=8.126379\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=59, batch=45 train loss <loss>=8.1145113945\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] Epoch[59] Batch [45]#011Speed: 1734.38 samples/sec#011loss=8.114511\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] Epoch[59] Batch[50] avg_epoch_loss=8.084346\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=59, batch=50 train loss <loss>=7.6976474762\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] Epoch[59] Batch [50]#011Speed: 1722.95 samples/sec#011loss=7.697647\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] processed a total of 1661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1348.620891571045, \"sum\": 1348.620891571045, \"min\": 1348.620891571045}}, \"EndTime\": 1578471608.745424, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471607.396749}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1231.5279693 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=59, train loss <loss>=8.07216000557\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] Epoch[60] Batch[0] avg_epoch_loss=7.832982\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=7.83298158646\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] Epoch[60] Batch[5] avg_epoch_loss=8.092765\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=8.09276469549\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:08 INFO 139919921551168] Epoch[60] Batch [5]#011Speed: 1941.06 samples/sec#011loss=8.092765\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] Epoch[60] Batch[10] avg_epoch_loss=8.074996\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=8.05367393494\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] Epoch[60] Batch [10]#011Speed: 1075.35 samples/sec#011loss=8.053674\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] Epoch[60] Batch[15] avg_epoch_loss=8.210847\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=60, batch=15 train loss <loss>=8.50971794128\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] Epoch[60] Batch [15]#011Speed: 2019.59 samples/sec#011loss=8.509718\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] Epoch[60] Batch[20] avg_epoch_loss=8.184038\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=60, batch=20 train loss <loss>=8.09824905396\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] Epoch[60] Batch [20]#011Speed: 1051.95 samples/sec#011loss=8.098249\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] Epoch[60] Batch[25] avg_epoch_loss=8.150936\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=60, batch=25 train loss <loss>=8.01190910339\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] Epoch[60] Batch [25]#011Speed: 1972.82 samples/sec#011loss=8.011909\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] Epoch[60] Batch[30] avg_epoch_loss=8.104559\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=60, batch=30 train loss <loss>=7.86340093613\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] Epoch[60] Batch [30]#011Speed: 892.70 samples/sec#011loss=7.863401\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] Epoch[60] Batch[35] avg_epoch_loss=8.036984\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=60, batch=35 train loss <loss>=7.61801605225\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] Epoch[60] Batch [35]#011Speed: 2053.73 samples/sec#011loss=7.618016\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] Epoch[60] Batch[40] avg_epoch_loss=8.021587\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=60, batch=40 train loss <loss>=7.91072883606\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] Epoch[60] Batch [40]#011Speed: 931.98 samples/sec#011loss=7.910729\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] Epoch[60] Batch[45] avg_epoch_loss=8.019222\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=60, batch=45 train loss <loss>=7.9998251915\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:09 INFO 139919921551168] Epoch[60] Batch [45]#011Speed: 1635.53 samples/sec#011loss=7.999825\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] Epoch[60] Batch[50] avg_epoch_loss=7.991169\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=60, batch=50 train loss <loss>=7.73308906555\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] Epoch[60] Batch [50]#011Speed: 1498.91 samples/sec#011loss=7.733089\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] processed a total of 1684 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1330.7311534881592, \"sum\": 1330.7311534881592, \"min\": 1330.7311534881592}}, \"EndTime\": 1578471610.076653, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471608.745501}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1265.36431602 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=60, train loss <loss>=7.99003726132\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] Epoch[61] Batch[0] avg_epoch_loss=8.152049\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=8.15204906464\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] Epoch[61] Batch[5] avg_epoch_loss=8.356881\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=8.35688066483\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] Epoch[61] Batch [5]#011Speed: 2109.35 samples/sec#011loss=8.356881\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] Epoch[61] Batch[10] avg_epoch_loss=8.365848\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=8.37660903931\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] Epoch[61] Batch [10]#011Speed: 884.52 samples/sec#011loss=8.376609\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] Epoch[61] Batch[15] avg_epoch_loss=8.395308\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=61, batch=15 train loss <loss>=8.46011886597\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] Epoch[61] Batch [15]#011Speed: 1869.23 samples/sec#011loss=8.460119\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] Epoch[61] Batch[20] avg_epoch_loss=8.382798\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=61, batch=20 train loss <loss>=8.34276752472\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] Epoch[61] Batch [20]#011Speed: 1930.15 samples/sec#011loss=8.342768\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] Epoch[61] Batch[25] avg_epoch_loss=8.362471\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=61, batch=25 train loss <loss>=8.27709522247\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] Epoch[61] Batch [25]#011Speed: 926.76 samples/sec#011loss=8.277095\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] Epoch[61] Batch[30] avg_epoch_loss=8.301433\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=61, batch=30 train loss <loss>=7.98403749466\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:10 INFO 139919921551168] Epoch[61] Batch [30]#011Speed: 2073.30 samples/sec#011loss=7.984037\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] Epoch[61] Batch[35] avg_epoch_loss=8.192466\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=61, batch=35 train loss <loss>=7.51687355042\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] Epoch[61] Batch [35]#011Speed: 898.74 samples/sec#011loss=7.516874\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] Epoch[61] Batch[40] avg_epoch_loss=8.130492\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=61, batch=40 train loss <loss>=7.68427581787\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] Epoch[61] Batch [40]#011Speed: 1617.11 samples/sec#011loss=7.684276\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] Epoch[61] Batch[45] avg_epoch_loss=8.146846\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=61, batch=45 train loss <loss>=8.28095207214\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] Epoch[61] Batch [45]#011Speed: 901.43 samples/sec#011loss=8.280952\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] Epoch[61] Batch[50] avg_epoch_loss=8.115695\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=61, batch=50 train loss <loss>=7.8291015625\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] Epoch[61] Batch [50]#011Speed: 1638.91 samples/sec#011loss=7.829102\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] processed a total of 1674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1370.290994644165, \"sum\": 1370.290994644165, \"min\": 1370.290994644165}}, \"EndTime\": 1578471611.447534, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471610.076726}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1221.55628785 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=61, train loss <loss>=8.08082321455\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] Epoch[62] Batch[0] avg_epoch_loss=8.123685\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=8.12368488312\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] Epoch[62] Batch[5] avg_epoch_loss=8.134099\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=8.13409948349\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] Epoch[62] Batch [5]#011Speed: 1632.37 samples/sec#011loss=8.134099\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] Epoch[62] Batch[10] avg_epoch_loss=8.261448\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=8.41426610947\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] Epoch[62] Batch [10]#011Speed: 823.23 samples/sec#011loss=8.414266\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] Epoch[62] Batch[15] avg_epoch_loss=8.414491\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=62, batch=15 train loss <loss>=8.75118637085\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:11 INFO 139919921551168] Epoch[62] Batch [15]#011Speed: 1944.06 samples/sec#011loss=8.751186\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] Epoch[62] Batch[20] avg_epoch_loss=8.321841\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=62, batch=20 train loss <loss>=8.0253610611\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] Epoch[62] Batch [20]#011Speed: 973.89 samples/sec#011loss=8.025361\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] Epoch[62] Batch[25] avg_epoch_loss=8.267855\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=62, batch=25 train loss <loss>=8.04111442566\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] Epoch[62] Batch [25]#011Speed: 2157.06 samples/sec#011loss=8.041114\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] Epoch[62] Batch[30] avg_epoch_loss=8.178283\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=62, batch=30 train loss <loss>=7.71250524521\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] Epoch[62] Batch [30]#011Speed: 956.65 samples/sec#011loss=7.712505\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] Epoch[62] Batch[35] avg_epoch_loss=8.107660\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=62, batch=35 train loss <loss>=7.66979866028\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] Epoch[62] Batch [35]#011Speed: 1988.52 samples/sec#011loss=7.669799\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] Epoch[62] Batch[40] avg_epoch_loss=8.112529\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=62, batch=40 train loss <loss>=8.14759044647\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] Epoch[62] Batch [40]#011Speed: 962.52 samples/sec#011loss=8.147590\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] Epoch[62] Batch[45] avg_epoch_loss=8.030747\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=62, batch=45 train loss <loss>=7.36012945175\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] Epoch[62] Batch [45]#011Speed: 1515.91 samples/sec#011loss=7.360129\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] processed a total of 1504 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1248.610019683838, \"sum\": 1248.610019683838, \"min\": 1248.610019683838}}, \"EndTime\": 1578471612.696727, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471611.447592}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1204.43823587 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=62, train loss <loss>=8.00673891636\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] Epoch[63] Batch[0] avg_epoch_loss=8.477230\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=8.47723007202\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] Epoch[63] Batch[5] avg_epoch_loss=8.031021\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=8.0310207208\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:12 INFO 139919921551168] Epoch[63] Batch [5]#011Speed: 2143.71 samples/sec#011loss=8.031021\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] Epoch[63] Batch[10] avg_epoch_loss=8.148384\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=8.28922080994\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] Epoch[63] Batch [10]#011Speed: 967.83 samples/sec#011loss=8.289221\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] Epoch[63] Batch[15] avg_epoch_loss=8.172119\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=63, batch=15 train loss <loss>=8.22433662415\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] Epoch[63] Batch [15]#011Speed: 1930.62 samples/sec#011loss=8.224337\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] Epoch[63] Batch[20] avg_epoch_loss=8.200941\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=63, batch=20 train loss <loss>=8.29317121506\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] Epoch[63] Batch [20]#011Speed: 988.72 samples/sec#011loss=8.293171\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] Epoch[63] Batch[25] avg_epoch_loss=8.135974\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=63, batch=25 train loss <loss>=7.86311206818\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] Epoch[63] Batch [25]#011Speed: 1947.95 samples/sec#011loss=7.863112\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] Epoch[63] Batch[30] avg_epoch_loss=8.080305\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=63, batch=30 train loss <loss>=7.7908285141\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] Epoch[63] Batch [30]#011Speed: 944.35 samples/sec#011loss=7.790829\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] Epoch[63] Batch[35] avg_epoch_loss=8.061426\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=63, batch=35 train loss <loss>=7.94437093735\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] Epoch[63] Batch [35]#011Speed: 1585.05 samples/sec#011loss=7.944371\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] Epoch[63] Batch[40] avg_epoch_loss=8.063318\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=63, batch=40 train loss <loss>=8.07693977356\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] Epoch[63] Batch [40]#011Speed: 1020.47 samples/sec#011loss=8.076940\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] Epoch[63] Batch[45] avg_epoch_loss=8.061395\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=63, batch=45 train loss <loss>=8.04563007355\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] Epoch[63] Batch [45]#011Speed: 2134.39 samples/sec#011loss=8.045630\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] processed a total of 1575 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1244.1859245300293, \"sum\": 1244.1859245300293, \"min\": 1244.1859245300293}}, \"EndTime\": 1578471613.941467, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471612.6968}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1265.7730034 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=63, train loss <loss>=8.03236757278\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:13 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:14 INFO 139919921551168] Epoch[64] Batch[0] avg_epoch_loss=8.165965\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=8.16596508026\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:14 INFO 139919921551168] Epoch[64] Batch[5] avg_epoch_loss=8.094407\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=8.09440660477\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:14 INFO 139919921551168] Epoch[64] Batch [5]#011Speed: 2064.36 samples/sec#011loss=8.094407\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:14 INFO 139919921551168] Epoch[64] Batch[10] avg_epoch_loss=8.169077\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=8.2586807251\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:14 INFO 139919921551168] Epoch[64] Batch [10]#011Speed: 910.84 samples/sec#011loss=8.258681\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:14 INFO 139919921551168] Epoch[64] Batch[15] avg_epoch_loss=8.286440\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=64, batch=15 train loss <loss>=8.54464092255\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:14 INFO 139919921551168] Epoch[64] Batch [15]#011Speed: 2123.00 samples/sec#011loss=8.544641\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:14 INFO 139919921551168] Epoch[64] Batch[20] avg_epoch_loss=8.316918\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=64, batch=20 train loss <loss>=8.41444702148\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:14 INFO 139919921551168] Epoch[64] Batch [20]#011Speed: 933.59 samples/sec#011loss=8.414447\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:14 INFO 139919921551168] Epoch[64] Batch[25] avg_epoch_loss=8.264803\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=64, batch=25 train loss <loss>=8.04591741562\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:14 INFO 139919921551168] Epoch[64] Batch [25]#011Speed: 1887.37 samples/sec#011loss=8.045917\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:14 INFO 139919921551168] Epoch[64] Batch[30] avg_epoch_loss=8.194133\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=64, batch=30 train loss <loss>=7.82665071487\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:14 INFO 139919921551168] Epoch[64] Batch [30]#011Speed: 872.39 samples/sec#011loss=7.826651\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:14 INFO 139919921551168] Epoch[64] Batch[35] avg_epoch_loss=8.131892\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=64, batch=35 train loss <loss>=7.74599590302\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:14 INFO 139919921551168] Epoch[64] Batch [35]#011Speed: 1556.69 samples/sec#011loss=7.745996\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] Epoch[64] Batch[40] avg_epoch_loss=8.102653\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=64, batch=40 train loss <loss>=7.89213581085\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] Epoch[64] Batch [40]#011Speed: 1067.73 samples/sec#011loss=7.892136\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] Epoch[64] Batch[45] avg_epoch_loss=8.072842\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=64, batch=45 train loss <loss>=7.82838840485\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] Epoch[64] Batch [45]#011Speed: 1901.93 samples/sec#011loss=7.828388\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] Epoch[64] Batch[50] avg_epoch_loss=8.034621\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=64, batch=50 train loss <loss>=7.68298912048\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] Epoch[64] Batch [50]#011Speed: 1220.88 samples/sec#011loss=7.682989\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] processed a total of 1610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1340.6720161437988, \"sum\": 1340.6720161437988, \"min\": 1340.6720161437988}}, \"EndTime\": 1578471615.282657, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471613.941544}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1200.78992029 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=64, train loss <loss>=8.03462097692\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] Epoch[65] Batch[0] avg_epoch_loss=8.260931\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=8.26093101501\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] Epoch[65] Batch[5] avg_epoch_loss=8.048899\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=8.0488986969\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] Epoch[65] Batch [5]#011Speed: 2047.13 samples/sec#011loss=8.048899\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] Epoch[65] Batch[10] avg_epoch_loss=8.252822\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=8.49753093719\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] Epoch[65] Batch [10]#011Speed: 974.22 samples/sec#011loss=8.497531\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] Epoch[65] Batch[15] avg_epoch_loss=8.387376\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=65, batch=15 train loss <loss>=8.68339309692\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] Epoch[65] Batch [15]#011Speed: 1764.88 samples/sec#011loss=8.683393\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] Epoch[65] Batch[20] avg_epoch_loss=8.335143\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=65, batch=20 train loss <loss>=8.16799793243\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] Epoch[65] Batch [20]#011Speed: 954.10 samples/sec#011loss=8.167998\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] Epoch[65] Batch[25] avg_epoch_loss=8.279026\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=65, batch=25 train loss <loss>=8.04333591461\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:15 INFO 139919921551168] Epoch[65] Batch [25]#011Speed: 2151.75 samples/sec#011loss=8.043336\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] Epoch[65] Batch[30] avg_epoch_loss=8.229627\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=65, batch=30 train loss <loss>=7.97275133133\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] Epoch[65] Batch [30]#011Speed: 1028.05 samples/sec#011loss=7.972751\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] Epoch[65] Batch[35] avg_epoch_loss=8.195366\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=65, batch=35 train loss <loss>=7.9829460144\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] Epoch[65] Batch [35]#011Speed: 2026.01 samples/sec#011loss=7.982946\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] Epoch[65] Batch[40] avg_epoch_loss=8.156557\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=65, batch=40 train loss <loss>=7.87713680267\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] Epoch[65] Batch [40]#011Speed: 941.76 samples/sec#011loss=7.877137\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] Epoch[65] Batch[45] avg_epoch_loss=8.109358\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=65, batch=45 train loss <loss>=7.72232532501\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] Epoch[65] Batch [45]#011Speed: 2127.83 samples/sec#011loss=7.722325\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] Epoch[65] Batch[50] avg_epoch_loss=8.086504\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=65, batch=50 train loss <loss>=7.87624139786\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] Epoch[65] Batch [50]#011Speed: 1531.22 samples/sec#011loss=7.876241\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] processed a total of 1625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1272.650957107544, \"sum\": 1272.650957107544, \"min\": 1272.650957107544}}, \"EndTime\": 1578471616.555811, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471615.282734}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1276.7527302 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=65, train loss <loss>=8.08650364595\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] Epoch[66] Batch[0] avg_epoch_loss=8.595081\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=8.59508132935\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] Epoch[66] Batch[5] avg_epoch_loss=8.075747\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=8.07574748993\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] Epoch[66] Batch [5]#011Speed: 1911.59 samples/sec#011loss=8.075747\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] Epoch[66] Batch[10] avg_epoch_loss=8.211124\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=8.37357606888\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] Epoch[66] Batch [10]#011Speed: 952.86 samples/sec#011loss=8.373576\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] Epoch[66] Batch[15] avg_epoch_loss=8.224479\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=66, batch=15 train loss <loss>=8.25386095047\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:16 INFO 139919921551168] Epoch[66] Batch [15]#011Speed: 2108.21 samples/sec#011loss=8.253861\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] Epoch[66] Batch[20] avg_epoch_loss=8.254682\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=66, batch=20 train loss <loss>=8.35132846832\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] Epoch[66] Batch [20]#011Speed: 990.57 samples/sec#011loss=8.351328\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] Epoch[66] Batch[25] avg_epoch_loss=8.190599\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=66, batch=25 train loss <loss>=7.92145214081\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] Epoch[66] Batch [25]#011Speed: 2002.28 samples/sec#011loss=7.921452\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] Epoch[66] Batch[30] avg_epoch_loss=8.162323\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=66, batch=30 train loss <loss>=8.01529064178\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] Epoch[66] Batch [30]#011Speed: 961.94 samples/sec#011loss=8.015291\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] Epoch[66] Batch[35] avg_epoch_loss=8.110487\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=66, batch=35 train loss <loss>=7.7891002655\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] Epoch[66] Batch [35]#011Speed: 2115.87 samples/sec#011loss=7.789100\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] Epoch[66] Batch[40] avg_epoch_loss=8.083818\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=66, batch=40 train loss <loss>=7.891801548\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] Epoch[66] Batch [40]#011Speed: 939.23 samples/sec#011loss=7.891802\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] Epoch[66] Batch[45] avg_epoch_loss=8.051849\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=66, batch=45 train loss <loss>=7.78970804214\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] Epoch[66] Batch [45]#011Speed: 1936.37 samples/sec#011loss=7.789708\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] processed a total of 1550 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1243.199110031128, \"sum\": 1243.199110031128, \"min\": 1243.199110031128}}, \"EndTime\": 1578471617.799495, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471616.555885}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1246.66910714 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=66, train loss <loss>=8.02166052254\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] Epoch[67] Batch[0] avg_epoch_loss=8.359047\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=8.35904693604\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] Epoch[67] Batch[5] avg_epoch_loss=8.331561\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=8.33156124751\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:17 INFO 139919921551168] Epoch[67] Batch [5]#011Speed: 2136.59 samples/sec#011loss=8.331561\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] Epoch[67] Batch[10] avg_epoch_loss=8.274075\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=8.20509223938\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] Epoch[67] Batch [10]#011Speed: 882.44 samples/sec#011loss=8.205092\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] Epoch[67] Batch[15] avg_epoch_loss=8.350359\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=67, batch=15 train loss <loss>=8.51818161011\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] Epoch[67] Batch [15]#011Speed: 1972.43 samples/sec#011loss=8.518182\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] Epoch[67] Batch[20] avg_epoch_loss=8.316216\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=67, batch=20 train loss <loss>=8.20696048737\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] Epoch[67] Batch [20]#011Speed: 1073.03 samples/sec#011loss=8.206960\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] Epoch[67] Batch[25] avg_epoch_loss=8.281763\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=67, batch=25 train loss <loss>=8.13706140518\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] Epoch[67] Batch [25]#011Speed: 1680.04 samples/sec#011loss=8.137061\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] Epoch[67] Batch[30] avg_epoch_loss=8.206078\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=67, batch=30 train loss <loss>=7.81251335144\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] Epoch[67] Batch [30]#011Speed: 961.59 samples/sec#011loss=7.812513\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] Epoch[67] Batch[35] avg_epoch_loss=8.133508\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=67, batch=35 train loss <loss>=7.68357152939\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] Epoch[67] Batch [35]#011Speed: 1778.73 samples/sec#011loss=7.683572\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] Epoch[67] Batch[40] avg_epoch_loss=8.087596\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=67, batch=40 train loss <loss>=7.75703582764\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] Epoch[67] Batch [40]#011Speed: 940.10 samples/sec#011loss=7.757036\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] Epoch[67] Batch[45] avg_epoch_loss=8.071277\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=67, batch=45 train loss <loss>=7.93745546341\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:18 INFO 139919921551168] Epoch[67] Batch [45]#011Speed: 2046.19 samples/sec#011loss=7.937455\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] Epoch[67] Batch[50] avg_epoch_loss=8.050019\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=67, batch=50 train loss <loss>=7.85445251465\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] Epoch[67] Batch [50]#011Speed: 1630.26 samples/sec#011loss=7.854453\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] processed a total of 1633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1308.0182075500488, \"sum\": 1308.0182075500488, \"min\": 1308.0182075500488}}, \"EndTime\": 1578471619.108068, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471617.799574}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1248.34685216 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=67, train loss <loss>=8.04339814186\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] Epoch[68] Batch[0] avg_epoch_loss=8.517575\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=8.51757526398\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] Epoch[68] Batch[5] avg_epoch_loss=8.271946\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=8.27194595337\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] Epoch[68] Batch [5]#011Speed: 1891.74 samples/sec#011loss=8.271946\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] Epoch[68] Batch[10] avg_epoch_loss=8.457661\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=8.68051834106\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] Epoch[68] Batch [10]#011Speed: 975.53 samples/sec#011loss=8.680518\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] Epoch[68] Batch[15] avg_epoch_loss=8.403978\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=68, batch=15 train loss <loss>=8.28587656021\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] Epoch[68] Batch [15]#011Speed: 2008.59 samples/sec#011loss=8.285877\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] Epoch[68] Batch[20] avg_epoch_loss=8.429584\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=68, batch=20 train loss <loss>=8.51152229309\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] Epoch[68] Batch [20]#011Speed: 899.05 samples/sec#011loss=8.511522\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] Epoch[68] Batch[25] avg_epoch_loss=8.343299\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=68, batch=25 train loss <loss>=7.9809047699\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] Epoch[68] Batch [25]#011Speed: 1957.35 samples/sec#011loss=7.980905\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] Epoch[68] Batch[30] avg_epoch_loss=8.264845\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=68, batch=30 train loss <loss>=7.85688333511\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:19 INFO 139919921551168] Epoch[68] Batch [30]#011Speed: 936.09 samples/sec#011loss=7.856883\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] Epoch[68] Batch[35] avg_epoch_loss=8.190997\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=68, batch=35 train loss <loss>=7.73313751221\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] Epoch[68] Batch [35]#011Speed: 1804.89 samples/sec#011loss=7.733138\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] Epoch[68] Batch[40] avg_epoch_loss=8.141959\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=68, batch=40 train loss <loss>=7.7888841629\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] Epoch[68] Batch [40]#011Speed: 877.78 samples/sec#011loss=7.788884\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] Epoch[68] Batch[45] avg_epoch_loss=8.104502\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=68, batch=45 train loss <loss>=7.79735298157\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] Epoch[68] Batch [45]#011Speed: 2021.86 samples/sec#011loss=7.797353\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] Epoch[68] Batch[50] avg_epoch_loss=8.052335\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=68, batch=50 train loss <loss>=7.5724023819\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] Epoch[68] Batch [50]#011Speed: 1448.71 samples/sec#011loss=7.572402\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] processed a total of 1611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1319.0929889678955, \"sum\": 1319.0929889678955, \"min\": 1319.0929889678955}}, \"EndTime\": 1578471620.427643, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471619.108145}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1221.17057092 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=68, train loss <loss>=8.05233504725\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] Epoch[69] Batch[0] avg_epoch_loss=8.671355\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=8.6713552475\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] Epoch[69] Batch[5] avg_epoch_loss=8.471280\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=8.4712797006\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] Epoch[69] Batch [5]#011Speed: 1733.38 samples/sec#011loss=8.471280\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] Epoch[69] Batch[10] avg_epoch_loss=8.293625\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=8.08043928146\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] Epoch[69] Batch [10]#011Speed: 897.38 samples/sec#011loss=8.080439\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] Epoch[69] Batch[15] avg_epoch_loss=8.303144\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=69, batch=15 train loss <loss>=8.32408647537\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:20 INFO 139919921551168] Epoch[69] Batch [15]#011Speed: 2038.56 samples/sec#011loss=8.324086\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] Epoch[69] Batch[20] avg_epoch_loss=8.358665\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=69, batch=20 train loss <loss>=8.53633308411\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] Epoch[69] Batch [20]#011Speed: 1044.64 samples/sec#011loss=8.536333\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] Epoch[69] Batch[25] avg_epoch_loss=8.273624\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=69, batch=25 train loss <loss>=7.91645088196\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] Epoch[69] Batch [25]#011Speed: 2058.40 samples/sec#011loss=7.916451\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] Epoch[69] Batch[30] avg_epoch_loss=8.190274\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=69, batch=30 train loss <loss>=7.75685071945\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] Epoch[69] Batch [30]#011Speed: 928.40 samples/sec#011loss=7.756851\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] Epoch[69] Batch[35] avg_epoch_loss=8.131409\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=69, batch=35 train loss <loss>=7.76644592285\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] Epoch[69] Batch [35]#011Speed: 2083.66 samples/sec#011loss=7.766446\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] Epoch[69] Batch[40] avg_epoch_loss=8.106393\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=69, batch=40 train loss <loss>=7.92627716064\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] Epoch[69] Batch [40]#011Speed: 1009.15 samples/sec#011loss=7.926277\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] Epoch[69] Batch[45] avg_epoch_loss=8.071870\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=69, batch=45 train loss <loss>=7.78878679276\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] Epoch[69] Batch [45]#011Speed: 2127.60 samples/sec#011loss=7.788787\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] Epoch[69] Batch[50] avg_epoch_loss=7.989142\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=69, batch=50 train loss <loss>=7.22804059982\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] Epoch[69] Batch [50]#011Speed: 1441.06 samples/sec#011loss=7.228041\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] processed a total of 1609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1301.3410568237305, \"sum\": 1301.3410568237305, \"min\": 1301.3410568237305}}, \"EndTime\": 1578471621.729498, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471620.427741}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1236.31242346 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=69, train loss <loss>=7.98914181952\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] Epoch[70] Batch[0] avg_epoch_loss=8.324883\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=8.32488250732\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] Epoch[70] Batch[5] avg_epoch_loss=8.266884\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=8.2668838501\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:21 INFO 139919921551168] Epoch[70] Batch [5]#011Speed: 1886.04 samples/sec#011loss=8.266884\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] Epoch[70] Batch[10] avg_epoch_loss=8.232239\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=8.19066419601\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] Epoch[70] Batch [10]#011Speed: 931.48 samples/sec#011loss=8.190664\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] Epoch[70] Batch[15] avg_epoch_loss=8.319746\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=70, batch=15 train loss <loss>=8.51226139069\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] Epoch[70] Batch [15]#011Speed: 2021.27 samples/sec#011loss=8.512261\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] Epoch[70] Batch[20] avg_epoch_loss=8.322506\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=70, batch=20 train loss <loss>=8.33133974075\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] Epoch[70] Batch [20]#011Speed: 977.14 samples/sec#011loss=8.331340\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] Epoch[70] Batch[25] avg_epoch_loss=8.261503\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=70, batch=25 train loss <loss>=8.00528974533\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] Epoch[70] Batch [25]#011Speed: 1779.20 samples/sec#011loss=8.005290\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] Epoch[70] Batch[30] avg_epoch_loss=8.197209\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=70, batch=30 train loss <loss>=7.8628827095\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] Epoch[70] Batch [30]#011Speed: 753.95 samples/sec#011loss=7.862883\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] Epoch[70] Batch[35] avg_epoch_loss=8.135474\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=70, batch=35 train loss <loss>=7.75271158218\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] Epoch[70] Batch [35]#011Speed: 1703.09 samples/sec#011loss=7.752712\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] Epoch[70] Batch[40] avg_epoch_loss=8.113603\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=70, batch=40 train loss <loss>=7.95613698959\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] Epoch[70] Batch [40]#011Speed: 971.11 samples/sec#011loss=7.956137\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] Epoch[70] Batch[45] avg_epoch_loss=8.099822\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=70, batch=45 train loss <loss>=7.98681354523\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:22 INFO 139919921551168] Epoch[70] Batch [45]#011Speed: 1712.56 samples/sec#011loss=7.986814\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] processed a total of 1600 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1345.1321125030518, \"sum\": 1345.1321125030518, \"min\": 1345.1321125030518}}, \"EndTime\": 1578471623.075115, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471621.729575}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1189.38232776 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=70, train loss <loss>=8.06543516159\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] Epoch[71] Batch[0] avg_epoch_loss=8.236011\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=8.23601055145\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] Epoch[71] Batch[5] avg_epoch_loss=8.178055\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=8.17805480957\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] Epoch[71] Batch [5]#011Speed: 1749.87 samples/sec#011loss=8.178055\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] Epoch[71] Batch[10] avg_epoch_loss=8.207519\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=8.24287700653\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] Epoch[71] Batch [10]#011Speed: 1013.22 samples/sec#011loss=8.242877\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] Epoch[71] Batch[15] avg_epoch_loss=8.324865\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=71, batch=15 train loss <loss>=8.5830247879\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] Epoch[71] Batch [15]#011Speed: 2063.18 samples/sec#011loss=8.583025\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] Epoch[71] Batch[20] avg_epoch_loss=8.280987\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=71, batch=20 train loss <loss>=8.14057674408\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] Epoch[71] Batch [20]#011Speed: 1015.47 samples/sec#011loss=8.140577\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] Epoch[71] Batch[25] avg_epoch_loss=8.215570\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=71, batch=25 train loss <loss>=7.94081935883\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] Epoch[71] Batch [25]#011Speed: 1563.23 samples/sec#011loss=7.940819\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] Epoch[71] Batch[30] avg_epoch_loss=8.134381\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=71, batch=30 train loss <loss>=7.71219797134\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:23 INFO 139919921551168] Epoch[71] Batch [30]#011Speed: 939.33 samples/sec#011loss=7.712198\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] Epoch[71] Batch[35] avg_epoch_loss=8.053171\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=71, batch=35 train loss <loss>=7.54967079163\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] Epoch[71] Batch [35]#011Speed: 2135.64 samples/sec#011loss=7.549671\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] Epoch[71] Batch[40] avg_epoch_loss=8.008020\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=71, batch=40 train loss <loss>=7.68293170929\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] Epoch[71] Batch [40]#011Speed: 1028.54 samples/sec#011loss=7.682932\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] Epoch[71] Batch[45] avg_epoch_loss=7.998200\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=71, batch=45 train loss <loss>=7.91767721176\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] Epoch[71] Batch [45]#011Speed: 2139.36 samples/sec#011loss=7.917677\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] processed a total of 1595 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1251.7359256744385, \"sum\": 1251.7359256744385, \"min\": 1251.7359256744385}}, \"EndTime\": 1578471624.327401, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471623.075184}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1274.13165204 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=71, train loss <loss>=7.98118917465\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] Epoch[72] Batch[0] avg_epoch_loss=8.008018\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=8.00801753998\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] Epoch[72] Batch[5] avg_epoch_loss=8.036308\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=8.03630812963\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] Epoch[72] Batch [5]#011Speed: 2107.62 samples/sec#011loss=8.036308\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] Epoch[72] Batch[10] avg_epoch_loss=8.173156\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=8.33737335205\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] Epoch[72] Batch [10]#011Speed: 975.43 samples/sec#011loss=8.337373\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] Epoch[72] Batch[15] avg_epoch_loss=8.287088\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=72, batch=15 train loss <loss>=8.53773956299\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] Epoch[72] Batch [15]#011Speed: 1945.22 samples/sec#011loss=8.537740\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] Epoch[72] Batch[20] avg_epoch_loss=8.282440\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=72, batch=20 train loss <loss>=8.26756629944\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] Epoch[72] Batch [20]#011Speed: 942.53 samples/sec#011loss=8.267566\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] Epoch[72] Batch[25] avg_epoch_loss=8.175683\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=72, batch=25 train loss <loss>=7.72730426788\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:24 INFO 139919921551168] Epoch[72] Batch [25]#011Speed: 1942.48 samples/sec#011loss=7.727304\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] Epoch[72] Batch[30] avg_epoch_loss=8.156431\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=72, batch=30 train loss <loss>=8.05631914139\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] Epoch[72] Batch [30]#011Speed: 864.74 samples/sec#011loss=8.056319\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] Epoch[72] Batch[35] avg_epoch_loss=8.102818\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=72, batch=35 train loss <loss>=7.77041873932\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] Epoch[72] Batch [35]#011Speed: 2154.39 samples/sec#011loss=7.770419\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] Epoch[72] Batch[40] avg_epoch_loss=8.080921\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=72, batch=40 train loss <loss>=7.92325839996\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] Epoch[72] Batch [40]#011Speed: 928.52 samples/sec#011loss=7.923258\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] Epoch[72] Batch[45] avg_epoch_loss=8.079216\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=72, batch=45 train loss <loss>=8.06523628235\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] Epoch[72] Batch [45]#011Speed: 2043.53 samples/sec#011loss=8.065236\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] processed a total of 1535 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1236.987829208374, \"sum\": 1236.987829208374, \"min\": 1236.987829208374}}, \"EndTime\": 1578471625.564965, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471624.327465}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1240.81598419 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=72, train loss <loss>=8.04379875461\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] Epoch[73] Batch[0] avg_epoch_loss=8.690060\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=8.69005966187\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] Epoch[73] Batch[5] avg_epoch_loss=8.346505\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=8.34650484721\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] Epoch[73] Batch [5]#011Speed: 2081.27 samples/sec#011loss=8.346505\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] Epoch[73] Batch[10] avg_epoch_loss=8.332056\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=8.31471672058\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] Epoch[73] Batch [10]#011Speed: 1004.56 samples/sec#011loss=8.314717\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] Epoch[73] Batch[15] avg_epoch_loss=8.348367\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=73, batch=15 train loss <loss>=8.38425216675\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:25 INFO 139919921551168] Epoch[73] Batch [15]#011Speed: 2065.42 samples/sec#011loss=8.384252\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] Epoch[73] Batch[20] avg_epoch_loss=8.298643\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=73, batch=20 train loss <loss>=8.13952674866\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] Epoch[73] Batch [20]#011Speed: 895.93 samples/sec#011loss=8.139527\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] Epoch[73] Batch[25] avg_epoch_loss=8.231395\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=73, batch=25 train loss <loss>=7.9489531517\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] Epoch[73] Batch [25]#011Speed: 2073.69 samples/sec#011loss=7.948953\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] Epoch[73] Batch[30] avg_epoch_loss=8.145769\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=73, batch=30 train loss <loss>=7.70051441193\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] Epoch[73] Batch [30]#011Speed: 898.42 samples/sec#011loss=7.700514\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] Epoch[73] Batch[35] avg_epoch_loss=8.100907\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=73, batch=35 train loss <loss>=7.82276124954\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] Epoch[73] Batch [35]#011Speed: 1690.37 samples/sec#011loss=7.822761\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] Epoch[73] Batch[40] avg_epoch_loss=8.046206\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=73, batch=40 train loss <loss>=7.65235509872\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] Epoch[73] Batch [40]#011Speed: 895.37 samples/sec#011loss=7.652355\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] Epoch[73] Batch[45] avg_epoch_loss=8.021294\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=73, batch=45 train loss <loss>=7.81702384949\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] Epoch[73] Batch [45]#011Speed: 2032.65 samples/sec#011loss=7.817024\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] Epoch[73] Batch[50] avg_epoch_loss=8.030192\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=73, batch=50 train loss <loss>=8.1120516777\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] Epoch[73] Batch [50]#011Speed: 1246.30 samples/sec#011loss=8.112052\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] processed a total of 1655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1339.0028476715088, \"sum\": 1339.0028476715088, \"min\": 1339.0028476715088}}, \"EndTime\": 1578471626.904501, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471625.565031}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1235.88545546 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=73, train loss <loss>=8.0209094286\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:26 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] Epoch[74] Batch[0] avg_epoch_loss=8.134871\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=8.13487148285\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] Epoch[74] Batch[5] avg_epoch_loss=8.116408\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=8.11640779177\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] Epoch[74] Batch [5]#011Speed: 2067.08 samples/sec#011loss=8.116408\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] Epoch[74] Batch[10] avg_epoch_loss=8.230137\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=8.36661214828\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] Epoch[74] Batch [10]#011Speed: 1003.86 samples/sec#011loss=8.366612\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] Epoch[74] Batch[15] avg_epoch_loss=8.287828\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=74, batch=15 train loss <loss>=8.41474838257\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] Epoch[74] Batch [15]#011Speed: 1907.01 samples/sec#011loss=8.414748\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] Epoch[74] Batch[20] avg_epoch_loss=8.203667\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=74, batch=20 train loss <loss>=7.93435239792\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] Epoch[74] Batch [20]#011Speed: 980.97 samples/sec#011loss=7.934352\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] Epoch[74] Batch[25] avg_epoch_loss=8.202530\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=74, batch=25 train loss <loss>=8.19775314331\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] Epoch[74] Batch [25]#011Speed: 1953.70 samples/sec#011loss=8.197753\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] Epoch[74] Batch[30] avg_epoch_loss=8.132392\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=74, batch=30 train loss <loss>=7.76767301559\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] Epoch[74] Batch [30]#011Speed: 922.96 samples/sec#011loss=7.767673\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] Epoch[74] Batch[35] avg_epoch_loss=8.086388\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=74, batch=35 train loss <loss>=7.80116491318\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] Epoch[74] Batch [35]#011Speed: 1654.66 samples/sec#011loss=7.801165\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] Epoch[74] Batch[40] avg_epoch_loss=8.072620\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=74, batch=40 train loss <loss>=7.97349157333\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:27 INFO 139919921551168] Epoch[74] Batch [40]#011Speed: 1070.26 samples/sec#011loss=7.973492\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] Epoch[74] Batch[45] avg_epoch_loss=8.047467\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=74, batch=45 train loss <loss>=7.84120950699\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] Epoch[74] Batch [45]#011Speed: 1705.41 samples/sec#011loss=7.841210\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] Epoch[74] Batch[50] avg_epoch_loss=7.985572\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=74, batch=50 train loss <loss>=7.4161356926\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] Epoch[74] Batch [50]#011Speed: 1342.06 samples/sec#011loss=7.416136\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] processed a total of 1624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1301.6269207000732, \"sum\": 1301.6269207000732, \"min\": 1301.6269207000732}}, \"EndTime\": 1578471628.206656, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471626.904583}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1247.57061978 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=74, train loss <loss>=7.98557158077\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] Epoch[75] Batch[0] avg_epoch_loss=8.604842\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=8.60484218597\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] Epoch[75] Batch[5] avg_epoch_loss=8.335130\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=8.3351298968\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] Epoch[75] Batch [5]#011Speed: 1635.69 samples/sec#011loss=8.335130\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] Epoch[75] Batch[10] avg_epoch_loss=8.380432\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=8.43479480743\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] Epoch[75] Batch [10]#011Speed: 1072.17 samples/sec#011loss=8.434795\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] Epoch[75] Batch[15] avg_epoch_loss=8.499518\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=75, batch=15 train loss <loss>=8.76150627136\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] Epoch[75] Batch [15]#011Speed: 1738.54 samples/sec#011loss=8.761506\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] Epoch[75] Batch[20] avg_epoch_loss=8.495991\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=75, batch=20 train loss <loss>=8.48470535278\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] Epoch[75] Batch [20]#011Speed: 883.60 samples/sec#011loss=8.484705\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] Epoch[75] Batch[25] avg_epoch_loss=8.425752\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=75, batch=25 train loss <loss>=8.13075056076\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:28 INFO 139919921551168] Epoch[75] Batch [25]#011Speed: 2050.12 samples/sec#011loss=8.130751\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] Epoch[75] Batch[30] avg_epoch_loss=8.343947\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=75, batch=30 train loss <loss>=7.9185593605\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] Epoch[75] Batch [30]#011Speed: 1104.45 samples/sec#011loss=7.918559\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] Epoch[75] Batch[35] avg_epoch_loss=8.265242\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=75, batch=35 train loss <loss>=7.77727365494\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] Epoch[75] Batch [35]#011Speed: 2087.46 samples/sec#011loss=7.777274\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] Epoch[75] Batch[40] avg_epoch_loss=8.194411\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=75, batch=40 train loss <loss>=7.68442687988\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] Epoch[75] Batch [40]#011Speed: 1039.45 samples/sec#011loss=7.684427\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] Epoch[75] Batch[45] avg_epoch_loss=8.169641\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=75, batch=45 train loss <loss>=7.96652793884\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] Epoch[75] Batch [45]#011Speed: 1855.41 samples/sec#011loss=7.966528\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] processed a total of 1578 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1235.5930805206299, \"sum\": 1235.5930805206299, \"min\": 1235.5930805206299}}, \"EndTime\": 1578471629.44274, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471628.206728}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1277.00392018 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=75, train loss <loss>=8.02837150097\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] Epoch[76] Batch[0] avg_epoch_loss=8.835784\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=8.83578395844\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] Epoch[76] Batch[5] avg_epoch_loss=8.386938\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=8.38693825404\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] Epoch[76] Batch [5]#011Speed: 1538.33 samples/sec#011loss=8.386938\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] Epoch[76] Batch[10] avg_epoch_loss=8.346730\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=8.29848079681\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] Epoch[76] Batch [10]#011Speed: 865.22 samples/sec#011loss=8.298481\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] Epoch[76] Batch[15] avg_epoch_loss=8.329721\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=76, batch=15 train loss <loss>=8.29230003357\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:29 INFO 139919921551168] Epoch[76] Batch [15]#011Speed: 1927.09 samples/sec#011loss=8.292300\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] Epoch[76] Batch[20] avg_epoch_loss=8.345499\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=76, batch=20 train loss <loss>=8.39598884583\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] Epoch[76] Batch [20]#011Speed: 984.08 samples/sec#011loss=8.395989\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] Epoch[76] Batch[25] avg_epoch_loss=8.282539\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=76, batch=25 train loss <loss>=8.01810846329\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] Epoch[76] Batch [25]#011Speed: 1641.90 samples/sec#011loss=8.018108\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] Epoch[76] Batch[30] avg_epoch_loss=8.198372\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=76, batch=30 train loss <loss>=7.76069993973\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] Epoch[76] Batch [30]#011Speed: 935.65 samples/sec#011loss=7.760700\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] Epoch[76] Batch[35] avg_epoch_loss=8.137466\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=76, batch=35 train loss <loss>=7.75984783173\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] Epoch[76] Batch [35]#011Speed: 1518.25 samples/sec#011loss=7.759848\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] Epoch[76] Batch[40] avg_epoch_loss=8.095248\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=76, batch=40 train loss <loss>=7.7912853241\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] Epoch[76] Batch [40]#011Speed: 958.47 samples/sec#011loss=7.791285\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] Epoch[76] Batch[45] avg_epoch_loss=8.102754\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=76, batch=45 train loss <loss>=8.16430091858\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] Epoch[76] Batch [45]#011Speed: 2071.15 samples/sec#011loss=8.164301\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] Epoch[76] Batch[50] avg_epoch_loss=8.032052\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=76, batch=50 train loss <loss>=7.38159236908\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] Epoch[76] Batch [50]#011Speed: 1653.75 samples/sec#011loss=7.381592\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] processed a total of 1610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1347.193956375122, \"sum\": 1347.193956375122, \"min\": 1347.193956375122}}, \"EndTime\": 1578471630.790451, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471629.442818}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1194.97976199 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=76, train loss <loss>=8.0320520027\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] Epoch[77] Batch[0] avg_epoch_loss=7.915589\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=7.91558933258\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] Epoch[77] Batch[5] avg_epoch_loss=7.973831\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=7.97383141518\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:30 INFO 139919921551168] Epoch[77] Batch [5]#011Speed: 1843.38 samples/sec#011loss=7.973831\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] Epoch[77] Batch[10] avg_epoch_loss=8.198039\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=8.46708889008\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] Epoch[77] Batch [10]#011Speed: 1034.41 samples/sec#011loss=8.467089\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] Epoch[77] Batch[15] avg_epoch_loss=8.319811\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=77, batch=15 train loss <loss>=8.58770751953\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] Epoch[77] Batch [15]#011Speed: 2147.53 samples/sec#011loss=8.587708\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] Epoch[77] Batch[20] avg_epoch_loss=8.301738\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=77, batch=20 train loss <loss>=8.24390354156\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] Epoch[77] Batch [20]#011Speed: 985.50 samples/sec#011loss=8.243904\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] Epoch[77] Batch[25] avg_epoch_loss=8.260839\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=77, batch=25 train loss <loss>=8.08906612396\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] Epoch[77] Batch [25]#011Speed: 1918.85 samples/sec#011loss=8.089066\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] Epoch[77] Batch[30] avg_epoch_loss=8.156380\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=77, batch=30 train loss <loss>=7.61318941116\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] Epoch[77] Batch [30]#011Speed: 852.01 samples/sec#011loss=7.613189\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] Epoch[77] Batch[35] avg_epoch_loss=8.125342\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=77, batch=35 train loss <loss>=7.93291082382\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] Epoch[77] Batch [35]#011Speed: 2153.09 samples/sec#011loss=7.932911\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] Epoch[77] Batch[40] avg_epoch_loss=8.103702\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=77, batch=40 train loss <loss>=7.94788999557\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] Epoch[77] Batch [40]#011Speed: 1007.66 samples/sec#011loss=7.947890\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] Epoch[77] Batch[45] avg_epoch_loss=8.080934\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=77, batch=45 train loss <loss>=7.89424085617\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:31 INFO 139919921551168] Epoch[77] Batch [45]#011Speed: 2089.67 samples/sec#011loss=7.894241\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] Epoch[77] Batch[50] avg_epoch_loss=8.006371\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=77, batch=50 train loss <loss>=7.32038526535\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] Epoch[77] Batch [50]#011Speed: 1461.59 samples/sec#011loss=7.320385\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] processed a total of 1621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1282.7539443969727, \"sum\": 1282.7539443969727, \"min\": 1282.7539443969727}}, \"EndTime\": 1578471632.073685, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471630.790526}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1263.57702096 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=77, train loss <loss>=8.00637060053\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] Epoch[78] Batch[0] avg_epoch_loss=8.592231\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=8.59223079681\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] Epoch[78] Batch[5] avg_epoch_loss=8.462194\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=8.4621942838\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] Epoch[78] Batch [5]#011Speed: 1943.09 samples/sec#011loss=8.462194\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] Epoch[78] Batch[10] avg_epoch_loss=8.461577\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=8.46083583832\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] Epoch[78] Batch [10]#011Speed: 954.94 samples/sec#011loss=8.460836\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] Epoch[78] Batch[15] avg_epoch_loss=8.501475\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=78, batch=15 train loss <loss>=8.58925247192\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] Epoch[78] Batch [15]#011Speed: 2141.99 samples/sec#011loss=8.589252\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] Epoch[78] Batch[20] avg_epoch_loss=8.418162\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=78, batch=20 train loss <loss>=8.15155754089\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] Epoch[78] Batch [20]#011Speed: 1034.10 samples/sec#011loss=8.151558\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] Epoch[78] Batch[25] avg_epoch_loss=8.334767\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=78, batch=25 train loss <loss>=7.98451070786\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] Epoch[78] Batch [25]#011Speed: 1799.33 samples/sec#011loss=7.984511\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] Epoch[78] Batch[30] avg_epoch_loss=8.229388\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=78, batch=30 train loss <loss>=7.68141517639\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] Epoch[78] Batch [30]#011Speed: 988.40 samples/sec#011loss=7.681415\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] Epoch[78] Batch[35] avg_epoch_loss=8.158539\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=78, batch=35 train loss <loss>=7.71927518845\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:32 INFO 139919921551168] Epoch[78] Batch [35]#011Speed: 1801.46 samples/sec#011loss=7.719275\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] Epoch[78] Batch[40] avg_epoch_loss=8.121689\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=78, batch=40 train loss <loss>=7.85636863708\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] Epoch[78] Batch [40]#011Speed: 981.20 samples/sec#011loss=7.856369\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] Epoch[78] Batch[45] avg_epoch_loss=8.128799\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=78, batch=45 train loss <loss>=8.18709983826\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] Epoch[78] Batch [45]#011Speed: 1919.96 samples/sec#011loss=8.187100\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] processed a total of 1522 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1207.9601287841797, \"sum\": 1207.9601287841797, \"min\": 1207.9601287841797}}, \"EndTime\": 1578471633.282161, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471632.073763}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1259.8574959 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=78, train loss <loss>=8.07959854603\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] Epoch[79] Batch[0] avg_epoch_loss=8.772187\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=8.77218723297\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] Epoch[79] Batch[5] avg_epoch_loss=8.412678\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=8.41267824173\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] Epoch[79] Batch [5]#011Speed: 1826.98 samples/sec#011loss=8.412678\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] Epoch[79] Batch[10] avg_epoch_loss=8.442545\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=8.47838554382\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] Epoch[79] Batch [10]#011Speed: 911.20 samples/sec#011loss=8.478386\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] Epoch[79] Batch[15] avg_epoch_loss=8.454020\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=79, batch=15 train loss <loss>=8.47926578522\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] Epoch[79] Batch [15]#011Speed: 1971.73 samples/sec#011loss=8.479266\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] Epoch[79] Batch[20] avg_epoch_loss=8.473563\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=79, batch=20 train loss <loss>=8.53609962463\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] Epoch[79] Batch [20]#011Speed: 866.11 samples/sec#011loss=8.536100\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] Epoch[79] Batch[25] avg_epoch_loss=8.345296\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=79, batch=25 train loss <loss>=7.80657501221\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:33 INFO 139919921551168] Epoch[79] Batch [25]#011Speed: 2051.63 samples/sec#011loss=7.806575\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] Epoch[79] Batch[30] avg_epoch_loss=8.262839\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=79, batch=30 train loss <loss>=7.83406419754\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] Epoch[79] Batch [30]#011Speed: 848.17 samples/sec#011loss=7.834064\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] Epoch[79] Batch[35] avg_epoch_loss=8.191242\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=79, batch=35 train loss <loss>=7.74734182358\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] Epoch[79] Batch [35]#011Speed: 1916.44 samples/sec#011loss=7.747342\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] Epoch[79] Batch[40] avg_epoch_loss=8.131884\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=79, batch=40 train loss <loss>=7.70450372696\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] Epoch[79] Batch [40]#011Speed: 973.63 samples/sec#011loss=7.704504\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] Epoch[79] Batch[45] avg_epoch_loss=8.121251\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=79, batch=45 train loss <loss>=8.03406229019\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] Epoch[79] Batch [45]#011Speed: 1933.63 samples/sec#011loss=8.034062\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] Epoch[79] Batch[50] avg_epoch_loss=8.060943\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=79, batch=50 train loss <loss>=7.50610208511\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] Epoch[79] Batch [50]#011Speed: 1546.22 samples/sec#011loss=7.506102\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] processed a total of 1635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1353.61909866333, \"sum\": 1353.61909866333, \"min\": 1353.61909866333}}, \"EndTime\": 1578471634.636337, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471633.282235}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1207.76879101 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=79, train loss <loss>=8.04948623364\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] Epoch[80] Batch[0] avg_epoch_loss=8.394450\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=8.39445018768\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] Epoch[80] Batch[5] avg_epoch_loss=8.193708\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=8.19370802244\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] Epoch[80] Batch [5]#011Speed: 1969.57 samples/sec#011loss=8.193708\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] Epoch[80] Batch[10] avg_epoch_loss=8.328797\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=8.49090385437\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:34 INFO 139919921551168] Epoch[80] Batch [10]#011Speed: 1032.36 samples/sec#011loss=8.490904\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] Epoch[80] Batch[15] avg_epoch_loss=8.445948\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=80, batch=15 train loss <loss>=8.70367908478\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] Epoch[80] Batch [15]#011Speed: 1879.39 samples/sec#011loss=8.703679\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] Epoch[80] Batch[20] avg_epoch_loss=8.372714\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=80, batch=20 train loss <loss>=8.1383682251\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] Epoch[80] Batch [20]#011Speed: 923.92 samples/sec#011loss=8.138368\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] Epoch[80] Batch[25] avg_epoch_loss=8.289830\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=80, batch=25 train loss <loss>=7.94171390533\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] Epoch[80] Batch [25]#011Speed: 2131.69 samples/sec#011loss=7.941714\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] Epoch[80] Batch[30] avg_epoch_loss=8.246439\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=80, batch=30 train loss <loss>=8.02080669403\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] Epoch[80] Batch [30]#011Speed: 969.23 samples/sec#011loss=8.020807\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] Epoch[80] Batch[35] avg_epoch_loss=8.195765\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=80, batch=35 train loss <loss>=7.8815861702\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] Epoch[80] Batch [35]#011Speed: 2073.56 samples/sec#011loss=7.881586\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] Epoch[80] Batch[40] avg_epoch_loss=8.180955\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=80, batch=40 train loss <loss>=8.07432365417\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] Epoch[80] Batch [40]#011Speed: 1031.02 samples/sec#011loss=8.074324\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] Epoch[80] Batch[45] avg_epoch_loss=8.135051\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=80, batch=45 train loss <loss>=7.75864009857\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] Epoch[80] Batch [45]#011Speed: 1768.72 samples/sec#011loss=7.758640\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] processed a total of 1599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1250.8831024169922, \"sum\": 1250.8831024169922, \"min\": 1250.8831024169922}}, \"EndTime\": 1578471635.887773, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471634.636417}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1278.18557088 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=80, train loss <loss>=8.0808434391\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] Epoch[81] Batch[0] avg_epoch_loss=8.485975\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=8.4859752655\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] Epoch[81] Batch[5] avg_epoch_loss=8.220264\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=8.22026379903\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] Epoch[81] Batch [5]#011Speed: 2024.70 samples/sec#011loss=8.220264\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] Epoch[81] Batch[10] avg_epoch_loss=8.240745\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=8.26532154083\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] Epoch[81] Batch [10]#011Speed: 960.01 samples/sec#011loss=8.265322\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] Epoch[81] Batch[15] avg_epoch_loss=8.369757\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=81, batch=15 train loss <loss>=8.65358486176\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] Epoch[81] Batch [15]#011Speed: 1963.87 samples/sec#011loss=8.653585\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] Epoch[81] Batch[20] avg_epoch_loss=8.340590\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=81, batch=20 train loss <loss>=8.24725542068\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] Epoch[81] Batch [20]#011Speed: 1024.34 samples/sec#011loss=8.247255\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] Epoch[81] Batch[25] avg_epoch_loss=8.240534\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=81, batch=25 train loss <loss>=7.82029905319\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] Epoch[81] Batch [25]#011Speed: 1963.58 samples/sec#011loss=7.820299\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] Epoch[81] Batch[30] avg_epoch_loss=8.203943\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=81, batch=30 train loss <loss>=8.01366662979\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] Epoch[81] Batch [30]#011Speed: 845.06 samples/sec#011loss=8.013667\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] Epoch[81] Batch[35] avg_epoch_loss=8.122176\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=81, batch=35 train loss <loss>=7.6152215004\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] Epoch[81] Batch [35]#011Speed: 1913.79 samples/sec#011loss=7.615222\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] Epoch[81] Batch[40] avg_epoch_loss=8.141448\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=81, batch=40 train loss <loss>=8.28020648956\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:36 INFO 139919921551168] Epoch[81] Batch [40]#011Speed: 970.99 samples/sec#011loss=8.280206\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] Epoch[81] Batch[45] avg_epoch_loss=8.078524\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=81, batch=45 train loss <loss>=7.56254463196\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] Epoch[81] Batch [45]#011Speed: 2109.40 samples/sec#011loss=7.562545\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] Epoch[81] Batch[50] avg_epoch_loss=7.985664\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=81, batch=50 train loss <loss>=7.13135728836\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] Epoch[81] Batch [50]#011Speed: 1498.79 samples/sec#011loss=7.131357\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] processed a total of 1610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1281.2910079956055, \"sum\": 1281.2910079956055, \"min\": 1281.2910079956055}}, \"EndTime\": 1578471637.16965, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471635.887851}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1256.45116239 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=81, train loss <loss>=7.98566411523\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] Epoch[82] Batch[0] avg_epoch_loss=8.078647\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=8.07864665985\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] Epoch[82] Batch[5] avg_epoch_loss=8.039524\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=8.03952423731\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] Epoch[82] Batch [5]#011Speed: 2093.36 samples/sec#011loss=8.039524\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] Epoch[82] Batch[10] avg_epoch_loss=8.216978\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=8.42992143631\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] Epoch[82] Batch [10]#011Speed: 997.37 samples/sec#011loss=8.429921\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] Epoch[82] Batch[15] avg_epoch_loss=8.329118\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=82, batch=15 train loss <loss>=8.57582778931\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] Epoch[82] Batch [15]#011Speed: 2160.44 samples/sec#011loss=8.575828\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] Epoch[82] Batch[20] avg_epoch_loss=8.360394\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=82, batch=20 train loss <loss>=8.46047477722\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] Epoch[82] Batch [20]#011Speed: 969.16 samples/sec#011loss=8.460475\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] Epoch[82] Batch[25] avg_epoch_loss=8.280432\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=82, batch=25 train loss <loss>=7.94459571838\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] Epoch[82] Batch [25]#011Speed: 2049.41 samples/sec#011loss=7.944596\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] Epoch[82] Batch[30] avg_epoch_loss=8.194469\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=82, batch=30 train loss <loss>=7.7474609375\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:37 INFO 139919921551168] Epoch[82] Batch [30]#011Speed: 999.25 samples/sec#011loss=7.747461\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] Epoch[82] Batch[35] avg_epoch_loss=8.141388\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=82, batch=35 train loss <loss>=7.81228189468\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] Epoch[82] Batch [35]#011Speed: 1796.58 samples/sec#011loss=7.812282\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] Epoch[82] Batch[40] avg_epoch_loss=8.096039\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=82, batch=40 train loss <loss>=7.76952953339\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] Epoch[82] Batch [40]#011Speed: 982.14 samples/sec#011loss=7.769530\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] Epoch[82] Batch[45] avg_epoch_loss=8.070006\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=82, batch=45 train loss <loss>=7.85653247833\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] Epoch[82] Batch [45]#011Speed: 2018.92 samples/sec#011loss=7.856532\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] processed a total of 1580 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1220.337152481079, \"sum\": 1220.337152481079, \"min\": 1220.337152481079}}, \"EndTime\": 1578471638.390505, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471637.16971}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1294.61287521 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=82, train loss <loss>=8.07479144096\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] Epoch[83] Batch[0] avg_epoch_loss=8.214311\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=8.21431064606\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] Epoch[83] Batch[5] avg_epoch_loss=8.278312\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=8.27831204732\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] Epoch[83] Batch [5]#011Speed: 2022.98 samples/sec#011loss=8.278312\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] Epoch[83] Batch[10] avg_epoch_loss=8.283111\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=8.28887062073\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] Epoch[83] Batch [10]#011Speed: 940.25 samples/sec#011loss=8.288871\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] Epoch[83] Batch[15] avg_epoch_loss=8.329459\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=83, batch=15 train loss <loss>=8.43142356873\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] Epoch[83] Batch [15]#011Speed: 1761.65 samples/sec#011loss=8.431424\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] Epoch[83] Batch[20] avg_epoch_loss=8.318076\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=83, batch=20 train loss <loss>=8.28164863586\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:38 INFO 139919921551168] Epoch[83] Batch [20]#011Speed: 1051.63 samples/sec#011loss=8.281649\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] Epoch[83] Batch[25] avg_epoch_loss=8.244735\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=83, batch=25 train loss <loss>=7.93670501709\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] Epoch[83] Batch [25]#011Speed: 1765.60 samples/sec#011loss=7.936705\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] Epoch[83] Batch[30] avg_epoch_loss=8.172573\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=83, batch=30 train loss <loss>=7.7973274231\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] Epoch[83] Batch [30]#011Speed: 907.49 samples/sec#011loss=7.797327\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] Epoch[83] Batch[35] avg_epoch_loss=8.104459\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=83, batch=35 train loss <loss>=7.68215293884\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] Epoch[83] Batch [35]#011Speed: 2097.59 samples/sec#011loss=7.682153\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] Epoch[83] Batch[40] avg_epoch_loss=8.049346\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=83, batch=40 train loss <loss>=7.65253763199\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] Epoch[83] Batch [40]#011Speed: 942.74 samples/sec#011loss=7.652538\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] Epoch[83] Batch[45] avg_epoch_loss=8.039291\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=83, batch=45 train loss <loss>=7.95684041977\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] Epoch[83] Batch [45]#011Speed: 1964.56 samples/sec#011loss=7.956840\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] processed a total of 1595 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1288.254976272583, \"sum\": 1288.254976272583, \"min\": 1288.254976272583}}, \"EndTime\": 1578471639.679308, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471638.390574}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1238.02141305 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=83, train loss <loss>=7.9961699295\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] Epoch[84] Batch[0] avg_epoch_loss=8.516498\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=8.516497612\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] Epoch[84] Batch[5] avg_epoch_loss=8.354173\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=8.35417286555\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:39 INFO 139919921551168] Epoch[84] Batch [5]#011Speed: 1673.27 samples/sec#011loss=8.354173\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] Epoch[84] Batch[10] avg_epoch_loss=8.292243\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=8.21792793274\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] Epoch[84] Batch [10]#011Speed: 991.01 samples/sec#011loss=8.217928\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] Epoch[84] Batch[15] avg_epoch_loss=8.362475\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=84, batch=15 train loss <loss>=8.51698551178\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] Epoch[84] Batch [15]#011Speed: 2056.82 samples/sec#011loss=8.516986\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] Epoch[84] Batch[20] avg_epoch_loss=8.346608\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=84, batch=20 train loss <loss>=8.29583463669\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] Epoch[84] Batch [20]#011Speed: 1055.79 samples/sec#011loss=8.295835\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] Epoch[84] Batch[25] avg_epoch_loss=8.270527\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=84, batch=25 train loss <loss>=7.95098333359\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] Epoch[84] Batch [25]#011Speed: 1973.85 samples/sec#011loss=7.950983\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] Epoch[84] Batch[30] avg_epoch_loss=8.182248\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=84, batch=30 train loss <loss>=7.72319812775\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] Epoch[84] Batch [30]#011Speed: 926.32 samples/sec#011loss=7.723198\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] Epoch[84] Batch[35] avg_epoch_loss=8.106989\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=84, batch=35 train loss <loss>=7.64038381577\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] Epoch[84] Batch [35]#011Speed: 2071.79 samples/sec#011loss=7.640384\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] Epoch[84] Batch[40] avg_epoch_loss=8.099580\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=84, batch=40 train loss <loss>=8.04623556137\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] Epoch[84] Batch [40]#011Speed: 888.60 samples/sec#011loss=8.046236\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] Epoch[84] Batch[45] avg_epoch_loss=8.100929\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=84, batch=45 train loss <loss>=8.11198635101\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] Epoch[84] Batch [45]#011Speed: 2046.30 samples/sec#011loss=8.111986\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] processed a total of 1597 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1263.5180950164795, \"sum\": 1263.5180950164795, \"min\": 1263.5180950164795}}, \"EndTime\": 1578471640.943425, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471639.679368}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1263.81844706 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=84, train loss <loss>=8.03759196281\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:40 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:41 INFO 139919921551168] Epoch[85] Batch[0] avg_epoch_loss=8.274137\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=8.27413654327\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:41 INFO 139919921551168] Epoch[85] Batch[5] avg_epoch_loss=8.118055\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=8.11805478732\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:41 INFO 139919921551168] Epoch[85] Batch [5]#011Speed: 2042.70 samples/sec#011loss=8.118055\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:41 INFO 139919921551168] Epoch[85] Batch[10] avg_epoch_loss=8.099566\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=8.07738027573\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:41 INFO 139919921551168] Epoch[85] Batch [10]#011Speed: 1007.36 samples/sec#011loss=8.077380\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:41 INFO 139919921551168] Epoch[85] Batch[15] avg_epoch_loss=8.222061\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=85, batch=15 train loss <loss>=8.49155063629\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:41 INFO 139919921551168] Epoch[85] Batch [15]#011Speed: 1888.78 samples/sec#011loss=8.491551\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:41 INFO 139919921551168] Epoch[85] Batch[20] avg_epoch_loss=8.168760\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=85, batch=20 train loss <loss>=7.99819583893\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:41 INFO 139919921551168] Epoch[85] Batch [20]#011Speed: 945.82 samples/sec#011loss=7.998196\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:41 INFO 139919921551168] Epoch[85] Batch[25] avg_epoch_loss=8.135460\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=85, batch=25 train loss <loss>=7.99559736252\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:41 INFO 139919921551168] Epoch[85] Batch [25]#011Speed: 2060.98 samples/sec#011loss=7.995597\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:41 INFO 139919921551168] Epoch[85] Batch[30] avg_epoch_loss=8.095545\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=85, batch=30 train loss <loss>=7.88798961639\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:41 INFO 139919921551168] Epoch[85] Batch [30]#011Speed: 1036.76 samples/sec#011loss=7.887990\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:41 INFO 139919921551168] Epoch[85] Batch[35] avg_epoch_loss=8.062053\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=85, batch=35 train loss <loss>=7.85440015793\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:41 INFO 139919921551168] Epoch[85] Batch [35]#011Speed: 2035.29 samples/sec#011loss=7.854400\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] Epoch[85] Batch[40] avg_epoch_loss=8.042741\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=85, batch=40 train loss <loss>=7.90369501114\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] Epoch[85] Batch [40]#011Speed: 857.02 samples/sec#011loss=7.903695\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] Epoch[85] Batch[45] avg_epoch_loss=8.008489\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=85, batch=45 train loss <loss>=7.72762289047\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] Epoch[85] Batch [45]#011Speed: 1528.51 samples/sec#011loss=7.727623\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] processed a total of 1552 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1271.2090015411377, \"sum\": 1271.2090015411377, \"min\": 1271.2090015411377}}, \"EndTime\": 1578471642.215193, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471640.943502}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1220.76891663 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=85, train loss <loss>=7.98527237834\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] Epoch[86] Batch[0] avg_epoch_loss=7.546776\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=7.54677629471\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] Epoch[86] Batch[5] avg_epoch_loss=8.051022\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=8.05102245013\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] Epoch[86] Batch [5]#011Speed: 2060.85 samples/sec#011loss=8.051022\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] Epoch[86] Batch[10] avg_epoch_loss=8.116753\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=8.19563064575\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] Epoch[86] Batch [10]#011Speed: 930.02 samples/sec#011loss=8.195631\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] Epoch[86] Batch[15] avg_epoch_loss=8.246253\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=86, batch=15 train loss <loss>=8.53115158081\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] Epoch[86] Batch [15]#011Speed: 1904.56 samples/sec#011loss=8.531152\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] Epoch[86] Batch[20] avg_epoch_loss=8.264517\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=86, batch=20 train loss <loss>=8.32296094894\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] Epoch[86] Batch [20]#011Speed: 907.88 samples/sec#011loss=8.322961\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] Epoch[86] Batch[25] avg_epoch_loss=8.235386\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=86, batch=25 train loss <loss>=8.11303882599\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:42 INFO 139919921551168] Epoch[86] Batch [25]#011Speed: 2024.06 samples/sec#011loss=8.113039\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] Epoch[86] Batch[30] avg_epoch_loss=8.172043\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=86, batch=30 train loss <loss>=7.84265956879\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] Epoch[86] Batch [30]#011Speed: 1011.85 samples/sec#011loss=7.842660\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] Epoch[86] Batch[35] avg_epoch_loss=8.108625\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=86, batch=35 train loss <loss>=7.71543102264\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] Epoch[86] Batch [35]#011Speed: 2137.38 samples/sec#011loss=7.715431\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] Epoch[86] Batch[40] avg_epoch_loss=8.098104\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=86, batch=40 train loss <loss>=8.02235021591\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] Epoch[86] Batch [40]#011Speed: 988.61 samples/sec#011loss=8.022350\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] Epoch[86] Batch[45] avg_epoch_loss=8.067341\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=86, batch=45 train loss <loss>=7.81508321762\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] Epoch[86] Batch [45]#011Speed: 1744.88 samples/sec#011loss=7.815083\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] processed a total of 1547 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1239.4471168518066, \"sum\": 1239.4471168518066, \"min\": 1239.4471168518066}}, \"EndTime\": 1578471643.455265, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471642.215276}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1248.02048353 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=86, train loss <loss>=7.98139159533\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] Epoch[87] Batch[0] avg_epoch_loss=8.266212\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=8.26621246338\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] Epoch[87] Batch[5] avg_epoch_loss=8.243657\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=8.24365727107\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] Epoch[87] Batch [5]#011Speed: 1671.45 samples/sec#011loss=8.243657\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] Epoch[87] Batch[10] avg_epoch_loss=8.319398\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=8.41028728485\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] Epoch[87] Batch [10]#011Speed: 882.76 samples/sec#011loss=8.410287\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] Epoch[87] Batch[15] avg_epoch_loss=8.299117\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=87, batch=15 train loss <loss>=8.25449953079\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:43 INFO 139919921551168] Epoch[87] Batch [15]#011Speed: 1853.38 samples/sec#011loss=8.254500\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] Epoch[87] Batch[20] avg_epoch_loss=8.331695\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=87, batch=20 train loss <loss>=8.43594226837\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] Epoch[87] Batch [20]#011Speed: 1042.55 samples/sec#011loss=8.435942\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] Epoch[87] Batch[25] avg_epoch_loss=8.264261\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=87, batch=25 train loss <loss>=7.98103752136\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] Epoch[87] Batch [25]#011Speed: 2064.20 samples/sec#011loss=7.981038\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] Epoch[87] Batch[30] avg_epoch_loss=8.188582\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=87, batch=30 train loss <loss>=7.79505443573\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] Epoch[87] Batch [30]#011Speed: 1042.71 samples/sec#011loss=7.795054\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] Epoch[87] Batch[35] avg_epoch_loss=8.112235\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=87, batch=35 train loss <loss>=7.63888034821\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] Epoch[87] Batch [35]#011Speed: 1743.44 samples/sec#011loss=7.638880\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] Epoch[87] Batch[40] avg_epoch_loss=8.087362\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=87, batch=40 train loss <loss>=7.90827455521\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] Epoch[87] Batch [40]#011Speed: 949.62 samples/sec#011loss=7.908275\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] Epoch[87] Batch[45] avg_epoch_loss=8.047688\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=87, batch=45 train loss <loss>=7.7223610878\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] Epoch[87] Batch [45]#011Speed: 1762.05 samples/sec#011loss=7.722361\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] Epoch[87] Batch[50] avg_epoch_loss=8.019188\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=87, batch=50 train loss <loss>=7.75699577332\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] Epoch[87] Batch [50]#011Speed: 1708.57 samples/sec#011loss=7.756996\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] processed a total of 1621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1305.649995803833, \"sum\": 1305.649995803833, \"min\": 1305.649995803833}}, \"EndTime\": 1578471644.761455, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471643.455344}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1241.42248174 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=87, train loss <loss>=8.01918838538\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] Epoch[88] Batch[0] avg_epoch_loss=8.078164\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=8.07816410065\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] Epoch[88] Batch[5] avg_epoch_loss=8.232228\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=8.2322277228\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:44 INFO 139919921551168] Epoch[88] Batch [5]#011Speed: 1556.33 samples/sec#011loss=8.232228\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] Epoch[88] Batch[10] avg_epoch_loss=8.321461\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=8.428540802\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] Epoch[88] Batch [10]#011Speed: 914.84 samples/sec#011loss=8.428541\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] Epoch[88] Batch[15] avg_epoch_loss=8.398095\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=88, batch=15 train loss <loss>=8.56668872833\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] Epoch[88] Batch [15]#011Speed: 2019.82 samples/sec#011loss=8.566689\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] Epoch[88] Batch[20] avg_epoch_loss=8.402072\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=88, batch=20 train loss <loss>=8.41480026245\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] Epoch[88] Batch [20]#011Speed: 994.31 samples/sec#011loss=8.414800\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] Epoch[88] Batch[25] avg_epoch_loss=8.298968\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=88, batch=25 train loss <loss>=7.86593198776\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] Epoch[88] Batch [25]#011Speed: 1644.99 samples/sec#011loss=7.865932\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] Epoch[88] Batch[30] avg_epoch_loss=8.211155\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=88, batch=30 train loss <loss>=7.75452823639\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] Epoch[88] Batch [30]#011Speed: 961.89 samples/sec#011loss=7.754528\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] Epoch[88] Batch[35] avg_epoch_loss=8.151327\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=88, batch=35 train loss <loss>=7.78039464951\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] Epoch[88] Batch [35]#011Speed: 1836.12 samples/sec#011loss=7.780395\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] Epoch[88] Batch[40] avg_epoch_loss=8.089182\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=88, batch=40 train loss <loss>=7.64173297882\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] Epoch[88] Batch [40]#011Speed: 998.48 samples/sec#011loss=7.641733\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] Epoch[88] Batch[45] avg_epoch_loss=8.048772\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=88, batch=45 train loss <loss>=7.71741580963\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:45 INFO 139919921551168] Epoch[88] Batch [45]#011Speed: 1892.03 samples/sec#011loss=7.717416\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] processed a total of 1587 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1312.927007675171, \"sum\": 1312.927007675171, \"min\": 1312.927007675171}}, \"EndTime\": 1578471646.074873, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471644.761532}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1208.64666649 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=88, train loss <loss>=8.02725951195\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] Epoch[89] Batch[0] avg_epoch_loss=7.840101\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=7.84010124207\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] Epoch[89] Batch[5] avg_epoch_loss=8.169004\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=8.16900412242\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] Epoch[89] Batch [5]#011Speed: 2044.47 samples/sec#011loss=8.169004\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] Epoch[89] Batch[10] avg_epoch_loss=8.403079\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=8.68396968842\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] Epoch[89] Batch [10]#011Speed: 1020.10 samples/sec#011loss=8.683970\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] Epoch[89] Batch[15] avg_epoch_loss=8.363035\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=89, batch=15 train loss <loss>=8.27493610382\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] Epoch[89] Batch [15]#011Speed: 1826.36 samples/sec#011loss=8.274936\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] Epoch[89] Batch[20] avg_epoch_loss=8.265643\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=89, batch=20 train loss <loss>=7.95398902893\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] Epoch[89] Batch [20]#011Speed: 1017.47 samples/sec#011loss=7.953989\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] Epoch[89] Batch[25] avg_epoch_loss=8.210218\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=89, batch=25 train loss <loss>=7.97743616104\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] Epoch[89] Batch [25]#011Speed: 1853.13 samples/sec#011loss=7.977436\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] Epoch[89] Batch[30] avg_epoch_loss=8.133970\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=89, batch=30 train loss <loss>=7.7374789238\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] Epoch[89] Batch [30]#011Speed: 1061.34 samples/sec#011loss=7.737479\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] Epoch[89] Batch[35] avg_epoch_loss=8.099049\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=89, batch=35 train loss <loss>=7.88253498077\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:46 INFO 139919921551168] Epoch[89] Batch [35]#011Speed: 1797.17 samples/sec#011loss=7.882535\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] Epoch[89] Batch[40] avg_epoch_loss=8.070787\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=89, batch=40 train loss <loss>=7.8673002243\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] Epoch[89] Batch [40]#011Speed: 923.82 samples/sec#011loss=7.867300\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] Epoch[89] Batch[45] avg_epoch_loss=8.053696\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=89, batch=45 train loss <loss>=7.91354980469\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] Epoch[89] Batch [45]#011Speed: 1447.57 samples/sec#011loss=7.913550\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] processed a total of 1534 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1225.4548072814941, \"sum\": 1225.4548072814941, \"min\": 1225.4548072814941}}, \"EndTime\": 1578471647.300849, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471646.074951}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1251.6766519 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=89, train loss <loss>=8.02570467194\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] Epoch[90] Batch[0] avg_epoch_loss=7.589722\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=7.58972215652\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] Epoch[90] Batch[5] avg_epoch_loss=8.182204\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=8.18220384916\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] Epoch[90] Batch [5]#011Speed: 1839.25 samples/sec#011loss=8.182204\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] Epoch[90] Batch[10] avg_epoch_loss=8.387427\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=8.63369522095\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] Epoch[90] Batch [10]#011Speed: 1022.84 samples/sec#011loss=8.633695\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] Epoch[90] Batch[15] avg_epoch_loss=8.445652\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=90, batch=15 train loss <loss>=8.57374763489\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] Epoch[90] Batch [15]#011Speed: 2136.59 samples/sec#011loss=8.573748\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] Epoch[90] Batch[20] avg_epoch_loss=8.354357\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=90, batch=20 train loss <loss>=8.06220989227\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] Epoch[90] Batch [20]#011Speed: 939.90 samples/sec#011loss=8.062210\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] Epoch[90] Batch[25] avg_epoch_loss=8.292834\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=90, batch=25 train loss <loss>=8.03444080353\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:47 INFO 139919921551168] Epoch[90] Batch [25]#011Speed: 2132.63 samples/sec#011loss=8.034441\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] Epoch[90] Batch[30] avg_epoch_loss=8.240241\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=90, batch=30 train loss <loss>=7.96675796509\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] Epoch[90] Batch [30]#011Speed: 1104.19 samples/sec#011loss=7.966758\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] Epoch[90] Batch[35] avg_epoch_loss=8.157681\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=90, batch=35 train loss <loss>=7.64580392838\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] Epoch[90] Batch [35]#011Speed: 2080.17 samples/sec#011loss=7.645804\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] Epoch[90] Batch[40] avg_epoch_loss=8.107277\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=90, batch=40 train loss <loss>=7.74437484741\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] Epoch[90] Batch [40]#011Speed: 1077.93 samples/sec#011loss=7.744375\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] Epoch[90] Batch[45] avg_epoch_loss=8.078959\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=90, batch=45 train loss <loss>=7.84674777985\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] Epoch[90] Batch [45]#011Speed: 1304.16 samples/sec#011loss=7.846748\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] processed a total of 1582 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1225.6791591644287, \"sum\": 1225.6791591644287, \"min\": 1225.6791591644287}}, \"EndTime\": 1578471648.527086, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471647.300919}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1290.60151498 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=90, train loss <loss>=8.11117598534\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] Epoch[91] Batch[0] avg_epoch_loss=8.132478\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=8.13247776031\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] Epoch[91] Batch[5] avg_epoch_loss=8.120755\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=8.12075503667\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] Epoch[91] Batch [5]#011Speed: 1816.45 samples/sec#011loss=8.120755\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] Epoch[91] Batch[10] avg_epoch_loss=8.286326\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=8.48501014709\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:48 INFO 139919921551168] Epoch[91] Batch [10]#011Speed: 1680.53 samples/sec#011loss=8.485010\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] Epoch[91] Batch[15] avg_epoch_loss=8.338168\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=91, batch=15 train loss <loss>=8.45222244263\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] Epoch[91] Batch [15]#011Speed: 821.27 samples/sec#011loss=8.452222\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] Epoch[91] Batch[20] avg_epoch_loss=8.400389\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=91, batch=20 train loss <loss>=8.59949626923\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] Epoch[91] Batch [20]#011Speed: 941.15 samples/sec#011loss=8.599496\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] Epoch[91] Batch[25] avg_epoch_loss=8.288183\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=91, batch=25 train loss <loss>=7.81691865921\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] Epoch[91] Batch [25]#011Speed: 1769.58 samples/sec#011loss=7.816919\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] Epoch[91] Batch[30] avg_epoch_loss=8.196796\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=91, batch=30 train loss <loss>=7.72158155441\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] Epoch[91] Batch [30]#011Speed: 944.79 samples/sec#011loss=7.721582\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] Epoch[91] Batch[35] avg_epoch_loss=8.097745\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=91, batch=35 train loss <loss>=7.48363027573\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] Epoch[91] Batch [35]#011Speed: 1671.87 samples/sec#011loss=7.483630\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] Epoch[91] Batch[40] avg_epoch_loss=8.067242\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=91, batch=40 train loss <loss>=7.84761543274\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] Epoch[91] Batch [40]#011Speed: 938.61 samples/sec#011loss=7.847615\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] Epoch[91] Batch[45] avg_epoch_loss=8.065963\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=91, batch=45 train loss <loss>=8.05547714233\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] Epoch[91] Batch [45]#011Speed: 1726.72 samples/sec#011loss=8.055477\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] Epoch[91] Batch[50] avg_epoch_loss=8.017571\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=91, batch=50 train loss <loss>=7.57236347198\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] Epoch[91] Batch [50]#011Speed: 1316.89 samples/sec#011loss=7.572363\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] processed a total of 1629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1391.4308547973633, \"sum\": 1391.4308547973633, \"min\": 1391.4308547973633}}, \"EndTime\": 1578471649.919079, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471648.527152}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1170.64462715 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=91, train loss <loss>=8.01757072935\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:49 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:50 INFO 139919921551168] Epoch[92] Batch[0] avg_epoch_loss=7.759730\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=7.75972986221\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:50 INFO 139919921551168] Epoch[92] Batch[5] avg_epoch_loss=8.102815\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=8.10281507174\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:50 INFO 139919921551168] Epoch[92] Batch [5]#011Speed: 1728.99 samples/sec#011loss=8.102815\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:50 INFO 139919921551168] Epoch[92] Batch[10] avg_epoch_loss=8.120173\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=8.14100313187\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:50 INFO 139919921551168] Epoch[92] Batch [10]#011Speed: 944.78 samples/sec#011loss=8.141003\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:50 INFO 139919921551168] Epoch[92] Batch[15] avg_epoch_loss=8.230980\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=92, batch=15 train loss <loss>=8.47475395203\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:50 INFO 139919921551168] Epoch[92] Batch [15]#011Speed: 1988.98 samples/sec#011loss=8.474754\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:50 INFO 139919921551168] Epoch[92] Batch[20] avg_epoch_loss=8.275847\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=92, batch=20 train loss <loss>=8.41942081451\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:50 INFO 139919921551168] Epoch[92] Batch [20]#011Speed: 999.25 samples/sec#011loss=8.419421\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:50 INFO 139919921551168] Epoch[92] Batch[25] avg_epoch_loss=8.177265\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=92, batch=25 train loss <loss>=7.76322107315\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:50 INFO 139919921551168] Epoch[92] Batch [25]#011Speed: 1994.31 samples/sec#011loss=7.763221\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:50 INFO 139919921551168] Epoch[92] Batch[30] avg_epoch_loss=8.138659\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=92, batch=30 train loss <loss>=7.93790884018\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:50 INFO 139919921551168] Epoch[92] Batch [30]#011Speed: 1060.36 samples/sec#011loss=7.937909\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:50 INFO 139919921551168] Epoch[92] Batch[35] avg_epoch_loss=8.093348\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=92, batch=35 train loss <loss>=7.81242160797\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:50 INFO 139919921551168] Epoch[92] Batch [35]#011Speed: 1932.11 samples/sec#011loss=7.812422\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] Epoch[92] Batch[40] avg_epoch_loss=8.086078\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=92, batch=40 train loss <loss>=8.03372917175\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] Epoch[92] Batch [40]#011Speed: 923.40 samples/sec#011loss=8.033729\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] Epoch[92] Batch[45] avg_epoch_loss=8.050807\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=92, batch=45 train loss <loss>=7.76158323288\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] Epoch[92] Batch [45]#011Speed: 1630.54 samples/sec#011loss=7.761583\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] Epoch[92] Batch[50] avg_epoch_loss=8.005894\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=92, batch=50 train loss <loss>=7.59269609451\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] Epoch[92] Batch [50]#011Speed: 1513.37 samples/sec#011loss=7.592696\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] processed a total of 1611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1298.6159324645996, \"sum\": 1298.6159324645996, \"min\": 1298.6159324645996}}, \"EndTime\": 1578471651.218206, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471649.919156}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1240.43881383 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=92, train loss <loss>=8.00589372597\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] Epoch[93] Batch[0] avg_epoch_loss=8.164083\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=8.16408252716\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] Epoch[93] Batch[5] avg_epoch_loss=8.255235\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=8.25523463885\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] Epoch[93] Batch [5]#011Speed: 2017.55 samples/sec#011loss=8.255235\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] Epoch[93] Batch[10] avg_epoch_loss=8.400768\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=8.5754076004\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] Epoch[93] Batch [10]#011Speed: 999.87 samples/sec#011loss=8.575408\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] Epoch[93] Batch[15] avg_epoch_loss=8.451841\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=93, batch=15 train loss <loss>=8.56420116425\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] Epoch[93] Batch [15]#011Speed: 1633.47 samples/sec#011loss=8.564201\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] Epoch[93] Batch[20] avg_epoch_loss=8.368083\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=93, batch=20 train loss <loss>=8.10005922318\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] Epoch[93] Batch [20]#011Speed: 942.64 samples/sec#011loss=8.100059\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] Epoch[93] Batch[25] avg_epoch_loss=8.230794\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=93, batch=25 train loss <loss>=7.65417709351\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:51 INFO 139919921551168] Epoch[93] Batch [25]#011Speed: 1774.19 samples/sec#011loss=7.654177\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] Epoch[93] Batch[30] avg_epoch_loss=8.154937\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=93, batch=30 train loss <loss>=7.76048517227\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] Epoch[93] Batch [30]#011Speed: 959.72 samples/sec#011loss=7.760485\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] Epoch[93] Batch[35] avg_epoch_loss=8.097669\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=93, batch=35 train loss <loss>=7.74260425568\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] Epoch[93] Batch [35]#011Speed: 1992.08 samples/sec#011loss=7.742604\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] Epoch[93] Batch[40] avg_epoch_loss=8.039938\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=93, batch=40 train loss <loss>=7.62427339554\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] Epoch[93] Batch [40]#011Speed: 1029.32 samples/sec#011loss=7.624273\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] Epoch[93] Batch[45] avg_epoch_loss=8.009729\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=93, batch=45 train loss <loss>=7.76201953888\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] Epoch[93] Batch [45]#011Speed: 2010.08 samples/sec#011loss=7.762020\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] Epoch[93] Batch[50] avg_epoch_loss=7.997844\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=93, batch=50 train loss <loss>=7.88850317001\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] Epoch[93] Batch [50]#011Speed: 1567.63 samples/sec#011loss=7.888503\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] processed a total of 1653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1297.2841262817383, \"sum\": 1297.2841262817383, \"min\": 1297.2841262817383}}, \"EndTime\": 1578471652.516043, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471651.218288}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1274.08172025 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=93, train loss <loss>=7.9809979934\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] Epoch[94] Batch[0] avg_epoch_loss=8.319963\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=8.31996250153\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] Epoch[94] Batch[5] avg_epoch_loss=8.199332\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=8.1993320783\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] Epoch[94] Batch [5]#011Speed: 1601.49 samples/sec#011loss=8.199332\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] Epoch[94] Batch[10] avg_epoch_loss=8.219726\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=8.24419927597\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] Epoch[94] Batch [10]#011Speed: 954.48 samples/sec#011loss=8.244199\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] Epoch[94] Batch[15] avg_epoch_loss=8.347727\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=94, batch=15 train loss <loss>=8.62932891846\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:52 INFO 139919921551168] Epoch[94] Batch [15]#011Speed: 1856.63 samples/sec#011loss=8.629329\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] Epoch[94] Batch[20] avg_epoch_loss=8.370303\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=94, batch=20 train loss <loss>=8.44254798889\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] Epoch[94] Batch [20]#011Speed: 1014.79 samples/sec#011loss=8.442548\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] Epoch[94] Batch[25] avg_epoch_loss=8.263197\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=94, batch=25 train loss <loss>=7.81334762573\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] Epoch[94] Batch [25]#011Speed: 2021.07 samples/sec#011loss=7.813348\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] Epoch[94] Batch[30] avg_epoch_loss=8.216902\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=94, batch=30 train loss <loss>=7.97616891861\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] Epoch[94] Batch [30]#011Speed: 1029.38 samples/sec#011loss=7.976169\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] Epoch[94] Batch[35] avg_epoch_loss=8.156164\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=94, batch=35 train loss <loss>=7.77958908081\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] Epoch[94] Batch [35]#011Speed: 2037.78 samples/sec#011loss=7.779589\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] Epoch[94] Batch[40] avg_epoch_loss=8.145344\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=94, batch=40 train loss <loss>=8.06744184494\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] Epoch[94] Batch [40]#011Speed: 989.17 samples/sec#011loss=8.067442\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] Epoch[94] Batch[45] avg_epoch_loss=8.134909\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=94, batch=45 train loss <loss>=8.04934034348\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] Epoch[94] Batch [45]#011Speed: 1727.45 samples/sec#011loss=8.049340\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] Epoch[94] Batch[50] avg_epoch_loss=8.068680\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=94, batch=50 train loss <loss>=7.45937023163\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] Epoch[94] Batch [50]#011Speed: 1783.25 samples/sec#011loss=7.459370\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] processed a total of 1644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1315.4559135437012, \"sum\": 1315.4559135437012, \"min\": 1315.4559135437012}}, \"EndTime\": 1578471653.832025, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471652.516129}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1249.65421942 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=94, train loss <loss>=8.05035305023\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] Epoch[95] Batch[0] avg_epoch_loss=8.504540\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=8.50454044342\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] Epoch[95] Batch[5] avg_epoch_loss=8.238317\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=8.2383166949\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] Epoch[95] Batch [5]#011Speed: 2013.82 samples/sec#011loss=8.238317\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] Epoch[95] Batch[10] avg_epoch_loss=8.230279\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=8.22063446045\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] Epoch[95] Batch [10]#011Speed: 1051.69 samples/sec#011loss=8.220634\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] Epoch[95] Batch[15] avg_epoch_loss=8.288235\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=95, batch=15 train loss <loss>=8.41573734283\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] Epoch[95] Batch [15]#011Speed: 1998.45 samples/sec#011loss=8.415737\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] Epoch[95] Batch[20] avg_epoch_loss=8.322210\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=95, batch=20 train loss <loss>=8.43093223572\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] Epoch[95] Batch [20]#011Speed: 985.18 samples/sec#011loss=8.430932\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] Epoch[95] Batch[25] avg_epoch_loss=8.178242\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=95, batch=25 train loss <loss>=7.57357597351\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] Epoch[95] Batch [25]#011Speed: 2023.45 samples/sec#011loss=7.573576\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] Epoch[95] Batch[30] avg_epoch_loss=8.133163\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=95, batch=30 train loss <loss>=7.89875135422\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] Epoch[95] Batch [30]#011Speed: 832.66 samples/sec#011loss=7.898751\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] Epoch[95] Batch[35] avg_epoch_loss=8.082047\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=95, batch=35 train loss <loss>=7.76513032913\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] Epoch[95] Batch [35]#011Speed: 1906.66 samples/sec#011loss=7.765130\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] Epoch[95] Batch[40] avg_epoch_loss=8.087144\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=95, batch=40 train loss <loss>=8.12384223938\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:54 INFO 139919921551168] Epoch[95] Batch [40]#011Speed: 906.22 samples/sec#011loss=8.123842\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] Epoch[95] Batch[45] avg_epoch_loss=8.088895\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=95, batch=45 train loss <loss>=8.10325088501\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] Epoch[95] Batch [45]#011Speed: 1814.02 samples/sec#011loss=8.103251\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] processed a total of 1575 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1286.9949340820312, \"sum\": 1286.9949340820312, \"min\": 1286.9949340820312}}, \"EndTime\": 1578471655.119578, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471653.832097}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1223.65183089 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=95, train loss <loss>=8.01566098213\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] Epoch[96] Batch[0] avg_epoch_loss=8.273737\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=8.27373695374\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] Epoch[96] Batch[5] avg_epoch_loss=8.192861\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=8.19286068281\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] Epoch[96] Batch [5]#011Speed: 2006.04 samples/sec#011loss=8.192861\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] Epoch[96] Batch[10] avg_epoch_loss=8.165809\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=8.13334655762\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] Epoch[96] Batch [10]#011Speed: 1013.85 samples/sec#011loss=8.133347\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] Epoch[96] Batch[15] avg_epoch_loss=8.361399\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=96, batch=15 train loss <loss>=8.79169788361\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] Epoch[96] Batch [15]#011Speed: 1644.14 samples/sec#011loss=8.791698\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] Epoch[96] Batch[20] avg_epoch_loss=8.382221\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=96, batch=20 train loss <loss>=8.44885015488\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] Epoch[96] Batch [20]#011Speed: 866.40 samples/sec#011loss=8.448850\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] Epoch[96] Batch[25] avg_epoch_loss=8.323136\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=96, batch=25 train loss <loss>=8.07497787476\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] Epoch[96] Batch [25]#011Speed: 2110.65 samples/sec#011loss=8.074978\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] Epoch[96] Batch[30] avg_epoch_loss=8.238303\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=96, batch=30 train loss <loss>=7.79717512131\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:55 INFO 139919921551168] Epoch[96] Batch [30]#011Speed: 914.11 samples/sec#011loss=7.797175\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] Epoch[96] Batch[35] avg_epoch_loss=8.180987\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=96, batch=35 train loss <loss>=7.82562532425\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] Epoch[96] Batch [35]#011Speed: 2089.84 samples/sec#011loss=7.825625\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] Epoch[96] Batch[40] avg_epoch_loss=8.145859\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=96, batch=40 train loss <loss>=7.89294033051\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] Epoch[96] Batch [40]#011Speed: 1075.80 samples/sec#011loss=7.892940\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] Epoch[96] Batch[45] avg_epoch_loss=8.097111\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=96, batch=45 train loss <loss>=7.69737710953\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] Epoch[96] Batch [45]#011Speed: 2009.80 samples/sec#011loss=7.697377\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] Epoch[96] Batch[50] avg_epoch_loss=8.046399\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=96, batch=50 train loss <loss>=7.57984466553\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] Epoch[96] Batch [50]#011Speed: 1456.84 samples/sec#011loss=7.579845\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] processed a total of 1630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1278.548002243042, \"sum\": 1278.548002243042, \"min\": 1278.548002243042}}, \"EndTime\": 1578471656.39872, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471655.119651}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1274.76911585 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=96, train loss <loss>=8.04639880797\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] Epoch[97] Batch[0] avg_epoch_loss=8.726612\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=8.72661209106\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] Epoch[97] Batch[5] avg_epoch_loss=8.284826\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=8.28482627869\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] Epoch[97] Batch [5]#011Speed: 1588.48 samples/sec#011loss=8.284826\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] Epoch[97] Batch[10] avg_epoch_loss=8.350250\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=8.42875804901\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] Epoch[97] Batch [10]#011Speed: 938.88 samples/sec#011loss=8.428758\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] Epoch[97] Batch[15] avg_epoch_loss=8.318646\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=97, batch=15 train loss <loss>=8.24911670685\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:56 INFO 139919921551168] Epoch[97] Batch [15]#011Speed: 1660.37 samples/sec#011loss=8.249117\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] Epoch[97] Batch[20] avg_epoch_loss=8.306737\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=97, batch=20 train loss <loss>=8.26862840652\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] Epoch[97] Batch [20]#011Speed: 952.64 samples/sec#011loss=8.268628\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] Epoch[97] Batch[25] avg_epoch_loss=8.236536\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=97, batch=25 train loss <loss>=7.94169187546\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] Epoch[97] Batch [25]#011Speed: 1633.12 samples/sec#011loss=7.941692\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] Epoch[97] Batch[30] avg_epoch_loss=8.161834\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=97, batch=30 train loss <loss>=7.77338685989\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] Epoch[97] Batch [30]#011Speed: 929.64 samples/sec#011loss=7.773387\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] Epoch[97] Batch[35] avg_epoch_loss=8.100479\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=97, batch=35 train loss <loss>=7.72007350922\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] Epoch[97] Batch [35]#011Speed: 1604.94 samples/sec#011loss=7.720074\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] Epoch[97] Batch[40] avg_epoch_loss=8.074369\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=97, batch=40 train loss <loss>=7.88637857437\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] Epoch[97] Batch [40]#011Speed: 906.01 samples/sec#011loss=7.886379\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] Epoch[97] Batch[45] avg_epoch_loss=8.047589\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=97, batch=45 train loss <loss>=7.82799434662\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] Epoch[97] Batch [45]#011Speed: 1709.88 samples/sec#011loss=7.827994\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] Epoch[97] Batch[50] avg_epoch_loss=8.023460\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=97, batch=50 train loss <loss>=7.80147180557\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] Epoch[97] Batch [50]#011Speed: 1262.47 samples/sec#011loss=7.801472\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] processed a total of 1636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1420.809030532837, \"sum\": 1420.809030532837, \"min\": 1420.809030532837}}, \"EndTime\": 1578471657.820046, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471656.398798}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1151.36525958 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=97, train loss <loss>=8.00316515336\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] Epoch[98] Batch[0] avg_epoch_loss=8.039905\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=8.03990459442\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] Epoch[98] Batch[5] avg_epoch_loss=7.917233\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=7.91723291079\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] Epoch[98] Batch [5]#011Speed: 1844.57 samples/sec#011loss=7.917233\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] Epoch[98] Batch[10] avg_epoch_loss=8.215920\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=8.57434387207\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] Epoch[98] Batch [10]#011Speed: 1039.59 samples/sec#011loss=8.574344\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] Epoch[98] Batch[15] avg_epoch_loss=8.265406\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=98, batch=15 train loss <loss>=8.37427520752\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] Epoch[98] Batch [15]#011Speed: 1872.26 samples/sec#011loss=8.374275\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] Epoch[98] Batch[20] avg_epoch_loss=8.131638\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=98, batch=20 train loss <loss>=7.70357980728\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] Epoch[98] Batch [20]#011Speed: 1044.62 samples/sec#011loss=7.703580\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] Epoch[98] Batch[25] avg_epoch_loss=8.093559\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=98, batch=25 train loss <loss>=7.9336271286\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] Epoch[98] Batch [25]#011Speed: 1935.83 samples/sec#011loss=7.933627\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] Epoch[98] Batch[30] avg_epoch_loss=8.030000\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=98, batch=30 train loss <loss>=7.69949703217\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] Epoch[98] Batch [30]#011Speed: 1017.32 samples/sec#011loss=7.699497\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] Epoch[98] Batch[35] avg_epoch_loss=7.965233\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=98, batch=35 train loss <loss>=7.56367206573\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] Epoch[98] Batch [35]#011Speed: 1880.52 samples/sec#011loss=7.563672\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] Epoch[98] Batch[40] avg_epoch_loss=7.973020\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=98, batch=40 train loss <loss>=8.02909021378\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:58 INFO 139919921551168] Epoch[98] Batch [40]#011Speed: 950.63 samples/sec#011loss=8.029090\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] Epoch[98] Batch[45] avg_epoch_loss=7.939907\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=98, batch=45 train loss <loss>=7.66838083267\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] Epoch[98] Batch [45]#011Speed: 1501.22 samples/sec#011loss=7.668381\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] processed a total of 1589 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1280.9460163116455, \"sum\": 1280.9460163116455, \"min\": 1280.9460163116455}}, \"EndTime\": 1578471659.101512, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471657.820124}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1240.37815669 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=98, train loss <loss>=7.94554055214\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] Saved checkpoint to \"/opt/ml/model/state_f903a286-fd2e-4588-a8d6-f95924ff985f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 11.684894561767578, \"sum\": 11.684894561767578, \"min\": 11.684894561767578}}, \"EndTime\": 1578471659.113818, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471659.101589}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] Epoch[99] Batch[0] avg_epoch_loss=8.459849\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=8.4598493576\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] Epoch[99] Batch[5] avg_epoch_loss=8.012936\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=8.01293603579\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] Epoch[99] Batch [5]#011Speed: 1902.84 samples/sec#011loss=8.012936\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] Epoch[99] Batch[10] avg_epoch_loss=8.071889\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=99, batch=10 train loss <loss>=8.14263362885\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] Epoch[99] Batch [10]#011Speed: 939.38 samples/sec#011loss=8.142634\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] Epoch[99] Batch[15] avg_epoch_loss=8.168515\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=99, batch=15 train loss <loss>=8.38109102249\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] Epoch[99] Batch [15]#011Speed: 1751.79 samples/sec#011loss=8.381091\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] Epoch[99] Batch[20] avg_epoch_loss=8.164455\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=99, batch=20 train loss <loss>=8.15146141052\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] Epoch[99] Batch [20]#011Speed: 935.84 samples/sec#011loss=8.151461\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] Epoch[99] Batch[25] avg_epoch_loss=8.154731\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=99, batch=25 train loss <loss>=8.11389036179\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] Epoch[99] Batch [25]#011Speed: 1869.20 samples/sec#011loss=8.113890\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] Epoch[99] Batch[30] avg_epoch_loss=8.115444\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=99, batch=30 train loss <loss>=7.91115589142\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:20:59 INFO 139919921551168] Epoch[99] Batch [30]#011Speed: 946.14 samples/sec#011loss=7.911156\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] Epoch[99] Batch[35] avg_epoch_loss=8.088833\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=99, batch=35 train loss <loss>=7.9238404274\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] Epoch[99] Batch [35]#011Speed: 2078.27 samples/sec#011loss=7.923840\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] Epoch[99] Batch[40] avg_epoch_loss=8.066354\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=99, batch=40 train loss <loss>=7.90451040268\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] Epoch[99] Batch [40]#011Speed: 886.02 samples/sec#011loss=7.904510\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] Epoch[99] Batch[45] avg_epoch_loss=8.042242\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=99, batch=45 train loss <loss>=7.84452171326\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] Epoch[99] Batch [45]#011Speed: 1846.94 samples/sec#011loss=7.844522\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] processed a total of 1582 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1296.8380451202393, \"sum\": 1296.8380451202393, \"min\": 1296.8380451202393}}, \"EndTime\": 1578471660.410771, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471659.113875}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1219.77738447 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=99, train loss <loss>=7.9822509861\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] Epoch[100] Batch[0] avg_epoch_loss=8.488613\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=8.48861312866\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] Epoch[100] Batch[5] avg_epoch_loss=8.243116\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=8.24311645826\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] Epoch[100] Batch [5]#011Speed: 1781.60 samples/sec#011loss=8.243116\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] Epoch[100] Batch[10] avg_epoch_loss=8.218468\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=100, batch=10 train loss <loss>=8.18889064789\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] Epoch[100] Batch [10]#011Speed: 1955.61 samples/sec#011loss=8.188891\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] Epoch[100] Batch[15] avg_epoch_loss=8.255042\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=100, batch=15 train loss <loss>=8.33550300598\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] Epoch[100] Batch [15]#011Speed: 1026.65 samples/sec#011loss=8.335503\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] Epoch[100] Batch[20] avg_epoch_loss=8.316593\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=100, batch=20 train loss <loss>=8.51355667114\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:00 INFO 139919921551168] Epoch[100] Batch [20]#011Speed: 1961.73 samples/sec#011loss=8.513557\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] Epoch[100] Batch[25] avg_epoch_loss=8.253574\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=100, batch=25 train loss <loss>=7.98889484406\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] Epoch[100] Batch [25]#011Speed: 898.55 samples/sec#011loss=7.988895\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] Epoch[100] Batch[30] avg_epoch_loss=8.204493\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=100, batch=30 train loss <loss>=7.94927396774\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] Epoch[100] Batch [30]#011Speed: 2130.97 samples/sec#011loss=7.949274\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] Epoch[100] Batch[35] avg_epoch_loss=8.134927\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=100, batch=35 train loss <loss>=7.70361795425\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] Epoch[100] Batch [35]#011Speed: 904.05 samples/sec#011loss=7.703618\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] Epoch[100] Batch[40] avg_epoch_loss=8.096633\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=100, batch=40 train loss <loss>=7.82091121674\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] Epoch[100] Batch [40]#011Speed: 1616.85 samples/sec#011loss=7.820911\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] Epoch[100] Batch[45] avg_epoch_loss=8.062927\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=100, batch=45 train loss <loss>=7.78654174805\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] Epoch[100] Batch [45]#011Speed: 996.10 samples/sec#011loss=7.786542\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] Epoch[100] Batch[50] avg_epoch_loss=8.050185\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=100, batch=50 train loss <loss>=7.93295564651\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] Epoch[100] Batch [50]#011Speed: 2051.10 samples/sec#011loss=7.932956\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] processed a total of 1676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1323.8120079040527, \"sum\": 1323.8120079040527, \"min\": 1323.8120079040527}}, \"EndTime\": 1578471661.735181, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471660.410855}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1265.93659596 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=100, train loss <loss>=8.00241975065\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] Epoch[101] Batch[0] avg_epoch_loss=8.321125\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=8.32112503052\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] Epoch[101] Batch[5] avg_epoch_loss=8.295032\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=8.29503202438\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:01 INFO 139919921551168] Epoch[101] Batch [5]#011Speed: 1758.34 samples/sec#011loss=8.295032\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] Epoch[101] Batch[10] avg_epoch_loss=8.252905\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=8.20235300064\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] Epoch[101] Batch [10]#011Speed: 987.67 samples/sec#011loss=8.202353\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] Epoch[101] Batch[15] avg_epoch_loss=8.289143\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=101, batch=15 train loss <loss>=8.36886577606\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] Epoch[101] Batch [15]#011Speed: 1909.33 samples/sec#011loss=8.368866\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] Epoch[101] Batch[20] avg_epoch_loss=8.248841\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=101, batch=20 train loss <loss>=8.11987466812\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] Epoch[101] Batch [20]#011Speed: 913.64 samples/sec#011loss=8.119875\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] Epoch[101] Batch[25] avg_epoch_loss=8.165542\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=101, batch=25 train loss <loss>=7.81568632126\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] Epoch[101] Batch [25]#011Speed: 1794.45 samples/sec#011loss=7.815686\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] Epoch[101] Batch[30] avg_epoch_loss=8.085924\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=101, batch=30 train loss <loss>=7.67190856934\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] Epoch[101] Batch [30]#011Speed: 1089.47 samples/sec#011loss=7.671909\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] Epoch[101] Batch[35] avg_epoch_loss=8.059202\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=101, batch=35 train loss <loss>=7.89353046417\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] Epoch[101] Batch [35]#011Speed: 2003.31 samples/sec#011loss=7.893530\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] Epoch[101] Batch[40] avg_epoch_loss=8.032360\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=101, batch=40 train loss <loss>=7.83909425735\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] Epoch[101] Batch [40]#011Speed: 1105.24 samples/sec#011loss=7.839094\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] Epoch[101] Batch[45] avg_epoch_loss=8.010777\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=101, batch=45 train loss <loss>=7.83379631042\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] Epoch[101] Batch [45]#011Speed: 1894.88 samples/sec#011loss=7.833796\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] processed a total of 1599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1241.818904876709, \"sum\": 1241.818904876709, \"min\": 1241.818904876709}}, \"EndTime\": 1578471662.977579, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471661.735252}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1287.51118172 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=101, train loss <loss>=8.00527979851\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:02 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:03 INFO 139919921551168] Epoch[102] Batch[0] avg_epoch_loss=8.292625\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=8.29262542725\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:03 INFO 139919921551168] Epoch[102] Batch[5] avg_epoch_loss=8.149818\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=8.14981826146\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:03 INFO 139919921551168] Epoch[102] Batch [5]#011Speed: 2083.66 samples/sec#011loss=8.149818\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:03 INFO 139919921551168] Epoch[102] Batch[10] avg_epoch_loss=8.245653\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=102, batch=10 train loss <loss>=8.36065359116\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:03 INFO 139919921551168] Epoch[102] Batch [10]#011Speed: 975.75 samples/sec#011loss=8.360654\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:03 INFO 139919921551168] Epoch[102] Batch[15] avg_epoch_loss=8.362278\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=102, batch=15 train loss <loss>=8.61885471344\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:03 INFO 139919921551168] Epoch[102] Batch [15]#011Speed: 2139.35 samples/sec#011loss=8.618855\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:03 INFO 139919921551168] Epoch[102] Batch[20] avg_epoch_loss=8.340062\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=102, batch=20 train loss <loss>=8.26896944046\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:03 INFO 139919921551168] Epoch[102] Batch [20]#011Speed: 913.72 samples/sec#011loss=8.268969\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:03 INFO 139919921551168] Epoch[102] Batch[25] avg_epoch_loss=8.283476\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=102, batch=25 train loss <loss>=8.04581365585\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:03 INFO 139919921551168] Epoch[102] Batch [25]#011Speed: 1969.16 samples/sec#011loss=8.045814\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:03 INFO 139919921551168] Epoch[102] Batch[30] avg_epoch_loss=8.175194\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=102, batch=30 train loss <loss>=7.612129879\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:03 INFO 139919921551168] Epoch[102] Batch [30]#011Speed: 951.79 samples/sec#011loss=7.612130\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:03 INFO 139919921551168] Epoch[102] Batch[35] avg_epoch_loss=8.114108\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=102, batch=35 train loss <loss>=7.73537778854\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:03 INFO 139919921551168] Epoch[102] Batch [35]#011Speed: 1842.96 samples/sec#011loss=7.735378\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] Epoch[102] Batch[40] avg_epoch_loss=8.118401\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=102, batch=40 train loss <loss>=8.14930896759\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] Epoch[102] Batch [40]#011Speed: 980.24 samples/sec#011loss=8.149309\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] Epoch[102] Batch[45] avg_epoch_loss=8.109870\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=102, batch=45 train loss <loss>=8.03991441727\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] Epoch[102] Batch [45]#011Speed: 2068.17 samples/sec#011loss=8.039914\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] processed a total of 1534 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1218.0700302124023, \"sum\": 1218.0700302124023, \"min\": 1218.0700302124023}}, \"EndTime\": 1578471664.196166, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471662.977655}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1259.23694112 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=102, train loss <loss>=8.06483122706\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] Epoch[103] Batch[0] avg_epoch_loss=8.286907\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=8.28690719604\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] Epoch[103] Batch[5] avg_epoch_loss=8.187436\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=8.18743578593\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] Epoch[103] Batch [5]#011Speed: 2041.36 samples/sec#011loss=8.187436\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] Epoch[103] Batch[10] avg_epoch_loss=8.176910\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=103, batch=10 train loss <loss>=8.16427879333\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] Epoch[103] Batch [10]#011Speed: 952.90 samples/sec#011loss=8.164279\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] Epoch[103] Batch[15] avg_epoch_loss=8.317549\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=103, batch=15 train loss <loss>=8.62695579529\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] Epoch[103] Batch [15]#011Speed: 1615.10 samples/sec#011loss=8.626956\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] Epoch[103] Batch[20] avg_epoch_loss=8.351220\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=103, batch=20 train loss <loss>=8.45896663666\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] Epoch[103] Batch [20]#011Speed: 963.56 samples/sec#011loss=8.458967\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] Epoch[103] Batch[25] avg_epoch_loss=8.222808\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=103, batch=25 train loss <loss>=7.68347988129\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:04 INFO 139919921551168] Epoch[103] Batch [25]#011Speed: 2097.76 samples/sec#011loss=7.683480\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] Epoch[103] Batch[30] avg_epoch_loss=8.137243\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=103, batch=30 train loss <loss>=7.69230546951\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] Epoch[103] Batch [30]#011Speed: 953.25 samples/sec#011loss=7.692305\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] Epoch[103] Batch[35] avg_epoch_loss=8.101245\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=103, batch=35 train loss <loss>=7.87805633545\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] Epoch[103] Batch [35]#011Speed: 2055.45 samples/sec#011loss=7.878056\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] Epoch[103] Batch[40] avg_epoch_loss=8.072928\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=103, batch=40 train loss <loss>=7.86904726028\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] Epoch[103] Batch [40]#011Speed: 1008.36 samples/sec#011loss=7.869047\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] Epoch[103] Batch[45] avg_epoch_loss=8.022345\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=103, batch=45 train loss <loss>=7.6075592041\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] Epoch[103] Batch [45]#011Speed: 2061.24 samples/sec#011loss=7.607559\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] Epoch[103] Batch[50] avg_epoch_loss=8.051073\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=103, batch=50 train loss <loss>=8.31537008286\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] Epoch[103] Batch [50]#011Speed: 1476.34 samples/sec#011loss=8.315370\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] processed a total of 1621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1269.2010402679443, \"sum\": 1269.2010402679443, \"min\": 1269.2010402679443}}, \"EndTime\": 1578471665.465941, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471664.196257}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1277.06987836 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=103, train loss <loss>=8.0510727845\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] Epoch[104] Batch[0] avg_epoch_loss=8.272587\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=8.27258682251\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] Epoch[104] Batch[5] avg_epoch_loss=8.132628\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=8.13262788455\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] Epoch[104] Batch [5]#011Speed: 1819.80 samples/sec#011loss=8.132628\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] Epoch[104] Batch[10] avg_epoch_loss=8.221301\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=104, batch=10 train loss <loss>=8.32770862579\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] Epoch[104] Batch [10]#011Speed: 1026.07 samples/sec#011loss=8.327709\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] Epoch[104] Batch[15] avg_epoch_loss=8.292004\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=104, batch=15 train loss <loss>=8.44755001068\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:05 INFO 139919921551168] Epoch[104] Batch [15]#011Speed: 1963.34 samples/sec#011loss=8.447550\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] Epoch[104] Batch[20] avg_epoch_loss=8.291036\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=104, batch=20 train loss <loss>=8.2879401207\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] Epoch[104] Batch [20]#011Speed: 955.05 samples/sec#011loss=8.287940\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] Epoch[104] Batch[25] avg_epoch_loss=8.259150\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=104, batch=25 train loss <loss>=8.12522535324\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] Epoch[104] Batch [25]#011Speed: 1660.54 samples/sec#011loss=8.125225\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] Epoch[104] Batch[30] avg_epoch_loss=8.166279\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=104, batch=30 train loss <loss>=7.68334980011\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] Epoch[104] Batch [30]#011Speed: 971.19 samples/sec#011loss=7.683350\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] Epoch[104] Batch[35] avg_epoch_loss=8.085971\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=104, batch=35 train loss <loss>=7.5880651474\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] Epoch[104] Batch [35]#011Speed: 2053.41 samples/sec#011loss=7.588065\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] Epoch[104] Batch[40] avg_epoch_loss=8.084399\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=104, batch=40 train loss <loss>=8.07307853699\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] Epoch[104] Batch [40]#011Speed: 860.11 samples/sec#011loss=8.073079\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] Epoch[104] Batch[45] avg_epoch_loss=8.063623\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=104, batch=45 train loss <loss>=7.89325799942\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] Epoch[104] Batch [45]#011Speed: 2013.26 samples/sec#011loss=7.893258\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] processed a total of 1541 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1267.4450874328613, \"sum\": 1267.4450874328613, \"min\": 1267.4450874328613}}, \"EndTime\": 1578471666.733862, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471665.466016}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1215.72519748 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=104, train loss <loss>=7.99154796406\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] Epoch[105] Batch[0] avg_epoch_loss=8.285144\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=8.28514385223\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] Epoch[105] Batch[5] avg_epoch_loss=8.086684\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=8.08668359121\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:06 INFO 139919921551168] Epoch[105] Batch [5]#011Speed: 1950.10 samples/sec#011loss=8.086684\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] Epoch[105] Batch[10] avg_epoch_loss=8.127058\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=8.17550649643\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] Epoch[105] Batch [10]#011Speed: 982.80 samples/sec#011loss=8.175506\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] Epoch[105] Batch[15] avg_epoch_loss=8.208192\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=105, batch=15 train loss <loss>=8.38668708801\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] Epoch[105] Batch [15]#011Speed: 2141.56 samples/sec#011loss=8.386687\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] Epoch[105] Batch[20] avg_epoch_loss=8.171715\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=105, batch=20 train loss <loss>=8.05498790741\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] Epoch[105] Batch [20]#011Speed: 977.71 samples/sec#011loss=8.054988\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] Epoch[105] Batch[25] avg_epoch_loss=8.126426\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=105, batch=25 train loss <loss>=7.93621473312\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] Epoch[105] Batch [25]#011Speed: 1492.90 samples/sec#011loss=7.936215\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] Epoch[105] Batch[30] avg_epoch_loss=8.083446\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=105, batch=30 train loss <loss>=7.8599486351\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] Epoch[105] Batch [30]#011Speed: 1073.66 samples/sec#011loss=7.859949\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] Epoch[105] Batch[35] avg_epoch_loss=8.055557\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=105, batch=35 train loss <loss>=7.88264741898\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] Epoch[105] Batch [35]#011Speed: 1888.44 samples/sec#011loss=7.882647\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] Epoch[105] Batch[40] avg_epoch_loss=8.041412\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=105, batch=40 train loss <loss>=7.93956727982\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] Epoch[105] Batch [40]#011Speed: 923.45 samples/sec#011loss=7.939567\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] Epoch[105] Batch[45] avg_epoch_loss=8.061913\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=105, batch=45 train loss <loss>=8.23002414703\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:07 INFO 139919921551168] Epoch[105] Batch [45]#011Speed: 1641.61 samples/sec#011loss=8.230024\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] Epoch[105] Batch[50] avg_epoch_loss=7.980338\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=105, batch=50 train loss <loss>=7.22984256744\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] Epoch[105] Batch [50]#011Speed: 1463.74 samples/sec#011loss=7.229843\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] processed a total of 1611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1306.6329956054688, \"sum\": 1306.6329956054688, \"min\": 1306.6329956054688}}, \"EndTime\": 1578471668.041038, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471666.73394}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1232.82970808 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=105, train loss <loss>=7.98033790027\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] Epoch[106] Batch[0] avg_epoch_loss=8.375916\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=8.37591552734\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] Epoch[106] Batch[5] avg_epoch_loss=8.277154\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=8.2771542867\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] Epoch[106] Batch [5]#011Speed: 2031.28 samples/sec#011loss=8.277154\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] Epoch[106] Batch[10] avg_epoch_loss=8.317155\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=106, batch=10 train loss <loss>=8.36515674591\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] Epoch[106] Batch [10]#011Speed: 1056.06 samples/sec#011loss=8.365157\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] Epoch[106] Batch[15] avg_epoch_loss=8.405091\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=106, batch=15 train loss <loss>=8.59854927063\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] Epoch[106] Batch [15]#011Speed: 2037.75 samples/sec#011loss=8.598549\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] Epoch[106] Batch[20] avg_epoch_loss=8.365068\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=106, batch=20 train loss <loss>=8.23699436188\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] Epoch[106] Batch [20]#011Speed: 1056.89 samples/sec#011loss=8.236994\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] Epoch[106] Batch[25] avg_epoch_loss=8.257068\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=106, batch=25 train loss <loss>=7.80346984863\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] Epoch[106] Batch [25]#011Speed: 1822.24 samples/sec#011loss=7.803470\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] Epoch[106] Batch[30] avg_epoch_loss=8.183525\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=106, batch=30 train loss <loss>=7.8010972023\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] Epoch[106] Batch [30]#011Speed: 935.26 samples/sec#011loss=7.801097\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] Epoch[106] Batch[35] avg_epoch_loss=8.100813\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=106, batch=35 train loss <loss>=7.58799934387\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:08 INFO 139919921551168] Epoch[106] Batch [35]#011Speed: 2054.26 samples/sec#011loss=7.587999\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] Epoch[106] Batch[40] avg_epoch_loss=8.097024\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=106, batch=40 train loss <loss>=8.06974554062\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] Epoch[106] Batch [40]#011Speed: 871.83 samples/sec#011loss=8.069746\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] Epoch[106] Batch[45] avg_epoch_loss=8.109611\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=106, batch=45 train loss <loss>=8.21282510757\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] Epoch[106] Batch [45]#011Speed: 1953.80 samples/sec#011loss=8.212825\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] Epoch[106] Batch[50] avg_epoch_loss=8.070787\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=106, batch=50 train loss <loss>=7.71360111237\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] Epoch[106] Batch [50]#011Speed: 1618.49 samples/sec#011loss=7.713601\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] processed a total of 1642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1274.0259170532227, \"sum\": 1274.0259170532227, \"min\": 1274.0259170532227}}, \"EndTime\": 1578471669.315594, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471668.041118}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1288.68501663 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=106, train loss <loss>=8.04684420732\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] Epoch[107] Batch[0] avg_epoch_loss=8.690705\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=8.69070529938\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] Epoch[107] Batch[5] avg_epoch_loss=8.344381\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=8.34438069661\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] Epoch[107] Batch [5]#011Speed: 1752.43 samples/sec#011loss=8.344381\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] Epoch[107] Batch[10] avg_epoch_loss=8.307072\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=8.26230134964\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] Epoch[107] Batch [10]#011Speed: 990.37 samples/sec#011loss=8.262301\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] Epoch[107] Batch[15] avg_epoch_loss=8.369109\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=107, batch=15 train loss <loss>=8.50559005737\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] Epoch[107] Batch [15]#011Speed: 1800.36 samples/sec#011loss=8.505590\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] Epoch[107] Batch[20] avg_epoch_loss=8.451412\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=107, batch=20 train loss <loss>=8.71478061676\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:09 INFO 139919921551168] Epoch[107] Batch [20]#011Speed: 991.76 samples/sec#011loss=8.714781\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] Epoch[107] Batch[25] avg_epoch_loss=8.346575\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=107, batch=25 train loss <loss>=7.90626125336\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] Epoch[107] Batch [25]#011Speed: 2064.65 samples/sec#011loss=7.906261\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] Epoch[107] Batch[30] avg_epoch_loss=8.234355\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=107, batch=30 train loss <loss>=7.65081071854\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] Epoch[107] Batch [30]#011Speed: 1068.87 samples/sec#011loss=7.650811\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] Epoch[107] Batch[35] avg_epoch_loss=8.153552\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=107, batch=35 train loss <loss>=7.65257406235\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] Epoch[107] Batch [35]#011Speed: 1642.61 samples/sec#011loss=7.652574\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] Epoch[107] Batch[40] avg_epoch_loss=8.125362\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=107, batch=40 train loss <loss>=7.9223947525\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] Epoch[107] Batch [40]#011Speed: 1111.16 samples/sec#011loss=7.922395\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] Epoch[107] Batch[45] avg_epoch_loss=8.117492\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=107, batch=45 train loss <loss>=8.05295257568\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] Epoch[107] Batch [45]#011Speed: 1896.83 samples/sec#011loss=8.052953\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] processed a total of 1575 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1252.025842666626, \"sum\": 1252.025842666626, \"min\": 1252.025842666626}}, \"EndTime\": 1578471670.568166, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471669.315698}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1257.84652131 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=107, train loss <loss>=8.06543689728\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] Epoch[108] Batch[0] avg_epoch_loss=8.278404\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=8.27840423584\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] Epoch[108] Batch[5] avg_epoch_loss=8.494029\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=8.4940290451\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] Epoch[108] Batch [5]#011Speed: 1948.77 samples/sec#011loss=8.494029\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] Epoch[108] Batch[10] avg_epoch_loss=8.392032\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=8.26963586807\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] Epoch[108] Batch [10]#011Speed: 1107.71 samples/sec#011loss=8.269636\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] Epoch[108] Batch[15] avg_epoch_loss=8.401115\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=108, batch=15 train loss <loss>=8.42109613419\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:10 INFO 139919921551168] Epoch[108] Batch [15]#011Speed: 2055.31 samples/sec#011loss=8.421096\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] Epoch[108] Batch[20] avg_epoch_loss=8.355926\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=108, batch=20 train loss <loss>=8.2113237381\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] Epoch[108] Batch [20]#011Speed: 926.52 samples/sec#011loss=8.211324\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] Epoch[108] Batch[25] avg_epoch_loss=8.312859\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=108, batch=25 train loss <loss>=8.13197422028\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] Epoch[108] Batch [25]#011Speed: 2125.74 samples/sec#011loss=8.131974\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] Epoch[108] Batch[30] avg_epoch_loss=8.248095\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=108, batch=30 train loss <loss>=7.91132164001\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] Epoch[108] Batch [30]#011Speed: 920.35 samples/sec#011loss=7.911322\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] Epoch[108] Batch[35] avg_epoch_loss=8.161066\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=108, batch=35 train loss <loss>=7.62148857117\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] Epoch[108] Batch [35]#011Speed: 1824.72 samples/sec#011loss=7.621489\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] Epoch[108] Batch[40] avg_epoch_loss=8.119102\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=108, batch=40 train loss <loss>=7.81696500778\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] Epoch[108] Batch [40]#011Speed: 976.56 samples/sec#011loss=7.816965\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] Epoch[108] Batch[45] avg_epoch_loss=8.086397\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=108, batch=45 train loss <loss>=7.81821098328\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] Epoch[108] Batch [45]#011Speed: 1654.16 samples/sec#011loss=7.818211\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] Epoch[108] Batch[50] avg_epoch_loss=8.125322\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=108, batch=50 train loss <loss>=8.48343830109\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] Epoch[108] Batch [50]#011Speed: 1437.69 samples/sec#011loss=8.483438\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] processed a total of 1603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1291.961908340454, \"sum\": 1291.961908340454, \"min\": 1291.961908340454}}, \"EndTime\": 1578471671.860655, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471670.568244}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1240.64494124 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=108, train loss <loss>=8.12532248217\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] Epoch[109] Batch[0] avg_epoch_loss=8.402886\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=8.40288639069\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] Epoch[109] Batch[5] avg_epoch_loss=8.274890\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=8.2748901844\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] Epoch[109] Batch [5]#011Speed: 1780.43 samples/sec#011loss=8.274890\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] Epoch[109] Batch[10] avg_epoch_loss=8.320940\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=109, batch=10 train loss <loss>=8.3762005806\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] Epoch[109] Batch [10]#011Speed: 1041.28 samples/sec#011loss=8.376201\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] Epoch[109] Batch[15] avg_epoch_loss=8.376728\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=109, batch=15 train loss <loss>=8.49946136475\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] Epoch[109] Batch [15]#011Speed: 2065.75 samples/sec#011loss=8.499461\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] Epoch[109] Batch[20] avg_epoch_loss=8.370683\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=109, batch=20 train loss <loss>=8.35133810043\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] Epoch[109] Batch [20]#011Speed: 919.56 samples/sec#011loss=8.351338\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] Epoch[109] Batch[25] avg_epoch_loss=8.261692\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=109, batch=25 train loss <loss>=7.80393095016\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] Epoch[109] Batch [25]#011Speed: 2147.97 samples/sec#011loss=7.803931\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] Epoch[109] Batch[30] avg_epoch_loss=8.206916\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=109, batch=30 train loss <loss>=7.92208127975\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] Epoch[109] Batch [30]#011Speed: 975.53 samples/sec#011loss=7.922081\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] Epoch[109] Batch[35] avg_epoch_loss=8.162500\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=109, batch=35 train loss <loss>=7.88712034225\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] Epoch[109] Batch [35]#011Speed: 1811.61 samples/sec#011loss=7.887120\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] Epoch[109] Batch[40] avg_epoch_loss=8.109749\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=109, batch=40 train loss <loss>=7.72994384766\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:12 INFO 139919921551168] Epoch[109] Batch [40]#011Speed: 987.47 samples/sec#011loss=7.729944\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] Epoch[109] Batch[45] avg_epoch_loss=8.056808\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=109, batch=45 train loss <loss>=7.62268571854\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] Epoch[109] Batch [45]#011Speed: 2055.97 samples/sec#011loss=7.622686\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] Epoch[109] Batch[50] avg_epoch_loss=8.035499\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=109, batch=50 train loss <loss>=7.83945817947\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] Epoch[109] Batch [50]#011Speed: 1413.12 samples/sec#011loss=7.839458\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] processed a total of 1616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1273.7090587615967, \"sum\": 1273.7090587615967, \"min\": 1273.7090587615967}}, \"EndTime\": 1578471673.134883, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471671.860726}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1268.62800612 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=109, train loss <loss>=8.03549888087\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] Epoch[110] Batch[0] avg_epoch_loss=8.091424\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=8.09142398834\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] Epoch[110] Batch[5] avg_epoch_loss=8.320754\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=8.32075444857\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] Epoch[110] Batch [5]#011Speed: 2068.20 samples/sec#011loss=8.320754\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] Epoch[110] Batch[10] avg_epoch_loss=8.182392\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=8.01635684967\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] Epoch[110] Batch [10]#011Speed: 1070.63 samples/sec#011loss=8.016357\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] Epoch[110] Batch[15] avg_epoch_loss=8.167743\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=110, batch=15 train loss <loss>=8.13551673889\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] Epoch[110] Batch [15]#011Speed: 1659.17 samples/sec#011loss=8.135517\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] Epoch[110] Batch[20] avg_epoch_loss=8.147148\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=110, batch=20 train loss <loss>=8.08124084473\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] Epoch[110] Batch [20]#011Speed: 948.09 samples/sec#011loss=8.081241\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] Epoch[110] Batch[25] avg_epoch_loss=8.090487\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=110, batch=25 train loss <loss>=7.85251226425\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] Epoch[110] Batch [25]#011Speed: 2009.12 samples/sec#011loss=7.852512\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] Epoch[110] Batch[30] avg_epoch_loss=8.038213\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=110, batch=30 train loss <loss>=7.76638994217\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:13 INFO 139919921551168] Epoch[110] Batch [30]#011Speed: 996.92 samples/sec#011loss=7.766390\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] Epoch[110] Batch[35] avg_epoch_loss=7.988688\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=110, batch=35 train loss <loss>=7.68163480759\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] Epoch[110] Batch [35]#011Speed: 1986.49 samples/sec#011loss=7.681635\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] Epoch[110] Batch[40] avg_epoch_loss=7.959836\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=110, batch=40 train loss <loss>=7.75209693909\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] Epoch[110] Batch [40]#011Speed: 738.82 samples/sec#011loss=7.752097\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] Epoch[110] Batch[45] avg_epoch_loss=7.982500\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=110, batch=45 train loss <loss>=8.16834564209\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] Epoch[110] Batch [45]#011Speed: 1560.44 samples/sec#011loss=8.168346\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] Epoch[110] Batch[50] avg_epoch_loss=7.937473\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=110, batch=50 train loss <loss>=7.52322645187\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] Epoch[110] Batch [50]#011Speed: 1644.65 samples/sec#011loss=7.523226\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] processed a total of 1659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1340.9059047698975, \"sum\": 1340.9059047698975, \"min\": 1340.9059047698975}}, \"EndTime\": 1578471674.476349, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471673.134952}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1237.12825323 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=110, train loss <loss>=7.91816954429\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] Saved checkpoint to \"/opt/ml/model/state_cfe4a010-df2c-427a-b1c5-a931962a9ecd-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.26010513305664, \"sum\": 10.26010513305664, \"min\": 10.26010513305664}}, \"EndTime\": 1578471674.487196, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471674.476412}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] Epoch[111] Batch[0] avg_epoch_loss=8.541220\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=8.5412197113\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] Epoch[111] Batch[5] avg_epoch_loss=8.162639\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=8.16263866425\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] Epoch[111] Batch [5]#011Speed: 2123.77 samples/sec#011loss=8.162639\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] Epoch[111] Batch[10] avg_epoch_loss=8.183395\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=8.20830249786\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] Epoch[111] Batch [10]#011Speed: 971.61 samples/sec#011loss=8.208302\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] Epoch[111] Batch[15] avg_epoch_loss=8.317684\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=111, batch=15 train loss <loss>=8.61312026978\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:14 INFO 139919921551168] Epoch[111] Batch [15]#011Speed: 2120.66 samples/sec#011loss=8.613120\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] Epoch[111] Batch[20] avg_epoch_loss=8.323570\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=111, batch=20 train loss <loss>=8.34240674973\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] Epoch[111] Batch [20]#011Speed: 975.35 samples/sec#011loss=8.342407\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] Epoch[111] Batch[25] avg_epoch_loss=8.239439\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=111, batch=25 train loss <loss>=7.88608436584\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] Epoch[111] Batch [25]#011Speed: 1800.93 samples/sec#011loss=7.886084\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] Epoch[111] Batch[30] avg_epoch_loss=8.161255\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=111, batch=30 train loss <loss>=7.75470380783\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] Epoch[111] Batch [30]#011Speed: 999.78 samples/sec#011loss=7.754704\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] Epoch[111] Batch[35] avg_epoch_loss=8.101828\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=111, batch=35 train loss <loss>=7.7333741188\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] Epoch[111] Batch [35]#011Speed: 2020.30 samples/sec#011loss=7.733374\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] Epoch[111] Batch[40] avg_epoch_loss=8.091150\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=111, batch=40 train loss <loss>=8.01426811218\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] Epoch[111] Batch [40]#011Speed: 1011.40 samples/sec#011loss=8.014268\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] Epoch[111] Batch[45] avg_epoch_loss=8.099186\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=111, batch=45 train loss <loss>=8.16508665085\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] Epoch[111] Batch [45]#011Speed: 2042.59 samples/sec#011loss=8.165087\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] processed a total of 1574 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1221.7881679534912, \"sum\": 1221.7881679534912, \"min\": 1221.7881679534912}}, \"EndTime\": 1578471675.709109, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471674.487264}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1288.16936359 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=111, train loss <loss>=8.04395572662\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] Epoch[112] Batch[0] avg_epoch_loss=8.282485\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=8.28248500824\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] Epoch[112] Batch[5] avg_epoch_loss=8.192333\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=8.19233258565\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:15 INFO 139919921551168] Epoch[112] Batch [5]#011Speed: 2053.89 samples/sec#011loss=8.192333\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] Epoch[112] Batch[10] avg_epoch_loss=8.219008\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=8.25101804733\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] Epoch[112] Batch [10]#011Speed: 868.10 samples/sec#011loss=8.251018\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] Epoch[112] Batch[15] avg_epoch_loss=8.310158\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=112, batch=15 train loss <loss>=8.5106877327\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] Epoch[112] Batch [15]#011Speed: 2119.99 samples/sec#011loss=8.510688\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] Epoch[112] Batch[20] avg_epoch_loss=8.250940\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=112, batch=20 train loss <loss>=8.06144285202\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] Epoch[112] Batch [20]#011Speed: 1010.45 samples/sec#011loss=8.061443\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] Epoch[112] Batch[25] avg_epoch_loss=8.235256\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=112, batch=25 train loss <loss>=8.1693816185\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] Epoch[112] Batch [25]#011Speed: 1598.72 samples/sec#011loss=8.169382\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] Epoch[112] Batch[30] avg_epoch_loss=8.148040\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=112, batch=30 train loss <loss>=7.69451808929\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] Epoch[112] Batch [30]#011Speed: 955.51 samples/sec#011loss=7.694518\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] Epoch[112] Batch[35] avg_epoch_loss=8.131171\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=112, batch=35 train loss <loss>=8.02658700943\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] Epoch[112] Batch [35]#011Speed: 1827.78 samples/sec#011loss=8.026587\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] Epoch[112] Batch[40] avg_epoch_loss=8.120820\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=112, batch=40 train loss <loss>=8.04629278183\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] Epoch[112] Batch [40]#011Speed: 790.83 samples/sec#011loss=8.046293\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] Epoch[112] Batch[45] avg_epoch_loss=8.098158\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=112, batch=45 train loss <loss>=7.91232252121\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:16 INFO 139919921551168] Epoch[112] Batch [45]#011Speed: 2089.16 samples/sec#011loss=7.912323\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] processed a total of 1545 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1294.1970825195312, \"sum\": 1294.1970825195312, \"min\": 1294.1970825195312}}, \"EndTime\": 1578471677.003851, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471675.709173}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1193.69074305 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=112, train loss <loss>=8.04169557532\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] Epoch[113] Batch[0] avg_epoch_loss=8.629875\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=8.62987518311\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] Epoch[113] Batch[5] avg_epoch_loss=8.375526\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=8.37552579244\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] Epoch[113] Batch [5]#011Speed: 1842.13 samples/sec#011loss=8.375526\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] Epoch[113] Batch[10] avg_epoch_loss=8.210051\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=8.01148138046\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] Epoch[113] Batch [10]#011Speed: 1055.05 samples/sec#011loss=8.011481\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] Epoch[113] Batch[15] avg_epoch_loss=8.303202\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=113, batch=15 train loss <loss>=8.50813331604\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] Epoch[113] Batch [15]#011Speed: 1909.17 samples/sec#011loss=8.508133\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] Epoch[113] Batch[20] avg_epoch_loss=8.287638\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=113, batch=20 train loss <loss>=8.23783531189\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] Epoch[113] Batch [20]#011Speed: 1031.72 samples/sec#011loss=8.237835\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] Epoch[113] Batch[25] avg_epoch_loss=8.201838\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=113, batch=25 train loss <loss>=7.84147577286\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] Epoch[113] Batch [25]#011Speed: 2059.86 samples/sec#011loss=7.841476\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] Epoch[113] Batch[30] avg_epoch_loss=8.142790\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=113, batch=30 train loss <loss>=7.83574075699\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] Epoch[113] Batch [30]#011Speed: 1041.37 samples/sec#011loss=7.835741\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] Epoch[113] Batch[35] avg_epoch_loss=8.091415\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=113, batch=35 train loss <loss>=7.77289199829\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:17 INFO 139919921551168] Epoch[113] Batch [35]#011Speed: 1650.22 samples/sec#011loss=7.772892\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] Epoch[113] Batch[40] avg_epoch_loss=8.042447\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=113, batch=40 train loss <loss>=7.68987894058\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] Epoch[113] Batch [40]#011Speed: 953.70 samples/sec#011loss=7.689879\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] Epoch[113] Batch[45] avg_epoch_loss=8.009666\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=113, batch=45 train loss <loss>=7.74085426331\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] Epoch[113] Batch [45]#011Speed: 1659.15 samples/sec#011loss=7.740854\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] Epoch[113] Batch[50] avg_epoch_loss=8.000938\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=113, batch=50 train loss <loss>=7.92064056396\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] Epoch[113] Batch [50]#011Speed: 1353.07 samples/sec#011loss=7.920641\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] processed a total of 1690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1324.8920440673828, \"sum\": 1324.8920440673828, \"min\": 1324.8920440673828}}, \"EndTime\": 1578471678.329246, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471677.003924}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1275.47853744 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=113, train loss <loss>=7.99393167136\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] Epoch[114] Batch[0] avg_epoch_loss=8.095172\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=8.09517192841\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] Epoch[114] Batch[5] avg_epoch_loss=8.126243\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=8.12624327342\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] Epoch[114] Batch [5]#011Speed: 2055.87 samples/sec#011loss=8.126243\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] Epoch[114] Batch[10] avg_epoch_loss=8.213376\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=8.31793518066\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] Epoch[114] Batch [10]#011Speed: 977.83 samples/sec#011loss=8.317935\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] Epoch[114] Batch[15] avg_epoch_loss=8.207204\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=114, batch=15 train loss <loss>=8.19362630844\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] Epoch[114] Batch [15]#011Speed: 1756.17 samples/sec#011loss=8.193626\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] Epoch[114] Batch[20] avg_epoch_loss=8.181084\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=114, batch=20 train loss <loss>=8.0974978447\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:18 INFO 139919921551168] Epoch[114] Batch [20]#011Speed: 873.96 samples/sec#011loss=8.097498\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] Epoch[114] Batch[25] avg_epoch_loss=8.104667\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=114, batch=25 train loss <loss>=7.7837187767\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] Epoch[114] Batch [25]#011Speed: 1852.99 samples/sec#011loss=7.783719\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] Epoch[114] Batch[30] avg_epoch_loss=8.070805\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=114, batch=30 train loss <loss>=7.89472074509\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] Epoch[114] Batch [30]#011Speed: 904.94 samples/sec#011loss=7.894721\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] Epoch[114] Batch[35] avg_epoch_loss=8.019492\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=114, batch=35 train loss <loss>=7.7013504982\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] Epoch[114] Batch [35]#011Speed: 2033.34 samples/sec#011loss=7.701350\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] Epoch[114] Batch[40] avg_epoch_loss=8.013567\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=114, batch=40 train loss <loss>=7.97090959549\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] Epoch[114] Batch [40]#011Speed: 936.46 samples/sec#011loss=7.970910\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] Epoch[114] Batch[45] avg_epoch_loss=8.010361\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=114, batch=45 train loss <loss>=7.98406658173\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] Epoch[114] Batch [45]#011Speed: 1717.27 samples/sec#011loss=7.984067\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] processed a total of 1599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1311.3629817962646, \"sum\": 1311.3629817962646, \"min\": 1311.3629817962646}}, \"EndTime\": 1578471679.641178, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471678.329309}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1219.22498961 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=114, train loss <loss>=7.99414432526\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] Epoch[115] Batch[0] avg_epoch_loss=8.220870\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=8.22087001801\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] Epoch[115] Batch[5] avg_epoch_loss=8.192806\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=8.19280616442\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:19 INFO 139919921551168] Epoch[115] Batch [5]#011Speed: 1737.88 samples/sec#011loss=8.192806\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] Epoch[115] Batch[10] avg_epoch_loss=8.264740\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=115, batch=10 train loss <loss>=8.35106105804\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] Epoch[115] Batch [10]#011Speed: 904.85 samples/sec#011loss=8.351061\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] Epoch[115] Batch[15] avg_epoch_loss=8.353699\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=115, batch=15 train loss <loss>=8.54940910339\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] Epoch[115] Batch [15]#011Speed: 1996.95 samples/sec#011loss=8.549409\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] Epoch[115] Batch[20] avg_epoch_loss=8.316293\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=115, batch=20 train loss <loss>=8.19659490585\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] Epoch[115] Batch [20]#011Speed: 862.97 samples/sec#011loss=8.196595\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] Epoch[115] Batch[25] avg_epoch_loss=8.246451\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=115, batch=25 train loss <loss>=7.95311393738\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] Epoch[115] Batch [25]#011Speed: 2090.68 samples/sec#011loss=7.953114\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] Epoch[115] Batch[30] avg_epoch_loss=8.165724\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=115, batch=30 train loss <loss>=7.74594526291\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] Epoch[115] Batch [30]#011Speed: 912.68 samples/sec#011loss=7.745945\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] Epoch[115] Batch[35] avg_epoch_loss=8.093597\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=115, batch=35 train loss <loss>=7.64640579224\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] Epoch[115] Batch [35]#011Speed: 2135.50 samples/sec#011loss=7.646406\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] Epoch[115] Batch[40] avg_epoch_loss=8.083134\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=115, batch=40 train loss <loss>=8.00780067444\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] Epoch[115] Batch [40]#011Speed: 987.34 samples/sec#011loss=8.007801\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] Epoch[115] Batch[45] avg_epoch_loss=8.083756\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=115, batch=45 train loss <loss>=8.08886013031\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] Epoch[115] Batch [45]#011Speed: 2058.67 samples/sec#011loss=8.088860\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] processed a total of 1570 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1278.5060405731201, \"sum\": 1278.5060405731201, \"min\": 1278.5060405731201}}, \"EndTime\": 1578471680.920226, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471679.641257}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1227.88928693 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=115, train loss <loss>=8.01197902679\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:20 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] Epoch[116] Batch[0] avg_epoch_loss=8.457933\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=8.4579334259\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] Epoch[116] Batch[5] avg_epoch_loss=8.485764\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=8.48576434453\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] Epoch[116] Batch [5]#011Speed: 2062.95 samples/sec#011loss=8.485764\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] Epoch[116] Batch[10] avg_epoch_loss=8.337388\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=116, batch=10 train loss <loss>=8.15933570862\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] Epoch[116] Batch [10]#011Speed: 1033.33 samples/sec#011loss=8.159336\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] Epoch[116] Batch[15] avg_epoch_loss=8.377169\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=116, batch=15 train loss <loss>=8.46468830109\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] Epoch[116] Batch [15]#011Speed: 2064.86 samples/sec#011loss=8.464688\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] Epoch[116] Batch[20] avg_epoch_loss=8.391613\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=116, batch=20 train loss <loss>=8.43783197403\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] Epoch[116] Batch [20]#011Speed: 1024.08 samples/sec#011loss=8.437832\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] Epoch[116] Batch[25] avg_epoch_loss=8.261356\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=116, batch=25 train loss <loss>=7.71427965164\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] Epoch[116] Batch [25]#011Speed: 2062.87 samples/sec#011loss=7.714280\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] Epoch[116] Batch[30] avg_epoch_loss=8.157808\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=116, batch=30 train loss <loss>=7.61935606003\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] Epoch[116] Batch [30]#011Speed: 1020.24 samples/sec#011loss=7.619356\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] Epoch[116] Batch[35] avg_epoch_loss=8.080392\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=116, batch=35 train loss <loss>=7.60041265488\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] Epoch[116] Batch [35]#011Speed: 1608.30 samples/sec#011loss=7.600413\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] Epoch[116] Batch[40] avg_epoch_loss=8.067661\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=116, batch=40 train loss <loss>=7.97600193024\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:21 INFO 139919921551168] Epoch[116] Batch [40]#011Speed: 941.17 samples/sec#011loss=7.976002\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] Epoch[116] Batch[45] avg_epoch_loss=8.058870\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=116, batch=45 train loss <loss>=7.9867846489\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] Epoch[116] Batch [45]#011Speed: 1795.19 samples/sec#011loss=7.986785\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] processed a total of 1557 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1210.5848789215088, \"sum\": 1210.5848789215088, \"min\": 1210.5848789215088}}, \"EndTime\": 1578471682.131373, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471680.920295}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1286.03081024 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=116, train loss <loss>=8.05876303692\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] Epoch[117] Batch[0] avg_epoch_loss=8.440370\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=8.44036960602\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] Epoch[117] Batch[5] avg_epoch_loss=8.381988\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=8.38198757172\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] Epoch[117] Batch [5]#011Speed: 2059.57 samples/sec#011loss=8.381988\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] Epoch[117] Batch[10] avg_epoch_loss=8.263480\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=117, batch=10 train loss <loss>=8.12127094269\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] Epoch[117] Batch [10]#011Speed: 1045.34 samples/sec#011loss=8.121271\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] Epoch[117] Batch[15] avg_epoch_loss=8.322846\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=117, batch=15 train loss <loss>=8.45345249176\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] Epoch[117] Batch [15]#011Speed: 2011.69 samples/sec#011loss=8.453452\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] Epoch[117] Batch[20] avg_epoch_loss=8.323140\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=117, batch=20 train loss <loss>=8.32408056259\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] Epoch[117] Batch [20]#011Speed: 1038.92 samples/sec#011loss=8.324081\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] Epoch[117] Batch[25] avg_epoch_loss=8.245824\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=117, batch=25 train loss <loss>=7.92109727859\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] Epoch[117] Batch [25]#011Speed: 1638.12 samples/sec#011loss=7.921097\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] Epoch[117] Batch[30] avg_epoch_loss=8.152651\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=117, batch=30 train loss <loss>=7.66815242767\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:22 INFO 139919921551168] Epoch[117] Batch [30]#011Speed: 984.43 samples/sec#011loss=7.668152\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] Epoch[117] Batch[35] avg_epoch_loss=8.109680\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=117, batch=35 train loss <loss>=7.84326000214\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] Epoch[117] Batch [35]#011Speed: 1621.75 samples/sec#011loss=7.843260\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] Epoch[117] Batch[40] avg_epoch_loss=8.055057\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=117, batch=40 train loss <loss>=7.66176738739\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] Epoch[117] Batch [40]#011Speed: 1009.26 samples/sec#011loss=7.661767\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] Epoch[117] Batch[45] avg_epoch_loss=8.058334\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=117, batch=45 train loss <loss>=8.08520526886\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] Epoch[117] Batch [45]#011Speed: 2068.14 samples/sec#011loss=8.085205\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] Epoch[117] Batch[50] avg_epoch_loss=8.037851\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=117, batch=50 train loss <loss>=7.84940490723\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] Epoch[117] Batch [50]#011Speed: 1830.22 samples/sec#011loss=7.849405\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] processed a total of 1608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1239.2940521240234, \"sum\": 1239.2940521240234, \"min\": 1239.2940521240234}}, \"EndTime\": 1578471683.371238, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471682.131453}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1297.40306124 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=117, train loss <loss>=8.03785062304\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] Epoch[118] Batch[0] avg_epoch_loss=8.513336\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=8.51333618164\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] Epoch[118] Batch[5] avg_epoch_loss=8.315259\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=8.31525913874\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] Epoch[118] Batch [5]#011Speed: 2063.40 samples/sec#011loss=8.315259\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] Epoch[118] Batch[10] avg_epoch_loss=8.355153\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=8.40302639008\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] Epoch[118] Batch [10]#011Speed: 1045.96 samples/sec#011loss=8.403026\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] Epoch[118] Batch[15] avg_epoch_loss=8.390848\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=118, batch=15 train loss <loss>=8.46937770844\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] Epoch[118] Batch [15]#011Speed: 1943.26 samples/sec#011loss=8.469378\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] Epoch[118] Batch[20] avg_epoch_loss=8.338588\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=118, batch=20 train loss <loss>=8.17135343552\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:23 INFO 139919921551168] Epoch[118] Batch [20]#011Speed: 945.23 samples/sec#011loss=8.171353\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] Epoch[118] Batch[25] avg_epoch_loss=8.236022\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=118, batch=25 train loss <loss>=7.8052441597\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] Epoch[118] Batch [25]#011Speed: 2041.99 samples/sec#011loss=7.805244\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] Epoch[118] Batch[30] avg_epoch_loss=8.170599\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=118, batch=30 train loss <loss>=7.8304028511\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] Epoch[118] Batch [30]#011Speed: 956.99 samples/sec#011loss=7.830403\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] Epoch[118] Batch[35] avg_epoch_loss=8.105154\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=118, batch=35 train loss <loss>=7.6993929863\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] Epoch[118] Batch [35]#011Speed: 1726.48 samples/sec#011loss=7.699393\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] Epoch[118] Batch[40] avg_epoch_loss=8.090731\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=118, batch=40 train loss <loss>=7.98688526154\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] Epoch[118] Batch [40]#011Speed: 918.11 samples/sec#011loss=7.986885\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] Epoch[118] Batch[45] avg_epoch_loss=8.073855\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=118, batch=45 train loss <loss>=7.93547306061\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] Epoch[118] Batch [45]#011Speed: 1624.86 samples/sec#011loss=7.935473\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] processed a total of 1562 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1248.0640411376953, \"sum\": 1248.0640411376953, \"min\": 1248.0640411376953}}, \"EndTime\": 1578471684.619843, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471683.371305}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1251.42909033 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=118, train loss <loss>=8.02183215472\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] Epoch[119] Batch[0] avg_epoch_loss=7.985800\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=7.98579978943\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] Epoch[119] Batch[5] avg_epoch_loss=8.245701\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=8.24570123355\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] Epoch[119] Batch [5]#011Speed: 1942.17 samples/sec#011loss=8.245701\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] Epoch[119] Batch[10] avg_epoch_loss=8.340654\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=119, batch=10 train loss <loss>=8.45459804535\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:24 INFO 139919921551168] Epoch[119] Batch [10]#011Speed: 992.32 samples/sec#011loss=8.454598\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] Epoch[119] Batch[15] avg_epoch_loss=8.396409\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=119, batch=15 train loss <loss>=8.51906909943\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] Epoch[119] Batch [15]#011Speed: 1812.91 samples/sec#011loss=8.519069\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] Epoch[119] Batch[20] avg_epoch_loss=8.407852\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=119, batch=20 train loss <loss>=8.44447078705\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] Epoch[119] Batch [20]#011Speed: 995.03 samples/sec#011loss=8.444471\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] Epoch[119] Batch[25] avg_epoch_loss=8.330474\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=119, batch=25 train loss <loss>=8.00548696518\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] Epoch[119] Batch [25]#011Speed: 1855.37 samples/sec#011loss=8.005487\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] Epoch[119] Batch[30] avg_epoch_loss=8.276148\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=119, batch=30 train loss <loss>=7.99365348816\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] Epoch[119] Batch [30]#011Speed: 1052.99 samples/sec#011loss=7.993653\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] Epoch[119] Batch[35] avg_epoch_loss=8.216939\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=119, batch=35 train loss <loss>=7.84984378815\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] Epoch[119] Batch [35]#011Speed: 1886.92 samples/sec#011loss=7.849844\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] Epoch[119] Batch[40] avg_epoch_loss=8.135156\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=119, batch=40 train loss <loss>=7.54631710052\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] Epoch[119] Batch [40]#011Speed: 913.92 samples/sec#011loss=7.546317\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] Epoch[119] Batch[45] avg_epoch_loss=8.128226\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=119, batch=45 train loss <loss>=8.07140197754\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] Epoch[119] Batch [45]#011Speed: 1770.15 samples/sec#011loss=8.071402\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] Epoch[119] Batch[50] avg_epoch_loss=8.096450\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=119, batch=50 train loss <loss>=7.80411043167\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] Epoch[119] Batch [50]#011Speed: 2007.62 samples/sec#011loss=7.804110\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] processed a total of 1701 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1348.3450412750244, \"sum\": 1348.3450412750244, \"min\": 1348.3450412750244}}, \"EndTime\": 1578471685.968693, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471684.619918}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1261.43522161 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=119, train loss <loss>=7.99453037756\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:25 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:26 INFO 139919921551168] Epoch[120] Batch[0] avg_epoch_loss=7.819695\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=7.81969499588\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:26 INFO 139919921551168] Epoch[120] Batch[5] avg_epoch_loss=8.156086\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=8.1560857296\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:26 INFO 139919921551168] Epoch[120] Batch [5]#011Speed: 2056.16 samples/sec#011loss=8.156086\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:26 INFO 139919921551168] Epoch[120] Batch[10] avg_epoch_loss=8.250508\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=120, batch=10 train loss <loss>=8.36381416321\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:26 INFO 139919921551168] Epoch[120] Batch [10]#011Speed: 953.98 samples/sec#011loss=8.363814\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:26 INFO 139919921551168] Epoch[120] Batch[15] avg_epoch_loss=8.200524\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=120, batch=15 train loss <loss>=8.09055843353\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:26 INFO 139919921551168] Epoch[120] Batch [15]#011Speed: 1926.62 samples/sec#011loss=8.090558\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:26 INFO 139919921551168] Epoch[120] Batch[20] avg_epoch_loss=8.181687\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=120, batch=20 train loss <loss>=8.12141141891\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:26 INFO 139919921551168] Epoch[120] Batch [20]#011Speed: 930.74 samples/sec#011loss=8.121411\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:26 INFO 139919921551168] Epoch[120] Batch[25] avg_epoch_loss=8.107180\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=120, batch=25 train loss <loss>=7.79424972534\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:26 INFO 139919921551168] Epoch[120] Batch [25]#011Speed: 1680.71 samples/sec#011loss=7.794250\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:26 INFO 139919921551168] Epoch[120] Batch[30] avg_epoch_loss=8.098071\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=120, batch=30 train loss <loss>=8.05070161819\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:26 INFO 139919921551168] Epoch[120] Batch [30]#011Speed: 1030.25 samples/sec#011loss=8.050702\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:26 INFO 139919921551168] Epoch[120] Batch[35] avg_epoch_loss=8.017083\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=120, batch=35 train loss <loss>=7.51495990753\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:26 INFO 139919921551168] Epoch[120] Batch [35]#011Speed: 2114.03 samples/sec#011loss=7.514960\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] Epoch[120] Batch[40] avg_epoch_loss=8.007642\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=120, batch=40 train loss <loss>=7.93966646194\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] Epoch[120] Batch [40]#011Speed: 964.98 samples/sec#011loss=7.939666\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] Epoch[120] Batch[45] avg_epoch_loss=7.982941\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=120, batch=45 train loss <loss>=7.78039293289\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] Epoch[120] Batch [45]#011Speed: 2047.97 samples/sec#011loss=7.780393\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] processed a total of 1587 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1258.0008506774902, \"sum\": 1258.0008506774902, \"min\": 1258.0008506774902}}, \"EndTime\": 1578471687.22723, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471685.968775}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1261.41277934 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=120, train loss <loss>=7.92665041924\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] Epoch[121] Batch[0] avg_epoch_loss=8.082895\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=8.08289527893\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] Epoch[121] Batch[5] avg_epoch_loss=8.097031\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=8.09703127543\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] Epoch[121] Batch [5]#011Speed: 1742.50 samples/sec#011loss=8.097031\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] Epoch[121] Batch[10] avg_epoch_loss=8.122359\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=121, batch=10 train loss <loss>=8.15275192261\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] Epoch[121] Batch [10]#011Speed: 2070.61 samples/sec#011loss=8.152752\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] Epoch[121] Batch[15] avg_epoch_loss=8.219959\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=121, batch=15 train loss <loss>=8.43468027115\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] Epoch[121] Batch [15]#011Speed: 1000.22 samples/sec#011loss=8.434680\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] Epoch[121] Batch[20] avg_epoch_loss=8.199641\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=121, batch=20 train loss <loss>=8.13462123871\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] Epoch[121] Batch [20]#011Speed: 937.97 samples/sec#011loss=8.134621\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] Epoch[121] Batch[25] avg_epoch_loss=8.116800\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=121, batch=25 train loss <loss>=7.76886777878\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:27 INFO 139919921551168] Epoch[121] Batch [25]#011Speed: 1883.88 samples/sec#011loss=7.768868\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] Epoch[121] Batch[30] avg_epoch_loss=8.064163\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=121, batch=30 train loss <loss>=7.7904540062\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] Epoch[121] Batch [30]#011Speed: 1100.04 samples/sec#011loss=7.790454\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] Epoch[121] Batch[35] avg_epoch_loss=8.006658\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=121, batch=35 train loss <loss>=7.65012559891\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] Epoch[121] Batch [35]#011Speed: 2072.67 samples/sec#011loss=7.650126\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] Epoch[121] Batch[40] avg_epoch_loss=7.984185\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=121, batch=40 train loss <loss>=7.82237586975\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] Epoch[121] Batch [40]#011Speed: 980.40 samples/sec#011loss=7.822376\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] Epoch[121] Batch[45] avg_epoch_loss=7.984100\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=121, batch=45 train loss <loss>=7.98340911865\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] Epoch[121] Batch [45]#011Speed: 1661.83 samples/sec#011loss=7.983409\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] Epoch[121] Batch[50] avg_epoch_loss=7.931205\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=121, batch=50 train loss <loss>=7.44456558228\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] Epoch[121] Batch [50]#011Speed: 1411.26 samples/sec#011loss=7.444566\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] processed a total of 1612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1294.226884841919, \"sum\": 1294.226884841919, \"min\": 1294.226884841919}}, \"EndTime\": 1578471688.521992, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471687.227307}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1245.42247822 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=121, train loss <loss>=7.93120479584\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] Epoch[122] Batch[0] avg_epoch_loss=8.067432\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=8.06743240356\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] Epoch[122] Batch[5] avg_epoch_loss=8.122320\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=8.12231969833\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] Epoch[122] Batch [5]#011Speed: 2045.02 samples/sec#011loss=8.122320\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] Epoch[122] Batch[10] avg_epoch_loss=8.191671\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=122, batch=10 train loss <loss>=8.27489185333\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] Epoch[122] Batch [10]#011Speed: 899.73 samples/sec#011loss=8.274892\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] Epoch[122] Batch[15] avg_epoch_loss=8.192481\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=122, batch=15 train loss <loss>=8.19426317215\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:28 INFO 139919921551168] Epoch[122] Batch [15]#011Speed: 1906.69 samples/sec#011loss=8.194263\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] Epoch[122] Batch[20] avg_epoch_loss=8.210731\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=122, batch=20 train loss <loss>=8.26913356781\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] Epoch[122] Batch [20]#011Speed: 916.53 samples/sec#011loss=8.269134\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] Epoch[122] Batch[25] avg_epoch_loss=8.141993\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=122, batch=25 train loss <loss>=7.85328950882\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] Epoch[122] Batch [25]#011Speed: 1894.18 samples/sec#011loss=7.853290\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] Epoch[122] Batch[30] avg_epoch_loss=8.104070\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=122, batch=30 train loss <loss>=7.90687150955\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] Epoch[122] Batch [30]#011Speed: 902.42 samples/sec#011loss=7.906872\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] Epoch[122] Batch[35] avg_epoch_loss=8.027170\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=122, batch=35 train loss <loss>=7.55038785934\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] Epoch[122] Batch [35]#011Speed: 2102.24 samples/sec#011loss=7.550388\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] Epoch[122] Batch[40] avg_epoch_loss=7.999307\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=122, batch=40 train loss <loss>=7.79869623184\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] Epoch[122] Batch [40]#011Speed: 893.78 samples/sec#011loss=7.798696\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] Epoch[122] Batch[45] avg_epoch_loss=7.987557\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=122, batch=45 train loss <loss>=7.89120502472\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] Epoch[122] Batch [45]#011Speed: 2077.11 samples/sec#011loss=7.891205\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] Epoch[122] Batch[50] avg_epoch_loss=7.947342\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=122, batch=50 train loss <loss>=7.57736740112\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] Epoch[122] Batch [50]#011Speed: 1558.16 samples/sec#011loss=7.577367\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] processed a total of 1653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1324.925184249878, \"sum\": 1324.925184249878, \"min\": 1324.925184249878}}, \"EndTime\": 1578471689.847461, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471688.522074}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1247.51884085 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=122, train loss <loss>=7.92548826108\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] Epoch[123] Batch[0] avg_epoch_loss=7.801291\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=7.80129098892\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] Epoch[123] Batch[5] avg_epoch_loss=8.171994\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=8.17199397087\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] Epoch[123] Batch [5]#011Speed: 1715.41 samples/sec#011loss=8.171994\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] Epoch[123] Batch[10] avg_epoch_loss=8.172717\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=123, batch=10 train loss <loss>=8.17358474731\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] Epoch[123] Batch [10]#011Speed: 958.89 samples/sec#011loss=8.173585\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] Epoch[123] Batch[15] avg_epoch_loss=8.229869\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=123, batch=15 train loss <loss>=8.35560245514\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] Epoch[123] Batch [15]#011Speed: 1998.01 samples/sec#011loss=8.355602\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] Epoch[123] Batch[20] avg_epoch_loss=8.184705\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=123, batch=20 train loss <loss>=8.04018115997\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] Epoch[123] Batch [20]#011Speed: 1005.15 samples/sec#011loss=8.040181\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] Epoch[123] Batch[25] avg_epoch_loss=8.111019\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=123, batch=25 train loss <loss>=7.80153532028\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] Epoch[123] Batch [25]#011Speed: 1985.16 samples/sec#011loss=7.801535\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] Epoch[123] Batch[30] avg_epoch_loss=8.067665\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=123, batch=30 train loss <loss>=7.84222602844\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] Epoch[123] Batch [30]#011Speed: 882.34 samples/sec#011loss=7.842226\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] Epoch[123] Batch[35] avg_epoch_loss=8.006286\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=123, batch=35 train loss <loss>=7.62573719025\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] Epoch[123] Batch [35]#011Speed: 1927.48 samples/sec#011loss=7.625737\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] Epoch[123] Batch[40] avg_epoch_loss=7.991687\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=123, batch=40 train loss <loss>=7.88657569885\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:30 INFO 139919921551168] Epoch[123] Batch [40]#011Speed: 847.55 samples/sec#011loss=7.886576\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] Epoch[123] Batch[45] avg_epoch_loss=7.974657\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=123, batch=45 train loss <loss>=7.83501262665\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] Epoch[123] Batch [45]#011Speed: 1933.42 samples/sec#011loss=7.835013\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] Epoch[123] Batch[50] avg_epoch_loss=7.962721\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=123, batch=50 train loss <loss>=7.85290975571\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] Epoch[123] Batch [50]#011Speed: 1657.19 samples/sec#011loss=7.852910\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] processed a total of 1641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1329.5681476593018, \"sum\": 1329.5681476593018, \"min\": 1329.5681476593018}}, \"EndTime\": 1578471691.177606, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471689.847526}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1234.12402826 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=123, train loss <loss>=7.92289382678\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] Epoch[124] Batch[0] avg_epoch_loss=7.691672\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=7.69167232513\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] Epoch[124] Batch[5] avg_epoch_loss=8.153938\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=8.1539384524\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] Epoch[124] Batch [5]#011Speed: 2025.65 samples/sec#011loss=8.153938\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] Epoch[124] Batch[10] avg_epoch_loss=8.186233\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=124, batch=10 train loss <loss>=8.22498588562\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] Epoch[124] Batch [10]#011Speed: 1064.26 samples/sec#011loss=8.224986\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] Epoch[124] Batch[15] avg_epoch_loss=8.233471\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=124, batch=15 train loss <loss>=8.33739366531\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] Epoch[124] Batch [15]#011Speed: 1751.87 samples/sec#011loss=8.337394\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] Epoch[124] Batch[20] avg_epoch_loss=8.307418\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=124, batch=20 train loss <loss>=8.54405183792\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] Epoch[124] Batch [20]#011Speed: 969.55 samples/sec#011loss=8.544052\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] Epoch[124] Batch[25] avg_epoch_loss=8.232074\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=124, batch=25 train loss <loss>=7.9156291008\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:31 INFO 139919921551168] Epoch[124] Batch [25]#011Speed: 1912.71 samples/sec#011loss=7.915629\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] Epoch[124] Batch[30] avg_epoch_loss=8.161226\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=124, batch=30 train loss <loss>=7.79281654358\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] Epoch[124] Batch [30]#011Speed: 944.87 samples/sec#011loss=7.792817\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] Epoch[124] Batch[35] avg_epoch_loss=8.062900\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=124, batch=35 train loss <loss>=7.45327548981\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] Epoch[124] Batch [35]#011Speed: 1940.26 samples/sec#011loss=7.453275\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] Epoch[124] Batch[40] avg_epoch_loss=8.049301\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=124, batch=40 train loss <loss>=7.95139312744\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] Epoch[124] Batch [40]#011Speed: 1987.03 samples/sec#011loss=7.951393\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] Epoch[124] Batch[45] avg_epoch_loss=8.058640\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=124, batch=45 train loss <loss>=8.13521909714\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] Epoch[124] Batch [45]#011Speed: 1060.37 samples/sec#011loss=8.135219\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] Epoch[124] Batch[50] avg_epoch_loss=8.042064\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=124, batch=50 train loss <loss>=7.88956680298\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] Epoch[124] Batch [50]#011Speed: 1763.77 samples/sec#011loss=7.889567\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] processed a total of 1654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1260.5631351470947, \"sum\": 1260.5631351470947, \"min\": 1260.5631351470947}}, \"EndTime\": 1578471692.438718, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471691.177687}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1311.99659887 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=124, train loss <loss>=8.0096385479\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] Epoch[125] Batch[0] avg_epoch_loss=8.144425\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=8.14442539215\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] Epoch[125] Batch[5] avg_epoch_loss=8.227816\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=8.22781626383\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] Epoch[125] Batch [5]#011Speed: 1719.32 samples/sec#011loss=8.227816\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] Epoch[125] Batch[10] avg_epoch_loss=8.251800\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=125, batch=10 train loss <loss>=8.28058071136\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] Epoch[125] Batch [10]#011Speed: 1054.20 samples/sec#011loss=8.280581\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] Epoch[125] Batch[15] avg_epoch_loss=8.252660\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=125, batch=15 train loss <loss>=8.25455131531\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:32 INFO 139919921551168] Epoch[125] Batch [15]#011Speed: 1966.44 samples/sec#011loss=8.254551\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] Epoch[125] Batch[20] avg_epoch_loss=8.285726\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=125, batch=20 train loss <loss>=8.3915394783\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] Epoch[125] Batch [20]#011Speed: 1090.80 samples/sec#011loss=8.391539\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] Epoch[125] Batch[25] avg_epoch_loss=8.228856\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=125, batch=25 train loss <loss>=7.98999958038\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] Epoch[125] Batch [25]#011Speed: 2009.98 samples/sec#011loss=7.990000\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] Epoch[125] Batch[30] avg_epoch_loss=8.160258\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=125, batch=30 train loss <loss>=7.80354652405\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] Epoch[125] Batch [30]#011Speed: 1072.23 samples/sec#011loss=7.803547\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] Epoch[125] Batch[35] avg_epoch_loss=8.075176\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=125, batch=35 train loss <loss>=7.54767351151\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] Epoch[125] Batch [35]#011Speed: 1915.89 samples/sec#011loss=7.547674\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] Epoch[125] Batch[40] avg_epoch_loss=8.036627\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=125, batch=40 train loss <loss>=7.7590669632\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] Epoch[125] Batch [40]#011Speed: 1016.96 samples/sec#011loss=7.759067\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] Epoch[125] Batch[45] avg_epoch_loss=7.989592\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=125, batch=45 train loss <loss>=7.60390892029\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] Epoch[125] Batch [45]#011Speed: 2104.26 samples/sec#011loss=7.603909\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] processed a total of 1568 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1185.1468086242676, \"sum\": 1185.1468086242676, \"min\": 1185.1468086242676}}, \"EndTime\": 1578471693.624404, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471692.438792}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1322.91296737 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=125, train loss <loss>=7.93296639773\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] Epoch[126] Batch[0] avg_epoch_loss=7.992797\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=7.99279689789\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] Epoch[126] Batch[5] avg_epoch_loss=7.994818\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=7.99481797218\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:33 INFO 139919921551168] Epoch[126] Batch [5]#011Speed: 1641.01 samples/sec#011loss=7.994818\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] Epoch[126] Batch[10] avg_epoch_loss=8.015727\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=126, batch=10 train loss <loss>=8.04081869125\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] Epoch[126] Batch [10]#011Speed: 852.73 samples/sec#011loss=8.040819\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] Epoch[126] Batch[15] avg_epoch_loss=8.156810\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=126, batch=15 train loss <loss>=8.4671913147\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] Epoch[126] Batch [15]#011Speed: 1766.20 samples/sec#011loss=8.467191\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] Epoch[126] Batch[20] avg_epoch_loss=8.218537\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=126, batch=20 train loss <loss>=8.41606483459\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] Epoch[126] Batch [20]#011Speed: 876.81 samples/sec#011loss=8.416065\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] Epoch[126] Batch[25] avg_epoch_loss=8.173873\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=126, batch=25 train loss <loss>=7.98628377914\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] Epoch[126] Batch [25]#011Speed: 1691.62 samples/sec#011loss=7.986284\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] Epoch[126] Batch[30] avg_epoch_loss=8.096555\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=126, batch=30 train loss <loss>=7.69449825287\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] Epoch[126] Batch [30]#011Speed: 981.21 samples/sec#011loss=7.694498\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] Epoch[126] Batch[35] avg_epoch_loss=8.046128\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=126, batch=35 train loss <loss>=7.73348379135\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] Epoch[126] Batch [35]#011Speed: 2016.87 samples/sec#011loss=7.733484\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] Epoch[126] Batch[40] avg_epoch_loss=8.063398\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=126, batch=40 train loss <loss>=8.18774280548\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] Epoch[126] Batch [40]#011Speed: 952.89 samples/sec#011loss=8.187743\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] Epoch[126] Batch[45] avg_epoch_loss=8.060029\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=126, batch=45 train loss <loss>=8.03239965439\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] Epoch[126] Batch [45]#011Speed: 1866.56 samples/sec#011loss=8.032400\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] processed a total of 1547 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1322.6277828216553, \"sum\": 1322.6277828216553, \"min\": 1322.6277828216553}}, \"EndTime\": 1578471694.947546, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471693.624483}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1169.53941268 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=126, train loss <loss>=8.05227003292\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:34 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] Epoch[127] Batch[0] avg_epoch_loss=8.415942\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=8.41594219208\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] Epoch[127] Batch[5] avg_epoch_loss=8.233324\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=8.23332436879\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] Epoch[127] Batch [5]#011Speed: 1989.11 samples/sec#011loss=8.233324\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] Epoch[127] Batch[10] avg_epoch_loss=8.205895\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=127, batch=10 train loss <loss>=8.17298069\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] Epoch[127] Batch [10]#011Speed: 1019.87 samples/sec#011loss=8.172981\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] Epoch[127] Batch[15] avg_epoch_loss=8.244370\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=127, batch=15 train loss <loss>=8.3290148735\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] Epoch[127] Batch [15]#011Speed: 2118.05 samples/sec#011loss=8.329015\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] Epoch[127] Batch[20] avg_epoch_loss=8.254887\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=127, batch=20 train loss <loss>=8.28854103088\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] Epoch[127] Batch [20]#011Speed: 1009.64 samples/sec#011loss=8.288541\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] Epoch[127] Batch[25] avg_epoch_loss=8.190227\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=127, batch=25 train loss <loss>=7.91865673065\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] Epoch[127] Batch [25]#011Speed: 2102.80 samples/sec#011loss=7.918657\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] Epoch[127] Batch[30] avg_epoch_loss=8.135957\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=127, batch=30 train loss <loss>=7.85374794006\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] Epoch[127] Batch [30]#011Speed: 926.96 samples/sec#011loss=7.853748\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] Epoch[127] Batch[35] avg_epoch_loss=8.068781\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=127, batch=35 train loss <loss>=7.65229463577\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] Epoch[127] Batch [35]#011Speed: 2117.33 samples/sec#011loss=7.652295\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] Epoch[127] Batch[40] avg_epoch_loss=8.028697\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=127, batch=40 train loss <loss>=7.74009389877\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:35 INFO 139919921551168] Epoch[127] Batch [40]#011Speed: 1086.65 samples/sec#011loss=7.740094\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] Epoch[127] Batch[45] avg_epoch_loss=7.990119\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=127, batch=45 train loss <loss>=7.67377357483\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] Epoch[127] Batch [45]#011Speed: 2073.08 samples/sec#011loss=7.673774\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] processed a total of 1573 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1205.260992050171, \"sum\": 1205.260992050171, \"min\": 1205.260992050171}}, \"EndTime\": 1578471696.153418, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471694.947633}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1304.98812175 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=127, train loss <loss>=8.02524476051\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] Epoch[128] Batch[0] avg_epoch_loss=8.555899\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=8.55589866638\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] Epoch[128] Batch[5] avg_epoch_loss=8.276859\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=8.27685856819\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] Epoch[128] Batch [5]#011Speed: 2120.08 samples/sec#011loss=8.276859\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] Epoch[128] Batch[10] avg_epoch_loss=8.342568\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=128, batch=10 train loss <loss>=8.42141971588\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] Epoch[128] Batch [10]#011Speed: 883.66 samples/sec#011loss=8.421420\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] Epoch[128] Batch[15] avg_epoch_loss=8.356347\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=128, batch=15 train loss <loss>=8.38665962219\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] Epoch[128] Batch [15]#011Speed: 2046.69 samples/sec#011loss=8.386660\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] Epoch[128] Batch[20] avg_epoch_loss=8.374188\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=128, batch=20 train loss <loss>=8.43128147125\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] Epoch[128] Batch [20]#011Speed: 992.97 samples/sec#011loss=8.431281\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] Epoch[128] Batch[25] avg_epoch_loss=8.303144\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=128, batch=25 train loss <loss>=8.00475988388\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:36 INFO 139919921551168] Epoch[128] Batch [25]#011Speed: 1878.71 samples/sec#011loss=8.004760\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] Epoch[128] Batch[30] avg_epoch_loss=8.235685\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=128, batch=30 train loss <loss>=7.88489723206\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] Epoch[128] Batch [30]#011Speed: 879.92 samples/sec#011loss=7.884897\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] Epoch[128] Batch[35] avg_epoch_loss=8.190706\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=128, batch=35 train loss <loss>=7.91183156967\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] Epoch[128] Batch [35]#011Speed: 2121.19 samples/sec#011loss=7.911832\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] Epoch[128] Batch[40] avg_epoch_loss=8.152601\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=128, batch=40 train loss <loss>=7.87824821472\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] Epoch[128] Batch [40]#011Speed: 1014.68 samples/sec#011loss=7.878248\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] Epoch[128] Batch[45] avg_epoch_loss=8.112974\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=128, batch=45 train loss <loss>=7.78803567886\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] Epoch[128] Batch [45]#011Speed: 2009.29 samples/sec#011loss=7.788036\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] Epoch[128] Batch[50] avg_epoch_loss=8.077232\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=128, batch=50 train loss <loss>=7.7484046936\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] Epoch[128] Batch [50]#011Speed: 1424.68 samples/sec#011loss=7.748405\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] processed a total of 1655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1304.7101497650146, \"sum\": 1304.7101497650146, \"min\": 1304.7101497650146}}, \"EndTime\": 1578471697.458678, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471696.153487}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1268.37319581 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=128, train loss <loss>=8.06273770332\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] Epoch[129] Batch[0] avg_epoch_loss=8.515701\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=8.51570129395\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] Epoch[129] Batch[5] avg_epoch_loss=8.292087\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=8.29208668073\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] Epoch[129] Batch [5]#011Speed: 1638.19 samples/sec#011loss=8.292087\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] Epoch[129] Batch[10] avg_epoch_loss=8.234830\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=129, batch=10 train loss <loss>=8.16612291336\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] Epoch[129] Batch [10]#011Speed: 912.09 samples/sec#011loss=8.166123\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] Epoch[129] Batch[15] avg_epoch_loss=8.349403\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=129, batch=15 train loss <loss>=8.60146121979\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:37 INFO 139919921551168] Epoch[129] Batch [15]#011Speed: 1859.71 samples/sec#011loss=8.601461\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] Epoch[129] Batch[20] avg_epoch_loss=8.301328\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=129, batch=20 train loss <loss>=8.14748840332\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] Epoch[129] Batch [20]#011Speed: 895.80 samples/sec#011loss=8.147488\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] Epoch[129] Batch[25] avg_epoch_loss=8.237071\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=129, batch=25 train loss <loss>=7.96719341278\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] Epoch[129] Batch [25]#011Speed: 1941.58 samples/sec#011loss=7.967193\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] Epoch[129] Batch[30] avg_epoch_loss=8.180689\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=129, batch=30 train loss <loss>=7.88750362396\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] Epoch[129] Batch [30]#011Speed: 996.07 samples/sec#011loss=7.887504\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] Epoch[129] Batch[35] avg_epoch_loss=8.079987\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=129, batch=35 train loss <loss>=7.45563144684\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] Epoch[129] Batch [35]#011Speed: 2052.39 samples/sec#011loss=7.455631\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] Epoch[129] Batch[40] avg_epoch_loss=8.065845\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=129, batch=40 train loss <loss>=7.96402540207\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] Epoch[129] Batch [40]#011Speed: 1087.48 samples/sec#011loss=7.964025\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] Epoch[129] Batch[45] avg_epoch_loss=8.073199\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=129, batch=45 train loss <loss>=8.13349599838\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] Epoch[129] Batch [45]#011Speed: 1999.42 samples/sec#011loss=8.133496\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] Epoch[129] Batch[50] avg_epoch_loss=7.992426\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=129, batch=50 train loss <loss>=7.24931850433\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] Epoch[129] Batch [50]#011Speed: 1601.20 samples/sec#011loss=7.249319\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] processed a total of 1620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1299.0741729736328, \"sum\": 1299.0741729736328, \"min\": 1299.0741729736328}}, \"EndTime\": 1578471698.758245, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471697.458754}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1246.93645806 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=129, train loss <loss>=7.99242597468\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] Epoch[130] Batch[0] avg_epoch_loss=8.492202\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=8.49220180511\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] Epoch[130] Batch[5] avg_epoch_loss=8.081497\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=8.08149663607\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:38 INFO 139919921551168] Epoch[130] Batch [5]#011Speed: 1790.73 samples/sec#011loss=8.081497\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] Epoch[130] Batch[10] avg_epoch_loss=8.096139\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=130, batch=10 train loss <loss>=8.11370925903\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] Epoch[130] Batch [10]#011Speed: 1007.89 samples/sec#011loss=8.113709\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] Epoch[130] Batch[15] avg_epoch_loss=8.243812\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=130, batch=15 train loss <loss>=8.56869220734\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] Epoch[130] Batch [15]#011Speed: 2047.01 samples/sec#011loss=8.568692\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] Epoch[130] Batch[20] avg_epoch_loss=8.236085\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=130, batch=20 train loss <loss>=8.21135797501\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] Epoch[130] Batch [20]#011Speed: 834.39 samples/sec#011loss=8.211358\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] Epoch[130] Batch[25] avg_epoch_loss=8.178064\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=130, batch=25 train loss <loss>=7.93437891006\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] Epoch[130] Batch [25]#011Speed: 1916.51 samples/sec#011loss=7.934379\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] Epoch[130] Batch[30] avg_epoch_loss=8.095251\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=130, batch=30 train loss <loss>=7.66462173462\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] Epoch[130] Batch [30]#011Speed: 935.45 samples/sec#011loss=7.664622\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] Epoch[130] Batch[35] avg_epoch_loss=8.089867\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=130, batch=35 train loss <loss>=8.05648813248\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] Epoch[130] Batch [35]#011Speed: 1852.56 samples/sec#011loss=8.056488\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] Epoch[130] Batch[40] avg_epoch_loss=8.032460\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=130, batch=40 train loss <loss>=7.61912870407\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] Epoch[130] Batch [40]#011Speed: 883.08 samples/sec#011loss=7.619129\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] Epoch[130] Batch[45] avg_epoch_loss=7.990615\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=130, batch=45 train loss <loss>=7.64748687744\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:39 INFO 139919921551168] Epoch[130] Batch [45]#011Speed: 2037.65 samples/sec#011loss=7.647487\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] Epoch[130] Batch[50] avg_epoch_loss=7.967915\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=130, batch=50 train loss <loss>=7.75906867981\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] Epoch[130] Batch [50]#011Speed: 1398.04 samples/sec#011loss=7.759069\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] processed a total of 1650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1355.3509712219238, \"sum\": 1355.3509712219238, \"min\": 1355.3509712219238}}, \"EndTime\": 1578471700.114106, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471698.758321}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1217.29641916 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=130, train loss <loss>=7.9560330556\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] Epoch[131] Batch[0] avg_epoch_loss=7.891230\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=7.89122962952\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] Epoch[131] Batch[5] avg_epoch_loss=7.999709\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=7.99970936775\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] Epoch[131] Batch [5]#011Speed: 2038.97 samples/sec#011loss=7.999709\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] Epoch[131] Batch[10] avg_epoch_loss=8.096487\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=131, batch=10 train loss <loss>=8.21262073517\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] Epoch[131] Batch [10]#011Speed: 991.58 samples/sec#011loss=8.212621\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] Epoch[131] Batch[15] avg_epoch_loss=8.042041\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=131, batch=15 train loss <loss>=7.92225828171\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] Epoch[131] Batch [15]#011Speed: 2052.05 samples/sec#011loss=7.922258\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] Epoch[131] Batch[20] avg_epoch_loss=8.092555\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=131, batch=20 train loss <loss>=8.25419893265\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] Epoch[131] Batch [20]#011Speed: 946.61 samples/sec#011loss=8.254199\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] Epoch[131] Batch[25] avg_epoch_loss=8.081044\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=131, batch=25 train loss <loss>=8.03269891739\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] Epoch[131] Batch [25]#011Speed: 2149.50 samples/sec#011loss=8.032699\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] Epoch[131] Batch[30] avg_epoch_loss=8.094110\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=131, batch=30 train loss <loss>=8.16205196381\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:40 INFO 139919921551168] Epoch[131] Batch [30]#011Speed: 989.35 samples/sec#011loss=8.162052\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] Epoch[131] Batch[35] avg_epoch_loss=8.044430\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=131, batch=35 train loss <loss>=7.7364192009\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] Epoch[131] Batch [35]#011Speed: 2086.76 samples/sec#011loss=7.736419\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] Epoch[131] Batch[40] avg_epoch_loss=8.021027\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=131, batch=40 train loss <loss>=7.85252141953\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] Epoch[131] Batch [40]#011Speed: 1008.57 samples/sec#011loss=7.852521\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] Epoch[131] Batch[45] avg_epoch_loss=8.030325\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=131, batch=45 train loss <loss>=8.10656642914\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] Epoch[131] Batch [45]#011Speed: 1973.36 samples/sec#011loss=8.106566\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] Epoch[131] Batch[50] avg_epoch_loss=7.952186\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=131, batch=50 train loss <loss>=7.2333114624\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] Epoch[131] Batch [50]#011Speed: 1471.54 samples/sec#011loss=7.233311\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] processed a total of 1619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1243.229866027832, \"sum\": 1243.229866027832, \"min\": 1243.229866027832}}, \"EndTime\": 1578471701.357894, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471700.114179}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1302.13477769 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=131, train loss <loss>=7.95218613568\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] Epoch[132] Batch[0] avg_epoch_loss=8.595838\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=8.59583759308\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] Epoch[132] Batch[5] avg_epoch_loss=8.369347\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=8.36934725444\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] Epoch[132] Batch [5]#011Speed: 1945.77 samples/sec#011loss=8.369347\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] Epoch[132] Batch[10] avg_epoch_loss=8.212288\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=132, batch=10 train loss <loss>=8.02381734848\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] Epoch[132] Batch [10]#011Speed: 900.81 samples/sec#011loss=8.023817\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] Epoch[132] Batch[15] avg_epoch_loss=8.312220\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=132, batch=15 train loss <loss>=8.53206996918\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] Epoch[132] Batch [15]#011Speed: 2109.17 samples/sec#011loss=8.532070\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] Epoch[132] Batch[20] avg_epoch_loss=8.268897\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=132, batch=20 train loss <loss>=8.13026428223\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:41 INFO 139919921551168] Epoch[132] Batch [20]#011Speed: 1036.64 samples/sec#011loss=8.130264\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] Epoch[132] Batch[25] avg_epoch_loss=8.195412\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=132, batch=25 train loss <loss>=7.88677434921\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] Epoch[132] Batch [25]#011Speed: 1939.94 samples/sec#011loss=7.886774\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] Epoch[132] Batch[30] avg_epoch_loss=8.108714\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=132, batch=30 train loss <loss>=7.65788173676\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] Epoch[132] Batch [30]#011Speed: 1077.84 samples/sec#011loss=7.657882\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] Epoch[132] Batch[35] avg_epoch_loss=8.080118\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=132, batch=35 train loss <loss>=7.90282411575\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] Epoch[132] Batch [35]#011Speed: 2060.37 samples/sec#011loss=7.902824\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] Epoch[132] Batch[40] avg_epoch_loss=8.043970\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=132, batch=40 train loss <loss>=7.78370714188\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] Epoch[132] Batch [40]#011Speed: 977.88 samples/sec#011loss=7.783707\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] Epoch[132] Batch[45] avg_epoch_loss=8.043053\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=132, batch=45 train loss <loss>=8.0355348587\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] Epoch[132] Batch [45]#011Speed: 1869.62 samples/sec#011loss=8.035535\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] Epoch[132] Batch[50] avg_epoch_loss=7.980246\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=132, batch=50 train loss <loss>=7.40241699219\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] Epoch[132] Batch [50]#011Speed: 1487.69 samples/sec#011loss=7.402417\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] processed a total of 1633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1266.5870189666748, \"sum\": 1266.5870189666748, \"min\": 1266.5870189666748}}, \"EndTime\": 1578471702.625019, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471701.357972}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1289.17754132 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=132, train loss <loss>=7.96264167015\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] Epoch[133] Batch[0] avg_epoch_loss=8.189309\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=8.18930912018\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] Epoch[133] Batch[5] avg_epoch_loss=8.060747\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=8.0607474645\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] Epoch[133] Batch [5]#011Speed: 2061.30 samples/sec#011loss=8.060747\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] Epoch[133] Batch[10] avg_epoch_loss=8.138046\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=133, batch=10 train loss <loss>=8.23080358505\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:42 INFO 139919921551168] Epoch[133] Batch [10]#011Speed: 987.81 samples/sec#011loss=8.230804\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] Epoch[133] Batch[15] avg_epoch_loss=8.215310\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=133, batch=15 train loss <loss>=8.38529005051\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] Epoch[133] Batch [15]#011Speed: 1653.11 samples/sec#011loss=8.385290\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] Epoch[133] Batch[20] avg_epoch_loss=8.240702\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=133, batch=20 train loss <loss>=8.32195625305\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] Epoch[133] Batch [20]#011Speed: 825.48 samples/sec#011loss=8.321956\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] Epoch[133] Batch[25] avg_epoch_loss=8.148866\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=133, batch=25 train loss <loss>=7.76315460205\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] Epoch[133] Batch [25]#011Speed: 2047.68 samples/sec#011loss=7.763155\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] Epoch[133] Batch[30] avg_epoch_loss=8.107085\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=133, batch=30 train loss <loss>=7.88982601166\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] Epoch[133] Batch [30]#011Speed: 1050.73 samples/sec#011loss=7.889826\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] Epoch[133] Batch[35] avg_epoch_loss=8.017558\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=133, batch=35 train loss <loss>=7.46248846054\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] Epoch[133] Batch [35]#011Speed: 1885.66 samples/sec#011loss=7.462488\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] Epoch[133] Batch[40] avg_epoch_loss=8.041083\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=133, batch=40 train loss <loss>=8.21046581268\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] Epoch[133] Batch [40]#011Speed: 989.10 samples/sec#011loss=8.210466\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] Epoch[133] Batch[45] avg_epoch_loss=8.041925\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=133, batch=45 train loss <loss>=8.04882459641\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] Epoch[133] Batch [45]#011Speed: 2066.68 samples/sec#011loss=8.048825\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] processed a total of 1539 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1243.1600093841553, \"sum\": 1243.1600093841553, \"min\": 1243.1600093841553}}, \"EndTime\": 1578471703.868683, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471702.625096}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1237.86070717 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=133, train loss <loss>=7.97695735036\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] Epoch[134] Batch[0] avg_epoch_loss=8.440144\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=8.44014358521\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:44 INFO 139919921551168] Epoch[134] Batch[5] avg_epoch_loss=8.223356\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=8.22335561117\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:44 INFO 139919921551168] Epoch[134] Batch [5]#011Speed: 1898.32 samples/sec#011loss=8.223356\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:44 INFO 139919921551168] Epoch[134] Batch[10] avg_epoch_loss=8.259099\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=134, batch=10 train loss <loss>=8.30199136734\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:44 INFO 139919921551168] Epoch[134] Batch [10]#011Speed: 988.23 samples/sec#011loss=8.301991\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:44 INFO 139919921551168] Epoch[134] Batch[15] avg_epoch_loss=8.365788\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=134, batch=15 train loss <loss>=8.60050430298\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:44 INFO 139919921551168] Epoch[134] Batch [15]#011Speed: 1484.05 samples/sec#011loss=8.600504\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:44 INFO 139919921551168] Epoch[134] Batch[20] avg_epoch_loss=8.312272\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=134, batch=20 train loss <loss>=8.14102115631\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:44 INFO 139919921551168] Epoch[134] Batch [20]#011Speed: 816.50 samples/sec#011loss=8.141021\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:44 INFO 139919921551168] Epoch[134] Batch[25] avg_epoch_loss=8.229720\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=134, batch=25 train loss <loss>=7.88300132751\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:44 INFO 139919921551168] Epoch[134] Batch [25]#011Speed: 1995.07 samples/sec#011loss=7.883001\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:44 INFO 139919921551168] Epoch[134] Batch[30] avg_epoch_loss=8.158779\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=134, batch=30 train loss <loss>=7.7898859024\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:44 INFO 139919921551168] Epoch[134] Batch [30]#011Speed: 974.21 samples/sec#011loss=7.789886\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:44 INFO 139919921551168] Epoch[134] Batch[35] avg_epoch_loss=8.108048\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=134, batch=35 train loss <loss>=7.79351816177\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:44 INFO 139919921551168] Epoch[134] Batch [35]#011Speed: 1815.60 samples/sec#011loss=7.793518\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] Epoch[134] Batch[40] avg_epoch_loss=8.088270\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=134, batch=40 train loss <loss>=7.94586820602\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] Epoch[134] Batch [40]#011Speed: 929.49 samples/sec#011loss=7.945868\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] Epoch[134] Batch[45] avg_epoch_loss=8.102270\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=134, batch=45 train loss <loss>=8.21706800461\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] Epoch[134] Batch [45]#011Speed: 2105.96 samples/sec#011loss=8.217068\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] processed a total of 1575 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1318.3481693267822, \"sum\": 1318.3481693267822, \"min\": 1318.3481693267822}}, \"EndTime\": 1578471705.187589, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471703.868767}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1194.55454756 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=134, train loss <loss>=8.12495814323\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] Epoch[135] Batch[0] avg_epoch_loss=8.112263\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=8.11226272583\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] Epoch[135] Batch[5] avg_epoch_loss=8.257297\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=8.2572971185\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] Epoch[135] Batch [5]#011Speed: 2034.95 samples/sec#011loss=8.257297\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] Epoch[135] Batch[10] avg_epoch_loss=8.250087\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=135, batch=10 train loss <loss>=8.24143505096\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] Epoch[135] Batch [10]#011Speed: 831.78 samples/sec#011loss=8.241435\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] Epoch[135] Batch[15] avg_epoch_loss=8.290271\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=135, batch=15 train loss <loss>=8.37867460251\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] Epoch[135] Batch [15]#011Speed: 1673.22 samples/sec#011loss=8.378675\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] Epoch[135] Batch[20] avg_epoch_loss=8.303964\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=135, batch=20 train loss <loss>=8.34778194427\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] Epoch[135] Batch [20]#011Speed: 906.49 samples/sec#011loss=8.347782\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] Epoch[135] Batch[25] avg_epoch_loss=8.224868\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=135, batch=25 train loss <loss>=7.89266328812\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:45 INFO 139919921551168] Epoch[135] Batch [25]#011Speed: 1872.70 samples/sec#011loss=7.892663\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] Epoch[135] Batch[30] avg_epoch_loss=8.125572\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=135, batch=30 train loss <loss>=7.60923633575\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] Epoch[135] Batch [30]#011Speed: 969.00 samples/sec#011loss=7.609236\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] Epoch[135] Batch[35] avg_epoch_loss=8.079250\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=135, batch=35 train loss <loss>=7.79205408096\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] Epoch[135] Batch [35]#011Speed: 1942.98 samples/sec#011loss=7.792054\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] Epoch[135] Batch[40] avg_epoch_loss=8.057313\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=135, batch=40 train loss <loss>=7.89936103821\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] Epoch[135] Batch [40]#011Speed: 1045.94 samples/sec#011loss=7.899361\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] Epoch[135] Batch[45] avg_epoch_loss=8.047917\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=135, batch=45 train loss <loss>=7.97087402344\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] Epoch[135] Batch [45]#011Speed: 1608.65 samples/sec#011loss=7.970874\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] processed a total of 1570 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1330.7199478149414, \"sum\": 1330.7199478149414, \"min\": 1330.7199478149414}}, \"EndTime\": 1578471706.518847, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471705.187687}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1179.71229244 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=135, train loss <loss>=8.01674334526\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] Epoch[136] Batch[0] avg_epoch_loss=8.071170\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=8.07116985321\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] Epoch[136] Batch[5] avg_epoch_loss=8.400578\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=8.40057833989\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] Epoch[136] Batch [5]#011Speed: 1660.30 samples/sec#011loss=8.400578\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] Epoch[136] Batch[10] avg_epoch_loss=8.321174\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=136, batch=10 train loss <loss>=8.2258893013\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] Epoch[136] Batch [10]#011Speed: 964.47 samples/sec#011loss=8.225889\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] Epoch[136] Batch[15] avg_epoch_loss=8.269402\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=136, batch=15 train loss <loss>=8.1555021286\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:46 INFO 139919921551168] Epoch[136] Batch [15]#011Speed: 1908.19 samples/sec#011loss=8.155502\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] Epoch[136] Batch[20] avg_epoch_loss=8.248390\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=136, batch=20 train loss <loss>=8.18115282059\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] Epoch[136] Batch [20]#011Speed: 1062.40 samples/sec#011loss=8.181153\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] Epoch[136] Batch[25] avg_epoch_loss=8.167629\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=136, batch=25 train loss <loss>=7.82843408585\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] Epoch[136] Batch [25]#011Speed: 2067.53 samples/sec#011loss=7.828434\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] Epoch[136] Batch[30] avg_epoch_loss=8.123323\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=136, batch=30 train loss <loss>=7.89292802811\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] Epoch[136] Batch [30]#011Speed: 1069.02 samples/sec#011loss=7.892928\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] Epoch[136] Batch[35] avg_epoch_loss=8.079815\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=136, batch=35 train loss <loss>=7.81006708145\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] Epoch[136] Batch [35]#011Speed: 1900.71 samples/sec#011loss=7.810067\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] Epoch[136] Batch[40] avg_epoch_loss=8.034950\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=136, batch=40 train loss <loss>=7.71192550659\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] Epoch[136] Batch [40]#011Speed: 968.30 samples/sec#011loss=7.711926\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] Epoch[136] Batch[45] avg_epoch_loss=8.001942\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=136, batch=45 train loss <loss>=7.73127202988\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] Epoch[136] Batch [45]#011Speed: 2036.30 samples/sec#011loss=7.731272\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] Epoch[136] Batch[50] avg_epoch_loss=7.981561\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=136, batch=50 train loss <loss>=7.79406061172\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] Epoch[136] Batch [50]#011Speed: 1542.56 samples/sec#011loss=7.794061\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] processed a total of 1633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1284.276008605957, \"sum\": 1284.276008605957, \"min\": 1284.276008605957}}, \"EndTime\": 1578471707.803644, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471706.518924}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1271.36807314 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=136, train loss <loss>=7.96299527242\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] Epoch[137] Batch[0] avg_epoch_loss=7.609964\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=7.60996437073\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] Epoch[137] Batch[5] avg_epoch_loss=7.940662\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=7.94066230456\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:47 INFO 139919921551168] Epoch[137] Batch [5]#011Speed: 2049.70 samples/sec#011loss=7.940662\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] Epoch[137] Batch[10] avg_epoch_loss=8.148026\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=137, batch=10 train loss <loss>=8.3968624115\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] Epoch[137] Batch [10]#011Speed: 1029.84 samples/sec#011loss=8.396862\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] Epoch[137] Batch[15] avg_epoch_loss=8.322304\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=137, batch=15 train loss <loss>=8.70571479797\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] Epoch[137] Batch [15]#011Speed: 2065.18 samples/sec#011loss=8.705715\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] Epoch[137] Batch[20] avg_epoch_loss=8.357959\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=137, batch=20 train loss <loss>=8.472057724\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] Epoch[137] Batch [20]#011Speed: 1055.26 samples/sec#011loss=8.472058\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] Epoch[137] Batch[25] avg_epoch_loss=8.284765\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=137, batch=25 train loss <loss>=7.97734613419\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] Epoch[137] Batch [25]#011Speed: 1991.19 samples/sec#011loss=7.977346\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] Epoch[137] Batch[30] avg_epoch_loss=8.219728\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=137, batch=30 train loss <loss>=7.88154020309\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] Epoch[137] Batch [30]#011Speed: 1045.59 samples/sec#011loss=7.881540\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] Epoch[137] Batch[35] avg_epoch_loss=8.161274\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=137, batch=35 train loss <loss>=7.79885950089\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] Epoch[137] Batch [35]#011Speed: 1985.38 samples/sec#011loss=7.798860\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] Epoch[137] Batch[40] avg_epoch_loss=8.128625\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=137, batch=40 train loss <loss>=7.8935500145\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] Epoch[137] Batch [40]#011Speed: 1010.61 samples/sec#011loss=7.893550\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] Epoch[137] Batch[45] avg_epoch_loss=8.118241\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=137, batch=45 train loss <loss>=8.03309288025\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] Epoch[137] Batch [45]#011Speed: 2031.05 samples/sec#011loss=8.033093\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] Epoch[137] Batch[50] avg_epoch_loss=8.078142\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=137, batch=50 train loss <loss>=7.70923080444\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:48 INFO 139919921551168] Epoch[137] Batch [50]#011Speed: 1986.00 samples/sec#011loss=7.709231\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] processed a total of 1672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1232.555866241455, \"sum\": 1232.555866241455, \"min\": 1232.555866241455}}, \"EndTime\": 1578471709.036845, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471707.803773}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1356.39095927 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=137, train loss <loss>=8.03945858973\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] Epoch[138] Batch[0] avg_epoch_loss=8.591188\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=8.59118843079\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] Epoch[138] Batch[5] avg_epoch_loss=8.319729\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=8.31972901026\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] Epoch[138] Batch [5]#011Speed: 2062.84 samples/sec#011loss=8.319729\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] Epoch[138] Batch[10] avg_epoch_loss=8.460186\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=138, batch=10 train loss <loss>=8.62873458862\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] Epoch[138] Batch [10]#011Speed: 949.05 samples/sec#011loss=8.628735\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] Epoch[138] Batch[15] avg_epoch_loss=8.376654\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=138, batch=15 train loss <loss>=8.19288415909\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] Epoch[138] Batch [15]#011Speed: 1965.32 samples/sec#011loss=8.192884\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] Epoch[138] Batch[20] avg_epoch_loss=8.343832\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=138, batch=20 train loss <loss>=8.23880176544\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] Epoch[138] Batch [20]#011Speed: 1010.22 samples/sec#011loss=8.238802\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] Epoch[138] Batch[25] avg_epoch_loss=8.227279\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=138, batch=25 train loss <loss>=7.73775472641\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] Epoch[138] Batch [25]#011Speed: 2049.10 samples/sec#011loss=7.737755\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] Epoch[138] Batch[30] avg_epoch_loss=8.155263\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=138, batch=30 train loss <loss>=7.78077783585\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] Epoch[138] Batch [30]#011Speed: 1056.76 samples/sec#011loss=7.780778\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] Epoch[138] Batch[35] avg_epoch_loss=8.108684\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=138, batch=35 train loss <loss>=7.81989660263\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:49 INFO 139919921551168] Epoch[138] Batch [35]#011Speed: 1679.19 samples/sec#011loss=7.819897\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] Epoch[138] Batch[40] avg_epoch_loss=8.065314\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=138, batch=40 train loss <loss>=7.75305109024\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] Epoch[138] Batch [40]#011Speed: 979.70 samples/sec#011loss=7.753051\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] Epoch[138] Batch[45] avg_epoch_loss=8.066161\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=138, batch=45 train loss <loss>=8.07310876846\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] Epoch[138] Batch [45]#011Speed: 2128.54 samples/sec#011loss=8.073109\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] processed a total of 1598 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1220.5381393432617, \"sum\": 1220.5381393432617, \"min\": 1220.5381393432617}}, \"EndTime\": 1578471710.257937, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471709.036935}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1309.13759632 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=138, train loss <loss>=8.02498552322\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] Epoch[139] Batch[0] avg_epoch_loss=8.252136\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=8.25213623047\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] Epoch[139] Batch[5] avg_epoch_loss=8.159460\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=8.15946046511\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] Epoch[139] Batch [5]#011Speed: 1999.72 samples/sec#011loss=8.159460\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] Epoch[139] Batch[10] avg_epoch_loss=8.185641\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=139, batch=10 train loss <loss>=8.21705703735\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] Epoch[139] Batch [10]#011Speed: 886.36 samples/sec#011loss=8.217057\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] Epoch[139] Batch[15] avg_epoch_loss=8.252125\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=139, batch=15 train loss <loss>=8.39839134216\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] Epoch[139] Batch [15]#011Speed: 1937.47 samples/sec#011loss=8.398391\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] Epoch[139] Batch[20] avg_epoch_loss=8.290789\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=139, batch=20 train loss <loss>=8.41451330185\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] Epoch[139] Batch [20]#011Speed: 886.26 samples/sec#011loss=8.414513\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] Epoch[139] Batch[25] avg_epoch_loss=8.199974\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=139, batch=25 train loss <loss>=7.81854925156\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:50 INFO 139919921551168] Epoch[139] Batch [25]#011Speed: 1709.91 samples/sec#011loss=7.818549\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] Epoch[139] Batch[30] avg_epoch_loss=8.132759\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=139, batch=30 train loss <loss>=7.78324127197\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] Epoch[139] Batch [30]#011Speed: 908.25 samples/sec#011loss=7.783241\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] Epoch[139] Batch[35] avg_epoch_loss=8.055666\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=139, batch=35 train loss <loss>=7.57768764496\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] Epoch[139] Batch [35]#011Speed: 2074.10 samples/sec#011loss=7.577688\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] Epoch[139] Batch[40] avg_epoch_loss=8.019130\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=139, batch=40 train loss <loss>=7.75607032776\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] Epoch[139] Batch [40]#011Speed: 1021.18 samples/sec#011loss=7.756070\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] Epoch[139] Batch[45] avg_epoch_loss=7.995316\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=139, batch=45 train loss <loss>=7.80004873276\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] Epoch[139] Batch [45]#011Speed: 2031.23 samples/sec#011loss=7.800049\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] Epoch[139] Batch[50] avg_epoch_loss=7.939473\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=139, batch=50 train loss <loss>=7.42571363449\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] Epoch[139] Batch [50]#011Speed: 1634.74 samples/sec#011loss=7.425714\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] processed a total of 1603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1303.1880855560303, \"sum\": 1303.1880855560303, \"min\": 1303.1880855560303}}, \"EndTime\": 1578471711.561646, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471710.258015}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1229.95482102 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=139, train loss <loss>=7.93947304931\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] Epoch[140] Batch[0] avg_epoch_loss=8.280437\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=8.28043746948\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] Epoch[140] Batch[5] avg_epoch_loss=8.130034\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=8.13003436724\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] Epoch[140] Batch [5]#011Speed: 1927.46 samples/sec#011loss=8.130034\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] Epoch[140] Batch[10] avg_epoch_loss=8.188569\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=140, batch=10 train loss <loss>=8.25881118774\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:51 INFO 139919921551168] Epoch[140] Batch [10]#011Speed: 907.92 samples/sec#011loss=8.258811\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] Epoch[140] Batch[15] avg_epoch_loss=8.276169\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=140, batch=15 train loss <loss>=8.46888751984\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] Epoch[140] Batch [15]#011Speed: 1861.35 samples/sec#011loss=8.468888\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] Epoch[140] Batch[20] avg_epoch_loss=8.284098\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=140, batch=20 train loss <loss>=8.30947179794\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] Epoch[140] Batch [20]#011Speed: 907.66 samples/sec#011loss=8.309472\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] Epoch[140] Batch[25] avg_epoch_loss=8.212791\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=140, batch=25 train loss <loss>=7.91330375671\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] Epoch[140] Batch [25]#011Speed: 1817.91 samples/sec#011loss=7.913304\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] Epoch[140] Batch[30] avg_epoch_loss=8.124780\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=140, batch=30 train loss <loss>=7.6671207428\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] Epoch[140] Batch [30]#011Speed: 900.57 samples/sec#011loss=7.667121\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] Epoch[140] Batch[35] avg_epoch_loss=8.089709\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=140, batch=35 train loss <loss>=7.87226572037\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] Epoch[140] Batch [35]#011Speed: 2007.58 samples/sec#011loss=7.872266\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] Epoch[140] Batch[40] avg_epoch_loss=8.045392\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=140, batch=40 train loss <loss>=7.72631444931\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] Epoch[140] Batch [40]#011Speed: 992.93 samples/sec#011loss=7.726314\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] Epoch[140] Batch[45] avg_epoch_loss=8.034289\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=140, batch=45 train loss <loss>=7.94324207306\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] Epoch[140] Batch [45]#011Speed: 2130.72 samples/sec#011loss=7.943242\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] Epoch[140] Batch[50] avg_epoch_loss=8.002116\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=140, batch=50 train loss <loss>=7.70612974167\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] Epoch[140] Batch [50]#011Speed: 1473.76 samples/sec#011loss=7.706130\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] processed a total of 1633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1335.1831436157227, \"sum\": 1335.1831436157227, \"min\": 1335.1831436157227}}, \"EndTime\": 1578471712.89732, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471711.561724}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1222.95251548 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=140, train loss <loss>=7.97096335888\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] Epoch[141] Batch[0] avg_epoch_loss=8.160483\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=8.16048336029\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] Epoch[141] Batch[5] avg_epoch_loss=8.113795\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=8.11379535993\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] Epoch[141] Batch [5]#011Speed: 1928.85 samples/sec#011loss=8.113795\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] Epoch[141] Batch[10] avg_epoch_loss=8.274570\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=141, batch=10 train loss <loss>=8.46749992371\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] Epoch[141] Batch [10]#011Speed: 996.35 samples/sec#011loss=8.467500\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] Epoch[141] Batch[15] avg_epoch_loss=8.273654\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=141, batch=15 train loss <loss>=8.27163686752\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] Epoch[141] Batch [15]#011Speed: 2063.10 samples/sec#011loss=8.271637\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] Epoch[141] Batch[20] avg_epoch_loss=8.282343\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=141, batch=20 train loss <loss>=8.31015110016\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] Epoch[141] Batch [20]#011Speed: 1060.81 samples/sec#011loss=8.310151\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] Epoch[141] Batch[25] avg_epoch_loss=8.209400\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=141, batch=25 train loss <loss>=7.9030374527\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] Epoch[141] Batch [25]#011Speed: 2058.83 samples/sec#011loss=7.903037\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] Epoch[141] Batch[30] avg_epoch_loss=8.160265\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=141, batch=30 train loss <loss>=7.90476493835\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] Epoch[141] Batch [30]#011Speed: 1031.83 samples/sec#011loss=7.904765\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] Epoch[141] Batch[35] avg_epoch_loss=8.096074\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=141, batch=35 train loss <loss>=7.69809045792\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] Epoch[141] Batch [35]#011Speed: 1866.87 samples/sec#011loss=7.698090\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] Epoch[141] Batch[40] avg_epoch_loss=8.056676\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=141, batch=40 train loss <loss>=7.77300720215\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:53 INFO 139919921551168] Epoch[141] Batch [40]#011Speed: 1068.48 samples/sec#011loss=7.773007\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] Epoch[141] Batch[45] avg_epoch_loss=8.065857\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=141, batch=45 train loss <loss>=8.14114580154\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] Epoch[141] Batch [45]#011Speed: 2044.49 samples/sec#011loss=8.141146\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] processed a total of 1569 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1197.157859802246, \"sum\": 1197.157859802246, \"min\": 1197.157859802246}}, \"EndTime\": 1578471714.094989, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471712.897396}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1310.48796052 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=141, train loss <loss>=7.99903269768\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] Epoch[142] Batch[0] avg_epoch_loss=8.396049\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=8.39604854584\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] Epoch[142] Batch[5] avg_epoch_loss=8.124856\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=8.12485631307\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] Epoch[142] Batch [5]#011Speed: 1655.34 samples/sec#011loss=8.124856\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] Epoch[142] Batch[10] avg_epoch_loss=8.244705\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=142, batch=10 train loss <loss>=8.38852338791\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] Epoch[142] Batch [10]#011Speed: 920.72 samples/sec#011loss=8.388523\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] Epoch[142] Batch[15] avg_epoch_loss=8.337914\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=142, batch=15 train loss <loss>=8.54297523499\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] Epoch[142] Batch [15]#011Speed: 1859.39 samples/sec#011loss=8.542975\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] Epoch[142] Batch[20] avg_epoch_loss=8.283841\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=142, batch=20 train loss <loss>=8.11080789566\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] Epoch[142] Batch [20]#011Speed: 990.58 samples/sec#011loss=8.110808\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] Epoch[142] Batch[25] avg_epoch_loss=8.237122\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=142, batch=25 train loss <loss>=8.04090013504\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] Epoch[142] Batch [25]#011Speed: 2060.90 samples/sec#011loss=8.040900\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] Epoch[142] Batch[30] avg_epoch_loss=8.192117\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=142, batch=30 train loss <loss>=7.95809297562\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:54 INFO 139919921551168] Epoch[142] Batch [30]#011Speed: 1067.72 samples/sec#011loss=7.958093\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] Epoch[142] Batch[35] avg_epoch_loss=8.140096\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=142, batch=35 train loss <loss>=7.81756353378\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] Epoch[142] Batch [35]#011Speed: 2066.54 samples/sec#011loss=7.817564\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] Epoch[142] Batch[40] avg_epoch_loss=8.137520\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=142, batch=40 train loss <loss>=8.11897449493\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] Epoch[142] Batch [40]#011Speed: 941.15 samples/sec#011loss=8.118974\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] Epoch[142] Batch[45] avg_epoch_loss=8.107469\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=142, batch=45 train loss <loss>=7.86104640961\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] Epoch[142] Batch [45]#011Speed: 1788.07 samples/sec#011loss=7.861046\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] processed a total of 1575 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1262.542963027954, \"sum\": 1262.542963027954, \"min\": 1262.542963027954}}, \"EndTime\": 1578471715.358109, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471714.095055}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1247.37936293 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=142, train loss <loss>=8.02706126213\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] Epoch[143] Batch[0] avg_epoch_loss=8.553072\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=8.55307197571\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] Epoch[143] Batch[5] avg_epoch_loss=8.010695\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=8.01069466273\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] Epoch[143] Batch [5]#011Speed: 1670.02 samples/sec#011loss=8.010695\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] Epoch[143] Batch[10] avg_epoch_loss=8.137861\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=143, batch=10 train loss <loss>=8.29046096802\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] Epoch[143] Batch [10]#011Speed: 901.15 samples/sec#011loss=8.290461\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] Epoch[143] Batch[15] avg_epoch_loss=8.269017\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=143, batch=15 train loss <loss>=8.55755996704\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] Epoch[143] Batch [15]#011Speed: 1752.37 samples/sec#011loss=8.557560\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] Epoch[143] Batch[20] avg_epoch_loss=8.189994\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=143, batch=20 train loss <loss>=7.93712158203\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:55 INFO 139919921551168] Epoch[143] Batch [20]#011Speed: 1055.48 samples/sec#011loss=7.937122\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] Epoch[143] Batch[25] avg_epoch_loss=8.146587\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=143, batch=25 train loss <loss>=7.96427402496\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] Epoch[143] Batch [25]#011Speed: 1994.37 samples/sec#011loss=7.964274\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] Epoch[143] Batch[30] avg_epoch_loss=8.101200\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=143, batch=30 train loss <loss>=7.86519107819\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] Epoch[143] Batch [30]#011Speed: 975.00 samples/sec#011loss=7.865191\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] Epoch[143] Batch[35] avg_epoch_loss=8.027264\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=143, batch=35 train loss <loss>=7.56886100769\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] Epoch[143] Batch [35]#011Speed: 1702.07 samples/sec#011loss=7.568861\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] Epoch[143] Batch[40] avg_epoch_loss=8.019699\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=143, batch=40 train loss <loss>=7.96522960663\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] Epoch[143] Batch [40]#011Speed: 906.65 samples/sec#011loss=7.965230\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] Epoch[143] Batch[45] avg_epoch_loss=8.008761\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=143, batch=45 train loss <loss>=7.91907281876\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] Epoch[143] Batch [45]#011Speed: 1731.06 samples/sec#011loss=7.919073\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] Epoch[143] Batch[50] avg_epoch_loss=7.979635\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=143, batch=50 train loss <loss>=7.71167602539\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] Epoch[143] Batch [50]#011Speed: 1528.76 samples/sec#011loss=7.711676\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] processed a total of 1656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1345.674991607666, \"sum\": 1345.674991607666, \"min\": 1345.674991607666}}, \"EndTime\": 1578471716.704333, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471715.358173}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1230.50213715 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=143, train loss <loss>=7.979161235\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] Epoch[144] Batch[0] avg_epoch_loss=8.025068\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=8.02506828308\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] Epoch[144] Batch[5] avg_epoch_loss=8.101604\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=8.10160414378\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:56 INFO 139919921551168] Epoch[144] Batch [5]#011Speed: 2129.67 samples/sec#011loss=8.101604\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] Epoch[144] Batch[10] avg_epoch_loss=8.242831\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=144, batch=10 train loss <loss>=8.41230287552\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] Epoch[144] Batch [10]#011Speed: 1046.22 samples/sec#011loss=8.412303\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] Epoch[144] Batch[15] avg_epoch_loss=8.316094\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=144, batch=15 train loss <loss>=8.47727241516\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] Epoch[144] Batch [15]#011Speed: 1932.55 samples/sec#011loss=8.477272\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] Epoch[144] Batch[20] avg_epoch_loss=8.260380\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=144, batch=20 train loss <loss>=8.08209562302\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] Epoch[144] Batch [20]#011Speed: 916.12 samples/sec#011loss=8.082096\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] Epoch[144] Batch[25] avg_epoch_loss=8.214736\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=144, batch=25 train loss <loss>=8.02303380966\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] Epoch[144] Batch [25]#011Speed: 2126.10 samples/sec#011loss=8.023034\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] Epoch[144] Batch[30] avg_epoch_loss=8.137160\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=144, batch=30 train loss <loss>=7.73376255035\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] Epoch[144] Batch [30]#011Speed: 1078.60 samples/sec#011loss=7.733763\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] Epoch[144] Batch[35] avg_epoch_loss=8.087513\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=144, batch=35 train loss <loss>=7.77969923019\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] Epoch[144] Batch [35]#011Speed: 2064.49 samples/sec#011loss=7.779699\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] Epoch[144] Batch[40] avg_epoch_loss=8.056278\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=144, batch=40 train loss <loss>=7.83138513565\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] Epoch[144] Batch [40]#011Speed: 1058.15 samples/sec#011loss=7.831385\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] Epoch[144] Batch[45] avg_epoch_loss=8.038356\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=144, batch=45 train loss <loss>=7.89139919281\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] Epoch[144] Batch [45]#011Speed: 1664.07 samples/sec#011loss=7.891399\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] processed a total of 1578 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1213.0510807037354, \"sum\": 1213.0510807037354, \"min\": 1213.0510807037354}}, \"EndTime\": 1578471717.917965, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471716.704412}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1300.72781592 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=144, train loss <loss>=7.96725556374\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:57 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:58 INFO 139919921551168] Epoch[145] Batch[0] avg_epoch_loss=8.672181\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=8.67218112946\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:58 INFO 139919921551168] Epoch[145] Batch[5] avg_epoch_loss=8.444132\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=8.44413248698\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:58 INFO 139919921551168] Epoch[145] Batch [5]#011Speed: 1856.04 samples/sec#011loss=8.444132\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:58 INFO 139919921551168] Epoch[145] Batch[10] avg_epoch_loss=8.294532\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=145, batch=10 train loss <loss>=8.11501216888\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:58 INFO 139919921551168] Epoch[145] Batch [10]#011Speed: 1069.96 samples/sec#011loss=8.115012\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:58 INFO 139919921551168] Epoch[145] Batch[15] avg_epoch_loss=8.339974\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=145, batch=15 train loss <loss>=8.43994674683\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:58 INFO 139919921551168] Epoch[145] Batch [15]#011Speed: 1999.45 samples/sec#011loss=8.439947\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:58 INFO 139919921551168] Epoch[145] Batch[20] avg_epoch_loss=8.354826\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=145, batch=20 train loss <loss>=8.4023519516\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:58 INFO 139919921551168] Epoch[145] Batch [20]#011Speed: 949.57 samples/sec#011loss=8.402352\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:58 INFO 139919921551168] Epoch[145] Batch[25] avg_epoch_loss=8.235998\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=145, batch=25 train loss <loss>=7.73692073822\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:58 INFO 139919921551168] Epoch[145] Batch [25]#011Speed: 1714.75 samples/sec#011loss=7.736921\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:58 INFO 139919921551168] Epoch[145] Batch[30] avg_epoch_loss=8.184375\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=145, batch=30 train loss <loss>=7.9159330368\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:58 INFO 139919921551168] Epoch[145] Batch [30]#011Speed: 961.46 samples/sec#011loss=7.915933\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:58 INFO 139919921551168] Epoch[145] Batch[35] avg_epoch_loss=8.116793\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=145, batch=35 train loss <loss>=7.6977891922\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:58 INFO 139919921551168] Epoch[145] Batch [35]#011Speed: 2137.81 samples/sec#011loss=7.697789\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] Epoch[145] Batch[40] avg_epoch_loss=8.086213\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=145, batch=40 train loss <loss>=7.86603689194\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] Epoch[145] Batch [40]#011Speed: 1025.77 samples/sec#011loss=7.866037\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] Epoch[145] Batch[45] avg_epoch_loss=8.055081\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=145, batch=45 train loss <loss>=7.79979829788\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] Epoch[145] Batch [45]#011Speed: 2026.42 samples/sec#011loss=7.799798\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] processed a total of 1545 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1248.9469051361084, \"sum\": 1248.9469051361084, \"min\": 1248.9469051361084}}, \"EndTime\": 1578471719.16746, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471717.918045}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1236.93119954 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=145, train loss <loss>=8.01472491634\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] Epoch[146] Batch[0] avg_epoch_loss=8.295801\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=8.29580116272\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] Epoch[146] Batch[5] avg_epoch_loss=7.998226\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=7.99822640419\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] Epoch[146] Batch [5]#011Speed: 1995.33 samples/sec#011loss=7.998226\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] Epoch[146] Batch[10] avg_epoch_loss=8.089445\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=146, batch=10 train loss <loss>=8.19890670776\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] Epoch[146] Batch [10]#011Speed: 901.78 samples/sec#011loss=8.198907\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] Epoch[146] Batch[15] avg_epoch_loss=8.285159\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=146, batch=15 train loss <loss>=8.71573200226\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] Epoch[146] Batch [15]#011Speed: 1694.11 samples/sec#011loss=8.715732\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] Epoch[146] Batch[20] avg_epoch_loss=8.263491\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=146, batch=20 train loss <loss>=8.19415187836\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] Epoch[146] Batch [20]#011Speed: 990.06 samples/sec#011loss=8.194152\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] Epoch[146] Batch[25] avg_epoch_loss=8.194729\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=146, batch=25 train loss <loss>=7.90592842102\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:21:59 INFO 139919921551168] Epoch[146] Batch [25]#011Speed: 1841.18 samples/sec#011loss=7.905928\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] Epoch[146] Batch[30] avg_epoch_loss=8.127303\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=146, batch=30 train loss <loss>=7.77668581009\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] Epoch[146] Batch [30]#011Speed: 1055.59 samples/sec#011loss=7.776686\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] Epoch[146] Batch[35] avg_epoch_loss=8.063372\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=146, batch=35 train loss <loss>=7.66700468063\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] Epoch[146] Batch [35]#011Speed: 1674.43 samples/sec#011loss=7.667005\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] Epoch[146] Batch[40] avg_epoch_loss=8.056022\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=146, batch=40 train loss <loss>=8.00309934616\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] Epoch[146] Batch [40]#011Speed: 978.19 samples/sec#011loss=8.003099\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] Epoch[146] Batch[45] avg_epoch_loss=8.053113\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=146, batch=45 train loss <loss>=8.02926235199\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] Epoch[146] Batch [45]#011Speed: 1674.71 samples/sec#011loss=8.029262\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] processed a total of 1575 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1299.5319366455078, \"sum\": 1299.5319366455078, \"min\": 1299.5319366455078}}, \"EndTime\": 1578471720.467545, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471719.167536}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1211.86566511 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=146, train loss <loss>=8.00363067627\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] Epoch[147] Batch[0] avg_epoch_loss=8.540589\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=8.54058933258\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] Epoch[147] Batch[5] avg_epoch_loss=8.395188\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=8.3951883316\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] Epoch[147] Batch [5]#011Speed: 1757.22 samples/sec#011loss=8.395188\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] Epoch[147] Batch[10] avg_epoch_loss=8.141251\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=147, batch=10 train loss <loss>=7.83652687073\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] Epoch[147] Batch [10]#011Speed: 2117.91 samples/sec#011loss=7.836527\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] Epoch[147] Batch[15] avg_epoch_loss=8.217672\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=147, batch=15 train loss <loss>=8.3857963562\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:00 INFO 139919921551168] Epoch[147] Batch [15]#011Speed: 974.78 samples/sec#011loss=8.385796\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] Epoch[147] Batch[20] avg_epoch_loss=8.161917\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=147, batch=20 train loss <loss>=7.98350419998\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] Epoch[147] Batch [20]#011Speed: 1904.22 samples/sec#011loss=7.983504\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] Epoch[147] Batch[25] avg_epoch_loss=8.128686\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=147, batch=25 train loss <loss>=7.98911371231\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] Epoch[147] Batch [25]#011Speed: 891.76 samples/sec#011loss=7.989114\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] Epoch[147] Batch[30] avg_epoch_loss=8.065775\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=147, batch=30 train loss <loss>=7.73863792419\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] Epoch[147] Batch [30]#011Speed: 842.85 samples/sec#011loss=7.738638\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] Epoch[147] Batch[35] avg_epoch_loss=8.003769\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=147, batch=35 train loss <loss>=7.61933441162\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] Epoch[147] Batch [35]#011Speed: 1899.40 samples/sec#011loss=7.619334\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] Epoch[147] Batch[40] avg_epoch_loss=7.992054\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=147, batch=40 train loss <loss>=7.90770540237\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] Epoch[147] Batch [40]#011Speed: 989.46 samples/sec#011loss=7.907705\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] Epoch[147] Batch[45] avg_epoch_loss=7.994170\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=147, batch=45 train loss <loss>=8.01152019501\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] Epoch[147] Batch [45]#011Speed: 1996.18 samples/sec#011loss=8.011520\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] Epoch[147] Batch[50] avg_epoch_loss=7.947057\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=147, batch=50 train loss <loss>=7.51361188889\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] Epoch[147] Batch [50]#011Speed: 1595.95 samples/sec#011loss=7.513612\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] processed a total of 1630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1342.2291278839111, \"sum\": 1342.2291278839111, \"min\": 1342.2291278839111}}, \"EndTime\": 1578471721.810352, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471720.467627}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1214.2920358 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=147, train loss <loss>=7.94705656463\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] Epoch[148] Batch[0] avg_epoch_loss=7.802482\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=7.80248165131\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] Epoch[148] Batch[5] avg_epoch_loss=8.003005\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=8.00300534566\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:01 INFO 139919921551168] Epoch[148] Batch [5]#011Speed: 2122.75 samples/sec#011loss=8.003005\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] Epoch[148] Batch[10] avg_epoch_loss=8.087057\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=148, batch=10 train loss <loss>=8.18791942596\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] Epoch[148] Batch [10]#011Speed: 893.27 samples/sec#011loss=8.187919\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] Epoch[148] Batch[15] avg_epoch_loss=8.168031\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=148, batch=15 train loss <loss>=8.34617214203\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] Epoch[148] Batch [15]#011Speed: 2136.24 samples/sec#011loss=8.346172\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] Epoch[148] Batch[20] avg_epoch_loss=8.217252\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=148, batch=20 train loss <loss>=8.37476167679\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] Epoch[148] Batch [20]#011Speed: 933.92 samples/sec#011loss=8.374762\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] Epoch[148] Batch[25] avg_epoch_loss=8.137965\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=148, batch=25 train loss <loss>=7.80495634079\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] Epoch[148] Batch [25]#011Speed: 2129.22 samples/sec#011loss=7.804956\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] Epoch[148] Batch[30] avg_epoch_loss=8.081612\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=148, batch=30 train loss <loss>=7.78857574463\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] Epoch[148] Batch [30]#011Speed: 949.49 samples/sec#011loss=7.788576\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] Epoch[148] Batch[35] avg_epoch_loss=8.049030\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=148, batch=35 train loss <loss>=7.84702243805\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] Epoch[148] Batch [35]#011Speed: 2140.76 samples/sec#011loss=7.847022\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] Epoch[148] Batch[40] avg_epoch_loss=8.021066\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=148, batch=40 train loss <loss>=7.81972675323\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] Epoch[148] Batch [40]#011Speed: 888.31 samples/sec#011loss=7.819727\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] Epoch[148] Batch[45] avg_epoch_loss=8.007954\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=148, batch=45 train loss <loss>=7.90043849945\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:02 INFO 139919921551168] Epoch[148] Batch [45]#011Speed: 2137.58 samples/sec#011loss=7.900438\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] Epoch[148] Batch[50] avg_epoch_loss=7.952494\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=148, batch=50 train loss <loss>=7.44225692749\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] Epoch[148] Batch [50]#011Speed: 1474.08 samples/sec#011loss=7.442257\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] processed a total of 1617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1276.1170864105225, \"sum\": 1276.1170864105225, \"min\": 1276.1170864105225}}, \"EndTime\": 1578471723.086984, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471721.810431}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1267.01503338 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=148, train loss <loss>=7.9524937611\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] Epoch[149] Batch[0] avg_epoch_loss=7.898667\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=7.89866733551\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] Epoch[149] Batch[5] avg_epoch_loss=8.048803\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=8.04880285263\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] Epoch[149] Batch [5]#011Speed: 2030.54 samples/sec#011loss=8.048803\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] Epoch[149] Batch[10] avg_epoch_loss=8.090214\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=149, batch=10 train loss <loss>=8.13990650177\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] Epoch[149] Batch [10]#011Speed: 2114.61 samples/sec#011loss=8.139907\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] Epoch[149] Batch[15] avg_epoch_loss=8.138257\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=149, batch=15 train loss <loss>=8.24395389557\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] Epoch[149] Batch [15]#011Speed: 959.29 samples/sec#011loss=8.243954\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] Epoch[149] Batch[20] avg_epoch_loss=8.215138\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=149, batch=20 train loss <loss>=8.46115722656\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] Epoch[149] Batch [20]#011Speed: 1817.44 samples/sec#011loss=8.461157\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] Epoch[149] Batch[25] avg_epoch_loss=8.170539\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=149, batch=25 train loss <loss>=7.9832198143\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] Epoch[149] Batch [25]#011Speed: 976.00 samples/sec#011loss=7.983220\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] Epoch[149] Batch[30] avg_epoch_loss=8.121249\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=149, batch=30 train loss <loss>=7.86494140625\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:03 INFO 139919921551168] Epoch[149] Batch [30]#011Speed: 2118.11 samples/sec#011loss=7.864941\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] Epoch[149] Batch[35] avg_epoch_loss=8.016433\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=149, batch=35 train loss <loss>=7.3665728569\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] Epoch[149] Batch [35]#011Speed: 901.83 samples/sec#011loss=7.366573\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] Epoch[149] Batch[40] avg_epoch_loss=7.974762\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=149, batch=40 train loss <loss>=7.6747341156\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] Epoch[149] Batch [40]#011Speed: 2045.20 samples/sec#011loss=7.674734\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] Epoch[149] Batch[45] avg_epoch_loss=7.965649\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=149, batch=45 train loss <loss>=7.89092540741\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] Epoch[149] Batch [45]#011Speed: 976.51 samples/sec#011loss=7.890925\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] Epoch[149] Batch[50] avg_epoch_loss=7.958751\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=149, batch=50 train loss <loss>=7.89528064728\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] Epoch[149] Batch [50]#011Speed: 2131.23 samples/sec#011loss=7.895281\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] processed a total of 1710 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1356.6241264343262, \"sum\": 1356.6241264343262, \"min\": 1356.6241264343262}}, \"EndTime\": 1578471724.444094, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471723.087059}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1260.37679191 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=149, train loss <loss>=7.91762608069\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] Saved checkpoint to \"/opt/ml/model/state_760129f1-efce-4377-b0ee-36dda9ffecfa-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 15.386104583740234, \"sum\": 15.386104583740234, \"min\": 15.386104583740234}}, \"EndTime\": 1578471724.460032, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471724.444173}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] Epoch[150] Batch[0] avg_epoch_loss=8.130584\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=8.13058376312\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] Epoch[150] Batch[5] avg_epoch_loss=8.329643\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=8.32964293162\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] Epoch[150] Batch [5]#011Speed: 1931.99 samples/sec#011loss=8.329643\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] Epoch[150] Batch[10] avg_epoch_loss=8.342258\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=150, batch=10 train loss <loss>=8.35739593506\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] Epoch[150] Batch [10]#011Speed: 1065.24 samples/sec#011loss=8.357396\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] Epoch[150] Batch[15] avg_epoch_loss=8.359984\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=150, batch=15 train loss <loss>=8.3989818573\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:04 INFO 139919921551168] Epoch[150] Batch [15]#011Speed: 2042.25 samples/sec#011loss=8.398982\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] Epoch[150] Batch[20] avg_epoch_loss=8.370301\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=150, batch=20 train loss <loss>=8.40331287384\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] Epoch[150] Batch [20]#011Speed: 1049.70 samples/sec#011loss=8.403313\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] Epoch[150] Batch[25] avg_epoch_loss=8.307126\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=150, batch=25 train loss <loss>=8.04179067612\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] Epoch[150] Batch [25]#011Speed: 2065.82 samples/sec#011loss=8.041791\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] Epoch[150] Batch[30] avg_epoch_loss=8.162915\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=150, batch=30 train loss <loss>=7.41302061081\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] Epoch[150] Batch [30]#011Speed: 1027.08 samples/sec#011loss=7.413021\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] Epoch[150] Batch[35] avg_epoch_loss=8.115405\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=150, batch=35 train loss <loss>=7.82084321976\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] Epoch[150] Batch [35]#011Speed: 1605.36 samples/sec#011loss=7.820843\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] Epoch[150] Batch[40] avg_epoch_loss=8.103610\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=150, batch=40 train loss <loss>=8.01868562698\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] Epoch[150] Batch [40]#011Speed: 864.97 samples/sec#011loss=8.018686\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] Epoch[150] Batch[45] avg_epoch_loss=8.101883\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=150, batch=45 train loss <loss>=8.08772010803\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] Epoch[150] Batch [45]#011Speed: 1946.07 samples/sec#011loss=8.087720\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] processed a total of 1540 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1247.4708557128906, \"sum\": 1247.4708557128906, \"min\": 1247.4708557128906}}, \"EndTime\": 1578471725.707612, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471724.460091}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1234.36118475 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=150, train loss <loss>=8.01716742224\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] Epoch[151] Batch[0] avg_epoch_loss=8.253352\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=8.25335216522\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] Epoch[151] Batch[5] avg_epoch_loss=8.298258\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=8.2982583046\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] Epoch[151] Batch [5]#011Speed: 2037.00 samples/sec#011loss=8.298258\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] Epoch[151] Batch[10] avg_epoch_loss=8.310119\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=151, batch=10 train loss <loss>=8.32435092926\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:05 INFO 139919921551168] Epoch[151] Batch [10]#011Speed: 2130.64 samples/sec#011loss=8.324351\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] Epoch[151] Batch[15] avg_epoch_loss=8.383279\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=151, batch=15 train loss <loss>=8.54423294067\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] Epoch[151] Batch [15]#011Speed: 944.66 samples/sec#011loss=8.544233\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] Epoch[151] Batch[20] avg_epoch_loss=8.393908\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=151, batch=20 train loss <loss>=8.42792139053\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] Epoch[151] Batch [20]#011Speed: 1719.82 samples/sec#011loss=8.427921\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] Epoch[151] Batch[25] avg_epoch_loss=8.309618\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=151, batch=25 train loss <loss>=7.95559625626\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] Epoch[151] Batch [25]#011Speed: 972.59 samples/sec#011loss=7.955596\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] Epoch[151] Batch[30] avg_epoch_loss=8.251153\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=151, batch=30 train loss <loss>=7.9471364975\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] Epoch[151] Batch [30]#011Speed: 1087.81 samples/sec#011loss=7.947136\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] Epoch[151] Batch[35] avg_epoch_loss=8.189637\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=151, batch=35 train loss <loss>=7.80824069977\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] Epoch[151] Batch [35]#011Speed: 2044.85 samples/sec#011loss=7.808241\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] Epoch[151] Batch[40] avg_epoch_loss=8.176593\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=151, batch=40 train loss <loss>=8.08267459869\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] Epoch[151] Batch [40]#011Speed: 1048.71 samples/sec#011loss=8.082675\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] Epoch[151] Batch[45] avg_epoch_loss=8.131808\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=151, batch=45 train loss <loss>=7.76456575394\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] Epoch[151] Batch [45]#011Speed: 2045.72 samples/sec#011loss=7.764566\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] Epoch[151] Batch[50] avg_epoch_loss=8.084398\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=151, batch=50 train loss <loss>=7.64823198318\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] Epoch[151] Batch [50]#011Speed: 1719.73 samples/sec#011loss=7.648232\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] processed a total of 1638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1260.390043258667, \"sum\": 1260.390043258667, \"min\": 1260.390043258667}}, \"EndTime\": 1578471726.968555, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471725.707717}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1299.47110616 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=151, train loss <loss>=8.05238855802\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:06 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] Epoch[152] Batch[0] avg_epoch_loss=7.925150\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=7.9251499176\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] Epoch[152] Batch[5] avg_epoch_loss=8.397885\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=8.39788484573\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] Epoch[152] Batch [5]#011Speed: 1985.50 samples/sec#011loss=8.397885\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] Epoch[152] Batch[10] avg_epoch_loss=8.402960\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=152, batch=10 train loss <loss>=8.40904998779\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] Epoch[152] Batch [10]#011Speed: 1062.27 samples/sec#011loss=8.409050\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] Epoch[152] Batch[15] avg_epoch_loss=8.470744\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=152, batch=15 train loss <loss>=8.61986865997\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] Epoch[152] Batch [15]#011Speed: 2051.49 samples/sec#011loss=8.619869\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] Epoch[152] Batch[20] avg_epoch_loss=8.494049\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=152, batch=20 train loss <loss>=8.56862325668\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] Epoch[152] Batch [20]#011Speed: 1054.37 samples/sec#011loss=8.568623\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] Epoch[152] Batch[25] avg_epoch_loss=8.390446\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=152, batch=25 train loss <loss>=7.9553150177\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] Epoch[152] Batch [25]#011Speed: 1943.12 samples/sec#011loss=7.955315\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] Epoch[152] Batch[30] avg_epoch_loss=8.243543\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=152, batch=30 train loss <loss>=7.47964887619\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] Epoch[152] Batch [30]#011Speed: 1023.50 samples/sec#011loss=7.479649\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] Epoch[152] Batch[35] avg_epoch_loss=8.162634\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=152, batch=35 train loss <loss>=7.66099824905\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] Epoch[152] Batch [35]#011Speed: 2039.10 samples/sec#011loss=7.660998\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] Epoch[152] Batch[40] avg_epoch_loss=8.150676\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=152, batch=40 train loss <loss>=8.06457948685\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:07 INFO 139919921551168] Epoch[152] Batch [40]#011Speed: 1079.64 samples/sec#011loss=8.064579\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] Epoch[152] Batch[45] avg_epoch_loss=8.135560\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=152, batch=45 train loss <loss>=8.01160707474\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] Epoch[152] Batch [45]#011Speed: 2045.47 samples/sec#011loss=8.011607\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] Epoch[152] Batch[50] avg_epoch_loss=8.067759\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=152, batch=50 train loss <loss>=7.44398670197\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] Epoch[152] Batch [50]#011Speed: 1744.57 samples/sec#011loss=7.443987\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] processed a total of 1634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1215.9240245819092, \"sum\": 1215.9240245819092, \"min\": 1215.9240245819092}}, \"EndTime\": 1578471728.184999, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471726.968633}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1343.70248923 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=152, train loss <loss>=8.03754502993\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] Epoch[153] Batch[0] avg_epoch_loss=8.123219\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=8.12321853638\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] Epoch[153] Batch[5] avg_epoch_loss=8.228184\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=8.22818366687\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] Epoch[153] Batch [5]#011Speed: 2060.34 samples/sec#011loss=8.228184\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] Epoch[153] Batch[10] avg_epoch_loss=8.068140\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=153, batch=10 train loss <loss>=7.8760884285\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] Epoch[153] Batch [10]#011Speed: 1084.38 samples/sec#011loss=7.876088\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] Epoch[153] Batch[15] avg_epoch_loss=8.246742\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=153, batch=15 train loss <loss>=8.63966503143\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] Epoch[153] Batch [15]#011Speed: 2140.81 samples/sec#011loss=8.639665\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] Epoch[153] Batch[20] avg_epoch_loss=8.154595\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=153, batch=20 train loss <loss>=7.85972394943\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] Epoch[153] Batch [20]#011Speed: 897.31 samples/sec#011loss=7.859724\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] Epoch[153] Batch[25] avg_epoch_loss=8.092380\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=153, batch=25 train loss <loss>=7.83107738495\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] Epoch[153] Batch [25]#011Speed: 2173.29 samples/sec#011loss=7.831077\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] Epoch[153] Batch[30] avg_epoch_loss=8.038716\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=153, batch=30 train loss <loss>=7.75966405869\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:08 INFO 139919921551168] Epoch[153] Batch [30]#011Speed: 1033.24 samples/sec#011loss=7.759664\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] Epoch[153] Batch[35] avg_epoch_loss=8.015147\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=153, batch=35 train loss <loss>=7.86901702881\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] Epoch[153] Batch [35]#011Speed: 2140.04 samples/sec#011loss=7.869017\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] Epoch[153] Batch[40] avg_epoch_loss=7.981922\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=153, batch=40 train loss <loss>=7.74270009995\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] Epoch[153] Batch [40]#011Speed: 902.26 samples/sec#011loss=7.742700\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] Epoch[153] Batch[45] avg_epoch_loss=7.949563\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=153, batch=45 train loss <loss>=7.6842209816\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] Epoch[153] Batch [45]#011Speed: 2077.79 samples/sec#011loss=7.684221\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] Epoch[153] Batch[50] avg_epoch_loss=7.888981\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=153, batch=50 train loss <loss>=7.33163204193\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] Epoch[153] Batch [50]#011Speed: 1380.73 samples/sec#011loss=7.331632\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] processed a total of 1642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1278.8448333740234, \"sum\": 1278.8448333740234, \"min\": 1278.8448333740234}}, \"EndTime\": 1578471729.464339, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471728.185074}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1283.85564319 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=153, train loss <loss>=7.88315631793\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] Saved checkpoint to \"/opt/ml/model/state_be50c727-c920-4f00-b313-4f6456a97628-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 15.846014022827148, \"sum\": 15.846014022827148, \"min\": 15.846014022827148}}, \"EndTime\": 1578471729.480756, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471729.464419}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] Epoch[154] Batch[0] avg_epoch_loss=8.519784\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=8.51978397369\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] Epoch[154] Batch[5] avg_epoch_loss=8.206076\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=8.20607614517\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] Epoch[154] Batch [5]#011Speed: 1633.44 samples/sec#011loss=8.206076\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] Epoch[154] Batch[10] avg_epoch_loss=8.208324\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=154, batch=10 train loss <loss>=8.21102209091\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] Epoch[154] Batch [10]#011Speed: 925.97 samples/sec#011loss=8.211022\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] Epoch[154] Batch[15] avg_epoch_loss=8.252524\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=154, batch=15 train loss <loss>=8.3497633934\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:09 INFO 139919921551168] Epoch[154] Batch [15]#011Speed: 1658.22 samples/sec#011loss=8.349763\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] Epoch[154] Batch[20] avg_epoch_loss=8.186677\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=154, batch=20 train loss <loss>=7.97596445084\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] Epoch[154] Batch [20]#011Speed: 971.39 samples/sec#011loss=7.975964\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] Epoch[154] Batch[25] avg_epoch_loss=8.165565\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=154, batch=25 train loss <loss>=8.07689809799\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] Epoch[154] Batch [25]#011Speed: 1646.63 samples/sec#011loss=8.076898\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] Epoch[154] Batch[30] avg_epoch_loss=8.119067\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=154, batch=30 train loss <loss>=7.87727375031\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] Epoch[154] Batch [30]#011Speed: 892.16 samples/sec#011loss=7.877274\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] Epoch[154] Batch[35] avg_epoch_loss=8.037196\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=154, batch=35 train loss <loss>=7.5295964241\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] Epoch[154] Batch [35]#011Speed: 1663.65 samples/sec#011loss=7.529596\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] Epoch[154] Batch[40] avg_epoch_loss=8.021482\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=154, batch=40 train loss <loss>=7.90834188461\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] Epoch[154] Batch [40]#011Speed: 1097.97 samples/sec#011loss=7.908342\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] Epoch[154] Batch[45] avg_epoch_loss=8.009711\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=154, batch=45 train loss <loss>=7.91319303513\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] Epoch[154] Batch [45]#011Speed: 1711.34 samples/sec#011loss=7.913193\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] Epoch[154] Batch[50] avg_epoch_loss=7.960799\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=154, batch=50 train loss <loss>=7.51080036163\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] Epoch[154] Batch [50]#011Speed: 1679.17 samples/sec#011loss=7.510800\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] processed a total of 1630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1345.447063446045, \"sum\": 1345.447063446045, \"min\": 1345.447063446045}}, \"EndTime\": 1578471730.826323, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471729.480821}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1211.40048827 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=154, train loss <loss>=7.96079851599\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] Epoch[155] Batch[0] avg_epoch_loss=8.088914\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=8.08891391754\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] Epoch[155] Batch[5] avg_epoch_loss=8.085058\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=8.0850575765\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] Epoch[155] Batch [5]#011Speed: 1647.41 samples/sec#011loss=8.085058\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] Epoch[155] Batch[10] avg_epoch_loss=8.095747\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=8.10857372284\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] Epoch[155] Batch [10]#011Speed: 1026.85 samples/sec#011loss=8.108574\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] Epoch[155] Batch[15] avg_epoch_loss=8.230806\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=155, batch=15 train loss <loss>=8.52793483734\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] Epoch[155] Batch [15]#011Speed: 1928.29 samples/sec#011loss=8.527935\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] Epoch[155] Batch[20] avg_epoch_loss=8.149553\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=155, batch=20 train loss <loss>=7.88954544067\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] Epoch[155] Batch [20]#011Speed: 1108.51 samples/sec#011loss=7.889545\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] Epoch[155] Batch[25] avg_epoch_loss=8.080465\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=155, batch=25 train loss <loss>=7.79029350281\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] Epoch[155] Batch [25]#011Speed: 1660.17 samples/sec#011loss=7.790294\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] Epoch[155] Batch[30] avg_epoch_loss=8.029551\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=155, batch=30 train loss <loss>=7.764798069\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] Epoch[155] Batch [30]#011Speed: 1007.96 samples/sec#011loss=7.764798\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] Epoch[155] Batch[35] avg_epoch_loss=7.980168\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=155, batch=35 train loss <loss>=7.67399158478\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] Epoch[155] Batch [35]#011Speed: 972.25 samples/sec#011loss=7.673992\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] Epoch[155] Batch[40] avg_epoch_loss=7.954583\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=155, batch=40 train loss <loss>=7.77037820816\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:11 INFO 139919921551168] Epoch[155] Batch [40]#011Speed: 1912.96 samples/sec#011loss=7.770378\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] Epoch[155] Batch[45] avg_epoch_loss=7.918077\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=155, batch=45 train loss <loss>=7.61872224808\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] Epoch[155] Batch [45]#011Speed: 1389.97 samples/sec#011loss=7.618722\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] processed a total of 1543 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1240.9389019012451, \"sum\": 1240.9389019012451, \"min\": 1240.9389019012451}}, \"EndTime\": 1578471732.067767, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471730.826389}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1243.32019061 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=155, train loss <loss>=7.88378549109\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] Epoch[156] Batch[0] avg_epoch_loss=8.647298\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=8.64729785919\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] Epoch[156] Batch[5] avg_epoch_loss=8.458924\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=8.45892429352\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] Epoch[156] Batch [5]#011Speed: 2064.25 samples/sec#011loss=8.458924\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] Epoch[156] Batch[10] avg_epoch_loss=8.395383\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=156, batch=10 train loss <loss>=8.31913290024\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] Epoch[156] Batch [10]#011Speed: 1048.29 samples/sec#011loss=8.319133\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] Epoch[156] Batch[15] avg_epoch_loss=8.444220\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=156, batch=15 train loss <loss>=8.55166187286\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] Epoch[156] Batch [15]#011Speed: 2110.85 samples/sec#011loss=8.551662\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] Epoch[156] Batch[20] avg_epoch_loss=8.374745\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=156, batch=20 train loss <loss>=8.15242376328\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] Epoch[156] Batch [20]#011Speed: 872.70 samples/sec#011loss=8.152424\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] Epoch[156] Batch[25] avg_epoch_loss=8.317436\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=156, batch=25 train loss <loss>=8.07673835754\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] Epoch[156] Batch [25]#011Speed: 1999.10 samples/sec#011loss=8.076738\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] Epoch[156] Batch[30] avg_epoch_loss=8.233557\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=156, batch=30 train loss <loss>=7.79738674164\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] Epoch[156] Batch [30]#011Speed: 1048.89 samples/sec#011loss=7.797387\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] Epoch[156] Batch[35] avg_epoch_loss=8.169461\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=156, batch=35 train loss <loss>=7.77206993103\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:12 INFO 139919921551168] Epoch[156] Batch [35]#011Speed: 1663.82 samples/sec#011loss=7.772070\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] Epoch[156] Batch[40] avg_epoch_loss=8.127640\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=156, batch=40 train loss <loss>=7.8265253067\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] Epoch[156] Batch [40]#011Speed: 981.64 samples/sec#011loss=7.826525\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] Epoch[156] Batch[45] avg_epoch_loss=8.092864\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=156, batch=45 train loss <loss>=7.80769662857\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] Epoch[156] Batch [45]#011Speed: 1707.65 samples/sec#011loss=7.807697\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] processed a total of 1546 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1247.0519542694092, \"sum\": 1247.0519542694092, \"min\": 1247.0519542694092}}, \"EndTime\": 1578471733.315352, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471732.067828}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1239.61834615 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=156, train loss <loss>=8.06607609379\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] Epoch[157] Batch[0] avg_epoch_loss=8.419215\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=8.41921520233\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] Epoch[157] Batch[5] avg_epoch_loss=8.106963\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=8.10696299871\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] Epoch[157] Batch [5]#011Speed: 1743.37 samples/sec#011loss=8.106963\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] Epoch[157] Batch[10] avg_epoch_loss=8.170542\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=157, batch=10 train loss <loss>=8.2468375206\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] Epoch[157] Batch [10]#011Speed: 957.31 samples/sec#011loss=8.246838\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] Epoch[157] Batch[15] avg_epoch_loss=8.231384\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=157, batch=15 train loss <loss>=8.36523456573\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] Epoch[157] Batch [15]#011Speed: 2091.94 samples/sec#011loss=8.365235\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] Epoch[157] Batch[20] avg_epoch_loss=8.246751\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=157, batch=20 train loss <loss>=8.29592552185\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:13 INFO 139919921551168] Epoch[157] Batch [20]#011Speed: 892.98 samples/sec#011loss=8.295926\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] Epoch[157] Batch[25] avg_epoch_loss=8.193985\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=157, batch=25 train loss <loss>=7.97236881256\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] Epoch[157] Batch [25]#011Speed: 2131.68 samples/sec#011loss=7.972369\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] Epoch[157] Batch[30] avg_epoch_loss=8.141756\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=157, batch=30 train loss <loss>=7.87016553879\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] Epoch[157] Batch [30]#011Speed: 1039.49 samples/sec#011loss=7.870166\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] Epoch[157] Batch[35] avg_epoch_loss=8.083049\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=157, batch=35 train loss <loss>=7.71906576157\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] Epoch[157] Batch [35]#011Speed: 2003.91 samples/sec#011loss=7.719066\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] Epoch[157] Batch[40] avg_epoch_loss=8.063476\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=157, batch=40 train loss <loss>=7.92254772186\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] Epoch[157] Batch [40]#011Speed: 938.31 samples/sec#011loss=7.922548\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] Epoch[157] Batch[45] avg_epoch_loss=8.028781\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=157, batch=45 train loss <loss>=7.74428730011\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] Epoch[157] Batch [45]#011Speed: 1755.46 samples/sec#011loss=7.744287\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] Epoch[157] Batch[50] avg_epoch_loss=7.995176\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=157, batch=50 train loss <loss>=7.68601140976\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] Epoch[157] Batch [50]#011Speed: 1315.76 samples/sec#011loss=7.686011\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] processed a total of 1606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1302.299976348877, \"sum\": 1302.299976348877, \"min\": 1302.299976348877}}, \"EndTime\": 1578471734.618215, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471733.315422}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1233.10055275 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=157, train loss <loss>=7.9951764462\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] Epoch[158] Batch[0] avg_epoch_loss=8.467325\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=8.46732521057\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] Epoch[158] Batch[5] avg_epoch_loss=8.164723\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=8.16472268105\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] Epoch[158] Batch [5]#011Speed: 2042.09 samples/sec#011loss=8.164723\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] Epoch[158] Batch[10] avg_epoch_loss=8.222618\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=158, batch=10 train loss <loss>=8.29209289551\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:14 INFO 139919921551168] Epoch[158] Batch [10]#011Speed: 1052.54 samples/sec#011loss=8.292093\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] Epoch[158] Batch[15] avg_epoch_loss=8.301342\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=158, batch=15 train loss <loss>=8.47453365326\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] Epoch[158] Batch [15]#011Speed: 2071.98 samples/sec#011loss=8.474534\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] Epoch[158] Batch[20] avg_epoch_loss=8.276487\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=158, batch=20 train loss <loss>=8.19695110321\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] Epoch[158] Batch [20]#011Speed: 952.44 samples/sec#011loss=8.196951\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] Epoch[158] Batch[25] avg_epoch_loss=8.205160\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=158, batch=25 train loss <loss>=7.90558710098\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] Epoch[158] Batch [25]#011Speed: 2070.45 samples/sec#011loss=7.905587\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] Epoch[158] Batch[30] avg_epoch_loss=8.129810\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=158, batch=30 train loss <loss>=7.73799209595\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] Epoch[158] Batch [30]#011Speed: 941.79 samples/sec#011loss=7.737992\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] Epoch[158] Batch[35] avg_epoch_loss=8.058023\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=158, batch=35 train loss <loss>=7.61294260025\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] Epoch[158] Batch [35]#011Speed: 2051.34 samples/sec#011loss=7.612943\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] Epoch[158] Batch[40] avg_epoch_loss=8.043415\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=158, batch=40 train loss <loss>=7.938240242\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] Epoch[158] Batch [40]#011Speed: 995.44 samples/sec#011loss=7.938240\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] Epoch[158] Batch[45] avg_epoch_loss=8.020509\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=158, batch=45 train loss <loss>=7.83267879486\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] Epoch[158] Batch [45]#011Speed: 1687.84 samples/sec#011loss=7.832679\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] processed a total of 1595 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1241.4278984069824, \"sum\": 1241.4278984069824, \"min\": 1241.4278984069824}}, \"EndTime\": 1578471735.860166, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471734.618293}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1284.69584775 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=158, train loss <loss>=7.99588337898\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] Epoch[159] Batch[0] avg_epoch_loss=7.756131\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=7.75613117218\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] Epoch[159] Batch[5] avg_epoch_loss=8.269412\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=8.26941188176\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] Epoch[159] Batch [5]#011Speed: 1659.96 samples/sec#011loss=8.269412\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] Epoch[159] Batch[10] avg_epoch_loss=8.159425\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=159, batch=10 train loss <loss>=8.02744169235\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] Epoch[159] Batch [10]#011Speed: 932.97 samples/sec#011loss=8.027442\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] Epoch[159] Batch[15] avg_epoch_loss=8.375815\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=159, batch=15 train loss <loss>=8.85187129974\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] Epoch[159] Batch [15]#011Speed: 2046.88 samples/sec#011loss=8.851871\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] Epoch[159] Batch[20] avg_epoch_loss=8.424871\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=159, batch=20 train loss <loss>=8.58185043335\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] Epoch[159] Batch [20]#011Speed: 1843.87 samples/sec#011loss=8.581850\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] Epoch[159] Batch[25] avg_epoch_loss=8.309598\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=159, batch=25 train loss <loss>=7.82545137405\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] Epoch[159] Batch [25]#011Speed: 933.21 samples/sec#011loss=7.825451\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] Epoch[159] Batch[30] avg_epoch_loss=8.242642\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=159, batch=30 train loss <loss>=7.8944691658\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] Epoch[159] Batch [30]#011Speed: 1668.42 samples/sec#011loss=7.894469\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] Epoch[159] Batch[35] avg_epoch_loss=8.163286\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=159, batch=35 train loss <loss>=7.67127790451\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] Epoch[159] Batch [35]#011Speed: 977.43 samples/sec#011loss=7.671278\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] Epoch[159] Batch[40] avg_epoch_loss=8.144921\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=159, batch=40 train loss <loss>=8.01269445419\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:16 INFO 139919921551168] Epoch[159] Batch [40]#011Speed: 960.86 samples/sec#011loss=8.012694\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] Epoch[159] Batch[45] avg_epoch_loss=8.144591\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=159, batch=45 train loss <loss>=8.14188423157\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] Epoch[159] Batch [45]#011Speed: 1714.02 samples/sec#011loss=8.141884\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] Epoch[159] Batch[50] avg_epoch_loss=8.099456\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=159, batch=50 train loss <loss>=7.68421373367\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] Epoch[159] Batch [50]#011Speed: 1647.94 samples/sec#011loss=7.684214\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] processed a total of 1656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1336.0090255737305, \"sum\": 1336.0090255737305, \"min\": 1336.0090255737305}}, \"EndTime\": 1578471737.196678, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471735.860237}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1239.40420669 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=159, train loss <loss>=8.09990710479\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] Epoch[160] Batch[0] avg_epoch_loss=8.867182\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=8.86718177795\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] Epoch[160] Batch[5] avg_epoch_loss=8.409185\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=8.40918540955\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] Epoch[160] Batch [5]#011Speed: 2073.96 samples/sec#011loss=8.409185\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] Epoch[160] Batch[10] avg_epoch_loss=8.463475\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=160, batch=10 train loss <loss>=8.52862186432\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] Epoch[160] Batch [10]#011Speed: 942.48 samples/sec#011loss=8.528622\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] Epoch[160] Batch[15] avg_epoch_loss=8.427897\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=160, batch=15 train loss <loss>=8.34962720871\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] Epoch[160] Batch [15]#011Speed: 1924.05 samples/sec#011loss=8.349627\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] Epoch[160] Batch[20] avg_epoch_loss=8.399408\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=160, batch=20 train loss <loss>=8.30824079514\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] Epoch[160] Batch [20]#011Speed: 967.21 samples/sec#011loss=8.308241\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] Epoch[160] Batch[25] avg_epoch_loss=8.306307\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=160, batch=25 train loss <loss>=7.91528158188\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:17 INFO 139919921551168] Epoch[160] Batch [25]#011Speed: 2051.75 samples/sec#011loss=7.915282\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] Epoch[160] Batch[30] avg_epoch_loss=8.230394\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=160, batch=30 train loss <loss>=7.83565149307\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] Epoch[160] Batch [30]#011Speed: 951.64 samples/sec#011loss=7.835651\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] Epoch[160] Batch[35] avg_epoch_loss=8.166591\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=160, batch=35 train loss <loss>=7.77101230621\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] Epoch[160] Batch [35]#011Speed: 2118.22 samples/sec#011loss=7.771012\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] Epoch[160] Batch[40] avg_epoch_loss=8.128719\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=160, batch=40 train loss <loss>=7.85604162216\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] Epoch[160] Batch [40]#011Speed: 1005.45 samples/sec#011loss=7.856042\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] Epoch[160] Batch[45] avg_epoch_loss=8.111716\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=160, batch=45 train loss <loss>=7.97228775024\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] Epoch[160] Batch [45]#011Speed: 1940.73 samples/sec#011loss=7.972288\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] processed a total of 1572 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1238.8019561767578, \"sum\": 1238.8019561767578, \"min\": 1238.8019561767578}}, \"EndTime\": 1578471738.436055, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471737.196753}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1268.85099447 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=160, train loss <loss>=8.11426804543\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] Epoch[161] Batch[0] avg_epoch_loss=8.383474\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=8.38347434998\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] Epoch[161] Batch[5] avg_epoch_loss=8.246568\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=8.24656764666\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] Epoch[161] Batch [5]#011Speed: 1914.49 samples/sec#011loss=8.246568\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] Epoch[161] Batch[10] avg_epoch_loss=8.173506\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=161, batch=10 train loss <loss>=8.08583116531\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] Epoch[161] Batch [10]#011Speed: 943.07 samples/sec#011loss=8.085831\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] Epoch[161] Batch[15] avg_epoch_loss=8.239166\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=161, batch=15 train loss <loss>=8.38361959457\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:18 INFO 139919921551168] Epoch[161] Batch [15]#011Speed: 1899.07 samples/sec#011loss=8.383620\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] Epoch[161] Batch[20] avg_epoch_loss=8.205973\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=161, batch=20 train loss <loss>=8.09975423813\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] Epoch[161] Batch [20]#011Speed: 999.41 samples/sec#011loss=8.099754\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] Epoch[161] Batch[25] avg_epoch_loss=8.121868\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=161, batch=25 train loss <loss>=7.76862840652\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] Epoch[161] Batch [25]#011Speed: 2003.05 samples/sec#011loss=7.768628\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] Epoch[161] Batch[30] avg_epoch_loss=8.091671\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=161, batch=30 train loss <loss>=7.93464345932\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] Epoch[161] Batch [30]#011Speed: 985.84 samples/sec#011loss=7.934643\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] Epoch[161] Batch[35] avg_epoch_loss=8.065732\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=161, batch=35 train loss <loss>=7.90490989685\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] Epoch[161] Batch [35]#011Speed: 1987.06 samples/sec#011loss=7.904910\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] Epoch[161] Batch[40] avg_epoch_loss=8.036257\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=161, batch=40 train loss <loss>=7.8240404129\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] Epoch[161] Batch [40]#011Speed: 887.69 samples/sec#011loss=7.824040\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] Epoch[161] Batch[45] avg_epoch_loss=7.971907\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=161, batch=45 train loss <loss>=7.44424037933\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] Epoch[161] Batch [45]#011Speed: 2114.16 samples/sec#011loss=7.444240\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] Epoch[161] Batch[50] avg_epoch_loss=7.923383\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=161, batch=50 train loss <loss>=7.47695941925\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] Epoch[161] Batch [50]#011Speed: 1510.05 samples/sec#011loss=7.476959\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] processed a total of 1623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1284.2628955841064, \"sum\": 1284.2628955841064, \"min\": 1284.2628955841064}}, \"EndTime\": 1578471739.720834, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471738.436133}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1263.65249681 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=161, train loss <loss>=7.92338315178\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] Epoch[162] Batch[0] avg_epoch_loss=8.063963\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=8.0639629364\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] Epoch[162] Batch[5] avg_epoch_loss=8.269427\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=8.2694272995\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:19 INFO 139919921551168] Epoch[162] Batch [5]#011Speed: 2032.47 samples/sec#011loss=8.269427\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] Epoch[162] Batch[10] avg_epoch_loss=8.353565\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=162, batch=10 train loss <loss>=8.45452919006\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] Epoch[162] Batch [10]#011Speed: 1102.38 samples/sec#011loss=8.454529\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] Epoch[162] Batch[15] avg_epoch_loss=8.373253\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=162, batch=15 train loss <loss>=8.41656780243\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] Epoch[162] Batch [15]#011Speed: 1882.13 samples/sec#011loss=8.416568\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] Epoch[162] Batch[20] avg_epoch_loss=8.311301\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=162, batch=20 train loss <loss>=8.11305408478\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] Epoch[162] Batch [20]#011Speed: 1033.52 samples/sec#011loss=8.113054\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] Epoch[162] Batch[25] avg_epoch_loss=8.206605\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=162, batch=25 train loss <loss>=7.76688432693\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] Epoch[162] Batch [25]#011Speed: 1927.10 samples/sec#011loss=7.766884\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] Epoch[162] Batch[30] avg_epoch_loss=8.197432\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=162, batch=30 train loss <loss>=8.14973144531\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] Epoch[162] Batch [30]#011Speed: 960.11 samples/sec#011loss=8.149731\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] Epoch[162] Batch[35] avg_epoch_loss=8.154365\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=162, batch=35 train loss <loss>=7.88734521866\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] Epoch[162] Batch [35]#011Speed: 2120.05 samples/sec#011loss=7.887345\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] Epoch[162] Batch[40] avg_epoch_loss=8.152858\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=162, batch=40 train loss <loss>=8.14200735092\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] Epoch[162] Batch [40]#011Speed: 1009.20 samples/sec#011loss=8.142007\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] Epoch[162] Batch[45] avg_epoch_loss=8.097567\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=162, batch=45 train loss <loss>=7.64418125153\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] Epoch[162] Batch [45]#011Speed: 1891.74 samples/sec#011loss=7.644181\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] processed a total of 1570 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1239.076852798462, \"sum\": 1239.076852798462, \"min\": 1239.076852798462}}, \"EndTime\": 1578471740.9604, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471739.72091}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1266.96896905 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=162, train loss <loss>=8.02596830368\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:20 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:21 INFO 139919921551168] Epoch[163] Batch[0] avg_epoch_loss=7.493097\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=7.4930973053\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:21 INFO 139919921551168] Epoch[163] Batch[5] avg_epoch_loss=8.040276\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=8.04027557373\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:21 INFO 139919921551168] Epoch[163] Batch [5]#011Speed: 2042.64 samples/sec#011loss=8.040276\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:21 INFO 139919921551168] Epoch[163] Batch[10] avg_epoch_loss=8.192763\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=163, batch=10 train loss <loss>=8.37574710846\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:21 INFO 139919921551168] Epoch[163] Batch [10]#011Speed: 952.18 samples/sec#011loss=8.375747\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:21 INFO 139919921551168] Epoch[163] Batch[15] avg_epoch_loss=8.363895\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=163, batch=15 train loss <loss>=8.74038639069\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:21 INFO 139919921551168] Epoch[163] Batch [15]#011Speed: 2039.28 samples/sec#011loss=8.740386\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:21 INFO 139919921551168] Epoch[163] Batch[20] avg_epoch_loss=8.352956\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=163, batch=20 train loss <loss>=8.3179517746\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:21 INFO 139919921551168] Epoch[163] Batch [20]#011Speed: 1007.06 samples/sec#011loss=8.317952\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:21 INFO 139919921551168] Epoch[163] Batch[25] avg_epoch_loss=8.231958\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=163, batch=25 train loss <loss>=7.72376756668\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:21 INFO 139919921551168] Epoch[163] Batch [25]#011Speed: 1859.84 samples/sec#011loss=7.723768\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:21 INFO 139919921551168] Epoch[163] Batch[30] avg_epoch_loss=8.157409\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=163, batch=30 train loss <loss>=7.76974964142\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:21 INFO 139919921551168] Epoch[163] Batch [30]#011Speed: 1006.59 samples/sec#011loss=7.769750\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:21 INFO 139919921551168] Epoch[163] Batch[35] avg_epoch_loss=8.124288\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=163, batch=35 train loss <loss>=7.9189414978\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:21 INFO 139919921551168] Epoch[163] Batch [35]#011Speed: 1850.27 samples/sec#011loss=7.918941\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] Epoch[163] Batch[40] avg_epoch_loss=8.095028\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=163, batch=40 train loss <loss>=7.8843536377\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] Epoch[163] Batch [40]#011Speed: 972.89 samples/sec#011loss=7.884354\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] Epoch[163] Batch[45] avg_epoch_loss=8.077160\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=163, batch=45 train loss <loss>=7.93064050674\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] Epoch[163] Batch [45]#011Speed: 1956.64 samples/sec#011loss=7.930641\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] Epoch[163] Batch[50] avg_epoch_loss=8.022979\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=163, batch=50 train loss <loss>=7.52451648712\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] Epoch[163] Batch [50]#011Speed: 1682.96 samples/sec#011loss=7.524516\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] processed a total of 1646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1270.2441215515137, \"sum\": 1270.2441215515137, \"min\": 1270.2441215515137}}, \"EndTime\": 1578471742.231226, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471740.960468}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1295.69158153 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=163, train loss <loss>=8.01074235256\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] Epoch[164] Batch[0] avg_epoch_loss=8.113037\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=8.11303710938\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] Epoch[164] Batch[5] avg_epoch_loss=8.380366\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=8.38036616643\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] Epoch[164] Batch [5]#011Speed: 2123.90 samples/sec#011loss=8.380366\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] Epoch[164] Batch[10] avg_epoch_loss=8.459158\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=8.55370874405\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] Epoch[164] Batch [10]#011Speed: 1035.50 samples/sec#011loss=8.553709\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] Epoch[164] Batch[15] avg_epoch_loss=8.422707\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=164, batch=15 train loss <loss>=8.34251537323\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] Epoch[164] Batch [15]#011Speed: 1662.75 samples/sec#011loss=8.342515\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] Epoch[164] Batch[20] avg_epoch_loss=8.351883\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=164, batch=20 train loss <loss>=8.1252448082\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] Epoch[164] Batch [20]#011Speed: 937.78 samples/sec#011loss=8.125245\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] Epoch[164] Batch[25] avg_epoch_loss=8.250584\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=164, batch=25 train loss <loss>=7.82512693405\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:22 INFO 139919921551168] Epoch[164] Batch [25]#011Speed: 1621.91 samples/sec#011loss=7.825127\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] Epoch[164] Batch[30] avg_epoch_loss=8.206825\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=164, batch=30 train loss <loss>=7.97927732468\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] Epoch[164] Batch [30]#011Speed: 805.58 samples/sec#011loss=7.979277\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] Epoch[164] Batch[35] avg_epoch_loss=8.136546\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=164, batch=35 train loss <loss>=7.70082159042\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] Epoch[164] Batch [35]#011Speed: 2124.18 samples/sec#011loss=7.700822\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] Epoch[164] Batch[40] avg_epoch_loss=8.111082\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=164, batch=40 train loss <loss>=7.92774038315\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] Epoch[164] Batch [40]#011Speed: 878.95 samples/sec#011loss=7.927740\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] Epoch[164] Batch[45] avg_epoch_loss=8.084098\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=164, batch=45 train loss <loss>=7.86282310486\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] Epoch[164] Batch [45]#011Speed: 2011.64 samples/sec#011loss=7.862823\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] Epoch[164] Batch[50] avg_epoch_loss=8.002488\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=164, batch=50 train loss <loss>=7.25168409348\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] Epoch[164] Batch [50]#011Speed: 1603.64 samples/sec#011loss=7.251684\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] processed a total of 1606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1355.3760051727295, \"sum\": 1355.3760051727295, \"min\": 1355.3760051727295}}, \"EndTime\": 1578471743.587125, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471742.231301}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1184.81830066 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=164, train loss <loss>=8.00248840743\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] Epoch[165] Batch[0] avg_epoch_loss=8.338051\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=8.33805084229\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] Epoch[165] Batch[5] avg_epoch_loss=8.217915\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=8.21791497866\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] Epoch[165] Batch [5]#011Speed: 1946.87 samples/sec#011loss=8.217915\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] Epoch[165] Batch[10] avg_epoch_loss=8.233077\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=165, batch=10 train loss <loss>=8.25127058029\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:23 INFO 139919921551168] Epoch[165] Batch [10]#011Speed: 922.89 samples/sec#011loss=8.251271\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] Epoch[165] Batch[15] avg_epoch_loss=8.284765\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=165, batch=15 train loss <loss>=8.39847927094\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] Epoch[165] Batch [15]#011Speed: 2117.94 samples/sec#011loss=8.398479\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] Epoch[165] Batch[20] avg_epoch_loss=8.220852\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=165, batch=20 train loss <loss>=8.01633205414\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] Epoch[165] Batch [20]#011Speed: 1006.73 samples/sec#011loss=8.016332\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] Epoch[165] Batch[25] avg_epoch_loss=8.180627\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=165, batch=25 train loss <loss>=8.01168088913\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] Epoch[165] Batch [25]#011Speed: 1979.12 samples/sec#011loss=8.011681\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] Epoch[165] Batch[30] avg_epoch_loss=8.150557\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=165, batch=30 train loss <loss>=7.99419555664\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] Epoch[165] Batch [30]#011Speed: 933.35 samples/sec#011loss=7.994196\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] Epoch[165] Batch[35] avg_epoch_loss=8.076320\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=165, batch=35 train loss <loss>=7.61604995728\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] Epoch[165] Batch [35]#011Speed: 2063.11 samples/sec#011loss=7.616050\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] Epoch[165] Batch[40] avg_epoch_loss=8.063597\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=165, batch=40 train loss <loss>=7.97198534012\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] Epoch[165] Batch [40]#011Speed: 966.17 samples/sec#011loss=7.971985\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] Epoch[165] Batch[45] avg_epoch_loss=8.063622\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=165, batch=45 train loss <loss>=8.06382913589\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] Epoch[165] Batch [45]#011Speed: 1955.53 samples/sec#011loss=8.063829\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] Epoch[165] Batch[50] avg_epoch_loss=7.942518\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=165, batch=50 train loss <loss>=6.82835969925\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] Epoch[165] Batch [50]#011Speed: 1363.47 samples/sec#011loss=6.828360\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] processed a total of 1602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1287.2600555419922, \"sum\": 1287.2600555419922, \"min\": 1287.2600555419922}}, \"EndTime\": 1578471744.874852, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471743.587198}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1244.39452896 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=165, train loss <loss>=7.94251769197\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] Epoch[166] Batch[0] avg_epoch_loss=8.332096\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=8.33209609985\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] Epoch[166] Batch[5] avg_epoch_loss=8.489478\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=8.48947763443\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] Epoch[166] Batch [5]#011Speed: 2122.52 samples/sec#011loss=8.489478\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] Epoch[166] Batch[10] avg_epoch_loss=8.313709\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=166, batch=10 train loss <loss>=8.10278739929\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] Epoch[166] Batch [10]#011Speed: 1026.88 samples/sec#011loss=8.102787\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] Epoch[166] Batch[15] avg_epoch_loss=8.295104\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=166, batch=15 train loss <loss>=8.25417203903\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] Epoch[166] Batch [15]#011Speed: 1801.68 samples/sec#011loss=8.254172\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] Epoch[166] Batch[20] avg_epoch_loss=8.330424\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=166, batch=20 train loss <loss>=8.44344902039\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] Epoch[166] Batch [20]#011Speed: 883.96 samples/sec#011loss=8.443449\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] Epoch[166] Batch[25] avg_epoch_loss=8.227046\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=166, batch=25 train loss <loss>=7.79285945892\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] Epoch[166] Batch [25]#011Speed: 1994.41 samples/sec#011loss=7.792859\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] Epoch[166] Batch[30] avg_epoch_loss=8.134082\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=166, batch=30 train loss <loss>=7.6506685257\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] Epoch[166] Batch [30]#011Speed: 1037.29 samples/sec#011loss=7.650669\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] Epoch[166] Batch[35] avg_epoch_loss=8.075755\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=166, batch=35 train loss <loss>=7.71412563324\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] Epoch[166] Batch [35]#011Speed: 2042.96 samples/sec#011loss=7.714126\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] Epoch[166] Batch[40] avg_epoch_loss=8.028141\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=166, batch=40 train loss <loss>=7.68531751633\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:25 INFO 139919921551168] Epoch[166] Batch [40]#011Speed: 981.48 samples/sec#011loss=7.685318\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] Epoch[166] Batch[45] avg_epoch_loss=8.030337\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=166, batch=45 train loss <loss>=8.0483496666\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] Epoch[166] Batch [45]#011Speed: 2142.34 samples/sec#011loss=8.048350\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] Epoch[166] Batch[50] avg_epoch_loss=7.980988\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=166, batch=50 train loss <loss>=7.52697658539\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] Epoch[166] Batch [50]#011Speed: 1548.38 samples/sec#011loss=7.526977\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] processed a total of 1610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1254.1489601135254, \"sum\": 1254.1489601135254, \"min\": 1254.1489601135254}}, \"EndTime\": 1578471746.12953, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471744.874927}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1283.62851199 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=166, train loss <loss>=7.98098813786\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] Epoch[167] Batch[0] avg_epoch_loss=8.624711\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=8.62471103668\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] Epoch[167] Batch[5] avg_epoch_loss=8.367096\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=8.36709626516\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] Epoch[167] Batch [5]#011Speed: 1643.42 samples/sec#011loss=8.367096\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] Epoch[167] Batch[10] avg_epoch_loss=8.235984\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=167, batch=10 train loss <loss>=8.07864904404\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] Epoch[167] Batch [10]#011Speed: 901.95 samples/sec#011loss=8.078649\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] Epoch[167] Batch[15] avg_epoch_loss=8.274592\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=167, batch=15 train loss <loss>=8.35952892303\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] Epoch[167] Batch [15]#011Speed: 1942.88 samples/sec#011loss=8.359529\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] Epoch[167] Batch[20] avg_epoch_loss=8.257224\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=167, batch=20 train loss <loss>=8.2016453743\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] Epoch[167] Batch [20]#011Speed: 951.13 samples/sec#011loss=8.201645\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] Epoch[167] Batch[25] avg_epoch_loss=8.178637\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=167, batch=25 train loss <loss>=7.84857177734\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] Epoch[167] Batch [25]#011Speed: 2054.31 samples/sec#011loss=7.848572\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] Epoch[167] Batch[30] avg_epoch_loss=8.113103\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=167, batch=30 train loss <loss>=7.77232685089\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:26 INFO 139919921551168] Epoch[167] Batch [30]#011Speed: 995.59 samples/sec#011loss=7.772327\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] Epoch[167] Batch[35] avg_epoch_loss=8.044162\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=167, batch=35 train loss <loss>=7.61673059464\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] Epoch[167] Batch [35]#011Speed: 1717.44 samples/sec#011loss=7.616731\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] Epoch[167] Batch[40] avg_epoch_loss=8.022111\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=167, batch=40 train loss <loss>=7.86334381104\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] Epoch[167] Batch [40]#011Speed: 929.27 samples/sec#011loss=7.863344\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] Epoch[167] Batch[45] avg_epoch_loss=8.020302\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=167, batch=45 train loss <loss>=8.00546274185\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] Epoch[167] Batch [45]#011Speed: 2058.83 samples/sec#011loss=8.005463\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] processed a total of 1595 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1289.665937423706, \"sum\": 1289.665937423706, \"min\": 1289.665937423706}}, \"EndTime\": 1578471747.419717, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471746.129601}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1236.64396068 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=167, train loss <loss>=7.94841314316\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] Epoch[168] Batch[0] avg_epoch_loss=8.458207\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=8.45820713043\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] Epoch[168] Batch[5] avg_epoch_loss=8.283341\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=8.28334124883\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] Epoch[168] Batch [5]#011Speed: 1796.58 samples/sec#011loss=8.283341\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] Epoch[168] Batch[10] avg_epoch_loss=8.324334\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=168, batch=10 train loss <loss>=8.37352466583\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] Epoch[168] Batch [10]#011Speed: 908.01 samples/sec#011loss=8.373525\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] Epoch[168] Batch[15] avg_epoch_loss=8.453913\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=168, batch=15 train loss <loss>=8.73898601532\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:27 INFO 139919921551168] Epoch[168] Batch [15]#011Speed: 2112.15 samples/sec#011loss=8.738986\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] Epoch[168] Batch[20] avg_epoch_loss=8.437308\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=168, batch=20 train loss <loss>=8.38417472839\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] Epoch[168] Batch [20]#011Speed: 851.22 samples/sec#011loss=8.384175\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] Epoch[168] Batch[25] avg_epoch_loss=8.288056\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=168, batch=25 train loss <loss>=7.66119737625\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] Epoch[168] Batch [25]#011Speed: 1973.92 samples/sec#011loss=7.661197\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] Epoch[168] Batch[30] avg_epoch_loss=8.224418\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=168, batch=30 train loss <loss>=7.89349880219\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] Epoch[168] Batch [30]#011Speed: 913.21 samples/sec#011loss=7.893499\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] Epoch[168] Batch[35] avg_epoch_loss=8.180200\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=168, batch=35 train loss <loss>=7.90605173111\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] Epoch[168] Batch [35]#011Speed: 1709.69 samples/sec#011loss=7.906052\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] Epoch[168] Batch[40] avg_epoch_loss=8.138978\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=168, batch=40 train loss <loss>=7.84217386246\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] Epoch[168] Batch [40]#011Speed: 866.49 samples/sec#011loss=7.842174\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] Epoch[168] Batch[45] avg_epoch_loss=8.156743\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=168, batch=45 train loss <loss>=8.30241756439\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] Epoch[168] Batch [45]#011Speed: 1919.99 samples/sec#011loss=8.302418\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] processed a total of 1578 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1345.8478450775146, \"sum\": 1345.8478450775146, \"min\": 1345.8478450775146}}, \"EndTime\": 1578471748.766098, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471747.419795}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1172.39914358 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=168, train loss <loss>=8.08978078842\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] Epoch[169] Batch[0] avg_epoch_loss=8.631287\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=8.63128662109\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] Epoch[169] Batch[5] avg_epoch_loss=8.260663\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=8.26066279411\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:28 INFO 139919921551168] Epoch[169] Batch [5]#011Speed: 1916.95 samples/sec#011loss=8.260663\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] Epoch[169] Batch[10] avg_epoch_loss=8.283771\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=8.31150188446\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] Epoch[169] Batch [10]#011Speed: 980.52 samples/sec#011loss=8.311502\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] Epoch[169] Batch[15] avg_epoch_loss=8.286704\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=169, batch=15 train loss <loss>=8.29315576553\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] Epoch[169] Batch [15]#011Speed: 2029.25 samples/sec#011loss=8.293156\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] Epoch[169] Batch[20] avg_epoch_loss=8.284747\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=169, batch=20 train loss <loss>=8.2784825325\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] Epoch[169] Batch [20]#011Speed: 904.82 samples/sec#011loss=8.278483\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] Epoch[169] Batch[25] avg_epoch_loss=8.228815\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=169, batch=25 train loss <loss>=7.99390153885\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] Epoch[169] Batch [25]#011Speed: 1755.49 samples/sec#011loss=7.993902\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] Epoch[169] Batch[30] avg_epoch_loss=8.145328\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=169, batch=30 train loss <loss>=7.7111992836\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] Epoch[169] Batch [30]#011Speed: 880.31 samples/sec#011loss=7.711199\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] Epoch[169] Batch[35] avg_epoch_loss=8.106660\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=169, batch=35 train loss <loss>=7.86691389084\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] Epoch[169] Batch [35]#011Speed: 1621.63 samples/sec#011loss=7.866914\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] Epoch[169] Batch[40] avg_epoch_loss=8.042551\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=169, batch=40 train loss <loss>=7.58097076416\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] Epoch[169] Batch [40]#011Speed: 1018.22 samples/sec#011loss=7.580971\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] Epoch[169] Batch[45] avg_epoch_loss=8.024394\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=169, batch=45 train loss <loss>=7.8755065918\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:29 INFO 139919921551168] Epoch[169] Batch [45]#011Speed: 2054.89 samples/sec#011loss=7.875507\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] Epoch[169] Batch[50] avg_epoch_loss=7.992364\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=169, batch=50 train loss <loss>=7.69768571854\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] Epoch[169] Batch [50]#011Speed: 1656.81 samples/sec#011loss=7.697686\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] processed a total of 1675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1353.7299633026123, \"sum\": 1353.7299633026123, \"min\": 1353.7299633026123}}, \"EndTime\": 1578471750.120332, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471748.766174}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1237.24343626 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=169, train loss <loss>=7.93297723554\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] Epoch[170] Batch[0] avg_epoch_loss=8.035958\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=8.0359582901\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] Epoch[170] Batch[5] avg_epoch_loss=8.283461\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=8.28346125285\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] Epoch[170] Batch [5]#011Speed: 2016.33 samples/sec#011loss=8.283461\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] Epoch[170] Batch[10] avg_epoch_loss=8.258815\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=170, batch=10 train loss <loss>=8.22923908234\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] Epoch[170] Batch [10]#011Speed: 794.85 samples/sec#011loss=8.229239\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] Epoch[170] Batch[15] avg_epoch_loss=8.202965\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=170, batch=15 train loss <loss>=8.08009643555\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] Epoch[170] Batch [15]#011Speed: 1791.27 samples/sec#011loss=8.080096\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] Epoch[170] Batch[20] avg_epoch_loss=8.165482\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=170, batch=20 train loss <loss>=8.04553365707\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] Epoch[170] Batch [20]#011Speed: 984.29 samples/sec#011loss=8.045534\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] Epoch[170] Batch[25] avg_epoch_loss=8.081625\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=170, batch=25 train loss <loss>=7.72942762375\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] Epoch[170] Batch [25]#011Speed: 1884.86 samples/sec#011loss=7.729428\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] Epoch[170] Batch[30] avg_epoch_loss=8.042919\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=170, batch=30 train loss <loss>=7.84164743423\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:30 INFO 139919921551168] Epoch[170] Batch [30]#011Speed: 1031.06 samples/sec#011loss=7.841647\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] Epoch[170] Batch[35] avg_epoch_loss=8.036621\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=170, batch=35 train loss <loss>=7.99757575989\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] Epoch[170] Batch [35]#011Speed: 1929.57 samples/sec#011loss=7.997576\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] Epoch[170] Batch[40] avg_epoch_loss=8.012191\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=170, batch=40 train loss <loss>=7.83628873825\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] Epoch[170] Batch [40]#011Speed: 964.58 samples/sec#011loss=7.836289\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] Epoch[170] Batch[45] avg_epoch_loss=8.023900\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=170, batch=45 train loss <loss>=8.11992034912\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] Epoch[170] Batch [45]#011Speed: 1742.22 samples/sec#011loss=8.119920\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] processed a total of 1585 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1282.6621532440186, \"sum\": 1282.6621532440186, \"min\": 1282.6621532440186}}, \"EndTime\": 1578471751.40354, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471750.12039}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1235.60050755 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=170, train loss <loss>=7.98635791779\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] Epoch[171] Batch[0] avg_epoch_loss=8.163839\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=8.16383934021\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] Epoch[171] Batch[5] avg_epoch_loss=8.189064\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=8.18906442324\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] Epoch[171] Batch [5]#011Speed: 1761.18 samples/sec#011loss=8.189064\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] Epoch[171] Batch[10] avg_epoch_loss=8.235579\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=171, batch=10 train loss <loss>=8.29139614105\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] Epoch[171] Batch [10]#011Speed: 817.86 samples/sec#011loss=8.291396\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] Epoch[171] Batch[15] avg_epoch_loss=8.358843\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=171, batch=15 train loss <loss>=8.63002471924\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:31 INFO 139919921551168] Epoch[171] Batch [15]#011Speed: 1961.79 samples/sec#011loss=8.630025\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] Epoch[171] Batch[20] avg_epoch_loss=8.351099\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=171, batch=20 train loss <loss>=8.3263174057\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] Epoch[171] Batch [20]#011Speed: 1013.09 samples/sec#011loss=8.326317\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] Epoch[171] Batch[25] avg_epoch_loss=8.255576\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=171, batch=25 train loss <loss>=7.85437850952\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] Epoch[171] Batch [25]#011Speed: 2140.44 samples/sec#011loss=7.854379\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] Epoch[171] Batch[30] avg_epoch_loss=8.186805\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=171, batch=30 train loss <loss>=7.82919473648\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] Epoch[171] Batch [30]#011Speed: 1023.92 samples/sec#011loss=7.829195\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] Epoch[171] Batch[35] avg_epoch_loss=8.127349\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=171, batch=35 train loss <loss>=7.75872573853\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] Epoch[171] Batch [35]#011Speed: 1792.80 samples/sec#011loss=7.758726\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] Epoch[171] Batch[40] avg_epoch_loss=8.094958\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=171, batch=40 train loss <loss>=7.86174440384\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] Epoch[171] Batch [40]#011Speed: 980.78 samples/sec#011loss=7.861744\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] Epoch[171] Batch[45] avg_epoch_loss=8.074466\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=171, batch=45 train loss <loss>=7.90642585754\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] Epoch[171] Batch [45]#011Speed: 1945.12 samples/sec#011loss=7.906426\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] processed a total of 1572 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1293.0262088775635, \"sum\": 1293.0262088775635, \"min\": 1293.0262088775635}}, \"EndTime\": 1578471752.697117, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471751.403619}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1215.64457863 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=171, train loss <loss>=7.95883306503\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] Epoch[172] Batch[0] avg_epoch_loss=8.213445\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=8.21344470978\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] Epoch[172] Batch[5] avg_epoch_loss=8.348021\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=8.34802126884\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:32 INFO 139919921551168] Epoch[172] Batch [5]#011Speed: 1964.52 samples/sec#011loss=8.348021\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] Epoch[172] Batch[10] avg_epoch_loss=8.286582\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=172, batch=10 train loss <loss>=8.21285572052\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] Epoch[172] Batch [10]#011Speed: 912.02 samples/sec#011loss=8.212856\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] Epoch[172] Batch[15] avg_epoch_loss=8.268715\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=172, batch=15 train loss <loss>=8.22940816879\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] Epoch[172] Batch [15]#011Speed: 1884.10 samples/sec#011loss=8.229408\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] Epoch[172] Batch[20] avg_epoch_loss=8.295371\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=172, batch=20 train loss <loss>=8.38066864014\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] Epoch[172] Batch [20]#011Speed: 928.61 samples/sec#011loss=8.380669\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] Epoch[172] Batch[25] avg_epoch_loss=8.196760\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=172, batch=25 train loss <loss>=7.78259544373\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] Epoch[172] Batch [25]#011Speed: 1845.97 samples/sec#011loss=7.782595\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] Epoch[172] Batch[30] avg_epoch_loss=8.126475\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=172, batch=30 train loss <loss>=7.76099090576\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] Epoch[172] Batch [30]#011Speed: 1016.06 samples/sec#011loss=7.760991\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] Epoch[172] Batch[35] avg_epoch_loss=8.060858\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=172, batch=35 train loss <loss>=7.6540350914\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] Epoch[172] Batch [35]#011Speed: 2038.76 samples/sec#011loss=7.654035\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] Epoch[172] Batch[40] avg_epoch_loss=8.060228\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=172, batch=40 train loss <loss>=8.0556895256\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] Epoch[172] Batch [40]#011Speed: 1069.09 samples/sec#011loss=8.055690\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] Epoch[172] Batch[45] avg_epoch_loss=8.017097\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=172, batch=45 train loss <loss>=7.6634188652\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] Epoch[172] Batch [45]#011Speed: 2063.40 samples/sec#011loss=7.663419\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] Epoch[172] Batch[50] avg_epoch_loss=7.996080\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=172, batch=50 train loss <loss>=7.80272750854\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] Epoch[172] Batch [50]#011Speed: 1657.31 samples/sec#011loss=7.802728\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] processed a total of 1657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1273.3001708984375, \"sum\": 1273.3001708984375, \"min\": 1273.3001708984375}}, \"EndTime\": 1578471753.97098, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471752.697193}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1301.22023826 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=172, train loss <loss>=7.97557811554\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:33 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:34 INFO 139919921551168] Epoch[173] Batch[0] avg_epoch_loss=7.982829\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=7.98282909393\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:34 INFO 139919921551168] Epoch[173] Batch[5] avg_epoch_loss=8.103005\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=8.10300469398\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:34 INFO 139919921551168] Epoch[173] Batch [5]#011Speed: 2014.38 samples/sec#011loss=8.103005\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:34 INFO 139919921551168] Epoch[173] Batch[10] avg_epoch_loss=8.113991\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=173, batch=10 train loss <loss>=8.12717447281\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:34 INFO 139919921551168] Epoch[173] Batch [10]#011Speed: 1034.66 samples/sec#011loss=8.127174\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:34 INFO 139919921551168] Epoch[173] Batch[15] avg_epoch_loss=8.173378\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=173, batch=15 train loss <loss>=8.30402832031\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:34 INFO 139919921551168] Epoch[173] Batch [15]#011Speed: 2045.85 samples/sec#011loss=8.304028\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:34 INFO 139919921551168] Epoch[173] Batch[20] avg_epoch_loss=8.180572\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=173, batch=20 train loss <loss>=8.20359477997\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:34 INFO 139919921551168] Epoch[173] Batch [20]#011Speed: 869.76 samples/sec#011loss=8.203595\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:34 INFO 139919921551168] Epoch[173] Batch[25] avg_epoch_loss=8.122648\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=173, batch=25 train loss <loss>=7.87936458588\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:34 INFO 139919921551168] Epoch[173] Batch [25]#011Speed: 1656.78 samples/sec#011loss=7.879365\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:34 INFO 139919921551168] Epoch[173] Batch[30] avg_epoch_loss=8.088500\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=173, batch=30 train loss <loss>=7.91093244553\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:34 INFO 139919921551168] Epoch[173] Batch [30]#011Speed: 976.46 samples/sec#011loss=7.910932\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:34 INFO 139919921551168] Epoch[173] Batch[35] avg_epoch_loss=8.039340\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=173, batch=35 train loss <loss>=7.73454580307\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:34 INFO 139919921551168] Epoch[173] Batch [35]#011Speed: 1936.39 samples/sec#011loss=7.734546\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] Epoch[173] Batch[40] avg_epoch_loss=8.007269\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=173, batch=40 train loss <loss>=7.7763625145\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] Epoch[173] Batch [40]#011Speed: 942.53 samples/sec#011loss=7.776363\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] Epoch[173] Batch[45] avg_epoch_loss=7.981336\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=173, batch=45 train loss <loss>=7.76868314743\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] Epoch[173] Batch [45]#011Speed: 2048.48 samples/sec#011loss=7.768683\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] Epoch[173] Batch[50] avg_epoch_loss=7.960421\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=173, batch=50 train loss <loss>=7.76800737381\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] Epoch[173] Batch [50]#011Speed: 1633.26 samples/sec#011loss=7.768007\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] processed a total of 1670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1318.0601596832275, \"sum\": 1318.0601596832275, \"min\": 1318.0601596832275}}, \"EndTime\": 1578471755.289618, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471753.971064}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1266.90394683 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=173, train loss <loss>=7.94988772554\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] Epoch[174] Batch[0] avg_epoch_loss=8.036327\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=8.03632736206\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] Epoch[174] Batch[5] avg_epoch_loss=7.964688\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=7.96468838056\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] Epoch[174] Batch [5]#011Speed: 1659.00 samples/sec#011loss=7.964688\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] Epoch[174] Batch[10] avg_epoch_loss=8.217041\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=174, batch=10 train loss <loss>=8.51986427307\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] Epoch[174] Batch [10]#011Speed: 891.18 samples/sec#011loss=8.519864\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] Epoch[174] Batch[15] avg_epoch_loss=8.329686\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=174, batch=15 train loss <loss>=8.57750511169\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] Epoch[174] Batch [15]#011Speed: 1643.15 samples/sec#011loss=8.577505\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] Epoch[174] Batch[20] avg_epoch_loss=8.275279\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=174, batch=20 train loss <loss>=8.10117692947\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:35 INFO 139919921551168] Epoch[174] Batch [20]#011Speed: 910.26 samples/sec#011loss=8.101177\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] Epoch[174] Batch[25] avg_epoch_loss=8.170437\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=174, batch=25 train loss <loss>=7.73010177612\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] Epoch[174] Batch [25]#011Speed: 2041.36 samples/sec#011loss=7.730102\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] Epoch[174] Batch[30] avg_epoch_loss=8.088522\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=174, batch=30 train loss <loss>=7.66256055832\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] Epoch[174] Batch [30]#011Speed: 967.61 samples/sec#011loss=7.662561\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] Epoch[174] Batch[35] avg_epoch_loss=8.065038\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=174, batch=35 train loss <loss>=7.91943616867\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] Epoch[174] Batch [35]#011Speed: 1801.68 samples/sec#011loss=7.919436\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] Epoch[174] Batch[40] avg_epoch_loss=8.052409\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=174, batch=40 train loss <loss>=7.96147909164\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] Epoch[174] Batch [40]#011Speed: 1037.12 samples/sec#011loss=7.961479\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] Epoch[174] Batch[45] avg_epoch_loss=8.039439\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=174, batch=45 train loss <loss>=7.93308572769\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] Epoch[174] Batch [45]#011Speed: 2009.37 samples/sec#011loss=7.933086\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] Epoch[174] Batch[50] avg_epoch_loss=8.003774\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=174, batch=50 train loss <loss>=7.67566013336\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] Epoch[174] Batch [50]#011Speed: 1642.47 samples/sec#011loss=7.675660\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] processed a total of 1633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1328.2248973846436, \"sum\": 1328.2248973846436, \"min\": 1328.2248973846436}}, \"EndTime\": 1578471756.618372, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471755.289693}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1229.3605005 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=174, train loss <loss>=8.07624615156\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] Epoch[175] Batch[0] avg_epoch_loss=7.871068\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=7.87106800079\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] Epoch[175] Batch[5] avg_epoch_loss=8.131231\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=8.13123051325\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] Epoch[175] Batch [5]#011Speed: 1663.22 samples/sec#011loss=8.131231\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] Epoch[175] Batch[10] avg_epoch_loss=8.185633\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=175, batch=10 train loss <loss>=8.25091514587\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:36 INFO 139919921551168] Epoch[175] Batch [10]#011Speed: 2008.29 samples/sec#011loss=8.250915\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] Epoch[175] Batch[15] avg_epoch_loss=8.196147\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=175, batch=15 train loss <loss>=8.21927928925\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] Epoch[175] Batch [15]#011Speed: 1083.58 samples/sec#011loss=8.219279\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] Epoch[175] Batch[20] avg_epoch_loss=8.196024\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=175, batch=20 train loss <loss>=8.19562950134\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] Epoch[175] Batch [20]#011Speed: 1072.50 samples/sec#011loss=8.195630\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] Epoch[175] Batch[25] avg_epoch_loss=8.106311\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=175, batch=25 train loss <loss>=7.7295173645\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] Epoch[175] Batch [25]#011Speed: 1996.93 samples/sec#011loss=7.729517\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] Epoch[175] Batch[30] avg_epoch_loss=8.055697\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=175, batch=30 train loss <loss>=7.79250459671\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] Epoch[175] Batch [30]#011Speed: 917.38 samples/sec#011loss=7.792505\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] Epoch[175] Batch[35] avg_epoch_loss=8.007883\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=175, batch=35 train loss <loss>=7.71143445969\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] Epoch[175] Batch [35]#011Speed: 1875.00 samples/sec#011loss=7.711434\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] Epoch[175] Batch[40] avg_epoch_loss=7.998021\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=175, batch=40 train loss <loss>=7.9270152092\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] Epoch[175] Batch [40]#011Speed: 826.98 samples/sec#011loss=7.927015\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] Epoch[175] Batch[45] avg_epoch_loss=8.026451\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=175, batch=45 train loss <loss>=8.25957374573\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] Epoch[175] Batch [45]#011Speed: 1891.43 samples/sec#011loss=8.259574\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] Epoch[175] Batch[50] avg_epoch_loss=7.945750\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=175, batch=50 train loss <loss>=7.20329990387\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] Epoch[175] Batch [50]#011Speed: 1738.77 samples/sec#011loss=7.203300\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] processed a total of 1609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1282.9639911651611, \"sum\": 1282.9639911651611, \"min\": 1282.9639911651611}}, \"EndTime\": 1578471757.90187, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471756.618442}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1254.01787495 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=175, train loss <loss>=7.94574959138\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] Epoch[176] Batch[0] avg_epoch_loss=7.940054\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=7.94005393982\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:38 INFO 139919921551168] Epoch[176] Batch[5] avg_epoch_loss=8.221607\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=8.22160689036\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:38 INFO 139919921551168] Epoch[176] Batch [5]#011Speed: 1654.31 samples/sec#011loss=8.221607\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:38 INFO 139919921551168] Epoch[176] Batch[10] avg_epoch_loss=8.276565\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=176, batch=10 train loss <loss>=8.34251403809\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:38 INFO 139919921551168] Epoch[176] Batch [10]#011Speed: 1008.47 samples/sec#011loss=8.342514\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:38 INFO 139919921551168] Epoch[176] Batch[15] avg_epoch_loss=8.359072\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=176, batch=15 train loss <loss>=8.54058952332\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:38 INFO 139919921551168] Epoch[176] Batch [15]#011Speed: 1885.79 samples/sec#011loss=8.540590\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:38 INFO 139919921551168] Epoch[176] Batch[20] avg_epoch_loss=8.423404\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=176, batch=20 train loss <loss>=8.62926597595\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:38 INFO 139919921551168] Epoch[176] Batch [20]#011Speed: 849.47 samples/sec#011loss=8.629266\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:38 INFO 139919921551168] Epoch[176] Batch[25] avg_epoch_loss=8.300022\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=176, batch=25 train loss <loss>=7.78181600571\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:38 INFO 139919921551168] Epoch[176] Batch [25]#011Speed: 1690.62 samples/sec#011loss=7.781816\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:38 INFO 139919921551168] Epoch[176] Batch[30] avg_epoch_loss=8.215960\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=176, batch=30 train loss <loss>=7.77883710861\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:38 INFO 139919921551168] Epoch[176] Batch [30]#011Speed: 876.04 samples/sec#011loss=7.778837\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:38 INFO 139919921551168] Epoch[176] Batch[35] avg_epoch_loss=8.137115\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=176, batch=35 train loss <loss>=7.64827690125\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:38 INFO 139919921551168] Epoch[176] Batch [35]#011Speed: 2043.42 samples/sec#011loss=7.648277\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] Epoch[176] Batch[40] avg_epoch_loss=8.098336\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=176, batch=40 train loss <loss>=7.81912574768\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] Epoch[176] Batch [40]#011Speed: 855.41 samples/sec#011loss=7.819126\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] Epoch[176] Batch[45] avg_epoch_loss=8.087332\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=176, batch=45 train loss <loss>=7.99710521698\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] Epoch[176] Batch [45]#011Speed: 1941.96 samples/sec#011loss=7.997105\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] Epoch[176] Batch[50] avg_epoch_loss=8.051269\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=176, batch=50 train loss <loss>=7.71948919296\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] Epoch[176] Batch [50]#011Speed: 1480.88 samples/sec#011loss=7.719489\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] processed a total of 1626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1358.4051132202148, \"sum\": 1358.4051132202148, \"min\": 1358.4051132202148}}, \"EndTime\": 1578471759.260829, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471757.901948}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1196.89259722 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=176, train loss <loss>=8.0512694097\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] Epoch[177] Batch[0] avg_epoch_loss=7.711280\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=7.71127986908\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] Epoch[177] Batch[5] avg_epoch_loss=7.951614\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=7.95161390305\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] Epoch[177] Batch [5]#011Speed: 1962.98 samples/sec#011loss=7.951614\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] Epoch[177] Batch[10] avg_epoch_loss=8.057002\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=177, batch=10 train loss <loss>=8.18346700668\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] Epoch[177] Batch [10]#011Speed: 925.99 samples/sec#011loss=8.183467\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] Epoch[177] Batch[15] avg_epoch_loss=8.223265\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=177, batch=15 train loss <loss>=8.58904380798\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] Epoch[177] Batch [15]#011Speed: 1768.50 samples/sec#011loss=8.589044\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] Epoch[177] Batch[20] avg_epoch_loss=8.270807\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=177, batch=20 train loss <loss>=8.42294225693\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] Epoch[177] Batch [20]#011Speed: 1078.33 samples/sec#011loss=8.422942\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] Epoch[177] Batch[25] avg_epoch_loss=8.166808\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=177, batch=25 train loss <loss>=7.73001317978\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:39 INFO 139919921551168] Epoch[177] Batch [25]#011Speed: 1913.12 samples/sec#011loss=7.730013\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] Epoch[177] Batch[30] avg_epoch_loss=8.097317\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=177, batch=30 train loss <loss>=7.73596391678\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] Epoch[177] Batch [30]#011Speed: 922.51 samples/sec#011loss=7.735964\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] Epoch[177] Batch[35] avg_epoch_loss=8.037307\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=177, batch=35 train loss <loss>=7.66524028778\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] Epoch[177] Batch [35]#011Speed: 2011.67 samples/sec#011loss=7.665240\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] Epoch[177] Batch[40] avg_epoch_loss=8.020725\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=177, batch=40 train loss <loss>=7.90134010315\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] Epoch[177] Batch [40]#011Speed: 935.47 samples/sec#011loss=7.901340\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] Epoch[177] Batch[45] avg_epoch_loss=8.014593\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=177, batch=45 train loss <loss>=7.96431159973\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] Epoch[177] Batch [45]#011Speed: 1902.86 samples/sec#011loss=7.964312\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] Epoch[177] Batch[50] avg_epoch_loss=7.976683\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=177, batch=50 train loss <loss>=7.62790584564\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] Epoch[177] Batch [50]#011Speed: 1523.85 samples/sec#011loss=7.627906\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] processed a total of 1618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1291.0680770874023, \"sum\": 1291.0680770874023, \"min\": 1291.0680770874023}}, \"EndTime\": 1578471760.552454, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471759.260905}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1253.10745536 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=177, train loss <loss>=7.97668281256\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] Epoch[178] Batch[0] avg_epoch_loss=8.121738\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=8.12173843384\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] Epoch[178] Batch[5] avg_epoch_loss=8.048066\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=8.04806629817\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] Epoch[178] Batch [5]#011Speed: 1642.27 samples/sec#011loss=8.048066\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] Epoch[178] Batch[10] avg_epoch_loss=8.118489\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] #quality_metric: host=algo-1, epoch=178, batch=10 train loss <loss>=8.20299596786\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:40 INFO 139919921551168] Epoch[178] Batch [10]#011Speed: 935.29 samples/sec#011loss=8.202996\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] Epoch[178] Batch[15] avg_epoch_loss=8.262374\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=178, batch=15 train loss <loss>=8.57892284393\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] Epoch[178] Batch [15]#011Speed: 1667.09 samples/sec#011loss=8.578923\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] Epoch[178] Batch[20] avg_epoch_loss=8.307697\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=178, batch=20 train loss <loss>=8.45272922516\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] Epoch[178] Batch [20]#011Speed: 931.31 samples/sec#011loss=8.452729\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] Epoch[178] Batch[25] avg_epoch_loss=8.212330\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=178, batch=25 train loss <loss>=7.81179056168\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] Epoch[178] Batch [25]#011Speed: 1526.56 samples/sec#011loss=7.811791\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] Epoch[178] Batch[30] avg_epoch_loss=8.144252\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=178, batch=30 train loss <loss>=7.7902422905\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] Epoch[178] Batch [30]#011Speed: 931.87 samples/sec#011loss=7.790242\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] Epoch[178] Batch[35] avg_epoch_loss=8.105428\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=178, batch=35 train loss <loss>=7.86472234726\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] Epoch[178] Batch [35]#011Speed: 1673.61 samples/sec#011loss=7.864722\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] Epoch[178] Batch[40] avg_epoch_loss=8.076247\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=178, batch=40 train loss <loss>=7.8661397934\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] Epoch[178] Batch [40]#011Speed: 926.09 samples/sec#011loss=7.866140\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] Epoch[178] Batch[45] avg_epoch_loss=8.063737\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=178, batch=45 train loss <loss>=7.96115894318\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] Epoch[178] Batch [45]#011Speed: 1593.72 samples/sec#011loss=7.961159\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] Epoch[178] Batch[50] avg_epoch_loss=8.004661\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=178, batch=50 train loss <loss>=7.46116046906\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] Epoch[178] Batch [50]#011Speed: 1511.32 samples/sec#011loss=7.461160\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] processed a total of 1622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1379.4610500335693, \"sum\": 1379.4610500335693, \"min\": 1379.4610500335693}}, \"EndTime\": 1578471761.932474, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471760.552538}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1175.72866284 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] #quality_metric: host=algo-1, epoch=178, train loss <loss>=8.00466098037\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:41 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:42 INFO 139919921551168] Epoch[179] Batch[0] avg_epoch_loss=8.049437\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=8.04943656921\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:42 INFO 139919921551168] Epoch[179] Batch[5] avg_epoch_loss=8.264874\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=8.26487350464\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:42 INFO 139919921551168] Epoch[179] Batch [5]#011Speed: 1984.74 samples/sec#011loss=8.264874\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:42 INFO 139919921551168] Epoch[179] Batch[10] avg_epoch_loss=8.388519\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=179, batch=10 train loss <loss>=8.53689317703\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:42 INFO 139919921551168] Epoch[179] Batch [10]#011Speed: 1023.08 samples/sec#011loss=8.536893\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:42 INFO 139919921551168] Epoch[179] Batch[15] avg_epoch_loss=8.299835\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=179, batch=15 train loss <loss>=8.10472917557\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:42 INFO 139919921551168] Epoch[179] Batch [15]#011Speed: 2109.54 samples/sec#011loss=8.104729\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:42 INFO 139919921551168] Epoch[179] Batch[20] avg_epoch_loss=8.261035\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=179, batch=20 train loss <loss>=8.13687763214\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:42 INFO 139919921551168] Epoch[179] Batch [20]#011Speed: 945.70 samples/sec#011loss=8.136878\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:42 INFO 139919921551168] Epoch[179] Batch[25] avg_epoch_loss=8.187597\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=179, batch=25 train loss <loss>=7.87915735245\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:42 INFO 139919921551168] Epoch[179] Batch [25]#011Speed: 1993.57 samples/sec#011loss=7.879157\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:42 INFO 139919921551168] Epoch[179] Batch[30] avg_epoch_loss=8.131764\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=179, batch=30 train loss <loss>=7.84142913818\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:42 INFO 139919921551168] Epoch[179] Batch [30]#011Speed: 952.55 samples/sec#011loss=7.841429\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:42 INFO 139919921551168] Epoch[179] Batch[35] avg_epoch_loss=8.047770\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:42 INFO 139919921551168] #quality_metric: host=algo-1, epoch=179, batch=35 train loss <loss>=7.52701025009\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:42 INFO 139919921551168] Epoch[179] Batch [35]#011Speed: 1833.31 samples/sec#011loss=7.527010\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] Epoch[179] Batch[40] avg_epoch_loss=8.052368\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=179, batch=40 train loss <loss>=8.08547544479\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] Epoch[179] Batch [40]#011Speed: 826.83 samples/sec#011loss=8.085475\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] Epoch[179] Batch[45] avg_epoch_loss=8.043723\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=179, batch=45 train loss <loss>=7.97283372879\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] Epoch[179] Batch [45]#011Speed: 1843.70 samples/sec#011loss=7.972834\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] processed a total of 1583 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1297.7619171142578, \"sum\": 1297.7619171142578, \"min\": 1297.7619171142578}}, \"EndTime\": 1578471763.230793, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471761.932546}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1219.69169476 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=179, train loss <loss>=7.97173167229\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] Epoch[180] Batch[0] avg_epoch_loss=8.303882\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=8.3038816452\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] Epoch[180] Batch[5] avg_epoch_loss=8.094481\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=8.09448107084\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] Epoch[180] Batch [5]#011Speed: 2048.24 samples/sec#011loss=8.094481\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] Epoch[180] Batch[10] avg_epoch_loss=8.201452\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=180, batch=10 train loss <loss>=8.32981739044\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] Epoch[180] Batch [10]#011Speed: 965.11 samples/sec#011loss=8.329817\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] Epoch[180] Batch[15] avg_epoch_loss=8.329697\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=180, batch=15 train loss <loss>=8.61183643341\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] Epoch[180] Batch [15]#011Speed: 1939.67 samples/sec#011loss=8.611836\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] Epoch[180] Batch[20] avg_epoch_loss=8.336554\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=180, batch=20 train loss <loss>=8.35849456787\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] Epoch[180] Batch [20]#011Speed: 870.92 samples/sec#011loss=8.358495\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] Epoch[180] Batch[25] avg_epoch_loss=8.232387\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] #quality_metric: host=algo-1, epoch=180, batch=25 train loss <loss>=7.79488716125\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:43 INFO 139919921551168] Epoch[180] Batch [25]#011Speed: 2153.90 samples/sec#011loss=7.794887\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] Epoch[180] Batch[30] avg_epoch_loss=8.176738\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=180, batch=30 train loss <loss>=7.88736534119\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] Epoch[180] Batch [30]#011Speed: 947.91 samples/sec#011loss=7.887365\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] Epoch[180] Batch[35] avg_epoch_loss=8.124610\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=180, batch=35 train loss <loss>=7.80141439438\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] Epoch[180] Batch [35]#011Speed: 1843.08 samples/sec#011loss=7.801414\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] Epoch[180] Batch[40] avg_epoch_loss=8.063160\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=180, batch=40 train loss <loss>=7.62071561813\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] Epoch[180] Batch [40]#011Speed: 917.80 samples/sec#011loss=7.620716\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] Epoch[180] Batch[45] avg_epoch_loss=8.017656\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=180, batch=45 train loss <loss>=7.64453077316\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] Epoch[180] Batch [45]#011Speed: 1775.78 samples/sec#011loss=7.644531\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] Epoch[180] Batch[50] avg_epoch_loss=8.012110\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=180, batch=50 train loss <loss>=7.96108093262\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] Epoch[180] Batch [50]#011Speed: 1239.25 samples/sec#011loss=7.961081\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] processed a total of 1651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1353.3999919891357, \"sum\": 1353.3999919891357, \"min\": 1353.3999919891357}}, \"EndTime\": 1578471764.584745, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471763.230864}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1219.78965873 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=180, train loss <loss>=8.03562107453\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] Epoch[181] Batch[0] avg_epoch_loss=7.927596\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=7.92759561539\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] Epoch[181] Batch[5] avg_epoch_loss=8.136918\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=8.13691782951\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] Epoch[181] Batch [5]#011Speed: 1810.07 samples/sec#011loss=8.136918\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] Epoch[181] Batch[10] avg_epoch_loss=8.199804\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] #quality_metric: host=algo-1, epoch=181, batch=10 train loss <loss>=8.2752664566\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:44 INFO 139919921551168] Epoch[181] Batch [10]#011Speed: 936.01 samples/sec#011loss=8.275266\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] Epoch[181] Batch[15] avg_epoch_loss=8.277152\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=181, batch=15 train loss <loss>=8.44731712341\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] Epoch[181] Batch [15]#011Speed: 1619.66 samples/sec#011loss=8.447317\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] Epoch[181] Batch[20] avg_epoch_loss=8.258738\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=181, batch=20 train loss <loss>=8.19981460571\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] Epoch[181] Batch [20]#011Speed: 1008.77 samples/sec#011loss=8.199815\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] Epoch[181] Batch[25] avg_epoch_loss=8.208584\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=181, batch=25 train loss <loss>=7.99793767929\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] Epoch[181] Batch [25]#011Speed: 2002.43 samples/sec#011loss=7.997938\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] Epoch[181] Batch[30] avg_epoch_loss=8.135730\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=181, batch=30 train loss <loss>=7.75688619614\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] Epoch[181] Batch [30]#011Speed: 1054.85 samples/sec#011loss=7.756886\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] Epoch[181] Batch[35] avg_epoch_loss=8.095363\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=181, batch=35 train loss <loss>=7.84509153366\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] Epoch[181] Batch [35]#011Speed: 2048.89 samples/sec#011loss=7.845092\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] Epoch[181] Batch[40] avg_epoch_loss=8.057846\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=181, batch=40 train loss <loss>=7.78772630692\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] Epoch[181] Batch [40]#011Speed: 835.78 samples/sec#011loss=7.787726\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] Epoch[181] Batch[45] avg_epoch_loss=8.049087\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=181, batch=45 train loss <loss>=7.9772608757\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] Epoch[181] Batch [45]#011Speed: 1729.56 samples/sec#011loss=7.977261\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] Epoch[181] Batch[50] avg_epoch_loss=8.016604\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=181, batch=50 train loss <loss>=7.71776151657\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] Epoch[181] Batch [50]#011Speed: 1686.92 samples/sec#011loss=7.717762\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] processed a total of 1678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1356.3270568847656, \"sum\": 1356.3270568847656, \"min\": 1356.3270568847656}}, \"EndTime\": 1578471765.941579, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471764.584823}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1237.06165902 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] #quality_metric: host=algo-1, epoch=181, train loss <loss>=7.98169959266\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:45 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:46 INFO 139919921551168] Epoch[182] Batch[0] avg_epoch_loss=8.537572\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=8.53757190704\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:46 INFO 139919921551168] Epoch[182] Batch[5] avg_epoch_loss=8.234172\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=8.23417170842\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:46 INFO 139919921551168] Epoch[182] Batch [5]#011Speed: 1805.64 samples/sec#011loss=8.234172\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:46 INFO 139919921551168] Epoch[182] Batch[10] avg_epoch_loss=8.242458\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=182, batch=10 train loss <loss>=8.25240221024\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:46 INFO 139919921551168] Epoch[182] Batch [10]#011Speed: 1037.83 samples/sec#011loss=8.252402\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:46 INFO 139919921551168] Epoch[182] Batch[15] avg_epoch_loss=8.198330\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=182, batch=15 train loss <loss>=8.10124673843\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:46 INFO 139919921551168] Epoch[182] Batch [15]#011Speed: 1687.82 samples/sec#011loss=8.101247\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:46 INFO 139919921551168] Epoch[182] Batch[20] avg_epoch_loss=8.193155\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=182, batch=20 train loss <loss>=8.17659521103\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:46 INFO 139919921551168] Epoch[182] Batch [20]#011Speed: 907.09 samples/sec#011loss=8.176595\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:46 INFO 139919921551168] Epoch[182] Batch[25] avg_epoch_loss=8.169474\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=182, batch=25 train loss <loss>=8.07001543045\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:46 INFO 139919921551168] Epoch[182] Batch [25]#011Speed: 1854.88 samples/sec#011loss=8.070015\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:46 INFO 139919921551168] Epoch[182] Batch[30] avg_epoch_loss=8.050066\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=182, batch=30 train loss <loss>=7.4291431427\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:46 INFO 139919921551168] Epoch[182] Batch [30]#011Speed: 1031.86 samples/sec#011loss=7.429143\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:46 INFO 139919921551168] Epoch[182] Batch[35] avg_epoch_loss=7.995682\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:46 INFO 139919921551168] #quality_metric: host=algo-1, epoch=182, batch=35 train loss <loss>=7.6585021019\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:46 INFO 139919921551168] Epoch[182] Batch [35]#011Speed: 959.90 samples/sec#011loss=7.658502\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] Epoch[182] Batch[40] avg_epoch_loss=7.967975\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=182, batch=40 train loss <loss>=7.76848669052\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] Epoch[182] Batch [40]#011Speed: 2099.46 samples/sec#011loss=7.768487\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] Epoch[182] Batch[45] avg_epoch_loss=7.932633\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=182, batch=45 train loss <loss>=7.64282436371\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] Epoch[182] Batch [45]#011Speed: 1320.50 samples/sec#011loss=7.642824\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] processed a total of 1532 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1270.373821258545, \"sum\": 1270.373821258545, \"min\": 1270.373821258545}}, \"EndTime\": 1578471767.212477, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471765.941657}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1205.8349401 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=182, train loss <loss>=7.91117879748\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] Epoch[183] Batch[0] avg_epoch_loss=8.224966\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=8.22496604919\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] Epoch[183] Batch[5] avg_epoch_loss=8.014637\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=8.01463683446\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] Epoch[183] Batch [5]#011Speed: 1661.58 samples/sec#011loss=8.014637\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] Epoch[183] Batch[10] avg_epoch_loss=8.017388\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=183, batch=10 train loss <loss>=8.02069044113\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] Epoch[183] Batch [10]#011Speed: 919.19 samples/sec#011loss=8.020690\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] Epoch[183] Batch[15] avg_epoch_loss=8.162207\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=183, batch=15 train loss <loss>=8.48080863953\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] Epoch[183] Batch [15]#011Speed: 1663.05 samples/sec#011loss=8.480809\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] Epoch[183] Batch[20] avg_epoch_loss=8.124011\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=183, batch=20 train loss <loss>=8.00178422928\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] Epoch[183] Batch [20]#011Speed: 893.91 samples/sec#011loss=8.001784\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] Epoch[183] Batch[25] avg_epoch_loss=8.043957\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] #quality_metric: host=algo-1, epoch=183, batch=25 train loss <loss>=7.70772857666\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:47 INFO 139919921551168] Epoch[183] Batch [25]#011Speed: 2135.78 samples/sec#011loss=7.707729\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] Epoch[183] Batch[30] avg_epoch_loss=7.948294\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=183, batch=30 train loss <loss>=7.45084657669\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] Epoch[183] Batch [30]#011Speed: 1021.52 samples/sec#011loss=7.450847\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] Epoch[183] Batch[35] avg_epoch_loss=7.875854\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=183, batch=35 train loss <loss>=7.42672662735\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] Epoch[183] Batch [35]#011Speed: 1981.99 samples/sec#011loss=7.426727\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] Epoch[183] Batch[40] avg_epoch_loss=7.873540\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=183, batch=40 train loss <loss>=7.85687475204\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] Epoch[183] Batch [40]#011Speed: 949.33 samples/sec#011loss=7.856875\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] Epoch[183] Batch[45] avg_epoch_loss=7.827915\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=183, batch=45 train loss <loss>=7.45379152298\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] Epoch[183] Batch [45]#011Speed: 2087.25 samples/sec#011loss=7.453792\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] processed a total of 1590 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1310.8909130096436, \"sum\": 1310.8909130096436, \"min\": 1310.8909130096436}}, \"EndTime\": 1578471768.523922, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471767.212556}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1212.82667579 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=183, train loss <loss>=7.79499479294\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] Saved checkpoint to \"/opt/ml/model/state_7ec1d343-883a-4aee-9368-0aee1dbd8938-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.129928588867188, \"sum\": 10.129928588867188, \"min\": 10.129928588867188}}, \"EndTime\": 1578471768.53464, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471768.523982}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] Epoch[184] Batch[0] avg_epoch_loss=7.526319\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=7.52631902695\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] Epoch[184] Batch[5] avg_epoch_loss=8.033537\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=8.03353675207\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] Epoch[184] Batch [5]#011Speed: 1962.54 samples/sec#011loss=8.033537\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] Epoch[184] Batch[10] avg_epoch_loss=8.181782\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=184, batch=10 train loss <loss>=8.35967693329\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] Epoch[184] Batch [10]#011Speed: 1008.46 samples/sec#011loss=8.359677\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] Epoch[184] Batch[15] avg_epoch_loss=8.294177\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] #quality_metric: host=algo-1, epoch=184, batch=15 train loss <loss>=8.54144630432\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:48 INFO 139919921551168] Epoch[184] Batch [15]#011Speed: 1991.17 samples/sec#011loss=8.541446\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] Epoch[184] Batch[20] avg_epoch_loss=8.289764\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=184, batch=20 train loss <loss>=8.27564029694\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] Epoch[184] Batch [20]#011Speed: 910.05 samples/sec#011loss=8.275640\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] Epoch[184] Batch[25] avg_epoch_loss=8.227950\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=184, batch=25 train loss <loss>=7.9683303833\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] Epoch[184] Batch [25]#011Speed: 1895.45 samples/sec#011loss=7.968330\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] Epoch[184] Batch[30] avg_epoch_loss=8.160008\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=184, batch=30 train loss <loss>=7.80671024323\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] Epoch[184] Batch [30]#011Speed: 834.90 samples/sec#011loss=7.806710\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] Epoch[184] Batch[35] avg_epoch_loss=8.101275\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=184, batch=35 train loss <loss>=7.73713130951\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] Epoch[184] Batch [35]#011Speed: 1720.91 samples/sec#011loss=7.737131\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] Epoch[184] Batch[40] avg_epoch_loss=8.046048\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=184, batch=40 train loss <loss>=7.64841594696\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] Epoch[184] Batch [40]#011Speed: 911.75 samples/sec#011loss=7.648416\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] Epoch[184] Batch[45] avg_epoch_loss=8.052835\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=184, batch=45 train loss <loss>=8.1084859848\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] Epoch[184] Batch [45]#011Speed: 1804.02 samples/sec#011loss=8.108486\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] Epoch[184] Batch[50] avg_epoch_loss=8.024506\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=184, batch=50 train loss <loss>=7.7638759613\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] Epoch[184] Batch [50]#011Speed: 1299.26 samples/sec#011loss=7.763876\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] processed a total of 1640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1370.1751232147217, \"sum\": 1370.1751232147217, \"min\": 1370.1751232147217}}, \"EndTime\": 1578471769.904932, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471768.534701}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1196.82358147 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=184, train loss <loss>=7.99010490454\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] Epoch[185] Batch[0] avg_epoch_loss=8.247042\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:49 INFO 139919921551168] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=8.24704170227\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] Epoch[185] Batch[5] avg_epoch_loss=8.053311\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=8.0533109506\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] Epoch[185] Batch [5]#011Speed: 2083.23 samples/sec#011loss=8.053311\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] Epoch[185] Batch[10] avg_epoch_loss=8.200120\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=185, batch=10 train loss <loss>=8.37629165649\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] Epoch[185] Batch [10]#011Speed: 974.07 samples/sec#011loss=8.376292\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] Epoch[185] Batch[15] avg_epoch_loss=8.252176\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=185, batch=15 train loss <loss>=8.36669778824\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] Epoch[185] Batch [15]#011Speed: 1725.96 samples/sec#011loss=8.366698\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] Epoch[185] Batch[20] avg_epoch_loss=8.277290\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=185, batch=20 train loss <loss>=8.35765514374\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] Epoch[185] Batch [20]#011Speed: 1019.99 samples/sec#011loss=8.357655\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] Epoch[185] Batch[25] avg_epoch_loss=8.204709\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=185, batch=25 train loss <loss>=7.89986915588\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] Epoch[185] Batch [25]#011Speed: 1982.38 samples/sec#011loss=7.899869\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] Epoch[185] Batch[30] avg_epoch_loss=8.158710\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=185, batch=30 train loss <loss>=7.91951808929\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] Epoch[185] Batch [30]#011Speed: 956.21 samples/sec#011loss=7.919518\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] Epoch[185] Batch[35] avg_epoch_loss=8.055862\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=185, batch=35 train loss <loss>=7.41820487976\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] Epoch[185] Batch [35]#011Speed: 2011.11 samples/sec#011loss=7.418205\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] Epoch[185] Batch[40] avg_epoch_loss=8.036284\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] #quality_metric: host=algo-1, epoch=185, batch=40 train loss <loss>=7.89531488419\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:50 INFO 139919921551168] Epoch[185] Batch [40]#011Speed: 975.76 samples/sec#011loss=7.895315\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] Epoch[185] Batch[45] avg_epoch_loss=8.029977\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=185, batch=45 train loss <loss>=7.97826690674\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] Epoch[185] Batch [45]#011Speed: 2142.73 samples/sec#011loss=7.978267\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] processed a total of 1589 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1249.7808933258057, \"sum\": 1249.7808933258057, \"min\": 1249.7808933258057}}, \"EndTime\": 1578471771.155283, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471769.905015}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1271.30281227 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=185, train loss <loss>=7.97452041626\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] Epoch[186] Batch[0] avg_epoch_loss=8.578114\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=8.57811355591\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] Epoch[186] Batch[5] avg_epoch_loss=8.261963\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=8.26196304957\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] Epoch[186] Batch [5]#011Speed: 1987.68 samples/sec#011loss=8.261963\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] Epoch[186] Batch[10] avg_epoch_loss=8.176868\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=186, batch=10 train loss <loss>=8.07475414276\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] Epoch[186] Batch [10]#011Speed: 1013.68 samples/sec#011loss=8.074754\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] Epoch[186] Batch[15] avg_epoch_loss=8.312178\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=186, batch=15 train loss <loss>=8.60986022949\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] Epoch[186] Batch [15]#011Speed: 1733.61 samples/sec#011loss=8.609860\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] Epoch[186] Batch[20] avg_epoch_loss=8.272148\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=186, batch=20 train loss <loss>=8.14405088425\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] Epoch[186] Batch [20]#011Speed: 993.50 samples/sec#011loss=8.144051\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] Epoch[186] Batch[25] avg_epoch_loss=8.209518\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=186, batch=25 train loss <loss>=7.94647502899\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] Epoch[186] Batch [25]#011Speed: 2046.71 samples/sec#011loss=7.946475\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] Epoch[186] Batch[30] avg_epoch_loss=8.156215\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] #quality_metric: host=algo-1, epoch=186, batch=30 train loss <loss>=7.87903862\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:51 INFO 139919921551168] Epoch[186] Batch [30]#011Speed: 997.52 samples/sec#011loss=7.879039\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] Epoch[186] Batch[35] avg_epoch_loss=8.099747\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=186, batch=35 train loss <loss>=7.74964494705\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] Epoch[186] Batch [35]#011Speed: 2137.03 samples/sec#011loss=7.749645\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] Epoch[186] Batch[40] avg_epoch_loss=8.090072\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=186, batch=40 train loss <loss>=8.0204126358\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] Epoch[186] Batch [40]#011Speed: 965.75 samples/sec#011loss=8.020413\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] Epoch[186] Batch[45] avg_epoch_loss=8.056792\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=186, batch=45 train loss <loss>=7.78389596939\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] Epoch[186] Batch [45]#011Speed: 1769.15 samples/sec#011loss=7.783896\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] Epoch[186] Batch[50] avg_epoch_loss=7.991572\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=186, batch=50 train loss <loss>=7.3915476799\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] Epoch[186] Batch [50]#011Speed: 1410.90 samples/sec#011loss=7.391548\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] processed a total of 1627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1283.9670181274414, \"sum\": 1283.9670181274414, \"min\": 1283.9670181274414}}, \"EndTime\": 1578471772.439821, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471771.155366}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1267.05804235 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=186, train loss <loss>=7.99157213697\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] Epoch[187] Batch[0] avg_epoch_loss=8.194026\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=8.19402599335\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] Epoch[187] Batch[5] avg_epoch_loss=8.078302\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=8.07830222448\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] Epoch[187] Batch [5]#011Speed: 1916.26 samples/sec#011loss=8.078302\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] Epoch[187] Batch[10] avg_epoch_loss=8.132202\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=8.19688081741\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] Epoch[187] Batch [10]#011Speed: 932.82 samples/sec#011loss=8.196881\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] Epoch[187] Batch[15] avg_epoch_loss=8.336121\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] #quality_metric: host=algo-1, epoch=187, batch=15 train loss <loss>=8.78474311829\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:52 INFO 139919921551168] Epoch[187] Batch [15]#011Speed: 2132.28 samples/sec#011loss=8.784743\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] Epoch[187] Batch[20] avg_epoch_loss=8.324038\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=187, batch=20 train loss <loss>=8.28537368774\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] Epoch[187] Batch [20]#011Speed: 999.39 samples/sec#011loss=8.285374\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] Epoch[187] Batch[25] avg_epoch_loss=8.226650\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=187, batch=25 train loss <loss>=7.81761846542\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] Epoch[187] Batch [25]#011Speed: 1873.95 samples/sec#011loss=7.817618\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] Epoch[187] Batch[30] avg_epoch_loss=8.167066\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=187, batch=30 train loss <loss>=7.85723152161\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] Epoch[187] Batch [30]#011Speed: 925.70 samples/sec#011loss=7.857232\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] Epoch[187] Batch[35] avg_epoch_loss=8.083428\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=187, batch=35 train loss <loss>=7.56486778259\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] Epoch[187] Batch [35]#011Speed: 2102.28 samples/sec#011loss=7.564868\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] Epoch[187] Batch[40] avg_epoch_loss=8.051920\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=187, batch=40 train loss <loss>=7.82506742477\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] Epoch[187] Batch [40]#011Speed: 930.52 samples/sec#011loss=7.825067\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] Epoch[187] Batch[45] avg_epoch_loss=8.062162\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=187, batch=45 train loss <loss>=8.14614534378\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] Epoch[187] Batch [45]#011Speed: 1774.13 samples/sec#011loss=8.146145\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] processed a total of 1585 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1277.3799896240234, \"sum\": 1277.3799896240234, \"min\": 1277.3799896240234}}, \"EndTime\": 1578471773.71769, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471772.439897}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1240.71407802 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=187, train loss <loss>=8.01489087105\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] Epoch[188] Batch[0] avg_epoch_loss=8.240574\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=8.24057388306\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] Epoch[188] Batch[5] avg_epoch_loss=7.828559\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=7.82855939865\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:53 INFO 139919921551168] Epoch[188] Batch [5]#011Speed: 1904.13 samples/sec#011loss=7.828559\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] Epoch[188] Batch[10] avg_epoch_loss=8.007691\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=188, batch=10 train loss <loss>=8.22264919281\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] Epoch[188] Batch [10]#011Speed: 1007.05 samples/sec#011loss=8.222649\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] Epoch[188] Batch[15] avg_epoch_loss=8.159791\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=188, batch=15 train loss <loss>=8.49440917969\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] Epoch[188] Batch [15]#011Speed: 1928.54 samples/sec#011loss=8.494409\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] Epoch[188] Batch[20] avg_epoch_loss=8.143044\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=188, batch=20 train loss <loss>=8.08945446014\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] Epoch[188] Batch [20]#011Speed: 1003.16 samples/sec#011loss=8.089454\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] Epoch[188] Batch[25] avg_epoch_loss=8.100419\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=188, batch=25 train loss <loss>=7.92139549255\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] Epoch[188] Batch [25]#011Speed: 1727.84 samples/sec#011loss=7.921395\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] Epoch[188] Batch[30] avg_epoch_loss=8.036696\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=188, batch=30 train loss <loss>=7.70533666611\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] Epoch[188] Batch [30]#011Speed: 977.86 samples/sec#011loss=7.705337\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] Epoch[188] Batch[35] avg_epoch_loss=7.999343\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=188, batch=35 train loss <loss>=7.76775074005\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] Epoch[188] Batch [35]#011Speed: 2060.79 samples/sec#011loss=7.767751\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] Epoch[188] Batch[40] avg_epoch_loss=7.979767\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=188, batch=40 train loss <loss>=7.8388220787\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] Epoch[188] Batch [40]#011Speed: 897.56 samples/sec#011loss=7.838822\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] Epoch[188] Batch[45] avg_epoch_loss=7.977007\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] #quality_metric: host=algo-1, epoch=188, batch=45 train loss <loss>=7.9543794632\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:54 INFO 139919921551168] Epoch[188] Batch [45]#011Speed: 1947.56 samples/sec#011loss=7.954379\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] Epoch[188] Batch[50] avg_epoch_loss=7.930986\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=188, batch=50 train loss <loss>=7.50758752823\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] Epoch[188] Batch [50]#011Speed: 1389.37 samples/sec#011loss=7.507588\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] processed a total of 1621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1296.6930866241455, \"sum\": 1296.6930866241455, \"min\": 1296.6930866241455}}, \"EndTime\": 1578471775.014895, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471773.717765}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1249.99894911 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=188, train loss <loss>=7.93098589018\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] Epoch[189] Batch[0] avg_epoch_loss=8.401511\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=8.40151119232\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] Epoch[189] Batch[5] avg_epoch_loss=8.190401\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=8.1904009978\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] Epoch[189] Batch [5]#011Speed: 2043.55 samples/sec#011loss=8.190401\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] Epoch[189] Batch[10] avg_epoch_loss=8.160968\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=189, batch=10 train loss <loss>=8.1256480217\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] Epoch[189] Batch [10]#011Speed: 1005.86 samples/sec#011loss=8.125648\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] Epoch[189] Batch[15] avg_epoch_loss=8.219131\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=189, batch=15 train loss <loss>=8.34708881378\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] Epoch[189] Batch [15]#011Speed: 1906.63 samples/sec#011loss=8.347089\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] Epoch[189] Batch[20] avg_epoch_loss=8.262870\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=189, batch=20 train loss <loss>=8.40283565521\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] Epoch[189] Batch [20]#011Speed: 926.46 samples/sec#011loss=8.402836\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] Epoch[189] Batch[25] avg_epoch_loss=8.144960\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=189, batch=25 train loss <loss>=7.64973678589\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] Epoch[189] Batch [25]#011Speed: 2122.42 samples/sec#011loss=7.649737\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] Epoch[189] Batch[30] avg_epoch_loss=8.111356\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=189, batch=30 train loss <loss>=7.93661584854\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] Epoch[189] Batch [30]#011Speed: 909.90 samples/sec#011loss=7.936616\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] Epoch[189] Batch[35] avg_epoch_loss=8.035507\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] #quality_metric: host=algo-1, epoch=189, batch=35 train loss <loss>=7.56524114609\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:55 INFO 139919921551168] Epoch[189] Batch [35]#011Speed: 1911.59 samples/sec#011loss=7.565241\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] Epoch[189] Batch[40] avg_epoch_loss=8.055110\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=189, batch=40 train loss <loss>=8.19625530243\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] Epoch[189] Batch [40]#011Speed: 955.21 samples/sec#011loss=8.196255\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] Epoch[189] Batch[45] avg_epoch_loss=8.064403\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=189, batch=45 train loss <loss>=8.14060916901\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] Epoch[189] Batch [45]#011Speed: 1912.43 samples/sec#011loss=8.140609\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] Epoch[189] Batch[50] avg_epoch_loss=7.995722\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=189, batch=50 train loss <loss>=7.36385641098\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] Epoch[189] Batch [50]#011Speed: 1553.45 samples/sec#011loss=7.363856\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] processed a total of 1625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1285.8247756958008, \"sum\": 1285.8247756958008, \"min\": 1285.8247756958008}}, \"EndTime\": 1578471776.301202, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471775.014971}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1263.67086071 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=189, train loss <loss>=7.99572238735\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] Epoch[190] Batch[0] avg_epoch_loss=7.943868\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=7.94386768341\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] Epoch[190] Batch[5] avg_epoch_loss=8.080438\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=8.08043766022\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] Epoch[190] Batch [5]#011Speed: 1904.85 samples/sec#011loss=8.080438\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] Epoch[190] Batch[10] avg_epoch_loss=8.245352\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=190, batch=10 train loss <loss>=8.44324827194\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] Epoch[190] Batch [10]#011Speed: 1041.39 samples/sec#011loss=8.443248\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] Epoch[190] Batch[15] avg_epoch_loss=8.216172\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=190, batch=15 train loss <loss>=8.15197629929\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] Epoch[190] Batch [15]#011Speed: 1738.11 samples/sec#011loss=8.151976\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] Epoch[190] Batch[20] avg_epoch_loss=8.219404\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=190, batch=20 train loss <loss>=8.22974624634\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] Epoch[190] Batch [20]#011Speed: 1079.90 samples/sec#011loss=8.229746\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] Epoch[190] Batch[25] avg_epoch_loss=8.137961\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] #quality_metric: host=algo-1, epoch=190, batch=25 train loss <loss>=7.79590005875\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:56 INFO 139919921551168] Epoch[190] Batch [25]#011Speed: 1898.46 samples/sec#011loss=7.795900\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] Epoch[190] Batch[30] avg_epoch_loss=8.080234\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=190, batch=30 train loss <loss>=7.78005189896\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] Epoch[190] Batch [30]#011Speed: 900.28 samples/sec#011loss=7.780052\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] Epoch[190] Batch[35] avg_epoch_loss=8.054095\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=190, batch=35 train loss <loss>=7.89203720093\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] Epoch[190] Batch [35]#011Speed: 1982.92 samples/sec#011loss=7.892037\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] Epoch[190] Batch[40] avg_epoch_loss=8.005960\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=190, batch=40 train loss <loss>=7.65938835144\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] Epoch[190] Batch [40]#011Speed: 915.88 samples/sec#011loss=7.659388\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] Epoch[190] Batch[45] avg_epoch_loss=7.981488\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=190, batch=45 train loss <loss>=7.78081531525\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] Epoch[190] Batch [45]#011Speed: 1921.09 samples/sec#011loss=7.780815\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] Epoch[190] Batch[50] avg_epoch_loss=7.940467\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=190, batch=50 train loss <loss>=7.56307516098\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] Epoch[190] Batch [50]#011Speed: 1409.10 samples/sec#011loss=7.563075\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] processed a total of 1634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1317.1541690826416, \"sum\": 1317.1541690826416, \"min\": 1317.1541690826416}}, \"EndTime\": 1578471777.618845, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471776.301279}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1240.44803072 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=190, train loss <loss>=7.93009633284\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] Epoch[191] Batch[0] avg_epoch_loss=7.894469\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=7.89446926117\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] Epoch[191] Batch[5] avg_epoch_loss=8.049595\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=8.04959535599\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] Epoch[191] Batch [5]#011Speed: 2003.88 samples/sec#011loss=8.049595\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] Epoch[191] Batch[10] avg_epoch_loss=8.160563\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] #quality_metric: host=algo-1, epoch=191, batch=10 train loss <loss>=8.29372425079\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:57 INFO 139919921551168] Epoch[191] Batch [10]#011Speed: 994.65 samples/sec#011loss=8.293724\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] Epoch[191] Batch[15] avg_epoch_loss=8.255246\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=191, batch=15 train loss <loss>=8.46354980469\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] Epoch[191] Batch [15]#011Speed: 2046.59 samples/sec#011loss=8.463550\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] Epoch[191] Batch[20] avg_epoch_loss=8.327032\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=191, batch=20 train loss <loss>=8.55674762726\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] Epoch[191] Batch [20]#011Speed: 2102.25 samples/sec#011loss=8.556748\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] Epoch[191] Batch[25] avg_epoch_loss=8.275378\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=191, batch=25 train loss <loss>=8.05842990875\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] Epoch[191] Batch [25]#011Speed: 979.16 samples/sec#011loss=8.058430\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] Epoch[191] Batch[30] avg_epoch_loss=8.228766\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=191, batch=30 train loss <loss>=7.98638324738\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] Epoch[191] Batch [30]#011Speed: 2144.23 samples/sec#011loss=7.986383\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] Epoch[191] Batch[35] avg_epoch_loss=8.134179\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=191, batch=35 train loss <loss>=7.54773864746\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] Epoch[191] Batch [35]#011Speed: 1009.06 samples/sec#011loss=7.547739\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] Epoch[191] Batch[40] avg_epoch_loss=8.111816\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=191, batch=40 train loss <loss>=7.9508020401\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] Epoch[191] Batch [40]#011Speed: 842.06 samples/sec#011loss=7.950802\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] Epoch[191] Batch[45] avg_epoch_loss=8.102815\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=191, batch=45 train loss <loss>=8.02900466919\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] Epoch[191] Batch [45]#011Speed: 1937.98 samples/sec#011loss=8.029005\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] Epoch[191] Batch[50] avg_epoch_loss=8.043871\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=191, batch=50 train loss <loss>=7.50158815384\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] Epoch[191] Batch [50]#011Speed: 1599.52 samples/sec#011loss=7.501588\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] processed a total of 1645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1290.6420230865479, \"sum\": 1290.6420230865479, \"min\": 1290.6420230865479}}, \"EndTime\": 1578471778.909986, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471777.618922}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1274.4389222 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] #quality_metric: host=algo-1, epoch=191, train loss <loss>=8.00446008719\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:58 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] Epoch[192] Batch[0] avg_epoch_loss=7.984367\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=7.98436689377\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] Epoch[192] Batch[5] avg_epoch_loss=8.176837\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=8.17683680852\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] Epoch[192] Batch [5]#011Speed: 1727.99 samples/sec#011loss=8.176837\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] Epoch[192] Batch[10] avg_epoch_loss=8.257195\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=192, batch=10 train loss <loss>=8.35362377167\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] Epoch[192] Batch [10]#011Speed: 957.23 samples/sec#011loss=8.353624\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] Epoch[192] Batch[15] avg_epoch_loss=8.256447\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=192, batch=15 train loss <loss>=8.25480251312\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] Epoch[192] Batch [15]#011Speed: 1824.44 samples/sec#011loss=8.254803\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] Epoch[192] Batch[20] avg_epoch_loss=8.210838\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=192, batch=20 train loss <loss>=8.06488933563\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] Epoch[192] Batch [20]#011Speed: 939.86 samples/sec#011loss=8.064889\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] Epoch[192] Batch[25] avg_epoch_loss=8.150689\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=192, batch=25 train loss <loss>=7.89806127548\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] Epoch[192] Batch [25]#011Speed: 1918.72 samples/sec#011loss=7.898061\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] Epoch[192] Batch[30] avg_epoch_loss=8.080394\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=192, batch=30 train loss <loss>=7.71485929489\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] Epoch[192] Batch [30]#011Speed: 1119.25 samples/sec#011loss=7.714859\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] Epoch[192] Batch[35] avg_epoch_loss=8.020307\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=192, batch=35 train loss <loss>=7.64776659012\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] Epoch[192] Batch [35]#011Speed: 2054.97 samples/sec#011loss=7.647767\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] Epoch[192] Batch[40] avg_epoch_loss=8.020875\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] #quality_metric: host=algo-1, epoch=192, batch=40 train loss <loss>=8.02496643066\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:22:59 INFO 139919921551168] Epoch[192] Batch [40]#011Speed: 1041.37 samples/sec#011loss=8.024966\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] Epoch[192] Batch[45] avg_epoch_loss=7.994642\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=192, batch=45 train loss <loss>=7.77953443527\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] Epoch[192] Batch [45]#011Speed: 2032.03 samples/sec#011loss=7.779534\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] processed a total of 1565 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1216.2210941314697, \"sum\": 1216.2210941314697, \"min\": 1216.2210941314697}}, \"EndTime\": 1578471780.126743, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471778.91007}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1286.654323 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=192, train loss <loss>=7.98728524422\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] Epoch[193] Batch[0] avg_epoch_loss=8.074283\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=8.07428264618\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] Epoch[193] Batch[5] avg_epoch_loss=8.069480\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=8.06948026021\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] Epoch[193] Batch [5]#011Speed: 2035.26 samples/sec#011loss=8.069480\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] Epoch[193] Batch[10] avg_epoch_loss=8.165581\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=193, batch=10 train loss <loss>=8.2809009552\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] Epoch[193] Batch [10]#011Speed: 1005.26 samples/sec#011loss=8.280901\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] Epoch[193] Batch[15] avg_epoch_loss=8.219069\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=193, batch=15 train loss <loss>=8.33674488068\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] Epoch[193] Batch [15]#011Speed: 1663.56 samples/sec#011loss=8.336745\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] Epoch[193] Batch[20] avg_epoch_loss=8.312800\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=193, batch=20 train loss <loss>=8.61273593903\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] Epoch[193] Batch [20]#011Speed: 990.68 samples/sec#011loss=8.612736\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] Epoch[193] Batch[25] avg_epoch_loss=8.208128\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=193, batch=25 train loss <loss>=7.76850605011\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] Epoch[193] Batch [25]#011Speed: 1835.95 samples/sec#011loss=7.768506\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] Epoch[193] Batch[30] avg_epoch_loss=8.123240\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] #quality_metric: host=algo-1, epoch=193, batch=30 train loss <loss>=7.68182249069\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:00 INFO 139919921551168] Epoch[193] Batch [30]#011Speed: 968.69 samples/sec#011loss=7.681822\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] Epoch[193] Batch[35] avg_epoch_loss=8.055037\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=193, batch=35 train loss <loss>=7.63218154907\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] Epoch[193] Batch [35]#011Speed: 2100.48 samples/sec#011loss=7.632182\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] Epoch[193] Batch[40] avg_epoch_loss=8.028380\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=193, batch=40 train loss <loss>=7.8364484787\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] Epoch[193] Batch [40]#011Speed: 1006.09 samples/sec#011loss=7.836448\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] Epoch[193] Batch[45] avg_epoch_loss=7.991528\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=193, batch=45 train loss <loss>=7.68934526443\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] Epoch[193] Batch [45]#011Speed: 1893.92 samples/sec#011loss=7.689345\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] Epoch[193] Batch[50] avg_epoch_loss=7.954548\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=193, batch=50 train loss <loss>=7.61432952881\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] Epoch[193] Batch [50]#011Speed: 1432.84 samples/sec#011loss=7.614330\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] processed a total of 1624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1266.5491104125977, \"sum\": 1266.5491104125977, \"min\": 1266.5491104125977}}, \"EndTime\": 1578471781.393845, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471780.126822}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1282.11517363 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=193, train loss <loss>=7.95454818127\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] Epoch[194] Batch[0] avg_epoch_loss=8.335251\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=8.33525085449\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] Epoch[194] Batch[5] avg_epoch_loss=8.293348\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=8.29334839185\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] Epoch[194] Batch [5]#011Speed: 2112.99 samples/sec#011loss=8.293348\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] Epoch[194] Batch[10] avg_epoch_loss=8.133522\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=194, batch=10 train loss <loss>=7.9417309761\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] Epoch[194] Batch [10]#011Speed: 815.52 samples/sec#011loss=7.941731\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] Epoch[194] Batch[15] avg_epoch_loss=8.225523\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] #quality_metric: host=algo-1, epoch=194, batch=15 train loss <loss>=8.42792549133\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:01 INFO 139919921551168] Epoch[194] Batch [15]#011Speed: 2029.60 samples/sec#011loss=8.427925\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] Epoch[194] Batch[20] avg_epoch_loss=8.214907\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=194, batch=20 train loss <loss>=8.18093328476\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] Epoch[194] Batch [20]#011Speed: 1046.31 samples/sec#011loss=8.180933\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] Epoch[194] Batch[25] avg_epoch_loss=8.157008\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=194, batch=25 train loss <loss>=7.91383543015\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] Epoch[194] Batch [25]#011Speed: 1784.74 samples/sec#011loss=7.913835\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] Epoch[194] Batch[30] avg_epoch_loss=8.096091\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=194, batch=30 train loss <loss>=7.77931985855\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] Epoch[194] Batch [30]#011Speed: 1049.94 samples/sec#011loss=7.779320\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] Epoch[194] Batch[35] avg_epoch_loss=8.030859\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=194, batch=35 train loss <loss>=7.62641820908\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] Epoch[194] Batch [35]#011Speed: 2079.38 samples/sec#011loss=7.626418\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] Epoch[194] Batch[40] avg_epoch_loss=8.027403\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=194, batch=40 train loss <loss>=8.00251960754\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] Epoch[194] Batch [40]#011Speed: 1076.55 samples/sec#011loss=8.002520\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] Epoch[194] Batch[45] avg_epoch_loss=7.995056\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=194, batch=45 train loss <loss>=7.72980995178\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] Epoch[194] Batch [45]#011Speed: 1686.66 samples/sec#011loss=7.729810\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] Epoch[194] Batch[50] avg_epoch_loss=7.927879\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=194, batch=50 train loss <loss>=7.30985631943\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] Epoch[194] Batch [50]#011Speed: 1527.35 samples/sec#011loss=7.309856\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] processed a total of 1618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1292.9871082305908, \"sum\": 1292.9871082305908, \"min\": 1292.9871082305908}}, \"EndTime\": 1578471782.687283, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471781.393919}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1251.26047719 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=194, train loss <loss>=7.92787913715\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] Epoch[195] Batch[0] avg_epoch_loss=8.127187\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=8.12718677521\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] Epoch[195] Batch[5] avg_epoch_loss=8.279427\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=8.27942736944\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:02 INFO 139919921551168] Epoch[195] Batch [5]#011Speed: 1752.58 samples/sec#011loss=8.279427\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] Epoch[195] Batch[10] avg_epoch_loss=8.228300\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=195, batch=10 train loss <loss>=8.16694755554\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] Epoch[195] Batch [10]#011Speed: 1013.41 samples/sec#011loss=8.166948\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] Epoch[195] Batch[15] avg_epoch_loss=8.358935\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=195, batch=15 train loss <loss>=8.64633216858\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] Epoch[195] Batch [15]#011Speed: 2049.55 samples/sec#011loss=8.646332\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] Epoch[195] Batch[20] avg_epoch_loss=8.349604\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=195, batch=20 train loss <loss>=8.3197432518\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] Epoch[195] Batch [20]#011Speed: 963.45 samples/sec#011loss=8.319743\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] Epoch[195] Batch[25] avg_epoch_loss=8.251384\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=195, batch=25 train loss <loss>=7.83886079788\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] Epoch[195] Batch [25]#011Speed: 2146.35 samples/sec#011loss=7.838861\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] Epoch[195] Batch[30] avg_epoch_loss=8.154040\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=195, batch=30 train loss <loss>=7.64784936905\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] Epoch[195] Batch [30]#011Speed: 1031.53 samples/sec#011loss=7.647849\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] Epoch[195] Batch[35] avg_epoch_loss=8.098745\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=195, batch=35 train loss <loss>=7.7559211731\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] Epoch[195] Batch [35]#011Speed: 2033.20 samples/sec#011loss=7.755921\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] Epoch[195] Batch[40] avg_epoch_loss=8.100622\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=195, batch=40 train loss <loss>=8.11413555145\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] Epoch[195] Batch [40]#011Speed: 916.09 samples/sec#011loss=8.114136\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] Epoch[195] Batch[45] avg_epoch_loss=8.087056\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=195, batch=45 train loss <loss>=7.97581157684\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] Epoch[195] Batch [45]#011Speed: 2050.26 samples/sec#011loss=7.975812\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] processed a total of 1574 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1244.0311908721924, \"sum\": 1244.0311908721924, \"min\": 1244.0311908721924}}, \"EndTime\": 1578471783.93183, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471782.687358}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1265.12569191 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] #quality_metric: host=algo-1, epoch=195, train loss <loss>=8.01919719696\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:03 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:04 INFO 139919921551168] Epoch[196] Batch[0] avg_epoch_loss=8.198670\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=8.19867038727\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:04 INFO 139919921551168] Epoch[196] Batch[5] avg_epoch_loss=7.972876\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=7.97287559509\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:04 INFO 139919921551168] Epoch[196] Batch [5]#011Speed: 1961.24 samples/sec#011loss=7.972876\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:04 INFO 139919921551168] Epoch[196] Batch[10] avg_epoch_loss=8.126281\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=196, batch=10 train loss <loss>=8.31036663055\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:04 INFO 139919921551168] Epoch[196] Batch [10]#011Speed: 1020.03 samples/sec#011loss=8.310367\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:04 INFO 139919921551168] Epoch[196] Batch[15] avg_epoch_loss=8.332610\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=196, batch=15 train loss <loss>=8.78653316498\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:04 INFO 139919921551168] Epoch[196] Batch [15]#011Speed: 2068.71 samples/sec#011loss=8.786533\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:04 INFO 139919921551168] Epoch[196] Batch[20] avg_epoch_loss=8.357540\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=196, batch=20 train loss <loss>=8.43731575012\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:04 INFO 139919921551168] Epoch[196] Batch [20]#011Speed: 1050.99 samples/sec#011loss=8.437316\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:04 INFO 139919921551168] Epoch[196] Batch[25] avg_epoch_loss=8.280009\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=196, batch=25 train loss <loss>=7.95437812805\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:04 INFO 139919921551168] Epoch[196] Batch [25]#011Speed: 2123.14 samples/sec#011loss=7.954378\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:04 INFO 139919921551168] Epoch[196] Batch[30] avg_epoch_loss=8.194877\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=196, batch=30 train loss <loss>=7.75219221115\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:04 INFO 139919921551168] Epoch[196] Batch [30]#011Speed: 880.26 samples/sec#011loss=7.752192\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:04 INFO 139919921551168] Epoch[196] Batch[35] avg_epoch_loss=8.111213\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:04 INFO 139919921551168] #quality_metric: host=algo-1, epoch=196, batch=35 train loss <loss>=7.59249696732\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:04 INFO 139919921551168] Epoch[196] Batch [35]#011Speed: 2015.47 samples/sec#011loss=7.592497\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] Epoch[196] Batch[40] avg_epoch_loss=8.103033\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=196, batch=40 train loss <loss>=8.04413928986\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] Epoch[196] Batch [40]#011Speed: 1018.63 samples/sec#011loss=8.044139\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] Epoch[196] Batch[45] avg_epoch_loss=8.075995\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=196, batch=45 train loss <loss>=7.85428113937\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] Epoch[196] Batch [45]#011Speed: 2170.14 samples/sec#011loss=7.854281\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] processed a total of 1547 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1230.341911315918, \"sum\": 1230.341911315918, \"min\": 1230.341911315918}}, \"EndTime\": 1578471785.162693, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471783.931908}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1257.26563858 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=196, train loss <loss>=7.98707692477\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] Epoch[197] Batch[0] avg_epoch_loss=8.424084\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=8.42408370972\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] Epoch[197] Batch[5] avg_epoch_loss=8.022250\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=8.02225041389\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] Epoch[197] Batch [5]#011Speed: 1573.32 samples/sec#011loss=8.022250\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] Epoch[197] Batch[10] avg_epoch_loss=8.007567\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=197, batch=10 train loss <loss>=7.9899474144\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] Epoch[197] Batch [10]#011Speed: 897.52 samples/sec#011loss=7.989947\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] Epoch[197] Batch[15] avg_epoch_loss=8.178616\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=197, batch=15 train loss <loss>=8.5549238205\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] Epoch[197] Batch [15]#011Speed: 2066.17 samples/sec#011loss=8.554924\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] Epoch[197] Batch[20] avg_epoch_loss=8.179739\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=197, batch=20 train loss <loss>=8.18333377838\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] Epoch[197] Batch [20]#011Speed: 966.94 samples/sec#011loss=8.183334\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] Epoch[197] Batch[25] avg_epoch_loss=8.118008\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] #quality_metric: host=algo-1, epoch=197, batch=25 train loss <loss>=7.85873794556\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:05 INFO 139919921551168] Epoch[197] Batch [25]#011Speed: 1632.41 samples/sec#011loss=7.858738\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] Epoch[197] Batch[30] avg_epoch_loss=8.107958\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=197, batch=30 train loss <loss>=8.05569400787\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] Epoch[197] Batch [30]#011Speed: 950.37 samples/sec#011loss=8.055694\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] Epoch[197] Batch[35] avg_epoch_loss=8.064756\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=197, batch=35 train loss <loss>=7.79690694809\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] Epoch[197] Batch [35]#011Speed: 1670.51 samples/sec#011loss=7.796907\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] Epoch[197] Batch[40] avg_epoch_loss=8.056684\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=197, batch=40 train loss <loss>=7.99856081009\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] Epoch[197] Batch [40]#011Speed: 1040.66 samples/sec#011loss=7.998561\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] Epoch[197] Batch[45] avg_epoch_loss=8.068433\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=197, batch=45 train loss <loss>=8.16477851868\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] Epoch[197] Batch [45]#011Speed: 1858.22 samples/sec#011loss=8.164779\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] Epoch[197] Batch[50] avg_epoch_loss=8.033265\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=197, batch=50 train loss <loss>=7.70971498489\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] Epoch[197] Batch [50]#011Speed: 1401.99 samples/sec#011loss=7.709715\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] processed a total of 1622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1333.942174911499, \"sum\": 1333.942174911499, \"min\": 1333.942174911499}}, \"EndTime\": 1578471786.497184, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471785.162762}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1215.84284312 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=197, train loss <loss>=8.03326458089\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] Epoch[198] Batch[0] avg_epoch_loss=8.194901\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=8.1949005127\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] Epoch[198] Batch[5] avg_epoch_loss=8.072105\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=8.07210453351\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] Epoch[198] Batch [5]#011Speed: 1629.23 samples/sec#011loss=8.072105\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] Epoch[198] Batch[10] avg_epoch_loss=8.075790\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=198, batch=10 train loss <loss>=8.08021154404\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] Epoch[198] Batch [10]#011Speed: 942.41 samples/sec#011loss=8.080212\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] Epoch[198] Batch[15] avg_epoch_loss=8.178952\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] #quality_metric: host=algo-1, epoch=198, batch=15 train loss <loss>=8.40590934753\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:06 INFO 139919921551168] Epoch[198] Batch [15]#011Speed: 1657.53 samples/sec#011loss=8.405909\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] Epoch[198] Batch[20] avg_epoch_loss=8.199101\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=198, batch=20 train loss <loss>=8.26357593536\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] Epoch[198] Batch [20]#011Speed: 958.41 samples/sec#011loss=8.263576\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] Epoch[198] Batch[25] avg_epoch_loss=8.117343\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=198, batch=25 train loss <loss>=7.7739616394\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] Epoch[198] Batch [25]#011Speed: 2090.74 samples/sec#011loss=7.773962\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] Epoch[198] Batch[30] avg_epoch_loss=7.996751\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=198, batch=30 train loss <loss>=7.36967096329\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] Epoch[198] Batch [30]#011Speed: 1064.63 samples/sec#011loss=7.369671\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] Epoch[198] Batch[35] avg_epoch_loss=7.960896\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=198, batch=35 train loss <loss>=7.73859701157\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] Epoch[198] Batch [35]#011Speed: 2047.34 samples/sec#011loss=7.738597\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] Epoch[198] Batch[40] avg_epoch_loss=7.936249\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=198, batch=40 train loss <loss>=7.75879230499\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] Epoch[198] Batch [40]#011Speed: 1067.59 samples/sec#011loss=7.758792\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] Epoch[198] Batch[45] avg_epoch_loss=7.940273\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=198, batch=45 train loss <loss>=7.97326507568\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] Epoch[198] Batch [45]#011Speed: 1991.06 samples/sec#011loss=7.973265\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] processed a total of 1537 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1212.1009826660156, \"sum\": 1212.1009826660156, \"min\": 1212.1009826660156}}, \"EndTime\": 1578471787.70979, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471786.497256}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1267.92370798 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=198, train loss <loss>=7.92016187979\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] Epoch[199] Batch[0] avg_epoch_loss=7.988486\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=7.98848628998\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] Epoch[199] Batch[5] avg_epoch_loss=8.225090\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=8.22508970896\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:07 INFO 139919921551168] Epoch[199] Batch [5]#011Speed: 2031.90 samples/sec#011loss=8.225090\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] Epoch[199] Batch[10] avg_epoch_loss=8.255436\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=199, batch=10 train loss <loss>=8.29185161591\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] Epoch[199] Batch [10]#011Speed: 1051.21 samples/sec#011loss=8.291852\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] Epoch[199] Batch[15] avg_epoch_loss=8.274088\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=199, batch=15 train loss <loss>=8.31512136459\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] Epoch[199] Batch [15]#011Speed: 1885.55 samples/sec#011loss=8.315121\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] Epoch[199] Batch[20] avg_epoch_loss=8.227948\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=199, batch=20 train loss <loss>=8.0803030014\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] Epoch[199] Batch [20]#011Speed: 928.79 samples/sec#011loss=8.080303\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] Epoch[199] Batch[25] avg_epoch_loss=8.134723\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=199, batch=25 train loss <loss>=7.74317770004\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] Epoch[199] Batch [25]#011Speed: 1901.59 samples/sec#011loss=7.743178\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] Epoch[199] Batch[30] avg_epoch_loss=8.077395\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=199, batch=30 train loss <loss>=7.77928628922\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] Epoch[199] Batch [30]#011Speed: 920.52 samples/sec#011loss=7.779286\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] Epoch[199] Batch[35] avg_epoch_loss=8.028119\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=199, batch=35 train loss <loss>=7.722605896\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] Epoch[199] Batch [35]#011Speed: 2115.70 samples/sec#011loss=7.722606\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] Epoch[199] Batch[40] avg_epoch_loss=7.998209\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=199, batch=40 train loss <loss>=7.78286113739\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] Epoch[199] Batch [40]#011Speed: 1018.06 samples/sec#011loss=7.782861\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] Epoch[199] Batch[45] avg_epoch_loss=7.972965\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=199, batch=45 train loss <loss>=7.76596288681\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] Epoch[199] Batch [45]#011Speed: 1934.85 samples/sec#011loss=7.765963\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] Epoch[199] Batch[50] avg_epoch_loss=7.934642\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=199, batch=50 train loss <loss>=7.58207397461\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] Epoch[199] Batch [50]#011Speed: 1497.26 samples/sec#011loss=7.582074\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] processed a total of 1616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1259.7670555114746, \"sum\": 1259.7670555114746, \"min\": 1259.7670555114746}}, \"EndTime\": 1578471788.970117, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471787.709871}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1282.66711378 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] #quality_metric: host=algo-1, epoch=199, train loss <loss>=7.93464230556\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:08 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:09 INFO 139919921551168] Epoch[200] Batch[0] avg_epoch_loss=8.125196\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=8.12519645691\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:09 INFO 139919921551168] Epoch[200] Batch[5] avg_epoch_loss=7.966189\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=7.96618930499\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:09 INFO 139919921551168] Epoch[200] Batch [5]#011Speed: 1979.61 samples/sec#011loss=7.966189\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:09 INFO 139919921551168] Epoch[200] Batch[10] avg_epoch_loss=8.057022\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=200, batch=10 train loss <loss>=8.16602163315\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:09 INFO 139919921551168] Epoch[200] Batch [10]#011Speed: 996.59 samples/sec#011loss=8.166022\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:09 INFO 139919921551168] Epoch[200] Batch[15] avg_epoch_loss=8.140256\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=200, batch=15 train loss <loss>=8.32337026596\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:09 INFO 139919921551168] Epoch[200] Batch [15]#011Speed: 1646.16 samples/sec#011loss=8.323370\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:09 INFO 139919921551168] Epoch[200] Batch[20] avg_epoch_loss=8.114383\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=200, batch=20 train loss <loss>=8.03159017563\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:09 INFO 139919921551168] Epoch[200] Batch [20]#011Speed: 942.17 samples/sec#011loss=8.031590\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:09 INFO 139919921551168] Epoch[200] Batch[25] avg_epoch_loss=8.035553\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=200, batch=25 train loss <loss>=7.70446653366\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:09 INFO 139919921551168] Epoch[200] Batch [25]#011Speed: 2131.12 samples/sec#011loss=7.704467\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:09 INFO 139919921551168] Epoch[200] Batch[30] avg_epoch_loss=7.968668\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=200, batch=30 train loss <loss>=7.62086801529\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:09 INFO 139919921551168] Epoch[200] Batch [30]#011Speed: 972.32 samples/sec#011loss=7.620868\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:09 INFO 139919921551168] Epoch[200] Batch[35] avg_epoch_loss=7.962149\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:09 INFO 139919921551168] #quality_metric: host=algo-1, epoch=200, batch=35 train loss <loss>=7.92172842026\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:09 INFO 139919921551168] Epoch[200] Batch [35]#011Speed: 1889.84 samples/sec#011loss=7.921728\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] Epoch[200] Batch[40] avg_epoch_loss=7.947673\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=200, batch=40 train loss <loss>=7.84345006943\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] Epoch[200] Batch [40]#011Speed: 1009.31 samples/sec#011loss=7.843450\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] Epoch[200] Batch[45] avg_epoch_loss=7.953971\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=200, batch=45 train loss <loss>=8.00561332703\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] Epoch[200] Batch [45]#011Speed: 2103.65 samples/sec#011loss=8.005613\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] processed a total of 1594 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1256.7620277404785, \"sum\": 1256.7620277404785, \"min\": 1256.7620277404785}}, \"EndTime\": 1578471790.227358, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471788.970192}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1268.22376302 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=200, train loss <loss>=7.91248385429\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] Epoch[201] Batch[0] avg_epoch_loss=8.220091\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=8.22009086609\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] Epoch[201] Batch[5] avg_epoch_loss=8.196096\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=8.19609578451\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] Epoch[201] Batch [5]#011Speed: 1852.43 samples/sec#011loss=8.196096\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] Epoch[201] Batch[10] avg_epoch_loss=8.318516\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=201, batch=10 train loss <loss>=8.46542053223\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] Epoch[201] Batch [10]#011Speed: 1083.63 samples/sec#011loss=8.465421\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] Epoch[201] Batch[15] avg_epoch_loss=8.333111\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=201, batch=15 train loss <loss>=8.36521911621\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] Epoch[201] Batch [15]#011Speed: 1702.06 samples/sec#011loss=8.365219\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] Epoch[201] Batch[20] avg_epoch_loss=8.325979\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=201, batch=20 train loss <loss>=8.30315761566\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] Epoch[201] Batch [20]#011Speed: 876.45 samples/sec#011loss=8.303158\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] Epoch[201] Batch[25] avg_epoch_loss=8.195388\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] #quality_metric: host=algo-1, epoch=201, batch=25 train loss <loss>=7.6469078064\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:10 INFO 139919921551168] Epoch[201] Batch [25]#011Speed: 1827.76 samples/sec#011loss=7.646908\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] Epoch[201] Batch[30] avg_epoch_loss=8.171821\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=201, batch=30 train loss <loss>=8.04927272797\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] Epoch[201] Batch [30]#011Speed: 1052.11 samples/sec#011loss=8.049273\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] Epoch[201] Batch[35] avg_epoch_loss=8.111789\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=201, batch=35 train loss <loss>=7.73958816528\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] Epoch[201] Batch [35]#011Speed: 1660.03 samples/sec#011loss=7.739588\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] Epoch[201] Batch[40] avg_epoch_loss=8.070005\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=201, batch=40 train loss <loss>=7.76916303635\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] Epoch[201] Batch [40]#011Speed: 1023.78 samples/sec#011loss=7.769163\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] Epoch[201] Batch[45] avg_epoch_loss=8.046784\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=201, batch=45 train loss <loss>=7.85636796951\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] Epoch[201] Batch [45]#011Speed: 1892.30 samples/sec#011loss=7.856368\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] Epoch[201] Batch[50] avg_epoch_loss=8.001636\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=201, batch=50 train loss <loss>=7.58627510071\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] Epoch[201] Batch [50]#011Speed: 1543.75 samples/sec#011loss=7.586275\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] processed a total of 1631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1298.8569736480713, \"sum\": 1298.8569736480713, \"min\": 1298.8569736480713}}, \"EndTime\": 1578471791.526756, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471790.227436}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1255.61207334 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=201, train loss <loss>=8.00163598154\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] Epoch[202] Batch[0] avg_epoch_loss=7.255962\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=7.25596237183\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] Epoch[202] Batch[5] avg_epoch_loss=8.035077\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=8.03507685661\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] Epoch[202] Batch [5]#011Speed: 1754.04 samples/sec#011loss=8.035077\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] Epoch[202] Batch[10] avg_epoch_loss=8.008732\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=202, batch=10 train loss <loss>=7.97711791992\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] Epoch[202] Batch [10]#011Speed: 1902.22 samples/sec#011loss=7.977118\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] Epoch[202] Batch[15] avg_epoch_loss=8.058698\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] #quality_metric: host=algo-1, epoch=202, batch=15 train loss <loss>=8.16862487793\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:11 INFO 139919921551168] Epoch[202] Batch [15]#011Speed: 1052.33 samples/sec#011loss=8.168625\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] Epoch[202] Batch[20] avg_epoch_loss=8.076311\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=202, batch=20 train loss <loss>=8.13267278671\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] Epoch[202] Batch [20]#011Speed: 1983.02 samples/sec#011loss=8.132673\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] Epoch[202] Batch[25] avg_epoch_loss=8.050679\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=202, batch=25 train loss <loss>=7.94302129745\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] Epoch[202] Batch [25]#011Speed: 997.75 samples/sec#011loss=7.943021\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] Epoch[202] Batch[30] avg_epoch_loss=7.997194\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=202, batch=30 train loss <loss>=7.71907110214\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] Epoch[202] Batch [30]#011Speed: 937.04 samples/sec#011loss=7.719071\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] Epoch[202] Batch[35] avg_epoch_loss=7.968713\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=202, batch=35 train loss <loss>=7.79213600159\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] Epoch[202] Batch [35]#011Speed: 1613.59 samples/sec#011loss=7.792136\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] Epoch[202] Batch[40] avg_epoch_loss=7.944472\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=202, batch=40 train loss <loss>=7.76993532181\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] Epoch[202] Batch [40]#011Speed: 918.73 samples/sec#011loss=7.769935\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] Epoch[202] Batch[45] avg_epoch_loss=7.958451\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=202, batch=45 train loss <loss>=8.07308168411\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] Epoch[202] Batch [45]#011Speed: 1674.03 samples/sec#011loss=8.073082\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] Epoch[202] Batch[50] avg_epoch_loss=7.937928\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=202, batch=50 train loss <loss>=7.74911336899\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] Epoch[202] Batch [50]#011Speed: 1664.39 samples/sec#011loss=7.749113\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] processed a total of 1674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1338.104009628296, \"sum\": 1338.104009628296, \"min\": 1338.104009628296}}, \"EndTime\": 1578471792.865352, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471791.526832}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1250.91728918 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=202, train loss <loss>=7.86202244489\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] Epoch[203] Batch[0] avg_epoch_loss=8.010693\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:12 INFO 139919921551168] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=8.01069259644\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] Epoch[203] Batch[5] avg_epoch_loss=7.978891\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=7.97889097532\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] Epoch[203] Batch [5]#011Speed: 2092.84 samples/sec#011loss=7.978891\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] Epoch[203] Batch[10] avg_epoch_loss=7.917834\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=203, batch=10 train loss <loss>=7.84456529617\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] Epoch[203] Batch [10]#011Speed: 1056.67 samples/sec#011loss=7.844565\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] Epoch[203] Batch[15] avg_epoch_loss=8.028500\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=203, batch=15 train loss <loss>=8.27196702957\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] Epoch[203] Batch [15]#011Speed: 2045.41 samples/sec#011loss=8.271967\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] Epoch[203] Batch[20] avg_epoch_loss=8.148996\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=203, batch=20 train loss <loss>=8.53458137512\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] Epoch[203] Batch [20]#011Speed: 1098.94 samples/sec#011loss=8.534581\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] Epoch[203] Batch[25] avg_epoch_loss=8.124042\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=203, batch=25 train loss <loss>=8.01923513412\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] Epoch[203] Batch [25]#011Speed: 2086.60 samples/sec#011loss=8.019235\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] Epoch[203] Batch[30] avg_epoch_loss=8.067590\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=203, batch=30 train loss <loss>=7.77404203415\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] Epoch[203] Batch [30]#011Speed: 966.88 samples/sec#011loss=7.774042\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] Epoch[203] Batch[35] avg_epoch_loss=7.992459\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=203, batch=35 train loss <loss>=7.52664775848\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] Epoch[203] Batch [35]#011Speed: 2057.22 samples/sec#011loss=7.526648\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] Epoch[203] Batch[40] avg_epoch_loss=7.971081\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=203, batch=40 train loss <loss>=7.8171541214\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] Epoch[203] Batch [40]#011Speed: 970.06 samples/sec#011loss=7.817154\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] Epoch[203] Batch[45] avg_epoch_loss=7.977020\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] #quality_metric: host=algo-1, epoch=203, batch=45 train loss <loss>=8.02572536469\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:13 INFO 139919921551168] Epoch[203] Batch [45]#011Speed: 1679.30 samples/sec#011loss=8.025725\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] processed a total of 1587 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1198.6730098724365, \"sum\": 1198.6730098724365, \"min\": 1198.6730098724365}}, \"EndTime\": 1578471794.064577, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471792.865421}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1323.83504906 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=203, train loss <loss>=7.94805429459\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] Epoch[204] Batch[0] avg_epoch_loss=8.354318\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=8.3543176651\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] Epoch[204] Batch[5] avg_epoch_loss=8.184275\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=8.18427538872\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] Epoch[204] Batch [5]#011Speed: 2104.77 samples/sec#011loss=8.184275\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] Epoch[204] Batch[10] avg_epoch_loss=8.145440\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=204, batch=10 train loss <loss>=8.09883708954\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] Epoch[204] Batch [10]#011Speed: 1075.37 samples/sec#011loss=8.098837\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] Epoch[204] Batch[15] avg_epoch_loss=8.281066\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=204, batch=15 train loss <loss>=8.57944221497\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] Epoch[204] Batch [15]#011Speed: 2087.03 samples/sec#011loss=8.579442\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] Epoch[204] Batch[20] avg_epoch_loss=8.298511\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=204, batch=20 train loss <loss>=8.35433702469\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] Epoch[204] Batch [20]#011Speed: 947.77 samples/sec#011loss=8.354337\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] Epoch[204] Batch[25] avg_epoch_loss=8.196152\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=204, batch=25 train loss <loss>=7.7662437439\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] Epoch[204] Batch [25]#011Speed: 1705.34 samples/sec#011loss=7.766244\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] Epoch[204] Batch[30] avg_epoch_loss=8.125866\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=204, batch=30 train loss <loss>=7.76037950516\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] Epoch[204] Batch [30]#011Speed: 955.74 samples/sec#011loss=7.760380\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] Epoch[204] Batch[35] avg_epoch_loss=8.052149\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] #quality_metric: host=algo-1, epoch=204, batch=35 train loss <loss>=7.59510402679\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:14 INFO 139919921551168] Epoch[204] Batch [35]#011Speed: 1855.33 samples/sec#011loss=7.595104\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] Epoch[204] Batch[40] avg_epoch_loss=7.972997\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=204, batch=40 train loss <loss>=7.40310201645\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] Epoch[204] Batch [40]#011Speed: 995.32 samples/sec#011loss=7.403102\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] Epoch[204] Batch[45] avg_epoch_loss=7.951954\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=204, batch=45 train loss <loss>=7.77940225601\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] Epoch[204] Batch [45]#011Speed: 1958.67 samples/sec#011loss=7.779402\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] Epoch[204] Batch[50] avg_epoch_loss=7.914092\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=204, batch=50 train loss <loss>=7.56575622559\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] Epoch[204] Batch [50]#011Speed: 1548.49 samples/sec#011loss=7.565756\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] processed a total of 1632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1255.0830841064453, \"sum\": 1255.0830841064453, \"min\": 1255.0830841064453}}, \"EndTime\": 1578471795.320222, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471794.064662}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1300.20043638 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=204, train loss <loss>=7.91409162447\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] Epoch[205] Batch[0] avg_epoch_loss=8.152557\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=8.15255737305\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] Epoch[205] Batch[5] avg_epoch_loss=8.105936\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=8.105935812\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] Epoch[205] Batch [5]#011Speed: 1972.19 samples/sec#011loss=8.105936\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] Epoch[205] Batch[10] avg_epoch_loss=8.069560\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=205, batch=10 train loss <loss>=8.0259100914\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] Epoch[205] Batch [10]#011Speed: 1028.32 samples/sec#011loss=8.025910\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] Epoch[205] Batch[15] avg_epoch_loss=8.154779\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=205, batch=15 train loss <loss>=8.34225988388\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] Epoch[205] Batch [15]#011Speed: 1851.21 samples/sec#011loss=8.342260\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] Epoch[205] Batch[20] avg_epoch_loss=8.155901\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=205, batch=20 train loss <loss>=8.15949077606\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] Epoch[205] Batch [20]#011Speed: 936.34 samples/sec#011loss=8.159491\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] Epoch[205] Batch[25] avg_epoch_loss=8.091743\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] #quality_metric: host=algo-1, epoch=205, batch=25 train loss <loss>=7.82227735519\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:15 INFO 139919921551168] Epoch[205] Batch [25]#011Speed: 2112.93 samples/sec#011loss=7.822277\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] Epoch[205] Batch[30] avg_epoch_loss=8.040055\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=205, batch=30 train loss <loss>=7.77127923965\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] Epoch[205] Batch [30]#011Speed: 932.40 samples/sec#011loss=7.771279\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] Epoch[205] Batch[35] avg_epoch_loss=7.972207\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=205, batch=35 train loss <loss>=7.55155181885\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] Epoch[205] Batch [35]#011Speed: 2105.38 samples/sec#011loss=7.551552\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] Epoch[205] Batch[40] avg_epoch_loss=7.951276\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=205, batch=40 train loss <loss>=7.80056753159\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] Epoch[205] Batch [40]#011Speed: 992.06 samples/sec#011loss=7.800568\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] Epoch[205] Batch[45] avg_epoch_loss=7.946798\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=205, batch=45 train loss <loss>=7.91007862091\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] Epoch[205] Batch [45]#011Speed: 1863.13 samples/sec#011loss=7.910079\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] Epoch[205] Batch[50] avg_epoch_loss=7.948326\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=205, batch=50 train loss <loss>=7.96238460541\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] Epoch[205] Batch [50]#011Speed: 1638.87 samples/sec#011loss=7.962385\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] processed a total of 1667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1295.328140258789, \"sum\": 1295.328140258789, \"min\": 1295.328140258789}}, \"EndTime\": 1578471796.616099, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471795.320295}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1286.82150722 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=205, train loss <loss>=7.86679391141\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] Epoch[206] Batch[0] avg_epoch_loss=8.116078\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=8.11607837677\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] Epoch[206] Batch[5] avg_epoch_loss=8.077291\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=8.0772913297\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] Epoch[206] Batch [5]#011Speed: 1668.28 samples/sec#011loss=8.077291\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] Epoch[206] Batch[10] avg_epoch_loss=8.184475\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] #quality_metric: host=algo-1, epoch=206, batch=10 train loss <loss>=8.31309509277\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:16 INFO 139919921551168] Epoch[206] Batch [10]#011Speed: 931.01 samples/sec#011loss=8.313095\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] Epoch[206] Batch[15] avg_epoch_loss=8.315515\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=206, batch=15 train loss <loss>=8.60380401611\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] Epoch[206] Batch [15]#011Speed: 2139.87 samples/sec#011loss=8.603804\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] Epoch[206] Batch[20] avg_epoch_loss=8.339315\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=206, batch=20 train loss <loss>=8.41547241211\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] Epoch[206] Batch [20]#011Speed: 1082.51 samples/sec#011loss=8.415472\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] Epoch[206] Batch[25] avg_epoch_loss=8.228267\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=206, batch=25 train loss <loss>=7.76186733246\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] Epoch[206] Batch [25]#011Speed: 2083.39 samples/sec#011loss=7.761867\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] Epoch[206] Batch[30] avg_epoch_loss=8.174699\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=206, batch=30 train loss <loss>=7.89614229202\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] Epoch[206] Batch [30]#011Speed: 945.60 samples/sec#011loss=7.896142\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] Epoch[206] Batch[35] avg_epoch_loss=8.143325\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=206, batch=35 train loss <loss>=7.9488114357\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] Epoch[206] Batch [35]#011Speed: 2115.56 samples/sec#011loss=7.948811\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] Epoch[206] Batch[40] avg_epoch_loss=8.081138\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=206, batch=40 train loss <loss>=7.63338880539\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] Epoch[206] Batch [40]#011Speed: 977.59 samples/sec#011loss=7.633389\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] Epoch[206] Batch[45] avg_epoch_loss=8.055018\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=206, batch=45 train loss <loss>=7.84083166122\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] Epoch[206] Batch [45]#011Speed: 1860.64 samples/sec#011loss=7.840832\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] Epoch[206] Batch[50] avg_epoch_loss=8.020136\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=206, batch=50 train loss <loss>=7.69922246933\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] Epoch[206] Batch [50]#011Speed: 1346.05 samples/sec#011loss=7.699222\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] processed a total of 1663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1290.1239395141602, \"sum\": 1290.1239395141602, \"min\": 1290.1239395141602}}, \"EndTime\": 1578471797.906786, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471796.616165}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1288.90458271 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] #quality_metric: host=algo-1, epoch=206, train loss <loss>=8.01291418993\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:17 INFO 139919921551168] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:23:18 INFO 139919921551168] Epoch[207] Batch[0] avg_epoch_loss=8.180338\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=8.18033790588\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:18 INFO 139919921551168] Epoch[207] Batch[5] avg_epoch_loss=8.288458\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=8.28845755259\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:18 INFO 139919921551168] Epoch[207] Batch [5]#011Speed: 1870.32 samples/sec#011loss=8.288458\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:18 INFO 139919921551168] Epoch[207] Batch[10] avg_epoch_loss=8.298046\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=207, batch=10 train loss <loss>=8.30955104828\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:18 INFO 139919921551168] Epoch[207] Batch [10]#011Speed: 907.69 samples/sec#011loss=8.309551\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:18 INFO 139919921551168] Epoch[207] Batch[15] avg_epoch_loss=8.394054\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=207, batch=15 train loss <loss>=8.6052728653\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:18 INFO 139919921551168] Epoch[207] Batch [15]#011Speed: 1964.42 samples/sec#011loss=8.605273\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:18 INFO 139919921551168] Epoch[207] Batch[20] avg_epoch_loss=8.304067\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=207, batch=20 train loss <loss>=8.01610994339\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:18 INFO 139919921551168] Epoch[207] Batch [20]#011Speed: 975.33 samples/sec#011loss=8.016110\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:18 INFO 139919921551168] Epoch[207] Batch[25] avg_epoch_loss=8.195881\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=207, batch=25 train loss <loss>=7.74149799347\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:18 INFO 139919921551168] Epoch[207] Batch [25]#011Speed: 2100.68 samples/sec#011loss=7.741498\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:18 INFO 139919921551168] Epoch[207] Batch[30] avg_epoch_loss=8.115080\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=207, batch=30 train loss <loss>=7.69491605759\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:18 INFO 139919921551168] Epoch[207] Batch [30]#011Speed: 969.74 samples/sec#011loss=7.694916\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:18 INFO 139919921551168] Epoch[207] Batch[35] avg_epoch_loss=8.058315\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:18 INFO 139919921551168] #quality_metric: host=algo-1, epoch=207, batch=35 train loss <loss>=7.70637178421\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:18 INFO 139919921551168] Epoch[207] Batch [35]#011Speed: 1809.83 samples/sec#011loss=7.706372\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] Epoch[207] Batch[40] avg_epoch_loss=8.034099\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=207, batch=40 train loss <loss>=7.85974473953\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] Epoch[207] Batch [40]#011Speed: 907.49 samples/sec#011loss=7.859745\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] Epoch[207] Batch[45] avg_epoch_loss=8.024875\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=207, batch=45 train loss <loss>=7.94924030304\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] Epoch[207] Batch [45]#011Speed: 1952.43 samples/sec#011loss=7.949240\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] Epoch[207] Batch[50] avg_epoch_loss=8.001486\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=207, batch=50 train loss <loss>=7.78630466461\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] Epoch[207] Batch [50]#011Speed: 1429.09 samples/sec#011loss=7.786305\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] processed a total of 1603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1309.196949005127, \"sum\": 1309.196949005127, \"min\": 1309.196949005127}}, \"EndTime\": 1578471799.216487, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471797.906863}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1224.3137069 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=207, train loss <loss>=8.00148612378\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] Epoch[208] Batch[0] avg_epoch_loss=8.568516\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=8.56851577759\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] Epoch[208] Batch[5] avg_epoch_loss=8.109068\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=8.10906831423\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] Epoch[208] Batch [5]#011Speed: 1818.94 samples/sec#011loss=8.109068\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] Epoch[208] Batch[10] avg_epoch_loss=8.046135\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=208, batch=10 train loss <loss>=7.97061471939\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] Epoch[208] Batch [10]#011Speed: 1932.25 samples/sec#011loss=7.970615\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] Epoch[208] Batch[15] avg_epoch_loss=8.192705\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=208, batch=15 train loss <loss>=8.51515884399\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] Epoch[208] Batch [15]#011Speed: 982.26 samples/sec#011loss=8.515159\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] Epoch[208] Batch[20] avg_epoch_loss=8.212732\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=208, batch=20 train loss <loss>=8.27681798935\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] Epoch[208] Batch [20]#011Speed: 981.82 samples/sec#011loss=8.276818\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] Epoch[208] Batch[25] avg_epoch_loss=8.118405\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] #quality_metric: host=algo-1, epoch=208, batch=25 train loss <loss>=7.72223110199\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:19 INFO 139919921551168] Epoch[208] Batch [25]#011Speed: 2026.78 samples/sec#011loss=7.722231\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] Epoch[208] Batch[30] avg_epoch_loss=8.074683\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=208, batch=30 train loss <loss>=7.8473274231\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] Epoch[208] Batch [30]#011Speed: 1009.85 samples/sec#011loss=7.847327\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] Epoch[208] Batch[35] avg_epoch_loss=8.027737\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=208, batch=35 train loss <loss>=7.73667755127\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] Epoch[208] Batch [35]#011Speed: 2123.62 samples/sec#011loss=7.736678\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] Epoch[208] Batch[40] avg_epoch_loss=7.989623\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=208, batch=40 train loss <loss>=7.7151966095\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] Epoch[208] Batch [40]#011Speed: 1037.93 samples/sec#011loss=7.715197\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] Epoch[208] Batch[45] avg_epoch_loss=7.951747\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=208, batch=45 train loss <loss>=7.64116983414\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] Epoch[208] Batch [45]#011Speed: 2152.97 samples/sec#011loss=7.641170\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] Epoch[208] Batch[50] avg_epoch_loss=7.906767\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=208, batch=50 train loss <loss>=7.49294662476\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] Epoch[208] Batch [50]#011Speed: 1397.09 samples/sec#011loss=7.492947\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] processed a total of 1651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1281.4850807189941, \"sum\": 1281.4850807189941, \"min\": 1281.4850807189941}}, \"EndTime\": 1578471800.498459, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471799.216562}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1288.25359085 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=208, train loss <loss>=7.86682812067\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] Epoch[209] Batch[0] avg_epoch_loss=7.660464\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=7.6604642868\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] Epoch[209] Batch[5] avg_epoch_loss=8.193757\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=8.19375705719\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] Epoch[209] Batch [5]#011Speed: 1859.06 samples/sec#011loss=8.193757\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] Epoch[209] Batch[10] avg_epoch_loss=8.236487\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=209, batch=10 train loss <loss>=8.28776359558\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] Epoch[209] Batch [10]#011Speed: 972.12 samples/sec#011loss=8.287764\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] Epoch[209] Batch[15] avg_epoch_loss=8.250902\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] #quality_metric: host=algo-1, epoch=209, batch=15 train loss <loss>=8.28261566162\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:20 INFO 139919921551168] Epoch[209] Batch [15]#011Speed: 1902.02 samples/sec#011loss=8.282616\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] Epoch[209] Batch[20] avg_epoch_loss=8.231662\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=209, batch=20 train loss <loss>=8.17009439468\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] Epoch[209] Batch [20]#011Speed: 1036.46 samples/sec#011loss=8.170094\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] Epoch[209] Batch[25] avg_epoch_loss=8.163141\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=209, batch=25 train loss <loss>=7.87534866333\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] Epoch[209] Batch [25]#011Speed: 2068.44 samples/sec#011loss=7.875349\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] Epoch[209] Batch[30] avg_epoch_loss=8.099795\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=209, batch=30 train loss <loss>=7.77039613724\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] Epoch[209] Batch [30]#011Speed: 1076.14 samples/sec#011loss=7.770396\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] Epoch[209] Batch[35] avg_epoch_loss=8.021504\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=209, batch=35 train loss <loss>=7.53610534668\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] Epoch[209] Batch [35]#011Speed: 2082.41 samples/sec#011loss=7.536105\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] Epoch[209] Batch[40] avg_epoch_loss=7.998750\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=209, batch=40 train loss <loss>=7.83491744995\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] Epoch[209] Batch [40]#011Speed: 1024.01 samples/sec#011loss=7.834917\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] Epoch[209] Batch[45] avg_epoch_loss=8.006559\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=209, batch=45 train loss <loss>=8.07059497833\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] Epoch[209] Batch [45]#011Speed: 1748.96 samples/sec#011loss=8.070595\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] Epoch[209] Batch[50] avg_epoch_loss=7.958089\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=209, batch=50 train loss <loss>=7.51216335297\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] Epoch[209] Batch [50]#011Speed: 1557.62 samples/sec#011loss=7.512163\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] processed a total of 1639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1256.9739818572998, \"sum\": 1256.9739818572998, \"min\": 1256.9739818572998}}, \"EndTime\": 1578471801.755978, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471800.49852}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1303.80793858 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=209, train loss <loss>=7.89115908513\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] Epoch[210] Batch[0] avg_epoch_loss=8.424783\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=8.42478275299\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] Epoch[210] Batch[5] avg_epoch_loss=8.301134\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=8.3011341095\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:21 INFO 139919921551168] Epoch[210] Batch [5]#011Speed: 1998.45 samples/sec#011loss=8.301134\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] Epoch[210] Batch[10] avg_epoch_loss=8.354561\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=210, batch=10 train loss <loss>=8.41867408752\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] Epoch[210] Batch [10]#011Speed: 1067.62 samples/sec#011loss=8.418674\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] Epoch[210] Batch[15] avg_epoch_loss=8.347755\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=210, batch=15 train loss <loss>=8.33278236389\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] Epoch[210] Batch [15]#011Speed: 1960.18 samples/sec#011loss=8.332782\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] Epoch[210] Batch[20] avg_epoch_loss=8.326081\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=210, batch=20 train loss <loss>=8.2567243576\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] Epoch[210] Batch [20]#011Speed: 1054.38 samples/sec#011loss=8.256724\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] Epoch[210] Batch[25] avg_epoch_loss=8.204676\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=210, batch=25 train loss <loss>=7.69477415085\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] Epoch[210] Batch [25]#011Speed: 1800.39 samples/sec#011loss=7.694774\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] Epoch[210] Batch[30] avg_epoch_loss=8.160026\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=210, batch=30 train loss <loss>=7.92784547806\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] Epoch[210] Batch [30]#011Speed: 1004.03 samples/sec#011loss=7.927845\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] Epoch[210] Batch[35] avg_epoch_loss=8.105017\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=210, batch=35 train loss <loss>=7.76396188736\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] Epoch[210] Batch [35]#011Speed: 2166.79 samples/sec#011loss=7.763962\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] Epoch[210] Batch[40] avg_epoch_loss=8.050355\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=210, batch=40 train loss <loss>=7.65678453445\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] Epoch[210] Batch [40]#011Speed: 972.88 samples/sec#011loss=7.656785\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] Epoch[210] Batch[45] avg_epoch_loss=8.035837\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] #quality_metric: host=algo-1, epoch=210, batch=45 train loss <loss>=7.91679210663\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:22 INFO 139919921551168] Epoch[210] Batch [45]#011Speed: 1836.95 samples/sec#011loss=7.916792\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] Epoch[210] Batch[50] avg_epoch_loss=7.975942\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=210, batch=50 train loss <loss>=7.42490930557\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] Epoch[210] Batch [50]#011Speed: 1419.57 samples/sec#011loss=7.424909\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] processed a total of 1635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1276.7419815063477, \"sum\": 1276.7419815063477, \"min\": 1276.7419815063477}}, \"EndTime\": 1578471803.033225, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471801.756044}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1280.50096051 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=210, train loss <loss>=7.97306179083\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] Epoch[211] Batch[0] avg_epoch_loss=8.465861\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=8.4658613205\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] Epoch[211] Batch[5] avg_epoch_loss=8.337853\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=8.3378534317\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] Epoch[211] Batch [5]#011Speed: 2118.25 samples/sec#011loss=8.337853\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] Epoch[211] Batch[10] avg_epoch_loss=8.301593\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=211, batch=10 train loss <loss>=8.25807943344\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] Epoch[211] Batch [10]#011Speed: 1020.93 samples/sec#011loss=8.258079\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] Epoch[211] Batch[15] avg_epoch_loss=8.417504\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=211, batch=15 train loss <loss>=8.67250823975\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] Epoch[211] Batch [15]#011Speed: 2057.99 samples/sec#011loss=8.672508\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] Epoch[211] Batch[20] avg_epoch_loss=8.291578\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=211, batch=20 train loss <loss>=7.88861551285\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] Epoch[211] Batch [20]#011Speed: 951.02 samples/sec#011loss=7.888616\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] Epoch[211] Batch[25] avg_epoch_loss=8.196990\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=211, batch=25 train loss <loss>=7.79971837997\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] Epoch[211] Batch [25]#011Speed: 1823.69 samples/sec#011loss=7.799718\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] Epoch[211] Batch[30] avg_epoch_loss=8.123436\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=211, batch=30 train loss <loss>=7.74096031189\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] Epoch[211] Batch [30]#011Speed: 856.26 samples/sec#011loss=7.740960\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] Epoch[211] Batch[35] avg_epoch_loss=8.073202\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] #quality_metric: host=algo-1, epoch=211, batch=35 train loss <loss>=7.76174945831\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:23 INFO 139919921551168] Epoch[211] Batch [35]#011Speed: 2065.82 samples/sec#011loss=7.761749\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] Epoch[211] Batch[40] avg_epoch_loss=8.011196\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=211, batch=40 train loss <loss>=7.56475334167\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] Epoch[211] Batch [40]#011Speed: 994.62 samples/sec#011loss=7.564753\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] Epoch[211] Batch[45] avg_epoch_loss=8.000300\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=211, batch=45 train loss <loss>=7.91095304489\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] Epoch[211] Batch [45]#011Speed: 1714.60 samples/sec#011loss=7.910953\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] Epoch[211] Batch[50] avg_epoch_loss=7.956233\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=211, batch=50 train loss <loss>=7.55081214905\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] Epoch[211] Batch [50]#011Speed: 1894.12 samples/sec#011loss=7.550812\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] processed a total of 1622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1265.7668590545654, \"sum\": 1265.7668590545654, \"min\": 1265.7668590545654}}, \"EndTime\": 1578471804.299512, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471803.033289}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1281.33331751 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=211, train loss <loss>=7.9562327441\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] Epoch[212] Batch[0] avg_epoch_loss=7.958823\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=212, batch=0 train loss <loss>=7.95882320404\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] Epoch[212] Batch[5] avg_epoch_loss=8.047723\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=212, batch=5 train loss <loss>=8.04772289594\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] Epoch[212] Batch [5]#011Speed: 1660.77 samples/sec#011loss=8.047723\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] Epoch[212] Batch[10] avg_epoch_loss=8.104985\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=212, batch=10 train loss <loss>=8.17369842529\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] Epoch[212] Batch [10]#011Speed: 1045.78 samples/sec#011loss=8.173698\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] Epoch[212] Batch[15] avg_epoch_loss=8.103700\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=212, batch=15 train loss <loss>=8.10087337494\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] Epoch[212] Batch [15]#011Speed: 1952.20 samples/sec#011loss=8.100873\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] Epoch[212] Batch[20] avg_epoch_loss=8.120488\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=212, batch=20 train loss <loss>=8.17421216965\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] Epoch[212] Batch [20]#011Speed: 830.95 samples/sec#011loss=8.174212\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] Epoch[212] Batch[25] avg_epoch_loss=8.076958\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] #quality_metric: host=algo-1, epoch=212, batch=25 train loss <loss>=7.89412765503\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:24 INFO 139919921551168] Epoch[212] Batch [25]#011Speed: 2137.01 samples/sec#011loss=7.894128\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] Epoch[212] Batch[30] avg_epoch_loss=8.021898\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=212, batch=30 train loss <loss>=7.73558931351\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] Epoch[212] Batch [30]#011Speed: 988.95 samples/sec#011loss=7.735589\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] Epoch[212] Batch[35] avg_epoch_loss=7.984825\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=212, batch=35 train loss <loss>=7.75497217178\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] Epoch[212] Batch [35]#011Speed: 2145.84 samples/sec#011loss=7.754972\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] Epoch[212] Batch[40] avg_epoch_loss=7.927561\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=212, batch=40 train loss <loss>=7.51525611877\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] Epoch[212] Batch [40]#011Speed: 1027.47 samples/sec#011loss=7.515256\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] Epoch[212] Batch[45] avg_epoch_loss=7.894642\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=212, batch=45 train loss <loss>=7.6247095108\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] Epoch[212] Batch [45]#011Speed: 2147.39 samples/sec#011loss=7.624710\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] processed a total of 1583 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1255.768060684204, \"sum\": 1255.768060684204, \"min\": 1255.768060684204}}, \"EndTime\": 1578471805.555791, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471804.299581}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1260.47182422 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=212, train loss <loss>=7.85190779686\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] Epoch[213] Batch[0] avg_epoch_loss=8.308231\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=213, batch=0 train loss <loss>=8.30823135376\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] Epoch[213] Batch[5] avg_epoch_loss=8.035682\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=213, batch=5 train loss <loss>=8.03568172455\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] Epoch[213] Batch [5]#011Speed: 1899.49 samples/sec#011loss=8.035682\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] Epoch[213] Batch[10] avg_epoch_loss=8.129503\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] #quality_metric: host=algo-1, epoch=213, batch=10 train loss <loss>=8.24208936691\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:25 INFO 139919921551168] Epoch[213] Batch [10]#011Speed: 827.52 samples/sec#011loss=8.242089\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] Epoch[213] Batch[15] avg_epoch_loss=8.211022\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=213, batch=15 train loss <loss>=8.39036178589\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] Epoch[213] Batch [15]#011Speed: 1521.13 samples/sec#011loss=8.390362\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] Epoch[213] Batch[20] avg_epoch_loss=8.159164\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=213, batch=20 train loss <loss>=7.99322071075\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] Epoch[213] Batch [20]#011Speed: 908.69 samples/sec#011loss=7.993221\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] Epoch[213] Batch[25] avg_epoch_loss=8.093040\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=213, batch=25 train loss <loss>=7.81531991959\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] Epoch[213] Batch [25]#011Speed: 2006.80 samples/sec#011loss=7.815320\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] Epoch[213] Batch[30] avg_epoch_loss=8.032876\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=213, batch=30 train loss <loss>=7.72001829147\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] Epoch[213] Batch [30]#011Speed: 908.73 samples/sec#011loss=7.720018\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] Epoch[213] Batch[35] avg_epoch_loss=7.985389\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=213, batch=35 train loss <loss>=7.69097576141\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] Epoch[213] Batch [35]#011Speed: 2132.14 samples/sec#011loss=7.690976\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] Epoch[213] Batch[40] avg_epoch_loss=7.961116\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=213, batch=40 train loss <loss>=7.78634576797\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] Epoch[213] Batch [40]#011Speed: 954.86 samples/sec#011loss=7.786346\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] Epoch[213] Batch[45] avg_epoch_loss=7.957770\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=213, batch=45 train loss <loss>=7.93033666611\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] Epoch[213] Batch [45]#011Speed: 1867.39 samples/sec#011loss=7.930337\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] Epoch[213] Batch[50] avg_epoch_loss=7.883833\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=213, batch=50 train loss <loss>=7.20361261368\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] Epoch[213] Batch [50]#011Speed: 1475.22 samples/sec#011loss=7.203613\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] processed a total of 1603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1355.4410934448242, \"sum\": 1355.4410934448242, \"min\": 1355.4410934448242}}, \"EndTime\": 1578471806.911761, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471805.555867}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1182.54308198 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] #quality_metric: host=algo-1, epoch=213, train loss <loss>=7.88383323071\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:26 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] Epoch[214] Batch[0] avg_epoch_loss=7.849149\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=214, batch=0 train loss <loss>=7.84914875031\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] Epoch[214] Batch[5] avg_epoch_loss=7.966180\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=214, batch=5 train loss <loss>=7.96618008614\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] Epoch[214] Batch [5]#011Speed: 2131.37 samples/sec#011loss=7.966180\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] Epoch[214] Batch[10] avg_epoch_loss=8.176538\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=214, batch=10 train loss <loss>=8.42896738052\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] Epoch[214] Batch [10]#011Speed: 982.84 samples/sec#011loss=8.428967\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] Epoch[214] Batch[15] avg_epoch_loss=8.259916\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=214, batch=15 train loss <loss>=8.44334754944\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] Epoch[214] Batch [15]#011Speed: 2067.90 samples/sec#011loss=8.443348\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] Epoch[214] Batch[20] avg_epoch_loss=8.241827\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=214, batch=20 train loss <loss>=8.18394298553\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] Epoch[214] Batch [20]#011Speed: 1056.31 samples/sec#011loss=8.183943\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] Epoch[214] Batch[25] avg_epoch_loss=8.178415\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=214, batch=25 train loss <loss>=7.91208410263\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] Epoch[214] Batch [25]#011Speed: 2072.48 samples/sec#011loss=7.912084\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] Epoch[214] Batch[30] avg_epoch_loss=8.156506\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=214, batch=30 train loss <loss>=8.04258213043\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] Epoch[214] Batch [30]#011Speed: 854.41 samples/sec#011loss=8.042582\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] Epoch[214] Batch[35] avg_epoch_loss=8.088880\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=214, batch=35 train loss <loss>=7.66959934235\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] Epoch[214] Batch [35]#011Speed: 1791.21 samples/sec#011loss=7.669599\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] Epoch[214] Batch[40] avg_epoch_loss=8.040676\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] #quality_metric: host=algo-1, epoch=214, batch=40 train loss <loss>=7.69360542297\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:27 INFO 139919921551168] Epoch[214] Batch [40]#011Speed: 913.05 samples/sec#011loss=7.693605\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] Epoch[214] Batch[45] avg_epoch_loss=8.013510\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=214, batch=45 train loss <loss>=7.79074373245\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] Epoch[214] Batch [45]#011Speed: 2152.88 samples/sec#011loss=7.790744\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] Epoch[214] Batch[50] avg_epoch_loss=7.945442\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=214, batch=50 train loss <loss>=7.31922187805\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] Epoch[214] Batch [50]#011Speed: 1486.51 samples/sec#011loss=7.319222\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] processed a total of 1613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1269.1590785980225, \"sum\": 1269.1590785980225, \"min\": 1269.1590785980225}}, \"EndTime\": 1578471808.181452, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471806.911838}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1270.81212662 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=214, train loss <loss>=7.94544221841\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] Epoch[215] Batch[0] avg_epoch_loss=9.160428\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=215, batch=0 train loss <loss>=9.16042804718\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] Epoch[215] Batch[5] avg_epoch_loss=8.387665\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=215, batch=5 train loss <loss>=8.38766527176\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] Epoch[215] Batch [5]#011Speed: 2059.99 samples/sec#011loss=8.387665\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] Epoch[215] Batch[10] avg_epoch_loss=8.357785\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=215, batch=10 train loss <loss>=8.3219291687\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] Epoch[215] Batch [10]#011Speed: 963.70 samples/sec#011loss=8.321929\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] Epoch[215] Batch[15] avg_epoch_loss=8.393853\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=215, batch=15 train loss <loss>=8.47320079803\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] Epoch[215] Batch [15]#011Speed: 1933.32 samples/sec#011loss=8.473201\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] Epoch[215] Batch[20] avg_epoch_loss=8.362785\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=215, batch=20 train loss <loss>=8.26336936951\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] Epoch[215] Batch [20]#011Speed: 1043.98 samples/sec#011loss=8.263369\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] Epoch[215] Batch[25] avg_epoch_loss=8.256413\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] #quality_metric: host=algo-1, epoch=215, batch=25 train loss <loss>=7.80965156555\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:28 INFO 139919921551168] Epoch[215] Batch [25]#011Speed: 1909.45 samples/sec#011loss=7.809652\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] Epoch[215] Batch[30] avg_epoch_loss=8.190124\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=215, batch=30 train loss <loss>=7.84542264938\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] Epoch[215] Batch [30]#011Speed: 936.74 samples/sec#011loss=7.845423\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] Epoch[215] Batch[35] avg_epoch_loss=8.111504\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=215, batch=35 train loss <loss>=7.62405586243\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] Epoch[215] Batch [35]#011Speed: 2019.90 samples/sec#011loss=7.624056\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] Epoch[215] Batch[40] avg_epoch_loss=8.086123\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=215, batch=40 train loss <loss>=7.90337781906\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] Epoch[215] Batch [40]#011Speed: 1063.54 samples/sec#011loss=7.903378\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] Epoch[215] Batch[45] avg_epoch_loss=8.082353\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=215, batch=45 train loss <loss>=8.05144233704\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] Epoch[215] Batch [45]#011Speed: 1956.70 samples/sec#011loss=8.051442\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] processed a total of 1554 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1214.6930694580078, \"sum\": 1214.6930694580078, \"min\": 1214.6930694580078}}, \"EndTime\": 1578471809.396631, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471808.181527}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1279.21651509 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=215, train loss <loss>=8.00924527888\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] Epoch[216] Batch[0] avg_epoch_loss=7.915519\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=216, batch=0 train loss <loss>=7.91551923752\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] Epoch[216] Batch[5] avg_epoch_loss=8.334304\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=216, batch=5 train loss <loss>=8.33430417379\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] Epoch[216] Batch [5]#011Speed: 1671.84 samples/sec#011loss=8.334304\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] Epoch[216] Batch[10] avg_epoch_loss=8.287089\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=216, batch=10 train loss <loss>=8.2304315567\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] Epoch[216] Batch [10]#011Speed: 1008.29 samples/sec#011loss=8.230432\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] Epoch[216] Batch[15] avg_epoch_loss=8.291997\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=216, batch=15 train loss <loss>=8.30279512405\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] Epoch[216] Batch [15]#011Speed: 1875.18 samples/sec#011loss=8.302795\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] Epoch[216] Batch[20] avg_epoch_loss=8.219715\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] #quality_metric: host=algo-1, epoch=216, batch=20 train loss <loss>=7.98840923309\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:29 INFO 139919921551168] Epoch[216] Batch [20]#011Speed: 1122.52 samples/sec#011loss=7.988409\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] Epoch[216] Batch[25] avg_epoch_loss=8.157165\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=216, batch=25 train loss <loss>=7.89445581436\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] Epoch[216] Batch [25]#011Speed: 2087.58 samples/sec#011loss=7.894456\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] Epoch[216] Batch[30] avg_epoch_loss=8.082739\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=216, batch=30 train loss <loss>=7.69572296143\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] Epoch[216] Batch [30]#011Speed: 1065.85 samples/sec#011loss=7.695723\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] Epoch[216] Batch[35] avg_epoch_loss=8.022355\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=216, batch=35 train loss <loss>=7.64797916412\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] Epoch[216] Batch [35]#011Speed: 2092.46 samples/sec#011loss=7.647979\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] Epoch[216] Batch[40] avg_epoch_loss=7.982273\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=216, batch=40 train loss <loss>=7.6936788559\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] Epoch[216] Batch [40]#011Speed: 1145.05 samples/sec#011loss=7.693679\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] Epoch[216] Batch[45] avg_epoch_loss=7.999423\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=216, batch=45 train loss <loss>=8.14005556107\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] Epoch[216] Batch [45]#011Speed: 1438.54 samples/sec#011loss=8.140056\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] processed a total of 1551 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1203.233003616333, \"sum\": 1203.233003616333, \"min\": 1203.233003616333}}, \"EndTime\": 1578471810.600386, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471809.39671}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1288.89561503 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=216, train loss <loss>=7.96227850233\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] Epoch[217] Batch[0] avg_epoch_loss=7.872442\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=217, batch=0 train loss <loss>=7.87244224548\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] Epoch[217] Batch[5] avg_epoch_loss=7.957574\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=217, batch=5 train loss <loss>=7.95757365227\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] Epoch[217] Batch [5]#011Speed: 2081.44 samples/sec#011loss=7.957574\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] Epoch[217] Batch[10] avg_epoch_loss=8.024867\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] #quality_metric: host=algo-1, epoch=217, batch=10 train loss <loss>=8.10561847687\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:30 INFO 139919921551168] Epoch[217] Batch [10]#011Speed: 997.95 samples/sec#011loss=8.105618\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] Epoch[217] Batch[15] avg_epoch_loss=8.220730\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=217, batch=15 train loss <loss>=8.65162830353\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] Epoch[217] Batch [15]#011Speed: 2136.21 samples/sec#011loss=8.651628\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] Epoch[217] Batch[20] avg_epoch_loss=8.248951\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=217, batch=20 train loss <loss>=8.33925704956\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] Epoch[217] Batch [20]#011Speed: 1018.28 samples/sec#011loss=8.339257\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] Epoch[217] Batch[25] avg_epoch_loss=8.161627\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=217, batch=25 train loss <loss>=7.79486818314\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] Epoch[217] Batch [25]#011Speed: 2081.00 samples/sec#011loss=7.794868\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] Epoch[217] Batch[30] avg_epoch_loss=8.108351\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=217, batch=30 train loss <loss>=7.83131694794\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] Epoch[217] Batch [30]#011Speed: 1052.01 samples/sec#011loss=7.831317\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] Epoch[217] Batch[35] avg_epoch_loss=8.066253\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=217, batch=35 train loss <loss>=7.80524606705\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] Epoch[217] Batch [35]#011Speed: 2075.63 samples/sec#011loss=7.805246\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] Epoch[217] Batch[40] avg_epoch_loss=8.042145\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=217, batch=40 train loss <loss>=7.86856431961\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] Epoch[217] Batch [40]#011Speed: 1097.72 samples/sec#011loss=7.868564\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] Epoch[217] Batch[45] avg_epoch_loss=8.035987\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=217, batch=45 train loss <loss>=7.98548879623\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] Epoch[217] Batch [45]#011Speed: 2045.96 samples/sec#011loss=7.985489\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] Epoch[217] Batch[50] avg_epoch_loss=7.975653\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=217, batch=50 train loss <loss>=7.42058725357\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] Epoch[217] Batch [50]#011Speed: 1727.86 samples/sec#011loss=7.420587\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] processed a total of 1625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1191.415786743164, \"sum\": 1191.415786743164, \"min\": 1191.415786743164}}, \"EndTime\": 1578471811.792325, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471810.600474}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1363.79851361 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=217, train loss <loss>=7.97565331179\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] Epoch[218] Batch[0] avg_epoch_loss=7.284935\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=218, batch=0 train loss <loss>=7.28493452072\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] Epoch[218] Batch[5] avg_epoch_loss=8.052234\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] #quality_metric: host=algo-1, epoch=218, batch=5 train loss <loss>=8.05223361651\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:31 INFO 139919921551168] Epoch[218] Batch [5]#011Speed: 1937.59 samples/sec#011loss=8.052234\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] Epoch[218] Batch[10] avg_epoch_loss=7.928718\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=218, batch=10 train loss <loss>=7.7804983139\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] Epoch[218] Batch [10]#011Speed: 955.40 samples/sec#011loss=7.780498\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] Epoch[218] Batch[15] avg_epoch_loss=8.000836\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=218, batch=15 train loss <loss>=8.15949783325\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] Epoch[218] Batch [15]#011Speed: 1909.24 samples/sec#011loss=8.159498\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] Epoch[218] Batch[20] avg_epoch_loss=8.111325\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=218, batch=20 train loss <loss>=8.46488990784\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] Epoch[218] Batch [20]#011Speed: 1930.62 samples/sec#011loss=8.464890\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] Epoch[218] Batch[25] avg_epoch_loss=8.003165\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=218, batch=25 train loss <loss>=7.54889335632\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] Epoch[218] Batch [25]#011Speed: 967.85 samples/sec#011loss=7.548893\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] Epoch[218] Batch[30] avg_epoch_loss=7.956699\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=218, batch=30 train loss <loss>=7.71507520676\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] Epoch[218] Batch [30]#011Speed: 2068.60 samples/sec#011loss=7.715075\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] Epoch[218] Batch[35] avg_epoch_loss=7.867774\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=218, batch=35 train loss <loss>=7.31643829346\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] Epoch[218] Batch [35]#011Speed: 1038.45 samples/sec#011loss=7.316438\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] Epoch[218] Batch[40] avg_epoch_loss=7.834897\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=218, batch=40 train loss <loss>=7.5981798172\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] Epoch[218] Batch [40]#011Speed: 2075.14 samples/sec#011loss=7.598180\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] Epoch[218] Batch[45] avg_epoch_loss=7.812313\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] #quality_metric: host=algo-1, epoch=218, batch=45 train loss <loss>=7.6271282196\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:32 INFO 139919921551168] Epoch[218] Batch [45]#011Speed: 1060.41 samples/sec#011loss=7.627128\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] Epoch[218] Batch[50] avg_epoch_loss=7.862140\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=218, batch=50 train loss <loss>=8.32055149078\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] Epoch[218] Batch [50]#011Speed: 2052.36 samples/sec#011loss=8.320551\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] processed a total of 1664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1241.9190406799316, \"sum\": 1241.9190406799316, \"min\": 1241.9190406799316}}, \"EndTime\": 1578471813.034744, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471811.7924}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1339.73664054 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=218, train loss <loss>=7.85055633692\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] Epoch[219] Batch[0] avg_epoch_loss=8.030491\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=219, batch=0 train loss <loss>=8.03049087524\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] Epoch[219] Batch[5] avg_epoch_loss=8.372424\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=219, batch=5 train loss <loss>=8.37242364883\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] Epoch[219] Batch [5]#011Speed: 1893.94 samples/sec#011loss=8.372424\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] Epoch[219] Batch[10] avg_epoch_loss=8.286322\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=219, batch=10 train loss <loss>=8.18300027847\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] Epoch[219] Batch [10]#011Speed: 914.29 samples/sec#011loss=8.183000\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] Epoch[219] Batch[15] avg_epoch_loss=8.351270\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=219, batch=15 train loss <loss>=8.49415397644\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] Epoch[219] Batch [15]#011Speed: 1737.43 samples/sec#011loss=8.494154\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] Epoch[219] Batch[20] avg_epoch_loss=8.273398\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=219, batch=20 train loss <loss>=8.02420721054\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] Epoch[219] Batch [20]#011Speed: 943.17 samples/sec#011loss=8.024207\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] Epoch[219] Batch[25] avg_epoch_loss=8.205228\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=219, batch=25 train loss <loss>=7.91891469955\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] Epoch[219] Batch [25]#011Speed: 1824.38 samples/sec#011loss=7.918915\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] Epoch[219] Batch[30] avg_epoch_loss=8.153201\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=219, batch=30 train loss <loss>=7.88266429901\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] Epoch[219] Batch [30]#011Speed: 953.55 samples/sec#011loss=7.882664\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] Epoch[219] Batch[35] avg_epoch_loss=8.085210\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] #quality_metric: host=algo-1, epoch=219, batch=35 train loss <loss>=7.66366262436\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:33 INFO 139919921551168] Epoch[219] Batch [35]#011Speed: 1736.64 samples/sec#011loss=7.663663\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] Epoch[219] Batch[40] avg_epoch_loss=8.056282\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=219, batch=40 train loss <loss>=7.84799785614\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] Epoch[219] Batch [40]#011Speed: 949.37 samples/sec#011loss=7.847998\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] Epoch[219] Batch[45] avg_epoch_loss=8.031032\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=219, batch=45 train loss <loss>=7.82398891449\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] Epoch[219] Batch [45]#011Speed: 2137.10 samples/sec#011loss=7.823989\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] Epoch[219] Batch[50] avg_epoch_loss=7.986273\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=219, batch=50 train loss <loss>=7.57448301315\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] Epoch[219] Batch [50]#011Speed: 1603.75 samples/sec#011loss=7.574483\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] processed a total of 1623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1299.4320392608643, \"sum\": 1299.4320392608643, \"min\": 1299.4320392608643}}, \"EndTime\": 1578471814.334718, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471813.034824}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1248.90250043 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=219, train loss <loss>=7.98627267164\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] Epoch[220] Batch[0] avg_epoch_loss=8.353592\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=220, batch=0 train loss <loss>=8.35359191895\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] Epoch[220] Batch[5] avg_epoch_loss=8.121958\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=220, batch=5 train loss <loss>=8.12195833524\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] Epoch[220] Batch [5]#011Speed: 1915.27 samples/sec#011loss=8.121958\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] Epoch[220] Batch[10] avg_epoch_loss=8.225366\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=220, batch=10 train loss <loss>=8.34945602417\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] Epoch[220] Batch [10]#011Speed: 990.68 samples/sec#011loss=8.349456\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] Epoch[220] Batch[15] avg_epoch_loss=8.270647\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=220, batch=15 train loss <loss>=8.3702630043\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] Epoch[220] Batch [15]#011Speed: 2149.84 samples/sec#011loss=8.370263\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] Epoch[220] Batch[20] avg_epoch_loss=8.278475\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=220, batch=20 train loss <loss>=8.30352506638\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] Epoch[220] Batch [20]#011Speed: 1019.91 samples/sec#011loss=8.303525\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] Epoch[220] Batch[25] avg_epoch_loss=8.201763\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] #quality_metric: host=algo-1, epoch=220, batch=25 train loss <loss>=7.87957372665\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:34 INFO 139919921551168] Epoch[220] Batch [25]#011Speed: 1939.98 samples/sec#011loss=7.879574\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] Epoch[220] Batch[30] avg_epoch_loss=8.132791\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=220, batch=30 train loss <loss>=7.77413330078\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] Epoch[220] Batch [30]#011Speed: 1020.81 samples/sec#011loss=7.774133\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] Epoch[220] Batch[35] avg_epoch_loss=8.101077\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=220, batch=35 train loss <loss>=7.90445137024\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] Epoch[220] Batch [35]#011Speed: 2175.75 samples/sec#011loss=7.904451\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] Epoch[220] Batch[40] avg_epoch_loss=8.070643\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=220, batch=40 train loss <loss>=7.85151634216\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] Epoch[220] Batch [40]#011Speed: 1025.44 samples/sec#011loss=7.851516\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] Epoch[220] Batch[45] avg_epoch_loss=8.064479\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=220, batch=45 train loss <loss>=8.01393852234\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] Epoch[220] Batch [45]#011Speed: 2064.30 samples/sec#011loss=8.013939\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] processed a total of 1582 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1203.585147857666, \"sum\": 1203.585147857666, \"min\": 1203.585147857666}}, \"EndTime\": 1578471815.538782, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471814.334793}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1314.28427957 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=220, train loss <loss>=8.00292507172\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] Epoch[221] Batch[0] avg_epoch_loss=8.060848\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=221, batch=0 train loss <loss>=8.06084823608\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] Epoch[221] Batch[5] avg_epoch_loss=8.121888\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=221, batch=5 train loss <loss>=8.12188816071\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] Epoch[221] Batch [5]#011Speed: 2051.05 samples/sec#011loss=8.121888\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] Epoch[221] Batch[10] avg_epoch_loss=8.093566\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=221, batch=10 train loss <loss>=8.0595785141\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] Epoch[221] Batch [10]#011Speed: 1095.64 samples/sec#011loss=8.059579\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] Epoch[221] Batch[15] avg_epoch_loss=8.222102\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] #quality_metric: host=algo-1, epoch=221, batch=15 train loss <loss>=8.50488300323\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:35 INFO 139919921551168] Epoch[221] Batch [15]#011Speed: 1609.69 samples/sec#011loss=8.504883\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] Epoch[221] Batch[20] avg_epoch_loss=8.215992\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=221, batch=20 train loss <loss>=8.19643859863\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] Epoch[221] Batch [20]#011Speed: 880.61 samples/sec#011loss=8.196439\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] Epoch[221] Batch[25] avg_epoch_loss=8.170484\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=221, batch=25 train loss <loss>=7.97934942245\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] Epoch[221] Batch [25]#011Speed: 2170.05 samples/sec#011loss=7.979349\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] Epoch[221] Batch[30] avg_epoch_loss=8.115970\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=221, batch=30 train loss <loss>=7.8324965477\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] Epoch[221] Batch [30]#011Speed: 1012.90 samples/sec#011loss=7.832497\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] Epoch[221] Batch[35] avg_epoch_loss=8.056754\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=221, batch=35 train loss <loss>=7.68961858749\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] Epoch[221] Batch [35]#011Speed: 2066.06 samples/sec#011loss=7.689619\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] Epoch[221] Batch[40] avg_epoch_loss=8.007784\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=221, batch=40 train loss <loss>=7.65520105362\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] Epoch[221] Batch [40]#011Speed: 1081.97 samples/sec#011loss=7.655201\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] Epoch[221] Batch[45] avg_epoch_loss=7.997033\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=221, batch=45 train loss <loss>=7.90887508392\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] Epoch[221] Batch [45]#011Speed: 2060.37 samples/sec#011loss=7.908875\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] Epoch[221] Batch[50] avg_epoch_loss=7.924764\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=221, batch=50 train loss <loss>=7.25988607407\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] Epoch[221] Batch [50]#011Speed: 1382.60 samples/sec#011loss=7.259886\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] processed a total of 1643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1267.6458358764648, \"sum\": 1267.6458358764648, \"min\": 1267.6458358764648}}, \"EndTime\": 1578471816.806975, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471815.538858}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1295.99170113 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=221, train loss <loss>=7.92119359053\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] Epoch[222] Batch[0] avg_epoch_loss=8.225924\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:36 INFO 139919921551168] #quality_metric: host=algo-1, epoch=222, batch=0 train loss <loss>=8.22592449188\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] Epoch[222] Batch[5] avg_epoch_loss=7.875771\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=222, batch=5 train loss <loss>=7.87577104568\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] Epoch[222] Batch [5]#011Speed: 1723.38 samples/sec#011loss=7.875771\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] Epoch[222] Batch[10] avg_epoch_loss=7.922125\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=222, batch=10 train loss <loss>=7.9777504921\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] Epoch[222] Batch [10]#011Speed: 927.72 samples/sec#011loss=7.977750\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] Epoch[222] Batch[15] avg_epoch_loss=7.998542\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=222, batch=15 train loss <loss>=8.16665935516\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] Epoch[222] Batch [15]#011Speed: 2162.37 samples/sec#011loss=8.166659\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] Epoch[222] Batch[20] avg_epoch_loss=8.022314\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=222, batch=20 train loss <loss>=8.0983836174\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] Epoch[222] Batch [20]#011Speed: 978.19 samples/sec#011loss=8.098384\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] Epoch[222] Batch[25] avg_epoch_loss=7.975147\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=222, batch=25 train loss <loss>=7.77704772949\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] Epoch[222] Batch [25]#011Speed: 2147.50 samples/sec#011loss=7.777048\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] Epoch[222] Batch[30] avg_epoch_loss=7.912245\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=222, batch=30 train loss <loss>=7.58515319824\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] Epoch[222] Batch [30]#011Speed: 949.52 samples/sec#011loss=7.585153\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] Epoch[222] Batch[35] avg_epoch_loss=7.860231\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=222, batch=35 train loss <loss>=7.53774261475\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] Epoch[222] Batch [35]#011Speed: 2085.75 samples/sec#011loss=7.537743\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] Epoch[222] Batch[40] avg_epoch_loss=7.876486\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=222, batch=40 train loss <loss>=7.99352416992\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] Epoch[222] Batch [40]#011Speed: 1078.79 samples/sec#011loss=7.993524\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] Epoch[222] Batch[45] avg_epoch_loss=7.885676\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] #quality_metric: host=algo-1, epoch=222, batch=45 train loss <loss>=7.96103448868\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:37 INFO 139919921551168] Epoch[222] Batch [45]#011Speed: 2012.71 samples/sec#011loss=7.961034\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] Epoch[222] Batch[50] avg_epoch_loss=7.847956\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=222, batch=50 train loss <loss>=7.50093107224\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] Epoch[222] Batch [50]#011Speed: 1715.08 samples/sec#011loss=7.500931\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] processed a total of 1602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1253.6540031433105, \"sum\": 1253.6540031433105, \"min\": 1253.6540031433105}}, \"EndTime\": 1578471818.061137, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471816.80705}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1277.74838876 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=222, train loss <loss>=7.84795607773\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] Epoch[223] Batch[0] avg_epoch_loss=7.981335\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=223, batch=0 train loss <loss>=7.98133516312\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] Epoch[223] Batch[5] avg_epoch_loss=8.196816\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=223, batch=5 train loss <loss>=8.19681580861\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] Epoch[223] Batch [5]#011Speed: 1862.39 samples/sec#011loss=8.196816\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] Epoch[223] Batch[10] avg_epoch_loss=8.255655\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=223, batch=10 train loss <loss>=8.32626171112\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] Epoch[223] Batch [10]#011Speed: 1017.95 samples/sec#011loss=8.326262\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] Epoch[223] Batch[15] avg_epoch_loss=8.290423\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=223, batch=15 train loss <loss>=8.36691188812\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] Epoch[223] Batch [15]#011Speed: 2065.10 samples/sec#011loss=8.366912\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] Epoch[223] Batch[20] avg_epoch_loss=8.294244\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=223, batch=20 train loss <loss>=8.3064702034\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] Epoch[223] Batch [20]#011Speed: 844.52 samples/sec#011loss=8.306470\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] Epoch[223] Batch[25] avg_epoch_loss=8.213037\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=223, batch=25 train loss <loss>=7.87196826935\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] Epoch[223] Batch [25]#011Speed: 1887.62 samples/sec#011loss=7.871968\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] Epoch[223] Batch[30] avg_epoch_loss=8.159481\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] #quality_metric: host=algo-1, epoch=223, batch=30 train loss <loss>=7.88099393845\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:38 INFO 139919921551168] Epoch[223] Batch [30]#011Speed: 1032.25 samples/sec#011loss=7.880994\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] Epoch[223] Batch[35] avg_epoch_loss=8.088917\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=223, batch=35 train loss <loss>=7.65142097473\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] Epoch[223] Batch [35]#011Speed: 1639.65 samples/sec#011loss=7.651421\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] Epoch[223] Batch[40] avg_epoch_loss=8.044811\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=223, batch=40 train loss <loss>=7.72724781036\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] Epoch[223] Batch [40]#011Speed: 978.28 samples/sec#011loss=7.727248\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] Epoch[223] Batch[45] avg_epoch_loss=8.041789\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=223, batch=45 train loss <loss>=8.01700143814\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] Epoch[223] Batch [45]#011Speed: 2075.52 samples/sec#011loss=8.017001\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] processed a total of 1571 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1256.2201023101807, \"sum\": 1256.2201023101807, \"min\": 1256.2201023101807}}, \"EndTime\": 1578471819.317877, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471818.061214}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] #throughput_metric: host=algo-1, train throughput=1250.47141561 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] #quality_metric: host=algo-1, epoch=223, train loss <loss>=7.96225250244\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] Loading parameters from best epoch (183)\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.deserialize.time\": {\"count\": 1, \"max\": 5.501985549926758, \"sum\": 5.501985549926758, \"min\": 5.501985549926758}}, \"EndTime\": 1578471819.324011, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471819.317946}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] stopping training now\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] Final loss: 7.79499479294 (occurred at epoch 183)\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] #quality_metric: host=algo-1, train final_loss <loss>=7.79499479294\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 WARNING 139919921551168] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 56.69689178466797, \"sum\": 56.69689178466797, \"min\": 56.69689178466797}}, \"EndTime\": 1578471819.38143, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471819.324061}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 83.76884460449219, \"sum\": 83.76884460449219, \"min\": 83.76884460449219}}, \"EndTime\": 1578471819.408475, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471819.381479}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 4.453897476196289, \"sum\": 4.453897476196289, \"min\": 4.453897476196289}}, \"EndTime\": 1578471819.413022, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471819.408529}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:39 INFO 139919921551168] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 0.03790855407714844, \"sum\": 0.03790855407714844, \"min\": 0.03790855407714844}}, \"EndTime\": 1578471819.413688, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471819.413062}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:41 INFO 139919921551168] Number of test batches scored: 10\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:23:44 INFO 139919921551168] Number of test batches scored: 20\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:46 INFO 139919921551168] Number of test batches scored: 30\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:48 INFO 139919921551168] Number of test batches scored: 40\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:51 INFO 139919921551168] Number of test batches scored: 50\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.score.time\": {\"count\": 1, \"max\": 11760.447025299072, \"sum\": 11760.447025299072, \"min\": 11760.447025299072}}, \"EndTime\": 1578471831.1741, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471819.413731}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:51 INFO 139919921551168] #test_score (algo-1, RMSE): 29551.6870584\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:51 INFO 139919921551168] #test_score (algo-1, mean_wQuantileLoss): 0.30525714\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:51 INFO 139919921551168] #test_score (algo-1, wQuantileLoss[0.1]): 0.18222009\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:51 INFO 139919921551168] #test_score (algo-1, wQuantileLoss[0.2]): 0.2988094\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:51 INFO 139919921551168] #test_score (algo-1, wQuantileLoss[0.3]): 0.36139387\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:51 INFO 139919921551168] #test_score (algo-1, wQuantileLoss[0.4]): 0.38409927\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:51 INFO 139919921551168] #test_score (algo-1, wQuantileLoss[0.5]): 0.38464084\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:51 INFO 139919921551168] #test_score (algo-1, wQuantileLoss[0.6]): 0.3653904\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:51 INFO 139919921551168] #test_score (algo-1, wQuantileLoss[0.7]): 0.32531098\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:51 INFO 139919921551168] #test_score (algo-1, wQuantileLoss[0.8]): 0.26719218\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:51 INFO 139919921551168] #test_score (algo-1, wQuantileLoss[0.9]): 0.17825715\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:51 INFO 139919921551168] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.30525714159\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:23:51 INFO 139919921551168] #quality_metric: host=algo-1, test RMSE <loss>=29551.6870584\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 300340.696811676, \"sum\": 300340.696811676, \"min\": 300340.696811676}, \"setuptime\": {\"count\": 1, \"max\": 10.757923126220703, \"sum\": 10.757923126220703, \"min\": 10.757923126220703}}, \"EndTime\": 1578471831.184307, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578471831.174186}\n",
      "\u001b[0m\n",
      "\n",
      "2020-01-08 08:24:01 Uploading - Uploading generated training model\n",
      "2020-01-08 08:24:01 Completed - Training job completed\n",
      "Training seconds: 363\n",
      "Billable seconds: 363\n",
      "CPU times: user 1.43 s, sys: 159 ms, total: 1.59 s\n",
      "Wall time: 8min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\n",
    "    \"train\": \"{}/train/\".format(s3_data_path),\n",
    "    \"test\": \"{}/test/\".format(s3_data_path)\n",
    "}\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you pass a test set in this example, accuracy metrics for the forecast are computed and logged (see bottom of the log).\n",
    "You can find the definition of these metrics from [our documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html). You can use these to optimize the parameters and tune your model or use SageMaker's [Automated Model Tuning service](https://aws.amazon.com/blogs/aws/sagemaker-automatic-model-tuning/) to tune the model for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint and predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a trained model, we can use it to perform predictions by deploying it to an endpoint.\n",
    "\n",
    "**Note: Remember to delete the endpoint after running this experiment. A cell at the very bottom of this notebook will do that: make sure you run it at the end.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To query the endpoint and perform predictions, we can define the following utility class: this allows making requests using `pandas.Series` objects rather than raw JSON strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepARPredictor(sagemaker.predictor.RealTimePredictor):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, content_type=sagemaker.content_types.CONTENT_TYPE_JSON, **kwargs)\n",
    "        \n",
    "    def predict(self, ts, cat=None, dynamic_feat=None, \n",
    "                num_samples=100, return_samples=False, quantiles=[\"0.1\", \"0.5\", \"0.9\"]):\n",
    "        \"\"\"Requests the prediction of for the time series listed in `ts`, each with the (optional)\n",
    "        corresponding category listed in `cat`.\n",
    "        \n",
    "        ts -- `pandas.Series` object, the time series to predict\n",
    "        cat -- integer, the group associated to the time series (default: None)\n",
    "        num_samples -- integer, number of samples to compute at prediction time (default: 100)\n",
    "        return_samples -- boolean indicating whether to include samples in the response (default: False)\n",
    "        quantiles -- list of strings specifying the quantiles to compute (default: [\"0.1\", \"0.5\", \"0.9\"])\n",
    "        \n",
    "        Return value: list of `pandas.DataFrame` objects, each containing the predictions\n",
    "        \"\"\"\n",
    "        prediction_time = ts.index[-1] + 1\n",
    "        quantiles = [str(q) for q in quantiles]\n",
    "        req = self.__encode_request(ts, cat, dynamic_feat, num_samples, return_samples, quantiles)\n",
    "        res = super(DeepARPredictor, self).predict(req)\n",
    "        return self.__decode_response(res, ts.index.freq, prediction_time, return_samples)\n",
    "    \n",
    "    def __encode_request(self, ts, cat, dynamic_feat, num_samples, return_samples, quantiles):\n",
    "        instance = series_to_dict(ts, cat if cat is not None else None, dynamic_feat if dynamic_feat else None)\n",
    "\n",
    "        configuration = {\n",
    "            \"num_samples\": num_samples,\n",
    "            \"output_types\": [\"quantiles\", \"samples\"] if return_samples else [\"quantiles\"],\n",
    "            \"quantiles\": quantiles\n",
    "        }\n",
    "        \n",
    "        http_request_data = {\n",
    "            \"instances\": [instance],\n",
    "            \"configuration\": configuration\n",
    "        }\n",
    "        \n",
    "        return json.dumps(http_request_data).encode('utf-8')\n",
    "    \n",
    "    def __decode_response(self, response, freq, prediction_time, return_samples):\n",
    "        # we only sent one time series so we only receive one in return\n",
    "        # however, if possible one will pass multiple time series as predictions will then be faster\n",
    "        predictions = json.loads(response.decode('utf-8'))['predictions'][0]\n",
    "        prediction_length = len(next(iter(predictions['quantiles'].values())))\n",
    "        prediction_index = pd.DatetimeIndex(start=prediction_time, freq=freq, periods=prediction_length)        \n",
    "        if return_samples:\n",
    "            dict_of_samples = {'sample_' + str(i): s for i, s in enumerate(predictions['samples'])}\n",
    "        else:\n",
    "            dict_of_samples = {}\n",
    "        return pd.DataFrame(data={**predictions['quantiles'], **dict_of_samples}, index=prediction_index)\n",
    "\n",
    "    def set_frequency(self, freq):\n",
    "        self.freq = freq\n",
    "        \n",
    "def encode_target(ts):\n",
    "    return [x if np.isfinite(x) else \"NaN\" for x in ts]        \n",
    "\n",
    "def series_to_dict(ts, cat=None, dynamic_feat=None):\n",
    "    \"\"\"Given a pandas.Series object, returns a dictionary encoding the time series.\n",
    "\n",
    "    ts -- a pands.Series object with the target time series\n",
    "    cat -- an integer indicating the time series category\n",
    "\n",
    "    Return value: a dictionary\n",
    "    \"\"\"\n",
    "    obj = {\"start\": str(ts.index[0]), \"target\": encode_target(ts)}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    if dynamic_feat is not None:\n",
    "        obj[\"dynamic_feat\"] = dynamic_feat        \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can deploy the model and create and endpoint that can be queried using our custom DeepARPredictor class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    predictor_cls=DeepARPredictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions and plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `predictor` object to generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:1: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:19: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:46: FutureWarning: Creating a DatetimeIndex by passing range endpoints is deprecated.  Use `pandas.date_range` instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.9</th>\n",
       "      <th>0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-09-24</th>\n",
       "      <td>-23.536985</td>\n",
       "      <td>43.095425</td>\n",
       "      <td>9.165945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-25</th>\n",
       "      <td>-22.334675</td>\n",
       "      <td>33.556595</td>\n",
       "      <td>6.025610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-26</th>\n",
       "      <td>-4.777271</td>\n",
       "      <td>32.448799</td>\n",
       "      <td>13.316997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-27</th>\n",
       "      <td>-0.875710</td>\n",
       "      <td>25.621033</td>\n",
       "      <td>12.435307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-28</th>\n",
       "      <td>-5.981627</td>\n",
       "      <td>27.068731</td>\n",
       "      <td>12.550020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-29</th>\n",
       "      <td>-3.012745</td>\n",
       "      <td>35.820847</td>\n",
       "      <td>11.772906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-30</th>\n",
       "      <td>-4.211638</td>\n",
       "      <td>26.411697</td>\n",
       "      <td>10.784533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0.1        0.9        0.5\n",
       "2019-09-24 -23.536985  43.095425   9.165945\n",
       "2019-09-25 -22.334675  33.556595   6.025610\n",
       "2019-09-26  -4.777271  32.448799  13.316997\n",
       "2019-09-27  -0.875710  25.621033  12.435307\n",
       "2019-09-28  -5.981627  27.068731  12.550020\n",
       "2019-09-29  -3.012745  35.820847  11.772906\n",
       "2019-09-30  -4.211638  26.411697  10.784533"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(ts=timeseries[0][start_dataset:end_test-1],quantiles=[0.10, 0.5, 0.90])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define a plotting function that queries the model and displays the forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(\n",
    "    predictor, \n",
    "    target_ts, \n",
    "    cat=None, \n",
    "    dynamic_feat=None, \n",
    "    forecast_date=end_training, \n",
    "    show_samples=False, \n",
    "    plot_history=7 * 12,\n",
    "    confidence=80\n",
    "):\n",
    "    print(\"calling served model to generate predictions starting from {}\".format(str(forecast_date)))\n",
    "    assert(confidence > 50 and confidence < 100)\n",
    "    low_quantile = 0.5 - confidence * 0.005\n",
    "    up_quantile = confidence * 0.005 + 0.5\n",
    "        \n",
    "    # we first construct the argument to call our model\n",
    "    args = {\n",
    "        \"ts\": target_ts[:forecast_date],\n",
    "        \"return_samples\": show_samples,\n",
    "        \"quantiles\": [low_quantile, 0.5, up_quantile],\n",
    "        \"num_samples\": 100\n",
    "    }\n",
    "\n",
    "\n",
    "    if dynamic_feat is not None:\n",
    "        args[\"dynamic_feat\"] = dynamic_feat\n",
    "        fig = plt.figure(figsize=(20, 12))\n",
    "        ax = plt.subplot(2, 1, 1)\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(20, 6))\n",
    "        ax = plt.subplot(1,1,1)\n",
    "    \n",
    "    if cat is not None:\n",
    "        args[\"cat\"] = cat\n",
    "        ax.text(0.9, 0.9, 'cat = {}'.format(cat), transform=ax.transAxes)\n",
    "\n",
    "    # call the end point to get the prediction\n",
    "    prediction = predictor.predict(**args)\n",
    "\n",
    "    # plot the samples\n",
    "    if show_samples: \n",
    "        for key in prediction.keys():\n",
    "            if \"sample\" in key:\n",
    "                prediction[key].plot(color='lightskyblue', alpha=0.2, label='_nolegend_')\n",
    "                \n",
    "                \n",
    "    # plot the target\n",
    "    target_section = target_ts[forecast_date-plot_history:forecast_date+prediction_length]\n",
    "    target_section.plot(color=\"black\", label='target')\n",
    "    \n",
    "    # plot the confidence interval and the median predicted\n",
    "    ax.fill_between(\n",
    "        prediction[str(low_quantile)].index, \n",
    "        prediction[str(low_quantile)].values, \n",
    "        prediction[str(up_quantile)].values, \n",
    "        color=\"b\", alpha=0.3, label='{}% confidence interval'.format(confidence)\n",
    "    )\n",
    "    prediction[\"0.5\"].plot(color=\"b\", label='P50')\n",
    "    ax.legend(loc=2)    \n",
    "    \n",
    "    # fix the scale as the samples may change it\n",
    "    ax.set_ylim(target_section.min() * 0.5, target_section.max() * 1.5)\n",
    "    \n",
    "    if dynamic_feat is not None:\n",
    "        for i, f in enumerate(dynamic_feat, start=1):\n",
    "            ax = plt.subplot(len(dynamic_feat) * 2, 1, len(dynamic_feat) + i, sharex=ax)\n",
    "            feat_ts = pd.Series(\n",
    "                index=pd.DatetimeIndex(start=target_ts.index[0], freq=target_ts.index.freq, periods=len(f)),\n",
    "                data=f\n",
    "            )\n",
    "            feat_ts[forecast_date-plot_history:forecast_date+prediction_length].plot(ax=ax, color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interact with the function previously defined, to look at the forecast of any customer at any point in (future) time. \n",
    "\n",
    "For each request, the predictions are obtained by calling our served model on the fly.\n",
    "\n",
    "Here we forecast the consumption of an office after week-end (note the lower week-end consumption). \n",
    "You can select any time series and any forecast date, just click on `Run Interact` to generate the predictions from our served endpoint and see the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "style = {'description_width': 'initial'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61c3fe0c05747e58b121ca1d209380f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=120, description='customer_id', max=1603, style=SliderStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "@interact_manual(\n",
    "    customer_id=IntSlider(min=0, max=1603, value=120, style=style), \n",
    "#     forecast_day= prediction_length,\n",
    "    confidence=IntSlider(min=60, max=95, value=80, step=5, style=style),\n",
    "    history_days_plot=IntSlider(min=1, max=50, value=7, style=style),\n",
    "    show_samples=Checkbox(value=False),\n",
    "    continuous_update=False\n",
    ")\n",
    "def plot_interact(customer_id, confidence, history_days_plot, show_samples):\n",
    "    plot(\n",
    "        predictor,\n",
    "        target_ts=timeseries[customer_id],\n",
    "        forecast_date= start_predict -1,#end_training + datetime.timedelta(days=forecast_day),\n",
    "        show_samples=show_samples,\n",
    "        plot_history=history_days_plot,\n",
    "        confidence=confidence\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:6: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:19: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:46: FutureWarning: Creating a DatetimeIndex by passing range endpoints is deprecated.  Use `pandas.date_range` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.91 s, sys: 65 ms, total: 4.98 s\n",
      "Wall time: 46.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "preds = []\n",
    "quantiles=[0.10, 0.5, 0.90]\n",
    "\n",
    "for i, ts_dict in enumerate(timeseries):\n",
    "    ts = ts_dict[start_dataset:end_test-1]\n",
    "    if ts.shape[0] == 0:\n",
    "        preds.append(None)\n",
    "        continue\n",
    "    pred = predictor.predict(ts=ts, quantiles=quantiles)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predict result and label data into a csv for later use\n",
    "df = pd.DataFrame()\n",
    "for i in range(len(timeseries)):\n",
    "    y =  timeseries[i][start_predict:end_predict].fillna(0)\n",
    "    y_hat = preds[i]['0.5']\n",
    "    dd = pd.DataFrame({'store_id':i,'y_label': y, 'y_pred': y_hat})\n",
    "    df = pd.concat([df, dd])\n",
    "df.index.name='date'\n",
    "df.to_csv(\"data/deepar-predict-result.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print sample site stores prediction result, you can print more if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 24\n",
      "RMSE: 1747.5466138892214\n",
      "MAE: 1580.5113281249999\n",
      "Target Mean: 5569.585714285714\n",
      "                 y_pred  y_label\n",
      "2019-09-24  4128.005371   7026.0\n",
      "2019-09-25  4450.132812   4043.6\n",
      "2019-09-26  4376.869141   6221.2\n",
      "2019-09-27  4871.150391   5847.8\n",
      "2019-09-28  6839.270508   5126.7\n",
      "2019-09-29  6986.127930   5775.6\n",
      "2019-09-30  2931.227051   4946.2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 31\n",
      "RMSE: 2083.425849160119\n",
      "MAE: 1708.9270089285567\n",
      "Target Mean: 9007.67142857143\n",
      "                 y_pred  y_label\n",
      "2019-09-24  7375.972168   7383.9\n",
      "2019-09-25  6947.657227   8558.8\n",
      "2019-09-26  6410.788574   9763.9\n",
      "2019-09-27  6179.758789   8243.4\n",
      "2019-09-28  7992.852539   9221.3\n",
      "2019-09-29  9907.239258  10352.9\n",
      "2019-09-30  6276.942383   9529.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 36\n",
      "RMSE: 5180.198995418675\n",
      "MAE: 3824.5450613839284\n",
      "Target Mean: 18153.442857142858\n",
      "                  y_pred  y_label\n",
      "2019-09-24  13529.896484  13646.5\n",
      "2019-09-25  12956.284180  16744.0\n",
      "2019-09-26  12954.523438  15419.9\n",
      "2019-09-27  15751.960938  18162.3\n",
      "2019-09-28  25792.523438  26111.2\n",
      "2019-09-29  22394.568359  15189.3\n",
      "2019-09-30  11333.064453  21800.9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 87\n",
      "RMSE: 8356.881688180623\n",
      "MAE: 7453.349084821428\n",
      "Target Mean: 41728.84428571429\n",
      "                  y_pred   y_label\n",
      "2019-09-24  36762.671875  34817.70\n",
      "2019-09-25  37347.226562  33837.11\n",
      "2019-09-26  38581.914062  32969.10\n",
      "2019-09-27  45389.429688  36843.10\n",
      "2019-09-28  58944.835938  67866.62\n",
      "2019-09-29  53907.312500  39937.69\n",
      "2019-09-30  36162.785156  45830.59\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.13 s, sys: 56.4 ms, total: 2.19 s\n",
      "Wall time: 2.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import metrics\n",
    "\n",
    "def show_metrics(sample_sites, target_quantile='0.5'):\n",
    "    for i in sample_sites:  # TODO len(timeseries)\n",
    "        if preds[i] is None:\n",
    "            continue\n",
    "        \n",
    "        s = timeseries[i].fillna(0)\n",
    "        \n",
    "        print(\"i:\", i)\n",
    "        p10 = preds[i]['0.1']\n",
    "        p90 = preds[i]['0.9']\n",
    "        y_label =  timeseries[i][start_predict:end_predict].fillna(0)\n",
    "        y_pred = preds[i][target_quantile]\n",
    "        if y_label.shape[0] != y_pred.shape[0]:\n",
    "            continue\n",
    "        \n",
    "        print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_label, y_pred)))\n",
    "        print(\"MAE:\",metrics.mean_absolute_error(y_label, y_pred))\n",
    "        print(\"Target Mean:\",y_label.mean())\n",
    "        print(pd.DataFrame({'y_pred': y_pred, 'y_label': y_label}))\n",
    "        plt.figure(figsize=(12,6))\n",
    "        s.plot(label='target %s'%str(i))\n",
    "        plt.fill_between(p10.index, p10, p90, color='y', alpha=0.5, label='80% confidence interval')\n",
    "        y_pred.plot(label='prediction median')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "show_metrics(sample_sites, target_quantile='0.5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional features\n",
    "\n",
    "We have seen how to prepare a dataset and run DeepAR for a simple example.\n",
    "\n",
    "In addition DeepAR supports the following features:\n",
    "\n",
    "* missing values: DeepAR can handle missing values in the time series during training as well as for inference.\n",
    "* Additional time features: DeepAR provides a set default time series features such as hour of day etc. However, you can provide additional feature time series via the `dynamic_feat` field. \n",
    "* generalize frequencies: any integer multiple of the previously supported base frequencies (minutes `min`, hours `H`, days `D`, weeks `W`, month `M`) are now allowed; e.g., `15min`. We already demonstrated this above by using `1D` frequency.\n",
    "* categories: If your time series belong to different groups (e.g. types of product, regions, etc), this information can be encoded as one or more categorical features using the `cat` field.\n",
    "\n",
    "We will now demonstrate categories and time features support. For this part we will reuse the stores sales dataset, we get categories of the stores from data owner and crawler weather data from http://lishi.tianqi.com/shenzhen as dynamic time series: \n",
    "* weather time series will contain: the high temperature, the low temperature of the day, whether is rainy, whether is sunshine, whether is cloudy;\n",
    "* besides that, we add addtional time series that whether the day is weekend;\n",
    "* categories: 1D array for each target series;\n",
    "\n",
    "dynamic_feat: total 6 dynamic_feat, the high temperature, the low temperature, is_sunshine, is_rain, is_cloudy, is_weekend. As the stores are in the same city, so each store time series will use same dynamic_feat values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will read those data as we have prepared in advance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cat is stand for category, here it is a one 1d vector for each store time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = pd.read_csv('data/cat.csv', sep=\",\", index_col=0, parse_dates=True)\n",
    "cat_num_timeseries = cat.shape[0]\n",
    "cat_timeseries = []\n",
    "for i in range(cat_num_timeseries):\n",
    "    cat_timeseries.append(cat.loc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2019-07-10    0\n",
       "2019-07-11    0\n",
       "2019-07-12    0\n",
       "2019-07-13    1\n",
       "2019-07-14    1\n",
       "2019-07-15    0\n",
       "2019-07-16    0\n",
       "2019-07-17    0\n",
       "2019-07-18    0\n",
       "2019-07-19    0\n",
       "2019-07-20    1\n",
       "2019-07-21    1\n",
       "2019-07-22    0\n",
       "2019-07-23    0\n",
       "2019-07-24    0\n",
       "2019-07-25    0\n",
       "2019-07-26    0\n",
       "2019-07-27    1\n",
       "2019-07-28    1\n",
       "2019-07-29    0\n",
       "2019-07-30    0\n",
       "2019-07-31    0\n",
       "2019-08-01    0\n",
       "2019-08-02    0\n",
       "2019-08-03    1\n",
       "2019-08-04    1\n",
       "2019-08-05    0\n",
       "2019-08-06    0\n",
       "2019-08-07    0\n",
       "2019-08-08    0\n",
       "             ..\n",
       "2019-09-01    1\n",
       "2019-09-02    0\n",
       "2019-09-03    0\n",
       "2019-09-04    0\n",
       "2019-09-05    0\n",
       "2019-09-06    0\n",
       "2019-09-07    1\n",
       "2019-09-08    1\n",
       "2019-09-09    0\n",
       "2019-09-10    0\n",
       "2019-09-11    0\n",
       "2019-09-12    0\n",
       "2019-09-13    0\n",
       "2019-09-14    1\n",
       "2019-09-15    1\n",
       "2019-09-16    0\n",
       "2019-09-17    0\n",
       "2019-09-18    0\n",
       "2019-09-19    0\n",
       "2019-09-20    0\n",
       "2019-09-21    1\n",
       "2019-09-22    1\n",
       "2019-09-23    0\n",
       "2019-09-24    0\n",
       "2019-09-25    0\n",
       "2019-09-26    0\n",
       "2019-09-27    0\n",
       "2019-09-28    1\n",
       "2019-09-29    1\n",
       "2019-09-30    0\n",
       "Name: is_weekend, Length: 83, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_weekend = pd.read_csv('data/is_weekend.csv', sep=\",\", index_col=0, parse_dates=True)\n",
    "is_weekend_timeseries = is_weekend.iloc[:,0]\n",
    "is_weekend_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv('data/shenzhen_weather.csv', sep=\",\", index_col=0, parse_dates=True)\n",
    "w_num_timeseries = weather.shape[1]\n",
    "w_timeseries = []\n",
    "for i in range(w_num_timeseries):\n",
    "    w_timeseries.append(weather.iloc[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  app.launch_new_instance()\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:4: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n"
     ]
    }
   ],
   "source": [
    "train_dynamic_feat= []\n",
    "for i in range(5):\n",
    "    train_dynamic_feat.append(w_timeseries[i][start_dataset:end_training -1].tolist())\n",
    "train_dynamic_feat.append(is_weekend_timeseries[start_dataset:end_training -1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  app.launch_new_instance()\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:4: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n"
     ]
    }
   ],
   "source": [
    "test_dynamic_feat= []\n",
    "for i in range(5):\n",
    "    test_dynamic_feat.append(w_timeseries[i][start_dataset:end_test -1].tolist())\n",
    "test_dynamic_feat.append(is_weekend_timeseries[start_dataset:end_test -1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  app.launch_new_instance()\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:4: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n"
     ]
    }
   ],
   "source": [
    "predict_dynamic_feat= []\n",
    "for i in range(5):\n",
    "    predict_dynamic_feat.append(w_timeseries[i][start_dataset:end_predict -1].tolist())\n",
    "predict_dynamic_feat.append(is_weekend_timeseries[start_dataset:end_predict -1].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DeepAR JSON input format represents each time series as a JSON object. In the case each time series consists of a start time stamp (``start``) and a list of values (``target``)as well as ``dynamic_feat`` for time-series features and ``cat`` for categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:9: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1604\n",
      "CPU times: user 427 ms, sys: 7.95 ms, total: 435 ms\n",
      "Wall time: 433 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "training_data_new_features = [\n",
    "    {\n",
    "        \"start\": str(start_dataset),\n",
    "        \"target\": timeseries[i][start_dataset:end_training -1].tolist(),\n",
    "        \"cat\": cat_timeseries[i].tolist(),\n",
    "        \"dynamic_feat\": train_dynamic_feat\n",
    "    }\n",
    "    for i in range(cat_num_timeseries)\n",
    "]\n",
    "print(len(training_data_new_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:8: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1604\n"
     ]
    }
   ],
   "source": [
    "test_data_new_features = [\n",
    "    {\n",
    "        \"start\": str(start_dataset),\n",
    "        \"target\": timeseries[i][start_dataset:end_test -1].tolist(),\n",
    "        \"cat\": cat_timeseries[i].tolist(),\n",
    "        \"dynamic_feat\": test_dynamic_feat\n",
    "    }\n",
    "    for i in range(cat_num_timeseries)\n",
    "]\n",
    "print(len(test_data_new_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataset_consistency(train_dataset, test_dataset=None):\n",
    "    d = train_dataset[0]\n",
    "    has_dynamic_feat = 'dynamic_feat' in d\n",
    "    if has_dynamic_feat:\n",
    "        num_dynamic_feat = len(d['dynamic_feat'])\n",
    "    has_cat = 'cat' in d\n",
    "    if has_cat:\n",
    "        num_cat = len(d['cat'])\n",
    "    \n",
    "    def check_ds(ds):\n",
    "        for i, d in enumerate(ds):\n",
    "            if has_dynamic_feat:\n",
    "                assert 'dynamic_feat' in d\n",
    "                assert num_dynamic_feat == len(d['dynamic_feat'])\n",
    "                for f in d['dynamic_feat']:\n",
    "                    assert len(d['target']) == len(f)\n",
    "                    \n",
    "            if has_cat:\n",
    "                assert 'cat' in d\n",
    "                assert len(d['cat']) == num_cat\n",
    "    check_ds(train_dataset)\n",
    "    if test_dataset is not None:\n",
    "        \n",
    "        check_ds(test_dataset)\n",
    "        \n",
    "check_dataset_consistency(training_data_new_features, test_data_new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the new train and test data to local disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 221 ms, sys: 12 ms, total: 233 ms\n",
      "Wall time: 232 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_dicts_to_file(\"data/train_new_features.json\", training_data_new_features)\n",
    "write_dicts_to_file(\"data/test_new_features.json\", test_data_new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the new train and test data to S3 bucket, here we will use new bucket which has a extend name '-new-features' of the bucket name you used in before case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading to S3 this may take a few minutes depending on your connection.\n",
      "Uploading file to s3://sagemaker-ap-northeast-2-169088282855/tko-ts-workshop-new-features/data/train/train_new_features.json\n",
      "Uploading file to s3://sagemaker-ap-northeast-2-169088282855/tko-ts-workshop-new-features/data/test/test_new_features.json\n",
      "CPU times: user 154 ms, sys: 19.1 ms, total: 173 ms\n",
      "Wall time: 431 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "s3_data_path_new_features = \"s3://{}/{}-new-features/data\".format(s3_bucket, s3_prefix)\n",
    "s3_output_path_new_features = \"s3://{}/{}-new-features/output\".format(s3_bucket, s3_prefix)\n",
    "\n",
    "print('Uploading to S3 this may take a few minutes depending on your connection.')\n",
    "copy_to_s3(\"data/train_new_features.json\", s3_data_path_new_features + \"/train/train_new_features.json\", override=True)\n",
    "copy_to_s3(\"data/test_new_features.json\", s3_data_path_new_features + \"/test/test_new_features.json\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agagin, let's setup the estimator and hyperparameters, then let's fit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-08 08:35:09 Starting - Starting the training job...\n",
      "2020-01-08 08:35:12 Starting - Launching requested ML instances......\n",
      "2020-01-08 08:36:13 Starting - Preparing the instances for training......\n",
      "2020-01-08 08:37:32 Downloading - Downloading input data\n",
      "2020-01-08 08:37:32 Training - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:46 INFO 140719404451648] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:46 INFO 140719404451648] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'num_dynamic_feat': u'auto', u'learning_rate': u'5E-4', u'prediction_length': u'7', u'epochs': u'400', u'time_freq': u'1D', u'context_length': u'14', u'mini_batch_size': u'32', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:46 INFO 140719404451648] Final configuration: {u'dropout_rate': u'0.10', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'5E-4', u'num_layers': u'2', u'epochs': u'400', u'embedding_dimension': u'10', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'32', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'7', u'time_freq': u'1D', u'context_length': u'14', u'_kvstore': u'auto', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:46 INFO 140719404451648] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] Using early stopping with patience 40\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/train_new_features.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train_new_features.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] [cardinality=auto] Inferred value of cardinality=[4, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] from dataset.\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=6 from dataset.\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] Training set statistics:\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] Real time series\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] number of time series: 1604\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] number of observations: 110676\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] mean target length: 69\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] min/mean/max target: 0.0/21018.1296408/1653507.875\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] mean abs(target): 21018.1296408\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] contains missing values: no\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] Test set statistics:\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] Real time series\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] number of time series: 1604\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] number of observations: 121904\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] mean target length: 76\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] min/mean/max target: 0.0/20798.7399189/1653507.875\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] mean abs(target): 20798.7399189\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] contains missing values: no\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] nvidia-smi took: 0.0251657962799 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 51.016807556152344, \"sum\": 51.016807556152344, \"min\": 51.016807556152344}}, \"EndTime\": 1578472667.769071, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472667.717225}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:47 INFO 140719404451648] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 141.7689323425293, \"sum\": 141.7689323425293, \"min\": 141.7689323425293}}, \"EndTime\": 1578472667.859102, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472667.769138}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:48 INFO 140719404451648] Epoch[0] Batch[0] avg_epoch_loss=8.696785\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:48 INFO 140719404451648] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=8.69678497314\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:48 INFO 140719404451648] Epoch[0] Batch[5] avg_epoch_loss=9.188303\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:48 INFO 140719404451648] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=9.18830331167\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:48 INFO 140719404451648] Epoch[0] Batch [5]#011Speed: 1595.45 samples/sec#011loss=9.188303\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:48 INFO 140719404451648] Epoch[0] Batch[10] avg_epoch_loss=9.061432\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:48 INFO 140719404451648] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=8.90918712616\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:48 INFO 140719404451648] Epoch[0] Batch [10]#011Speed: 705.89 samples/sec#011loss=8.909187\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:48 INFO 140719404451648] Epoch[0] Batch[15] avg_epoch_loss=8.983148\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:48 INFO 140719404451648] #quality_metric: host=algo-1, epoch=0, batch=15 train loss <loss>=8.81092090607\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:48 INFO 140719404451648] Epoch[0] Batch [15]#011Speed: 1469.21 samples/sec#011loss=8.810921\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:48 INFO 140719404451648] Epoch[0] Batch[20] avg_epoch_loss=8.876622\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:48 INFO 140719404451648] #quality_metric: host=algo-1, epoch=0, batch=20 train loss <loss>=8.53574085236\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:48 INFO 140719404451648] Epoch[0] Batch [20]#011Speed: 693.06 samples/sec#011loss=8.535741\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:48 INFO 140719404451648] Epoch[0] Batch[25] avg_epoch_loss=8.780155\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:48 INFO 140719404451648] #quality_metric: host=algo-1, epoch=0, batch=25 train loss <loss>=8.37499074936\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:48 INFO 140719404451648] Epoch[0] Batch [25]#011Speed: 1635.01 samples/sec#011loss=8.374991\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:49 INFO 140719404451648] Epoch[0] Batch[30] avg_epoch_loss=8.703469\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:49 INFO 140719404451648] #quality_metric: host=algo-1, epoch=0, batch=30 train loss <loss>=8.30470647812\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:49 INFO 140719404451648] Epoch[0] Batch [30]#011Speed: 766.94 samples/sec#011loss=8.304706\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:49 INFO 140719404451648] Epoch[0] Batch[35] avg_epoch_loss=8.658407\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:49 INFO 140719404451648] #quality_metric: host=algo-1, epoch=0, batch=35 train loss <loss>=8.37902355194\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:49 INFO 140719404451648] Epoch[0] Batch [35]#011Speed: 1351.10 samples/sec#011loss=8.379024\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:49 INFO 140719404451648] Epoch[0] Batch[40] avg_epoch_loss=8.565486\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:49 INFO 140719404451648] #quality_metric: host=algo-1, epoch=0, batch=40 train loss <loss>=7.89645290375\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:49 INFO 140719404451648] Epoch[0] Batch [40]#011Speed: 715.79 samples/sec#011loss=7.896453\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:49 INFO 140719404451648] Epoch[0] Batch[45] avg_epoch_loss=8.516826\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:49 INFO 140719404451648] #quality_metric: host=algo-1, epoch=0, batch=45 train loss <loss>=8.11780948639\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:49 INFO 140719404451648] Epoch[0] Batch [45]#011Speed: 1492.87 samples/sec#011loss=8.117809\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:49 INFO 140719404451648] processed a total of 1591 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 400, \"sum\": 400.0, \"min\": 400}, \"update.time\": {\"count\": 1, \"max\": 1734.4861030578613, \"sum\": 1734.4861030578613, \"min\": 1734.4861030578613}}, \"EndTime\": 1578472669.593722, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472667.859162}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:49 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=917.207374069 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:49 INFO 140719404451648] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:49 INFO 140719404451648] #quality_metric: host=algo-1, epoch=0, train loss <loss>=8.45562504768\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:49 INFO 140719404451648] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:49 INFO 140719404451648] Saved checkpoint to \"/opt/ml/model/state_6988a4ab-1ca4-4e0c-a68f-f6053d473bf8-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 27.14395523071289, \"sum\": 27.14395523071289, \"min\": 27.14395523071289}}, \"EndTime\": 1578472669.621479, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472669.593814}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:49 INFO 140719404451648] Epoch[1] Batch[0] avg_epoch_loss=9.225193\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:49 INFO 140719404451648] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=9.22519302368\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:49 INFO 140719404451648] Epoch[1] Batch[5] avg_epoch_loss=8.795240\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:49 INFO 140719404451648] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=8.79523992538\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:49 INFO 140719404451648] Epoch[1] Batch [5]#011Speed: 1471.82 samples/sec#011loss=8.795240\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:50 INFO 140719404451648] Epoch[1] Batch[10] avg_epoch_loss=8.787753\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:50 INFO 140719404451648] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=8.77876777649\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:50 INFO 140719404451648] Epoch[1] Batch [10]#011Speed: 713.40 samples/sec#011loss=8.778768\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:50 INFO 140719404451648] Epoch[1] Batch[15] avg_epoch_loss=8.765995\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:50 INFO 140719404451648] #quality_metric: host=algo-1, epoch=1, batch=15 train loss <loss>=8.71812725067\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:50 INFO 140719404451648] Epoch[1] Batch [15]#011Speed: 1497.01 samples/sec#011loss=8.718127\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:50 INFO 140719404451648] Epoch[1] Batch[20] avg_epoch_loss=8.645467\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:50 INFO 140719404451648] #quality_metric: host=algo-1, epoch=1, batch=20 train loss <loss>=8.25977916718\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:50 INFO 140719404451648] Epoch[1] Batch [20]#011Speed: 676.70 samples/sec#011loss=8.259779\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:50 INFO 140719404451648] Epoch[1] Batch[25] avg_epoch_loss=8.621627\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:50 INFO 140719404451648] #quality_metric: host=algo-1, epoch=1, batch=25 train loss <loss>=8.52149963379\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:50 INFO 140719404451648] Epoch[1] Batch [25]#011Speed: 1315.91 samples/sec#011loss=8.521500\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:50 INFO 140719404451648] Epoch[1] Batch[30] avg_epoch_loss=8.554321\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:50 INFO 140719404451648] #quality_metric: host=algo-1, epoch=1, batch=30 train loss <loss>=8.20433101654\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:50 INFO 140719404451648] Epoch[1] Batch [30]#011Speed: 665.88 samples/sec#011loss=8.204331\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:50 INFO 140719404451648] Epoch[1] Batch[35] avg_epoch_loss=8.463061\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:50 INFO 140719404451648] #quality_metric: host=algo-1, epoch=1, batch=35 train loss <loss>=7.89724378586\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:50 INFO 140719404451648] Epoch[1] Batch [35]#011Speed: 1436.36 samples/sec#011loss=7.897244\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] Epoch[1] Batch[40] avg_epoch_loss=8.421016\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] #quality_metric: host=algo-1, epoch=1, batch=40 train loss <loss>=8.11829338074\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] Epoch[1] Batch [40]#011Speed: 805.19 samples/sec#011loss=8.118293\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] Epoch[1] Batch[45] avg_epoch_loss=8.433607\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] #quality_metric: host=algo-1, epoch=1, batch=45 train loss <loss>=8.53685798645\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] Epoch[1] Batch [45]#011Speed: 1746.88 samples/sec#011loss=8.536858\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] Epoch[1] Batch[50] avg_epoch_loss=8.335248\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] #quality_metric: host=algo-1, epoch=1, batch=50 train loss <loss>=7.43034572601\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] Epoch[1] Batch [50]#011Speed: 1193.85 samples/sec#011loss=7.430346\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] processed a total of 1613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1732.8410148620605, \"sum\": 1732.8410148620605, \"min\": 1732.8410148620605}}, \"EndTime\": 1578472671.354433, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472669.621538}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=930.790339632 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] #quality_metric: host=algo-1, epoch=1, train loss <loss>=8.33524839551\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] Saved checkpoint to \"/opt/ml/model/state_75556c28-dcb2-43e3-9c62-4486a5df2dc8-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.313003540039062, \"sum\": 17.313003540039062, \"min\": 17.313003540039062}}, \"EndTime\": 1578472671.372305, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472671.354492}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] Epoch[2] Batch[0] avg_epoch_loss=8.853704\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=8.85370445251\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] Epoch[2] Batch[5] avg_epoch_loss=8.578393\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=8.57839314143\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] Epoch[2] Batch [5]#011Speed: 1318.86 samples/sec#011loss=8.578393\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] Epoch[2] Batch[10] avg_epoch_loss=8.631119\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=8.69438991547\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] Epoch[2] Batch [10]#011Speed: 766.05 samples/sec#011loss=8.694390\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] Epoch[2] Batch[15] avg_epoch_loss=8.718871\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] #quality_metric: host=algo-1, epoch=2, batch=15 train loss <loss>=8.91192550659\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:51 INFO 140719404451648] Epoch[2] Batch [15]#011Speed: 1650.64 samples/sec#011loss=8.911926\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:52 INFO 140719404451648] Epoch[2] Batch[20] avg_epoch_loss=8.580937\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:52 INFO 140719404451648] #quality_metric: host=algo-1, epoch=2, batch=20 train loss <loss>=8.13954973221\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:52 INFO 140719404451648] Epoch[2] Batch [20]#011Speed: 716.30 samples/sec#011loss=8.139550\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:52 INFO 140719404451648] Epoch[2] Batch[25] avg_epoch_loss=8.538914\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:52 INFO 140719404451648] #quality_metric: host=algo-1, epoch=2, batch=25 train loss <loss>=8.362413311\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:52 INFO 140719404451648] Epoch[2] Batch [25]#011Speed: 1232.96 samples/sec#011loss=8.362413\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:52 INFO 140719404451648] Epoch[2] Batch[30] avg_epoch_loss=8.463039\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:52 INFO 140719404451648] #quality_metric: host=algo-1, epoch=2, batch=30 train loss <loss>=8.06849079132\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:52 INFO 140719404451648] Epoch[2] Batch [30]#011Speed: 593.78 samples/sec#011loss=8.068491\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:52 INFO 140719404451648] Epoch[2] Batch[35] avg_epoch_loss=8.421935\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:52 INFO 140719404451648] #quality_metric: host=algo-1, epoch=2, batch=35 train loss <loss>=8.16708831787\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:52 INFO 140719404451648] Epoch[2] Batch [35]#011Speed: 1199.77 samples/sec#011loss=8.167088\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:52 INFO 140719404451648] Epoch[2] Batch[40] avg_epoch_loss=8.413598\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:52 INFO 140719404451648] #quality_metric: host=algo-1, epoch=2, batch=40 train loss <loss>=8.35357198715\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:52 INFO 140719404451648] Epoch[2] Batch [40]#011Speed: 578.43 samples/sec#011loss=8.353572\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:53 INFO 140719404451648] Epoch[2] Batch[45] avg_epoch_loss=8.370912\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:53 INFO 140719404451648] #quality_metric: host=algo-1, epoch=2, batch=45 train loss <loss>=8.02088832855\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:53 INFO 140719404451648] Epoch[2] Batch [45]#011Speed: 1282.04 samples/sec#011loss=8.020888\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:53 INFO 140719404451648] processed a total of 1533 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1782.3431491851807, \"sum\": 1782.3431491851807, \"min\": 1782.3431491851807}}, \"EndTime\": 1578472673.154764, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472671.372366}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:53 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=860.050698822 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:53 INFO 140719404451648] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:53 INFO 140719404451648] #quality_metric: host=algo-1, epoch=2, train loss <loss>=8.3117356499\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:53 INFO 140719404451648] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:53 INFO 140719404451648] Saved checkpoint to \"/opt/ml/model/state_1b192d5c-8a54-423c-94c6-1f7530ebfc76-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 25.981903076171875, \"sum\": 25.981903076171875, \"min\": 25.981903076171875}}, \"EndTime\": 1578472673.181298, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472673.15484}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:53 INFO 140719404451648] Epoch[3] Batch[0] avg_epoch_loss=7.963044\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:53 INFO 140719404451648] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=7.96304416656\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:53 INFO 140719404451648] Epoch[3] Batch[5] avg_epoch_loss=8.365887\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:53 INFO 140719404451648] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=8.36588652929\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:53 INFO 140719404451648] Epoch[3] Batch [5]#011Speed: 1525.45 samples/sec#011loss=8.365887\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:53 INFO 140719404451648] Epoch[3] Batch[10] avg_epoch_loss=8.627916\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:53 INFO 140719404451648] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=8.94235229492\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:53 INFO 140719404451648] Epoch[3] Batch [10]#011Speed: 714.63 samples/sec#011loss=8.942352\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:53 INFO 140719404451648] Epoch[3] Batch[15] avg_epoch_loss=8.692643\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:53 INFO 140719404451648] #quality_metric: host=algo-1, epoch=3, batch=15 train loss <loss>=8.83504104614\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:53 INFO 140719404451648] Epoch[3] Batch [15]#011Speed: 1692.26 samples/sec#011loss=8.835041\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:53 INFO 140719404451648] Epoch[3] Batch[20] avg_epoch_loss=8.676089\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:53 INFO 140719404451648] #quality_metric: host=algo-1, epoch=3, batch=20 train loss <loss>=8.62311668396\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:53 INFO 140719404451648] Epoch[3] Batch [20]#011Speed: 668.77 samples/sec#011loss=8.623117\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] Epoch[3] Batch[25] avg_epoch_loss=8.556936\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] #quality_metric: host=algo-1, epoch=3, batch=25 train loss <loss>=8.05649118423\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] Epoch[3] Batch [25]#011Speed: 1694.65 samples/sec#011loss=8.056491\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] Epoch[3] Batch[30] avg_epoch_loss=8.469622\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] #quality_metric: host=algo-1, epoch=3, batch=30 train loss <loss>=8.01559429169\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] Epoch[3] Batch [30]#011Speed: 819.59 samples/sec#011loss=8.015594\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] Epoch[3] Batch[35] avg_epoch_loss=8.427229\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] #quality_metric: host=algo-1, epoch=3, batch=35 train loss <loss>=8.16438875198\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] Epoch[3] Batch [35]#011Speed: 1694.29 samples/sec#011loss=8.164389\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] Epoch[3] Batch[40] avg_epoch_loss=8.377357\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] #quality_metric: host=algo-1, epoch=3, batch=40 train loss <loss>=8.01828260422\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] Epoch[3] Batch [40]#011Speed: 715.70 samples/sec#011loss=8.018283\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] Epoch[3] Batch[45] avg_epoch_loss=8.325132\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] #quality_metric: host=algo-1, epoch=3, batch=45 train loss <loss>=7.89688014984\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] Epoch[3] Batch [45]#011Speed: 1576.03 samples/sec#011loss=7.896880\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] Epoch[3] Batch[50] avg_epoch_loss=8.307516\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] #quality_metric: host=algo-1, epoch=3, batch=50 train loss <loss>=8.14544868469\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] Epoch[3] Batch [50]#011Speed: 1154.53 samples/sec#011loss=8.145449\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] processed a total of 1603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1667.1090126037598, \"sum\": 1667.1090126037598, \"min\": 1667.1090126037598}}, \"EndTime\": 1578472674.848523, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472673.181362}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=961.480171696 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] #quality_metric: host=algo-1, epoch=3, train loss <loss>=8.30751563988\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:54 INFO 140719404451648] Saved checkpoint to \"/opt/ml/model/state_3490542f-61f2-4adc-abbd-e508910cefb1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 26.56698226928711, \"sum\": 26.56698226928711, \"min\": 26.56698226928711}}, \"EndTime\": 1578472674.875642, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472674.848601}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:55 INFO 140719404451648] Epoch[4] Batch[0] avg_epoch_loss=7.807911\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:55 INFO 140719404451648] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=7.80791139603\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:55 INFO 140719404451648] Epoch[4] Batch[5] avg_epoch_loss=8.276399\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:55 INFO 140719404451648] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=8.27639945348\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:55 INFO 140719404451648] Epoch[4] Batch [5]#011Speed: 1592.02 samples/sec#011loss=8.276399\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:55 INFO 140719404451648] Epoch[4] Batch[10] avg_epoch_loss=8.295221\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:55 INFO 140719404451648] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=8.31780643463\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:55 INFO 140719404451648] Epoch[4] Batch [10]#011Speed: 819.57 samples/sec#011loss=8.317806\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:55 INFO 140719404451648] Epoch[4] Batch[15] avg_epoch_loss=8.368930\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:55 INFO 140719404451648] #quality_metric: host=algo-1, epoch=4, batch=15 train loss <loss>=8.53108968735\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:55 INFO 140719404451648] Epoch[4] Batch [15]#011Speed: 1651.63 samples/sec#011loss=8.531090\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:55 INFO 140719404451648] Epoch[4] Batch[20] avg_epoch_loss=8.354518\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:55 INFO 140719404451648] #quality_metric: host=algo-1, epoch=4, batch=20 train loss <loss>=8.30839939117\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:55 INFO 140719404451648] Epoch[4] Batch [20]#011Speed: 723.32 samples/sec#011loss=8.308399\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:55 INFO 140719404451648] Epoch[4] Batch[25] avg_epoch_loss=8.320039\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:55 INFO 140719404451648] #quality_metric: host=algo-1, epoch=4, batch=25 train loss <loss>=8.17522888184\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:55 INFO 140719404451648] Epoch[4] Batch [25]#011Speed: 1585.84 samples/sec#011loss=8.175229\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:55 INFO 140719404451648] Epoch[4] Batch[30] avg_epoch_loss=8.272893\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:55 INFO 140719404451648] #quality_metric: host=algo-1, epoch=4, batch=30 train loss <loss>=8.02773237228\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:55 INFO 140719404451648] Epoch[4] Batch [30]#011Speed: 786.80 samples/sec#011loss=8.027732\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:56 INFO 140719404451648] Epoch[4] Batch[35] avg_epoch_loss=8.232790\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:56 INFO 140719404451648] #quality_metric: host=algo-1, epoch=4, batch=35 train loss <loss>=7.9841550827\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:56 INFO 140719404451648] Epoch[4] Batch [35]#011Speed: 1654.46 samples/sec#011loss=7.984155\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-01-08 08:37:44 Training - Training image download completed. Training in progress.\u001b[34m[01/08/2020 08:37:56 INFO 140719404451648] Epoch[4] Batch[40] avg_epoch_loss=8.220587\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:56 INFO 140719404451648] #quality_metric: host=algo-1, epoch=4, batch=40 train loss <loss>=8.13272018433\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:56 INFO 140719404451648] Epoch[4] Batch [40]#011Speed: 739.86 samples/sec#011loss=8.132720\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:56 INFO 140719404451648] Epoch[4] Batch[45] avg_epoch_loss=8.220508\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:56 INFO 140719404451648] #quality_metric: host=algo-1, epoch=4, batch=45 train loss <loss>=8.21985960007\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:56 INFO 140719404451648] Epoch[4] Batch [45]#011Speed: 1396.48 samples/sec#011loss=8.219860\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:56 INFO 140719404451648] Epoch[4] Batch[50] avg_epoch_loss=8.190000\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:56 INFO 140719404451648] #quality_metric: host=algo-1, epoch=4, batch=50 train loss <loss>=7.90933322906\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:56 INFO 140719404451648] Epoch[4] Batch [50]#011Speed: 1090.75 samples/sec#011loss=7.909333\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:56 INFO 140719404451648] processed a total of 1633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1664.9489402770996, \"sum\": 1664.9489402770996, \"min\": 1664.9489402770996}}, \"EndTime\": 1578472676.540709, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472674.875706}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:56 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=980.747238699 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:56 INFO 140719404451648] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:56 INFO 140719404451648] #quality_metric: host=algo-1, epoch=4, train loss <loss>=8.25962175773\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:56 INFO 140719404451648] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:56 INFO 140719404451648] Saved checkpoint to \"/opt/ml/model/state_2a0d1d28-a1cb-4104-a329-62d4860d8fb9-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 25.825023651123047, \"sum\": 25.825023651123047, \"min\": 25.825023651123047}}, \"EndTime\": 1578472676.567078, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472676.540782}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:56 INFO 140719404451648] Epoch[5] Batch[0] avg_epoch_loss=8.983035\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:56 INFO 140719404451648] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=8.98303508759\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:56 INFO 140719404451648] Epoch[5] Batch[5] avg_epoch_loss=8.505821\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:56 INFO 140719404451648] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=8.50582138697\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:56 INFO 140719404451648] Epoch[5] Batch [5]#011Speed: 1529.94 samples/sec#011loss=8.505821\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:57 INFO 140719404451648] Epoch[5] Batch[10] avg_epoch_loss=8.450586\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:57 INFO 140719404451648] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=8.38430376053\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:57 INFO 140719404451648] Epoch[5] Batch [10]#011Speed: 741.83 samples/sec#011loss=8.384304\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:57 INFO 140719404451648] Epoch[5] Batch[15] avg_epoch_loss=8.486590\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:57 INFO 140719404451648] #quality_metric: host=algo-1, epoch=5, batch=15 train loss <loss>=8.56579818726\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:57 INFO 140719404451648] Epoch[5] Batch [15]#011Speed: 1556.75 samples/sec#011loss=8.565798\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:57 INFO 140719404451648] Epoch[5] Batch[20] avg_epoch_loss=8.422946\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:57 INFO 140719404451648] #quality_metric: host=algo-1, epoch=5, batch=20 train loss <loss>=8.21928443909\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:57 INFO 140719404451648] Epoch[5] Batch [20]#011Speed: 825.38 samples/sec#011loss=8.219284\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:57 INFO 140719404451648] Epoch[5] Batch[25] avg_epoch_loss=8.383616\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:57 INFO 140719404451648] #quality_metric: host=algo-1, epoch=5, batch=25 train loss <loss>=8.21843147278\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:57 INFO 140719404451648] Epoch[5] Batch [25]#011Speed: 1512.16 samples/sec#011loss=8.218431\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:57 INFO 140719404451648] Epoch[5] Batch[30] avg_epoch_loss=8.290814\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:57 INFO 140719404451648] #quality_metric: host=algo-1, epoch=5, batch=30 train loss <loss>=7.80824222565\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:57 INFO 140719404451648] Epoch[5] Batch [30]#011Speed: 747.32 samples/sec#011loss=7.808242\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:57 INFO 140719404451648] Epoch[5] Batch[35] avg_epoch_loss=8.249561\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:57 INFO 140719404451648] #quality_metric: host=algo-1, epoch=5, batch=35 train loss <loss>=7.99379472733\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:57 INFO 140719404451648] Epoch[5] Batch [35]#011Speed: 1561.71 samples/sec#011loss=7.993795\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:57 INFO 140719404451648] Epoch[5] Batch[40] avg_epoch_loss=8.251460\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:57 INFO 140719404451648] #quality_metric: host=algo-1, epoch=5, batch=40 train loss <loss>=8.26513252258\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:57 INFO 140719404451648] Epoch[5] Batch [40]#011Speed: 779.69 samples/sec#011loss=8.265133\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:58 INFO 140719404451648] Epoch[5] Batch[45] avg_epoch_loss=8.212661\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:58 INFO 140719404451648] #quality_metric: host=algo-1, epoch=5, batch=45 train loss <loss>=7.89451084137\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:58 INFO 140719404451648] Epoch[5] Batch [45]#011Speed: 957.87 samples/sec#011loss=7.894511\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:58 INFO 140719404451648] processed a total of 1560 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1628.1158924102783, \"sum\": 1628.1158924102783, \"min\": 1628.1158924102783}}, \"EndTime\": 1578472678.195305, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472676.567138}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:58 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=958.099192505 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:58 INFO 140719404451648] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:58 INFO 140719404451648] #quality_metric: host=algo-1, epoch=5, train loss <loss>=8.21312795367\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:58 INFO 140719404451648] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:58 INFO 140719404451648] Saved checkpoint to \"/opt/ml/model/state_dfbe786a-ee4e-4a2a-bd95-4f55df688f60-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 25.716066360473633, \"sum\": 25.716066360473633, \"min\": 25.716066360473633}}, \"EndTime\": 1578472678.221563, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472678.19538}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:58 INFO 140719404451648] Epoch[6] Batch[0] avg_epoch_loss=8.386242\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:58 INFO 140719404451648] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=8.38624191284\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:58 INFO 140719404451648] Epoch[6] Batch[5] avg_epoch_loss=8.248165\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:58 INFO 140719404451648] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=8.24816465378\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:58 INFO 140719404451648] Epoch[6] Batch [5]#011Speed: 1634.34 samples/sec#011loss=8.248165\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:58 INFO 140719404451648] Epoch[6] Batch[10] avg_epoch_loss=8.300272\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:58 INFO 140719404451648] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=8.36280097961\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:58 INFO 140719404451648] Epoch[6] Batch [10]#011Speed: 688.75 samples/sec#011loss=8.362801\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:58 INFO 140719404451648] Epoch[6] Batch[15] avg_epoch_loss=8.501986\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:58 INFO 140719404451648] #quality_metric: host=algo-1, epoch=6, batch=15 train loss <loss>=8.9457567215\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:58 INFO 140719404451648] Epoch[6] Batch [15]#011Speed: 1547.97 samples/sec#011loss=8.945757\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:58 INFO 140719404451648] Epoch[6] Batch[20] avg_epoch_loss=8.502997\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:58 INFO 140719404451648] #quality_metric: host=algo-1, epoch=6, batch=20 train loss <loss>=8.50623416901\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:58 INFO 140719404451648] Epoch[6] Batch [20]#011Speed: 795.63 samples/sec#011loss=8.506234\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] Epoch[6] Batch[25] avg_epoch_loss=8.476048\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] #quality_metric: host=algo-1, epoch=6, batch=25 train loss <loss>=8.36285991669\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] Epoch[6] Batch [25]#011Speed: 1454.18 samples/sec#011loss=8.362860\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] Epoch[6] Batch[30] avg_epoch_loss=8.427621\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] #quality_metric: host=algo-1, epoch=6, batch=30 train loss <loss>=8.17579870224\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] Epoch[6] Batch [30]#011Speed: 706.29 samples/sec#011loss=8.175799\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] Epoch[6] Batch[35] avg_epoch_loss=8.365994\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] #quality_metric: host=algo-1, epoch=6, batch=35 train loss <loss>=7.98390989304\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] Epoch[6] Batch [35]#011Speed: 1721.67 samples/sec#011loss=7.983910\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] Epoch[6] Batch[40] avg_epoch_loss=8.331784\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] #quality_metric: host=algo-1, epoch=6, batch=40 train loss <loss>=8.08547039032\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] Epoch[6] Batch [40]#011Speed: 775.10 samples/sec#011loss=8.085470\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] Epoch[6] Batch[45] avg_epoch_loss=8.333344\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] #quality_metric: host=algo-1, epoch=6, batch=45 train loss <loss>=8.34614009857\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] Epoch[6] Batch [45]#011Speed: 1737.30 samples/sec#011loss=8.346140\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] Epoch[6] Batch[50] avg_epoch_loss=8.231354\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] #quality_metric: host=algo-1, epoch=6, batch=50 train loss <loss>=7.29304542542\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] Epoch[6] Batch [50]#011Speed: 1341.74 samples/sec#011loss=7.293045\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] processed a total of 1618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1621.3111877441406, \"sum\": 1621.3111877441406, \"min\": 1621.3111877441406}}, \"EndTime\": 1578472679.842984, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472678.221622}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=997.891969086 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] #quality_metric: host=algo-1, epoch=6, train loss <loss>=8.23135430205\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] Epoch[7] Batch[0] avg_epoch_loss=8.395816\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:37:59 INFO 140719404451648] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=8.3958158493\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:00 INFO 140719404451648] Epoch[7] Batch[5] avg_epoch_loss=8.149618\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:00 INFO 140719404451648] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=8.14961806933\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:00 INFO 140719404451648] Epoch[7] Batch [5]#011Speed: 1187.82 samples/sec#011loss=8.149618\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:00 INFO 140719404451648] Epoch[7] Batch[10] avg_epoch_loss=8.313040\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:00 INFO 140719404451648] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=8.50914573669\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:00 INFO 140719404451648] Epoch[7] Batch [10]#011Speed: 799.83 samples/sec#011loss=8.509146\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:00 INFO 140719404451648] Epoch[7] Batch[15] avg_epoch_loss=8.427278\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:00 INFO 140719404451648] #quality_metric: host=algo-1, epoch=7, batch=15 train loss <loss>=8.67860145569\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:00 INFO 140719404451648] Epoch[7] Batch [15]#011Speed: 1405.51 samples/sec#011loss=8.678601\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:00 INFO 140719404451648] Epoch[7] Batch[20] avg_epoch_loss=8.439887\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:00 INFO 140719404451648] #quality_metric: host=algo-1, epoch=7, batch=20 train loss <loss>=8.48023757935\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:00 INFO 140719404451648] Epoch[7] Batch [20]#011Speed: 725.65 samples/sec#011loss=8.480238\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:00 INFO 140719404451648] Epoch[7] Batch[25] avg_epoch_loss=8.392244\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:00 INFO 140719404451648] #quality_metric: host=algo-1, epoch=7, batch=25 train loss <loss>=8.19213981628\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:00 INFO 140719404451648] Epoch[7] Batch [25]#011Speed: 1294.32 samples/sec#011loss=8.192140\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:00 INFO 140719404451648] Epoch[7] Batch[30] avg_epoch_loss=8.304548\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:00 INFO 140719404451648] #quality_metric: host=algo-1, epoch=7, batch=30 train loss <loss>=7.84853105545\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:00 INFO 140719404451648] Epoch[7] Batch [30]#011Speed: 798.22 samples/sec#011loss=7.848531\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:01 INFO 140719404451648] Epoch[7] Batch[35] avg_epoch_loss=8.264557\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:01 INFO 140719404451648] #quality_metric: host=algo-1, epoch=7, batch=35 train loss <loss>=8.01661224365\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:01 INFO 140719404451648] Epoch[7] Batch [35]#011Speed: 1344.90 samples/sec#011loss=8.016612\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:01 INFO 140719404451648] Epoch[7] Batch[40] avg_epoch_loss=8.250138\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:01 INFO 140719404451648] #quality_metric: host=algo-1, epoch=7, batch=40 train loss <loss>=8.14631881714\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:01 INFO 140719404451648] Epoch[7] Batch [40]#011Speed: 750.93 samples/sec#011loss=8.146319\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:01 INFO 140719404451648] Epoch[7] Batch[45] avg_epoch_loss=8.232998\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:01 INFO 140719404451648] #quality_metric: host=algo-1, epoch=7, batch=45 train loss <loss>=8.09245386124\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:01 INFO 140719404451648] Epoch[7] Batch [45]#011Speed: 1185.72 samples/sec#011loss=8.092454\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:01 INFO 140719404451648] processed a total of 1546 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1669.3148612976074, \"sum\": 1669.3148612976074, \"min\": 1669.3148612976074}}, \"EndTime\": 1578472681.512784, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472679.843058}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:01 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=926.066823572 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:01 INFO 140719404451648] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:01 INFO 140719404451648] #quality_metric: host=algo-1, epoch=7, train loss <loss>=8.25055423075\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:01 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:01 INFO 140719404451648] Epoch[8] Batch[0] avg_epoch_loss=8.390964\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:01 INFO 140719404451648] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=8.39096355438\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:01 INFO 140719404451648] Epoch[8] Batch[5] avg_epoch_loss=8.441681\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:01 INFO 140719404451648] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=8.44168122609\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:01 INFO 140719404451648] Epoch[8] Batch [5]#011Speed: 1472.59 samples/sec#011loss=8.441681\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:02 INFO 140719404451648] Epoch[8] Batch[10] avg_epoch_loss=8.515148\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:02 INFO 140719404451648] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=8.60330905914\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:02 INFO 140719404451648] Epoch[8] Batch [10]#011Speed: 646.16 samples/sec#011loss=8.603309\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:02 INFO 140719404451648] Epoch[8] Batch[15] avg_epoch_loss=8.567561\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:02 INFO 140719404451648] #quality_metric: host=algo-1, epoch=8, batch=15 train loss <loss>=8.68286762238\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:02 INFO 140719404451648] Epoch[8] Batch [15]#011Speed: 1461.79 samples/sec#011loss=8.682868\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:02 INFO 140719404451648] Epoch[8] Batch[20] avg_epoch_loss=8.515269\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:02 INFO 140719404451648] #quality_metric: host=algo-1, epoch=8, batch=20 train loss <loss>=8.34793491364\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:02 INFO 140719404451648] Epoch[8] Batch [20]#011Speed: 1609.69 samples/sec#011loss=8.347935\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:02 INFO 140719404451648] Epoch[8] Batch[25] avg_epoch_loss=8.454371\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:02 INFO 140719404451648] #quality_metric: host=algo-1, epoch=8, batch=25 train loss <loss>=8.19859952927\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:02 INFO 140719404451648] Epoch[8] Batch [25]#011Speed: 722.06 samples/sec#011loss=8.198600\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:02 INFO 140719404451648] Epoch[8] Batch[30] avg_epoch_loss=8.386422\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:02 INFO 140719404451648] #quality_metric: host=algo-1, epoch=8, batch=30 train loss <loss>=8.03308572769\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:02 INFO 140719404451648] Epoch[8] Batch [30]#011Speed: 1715.87 samples/sec#011loss=8.033086\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:02 INFO 140719404451648] Epoch[8] Batch[35] avg_epoch_loss=8.338224\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:02 INFO 140719404451648] #quality_metric: host=algo-1, epoch=8, batch=35 train loss <loss>=8.03940181732\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:02 INFO 140719404451648] Epoch[8] Batch [35]#011Speed: 727.68 samples/sec#011loss=8.039402\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:02 INFO 140719404451648] Epoch[8] Batch[40] avg_epoch_loss=8.304107\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:02 INFO 140719404451648] #quality_metric: host=algo-1, epoch=8, batch=40 train loss <loss>=8.05846185684\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:02 INFO 140719404451648] Epoch[8] Batch [40]#011Speed: 1567.25 samples/sec#011loss=8.058462\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:03 INFO 140719404451648] Epoch[8] Batch[45] avg_epoch_loss=8.280246\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:03 INFO 140719404451648] #quality_metric: host=algo-1, epoch=8, batch=45 train loss <loss>=8.08458509445\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:03 INFO 140719404451648] Epoch[8] Batch [45]#011Speed: 724.50 samples/sec#011loss=8.084585\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:03 INFO 140719404451648] Epoch[8] Batch[50] avg_epoch_loss=8.265000\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:03 INFO 140719404451648] #quality_metric: host=algo-1, epoch=8, batch=50 train loss <loss>=8.12474031448\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:03 INFO 140719404451648] Epoch[8] Batch [50]#011Speed: 1330.55 samples/sec#011loss=8.124740\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:03 INFO 140719404451648] processed a total of 1752 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1799.2489337921143, \"sum\": 1799.2489337921143, \"min\": 1799.2489337921143}}, \"EndTime\": 1578472683.312547, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472681.51286}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:03 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=973.68067169 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:03 INFO 140719404451648] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:03 INFO 140719404451648] #quality_metric: host=algo-1, epoch=8, train loss <loss>=8.20461853201\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:03 INFO 140719404451648] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:03 INFO 140719404451648] Saved checkpoint to \"/opt/ml/model/state_6696c2c4-8400-4c79-b22d-650f9a7d76d2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 19.03700828552246, \"sum\": 19.03700828552246, \"min\": 19.03700828552246}}, \"EndTime\": 1578472683.332158, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472683.312619}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:03 INFO 140719404451648] Epoch[9] Batch[0] avg_epoch_loss=8.361693\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:03 INFO 140719404451648] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=8.36169338226\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:03 INFO 140719404451648] Epoch[9] Batch[5] avg_epoch_loss=8.394306\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:03 INFO 140719404451648] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=8.39430618286\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:03 INFO 140719404451648] Epoch[9] Batch [5]#011Speed: 1562.59 samples/sec#011loss=8.394306\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:03 INFO 140719404451648] Epoch[9] Batch[10] avg_epoch_loss=8.434897\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:03 INFO 140719404451648] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=8.48360538483\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:03 INFO 140719404451648] Epoch[9] Batch [10]#011Speed: 754.40 samples/sec#011loss=8.483605\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:03 INFO 140719404451648] Epoch[9] Batch[15] avg_epoch_loss=8.534600\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:03 INFO 140719404451648] #quality_metric: host=algo-1, epoch=9, batch=15 train loss <loss>=8.75394630432\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:03 INFO 140719404451648] Epoch[9] Batch [15]#011Speed: 1332.52 samples/sec#011loss=8.753946\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:04 INFO 140719404451648] Epoch[9] Batch[20] avg_epoch_loss=8.485204\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:04 INFO 140719404451648] #quality_metric: host=algo-1, epoch=9, batch=20 train loss <loss>=8.32713832855\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:04 INFO 140719404451648] Epoch[9] Batch [20]#011Speed: 664.36 samples/sec#011loss=8.327138\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:04 INFO 140719404451648] Epoch[9] Batch[25] avg_epoch_loss=8.425751\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:04 INFO 140719404451648] #quality_metric: host=algo-1, epoch=9, batch=25 train loss <loss>=8.17604866028\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:04 INFO 140719404451648] Epoch[9] Batch [25]#011Speed: 1611.04 samples/sec#011loss=8.176049\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:04 INFO 140719404451648] Epoch[9] Batch[30] avg_epoch_loss=8.344676\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:04 INFO 140719404451648] #quality_metric: host=algo-1, epoch=9, batch=30 train loss <loss>=7.92308740616\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:04 INFO 140719404451648] Epoch[9] Batch [30]#011Speed: 740.89 samples/sec#011loss=7.923087\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:04 INFO 140719404451648] Epoch[9] Batch[35] avg_epoch_loss=8.276328\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:04 INFO 140719404451648] #quality_metric: host=algo-1, epoch=9, batch=35 train loss <loss>=7.85256624222\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:04 INFO 140719404451648] Epoch[9] Batch [35]#011Speed: 1315.53 samples/sec#011loss=7.852566\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:04 INFO 140719404451648] Epoch[9] Batch[40] avg_epoch_loss=8.275873\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:04 INFO 140719404451648] #quality_metric: host=algo-1, epoch=9, batch=40 train loss <loss>=8.27259845734\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:04 INFO 140719404451648] Epoch[9] Batch [40]#011Speed: 751.02 samples/sec#011loss=8.272598\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:04 INFO 140719404451648] Epoch[9] Batch[45] avg_epoch_loss=8.260440\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:04 INFO 140719404451648] #quality_metric: host=algo-1, epoch=9, batch=45 train loss <loss>=8.13388738632\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:04 INFO 140719404451648] Epoch[9] Batch [45]#011Speed: 1660.01 samples/sec#011loss=8.133887\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:04 INFO 140719404451648] processed a total of 1572 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1653.9030075073242, \"sum\": 1653.9030075073242, \"min\": 1653.9030075073242}}, \"EndTime\": 1578472684.986158, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472683.332202}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:04 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=950.414012304 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:04 INFO 140719404451648] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:04 INFO 140719404451648] #quality_metric: host=algo-1, epoch=9, train loss <loss>=8.18369242668\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:04 INFO 140719404451648] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:05 INFO 140719404451648] Saved checkpoint to \"/opt/ml/model/state_99fe967d-da4e-4529-bcad-69ff61a28e25-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 24.0170955657959, \"sum\": 24.0170955657959, \"min\": 24.0170955657959}}, \"EndTime\": 1578472685.010745, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472684.986235}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:05 INFO 140719404451648] Epoch[10] Batch[0] avg_epoch_loss=8.977525\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:05 INFO 140719404451648] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=8.97752475739\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:05 INFO 140719404451648] Epoch[10] Batch[5] avg_epoch_loss=8.476182\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:05 INFO 140719404451648] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=8.47618166606\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:05 INFO 140719404451648] Epoch[10] Batch [5]#011Speed: 1402.21 samples/sec#011loss=8.476182\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:05 INFO 140719404451648] Epoch[10] Batch[10] avg_epoch_loss=8.494353\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:05 INFO 140719404451648] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=8.51615819931\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:05 INFO 140719404451648] Epoch[10] Batch [10]#011Speed: 715.63 samples/sec#011loss=8.516158\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:05 INFO 140719404451648] Epoch[10] Batch[15] avg_epoch_loss=8.630739\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:05 INFO 140719404451648] #quality_metric: host=algo-1, epoch=10, batch=15 train loss <loss>=8.93078861237\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:05 INFO 140719404451648] Epoch[10] Batch [15]#011Speed: 1310.65 samples/sec#011loss=8.930789\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:05 INFO 140719404451648] Epoch[10] Batch[20] avg_epoch_loss=8.584598\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:05 INFO 140719404451648] #quality_metric: host=algo-1, epoch=10, batch=20 train loss <loss>=8.43694887161\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:05 INFO 140719404451648] Epoch[10] Batch [20]#011Speed: 768.59 samples/sec#011loss=8.436949\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:05 INFO 140719404451648] Epoch[10] Batch[25] avg_epoch_loss=8.470829\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:05 INFO 140719404451648] #quality_metric: host=algo-1, epoch=10, batch=25 train loss <loss>=7.99299488068\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:05 INFO 140719404451648] Epoch[10] Batch [25]#011Speed: 1550.28 samples/sec#011loss=7.992995\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] Epoch[10] Batch[30] avg_epoch_loss=8.404627\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] #quality_metric: host=algo-1, epoch=10, batch=30 train loss <loss>=8.06037864685\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] Epoch[10] Batch [30]#011Speed: 740.52 samples/sec#011loss=8.060379\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] Epoch[10] Batch[35] avg_epoch_loss=8.352675\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] #quality_metric: host=algo-1, epoch=10, batch=35 train loss <loss>=8.03057613373\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] Epoch[10] Batch [35]#011Speed: 1485.18 samples/sec#011loss=8.030576\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] Epoch[10] Batch[40] avg_epoch_loss=8.324907\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] #quality_metric: host=algo-1, epoch=10, batch=40 train loss <loss>=8.12497262955\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] Epoch[10] Batch [40]#011Speed: 792.46 samples/sec#011loss=8.124973\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] Epoch[10] Batch[45] avg_epoch_loss=8.327866\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] #quality_metric: host=algo-1, epoch=10, batch=45 train loss <loss>=8.35213308334\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] Epoch[10] Batch [45]#011Speed: 1541.15 samples/sec#011loss=8.352133\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] Epoch[10] Batch[50] avg_epoch_loss=8.170184\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] #quality_metric: host=algo-1, epoch=10, batch=50 train loss <loss>=6.71950492859\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] Epoch[10] Batch [50]#011Speed: 1321.94 samples/sec#011loss=6.719505\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] processed a total of 1603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1677.4611473083496, \"sum\": 1677.4611473083496, \"min\": 1677.4611473083496}}, \"EndTime\": 1578472686.688341, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472685.01082}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=955.550505626 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] #quality_metric: host=algo-1, epoch=10, train loss <loss>=8.17018372405\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] Saved checkpoint to \"/opt/ml/model/state_07b04563-54b3-4e2b-88d0-5bc78cbfe2d3-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 21.765947341918945, \"sum\": 21.765947341918945, \"min\": 21.765947341918945}}, \"EndTime\": 1578472686.710713, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472686.688411}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] Epoch[11] Batch[0] avg_epoch_loss=8.994443\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=8.99444293976\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] Epoch[11] Batch[5] avg_epoch_loss=8.570872\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=8.57087214788\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:06 INFO 140719404451648] Epoch[11] Batch [5]#011Speed: 1425.44 samples/sec#011loss=8.570872\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:07 INFO 140719404451648] Epoch[11] Batch[10] avg_epoch_loss=8.411361\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:07 INFO 140719404451648] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=8.21994762421\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:07 INFO 140719404451648] Epoch[11] Batch [10]#011Speed: 807.06 samples/sec#011loss=8.219948\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:07 INFO 140719404451648] Epoch[11] Batch[15] avg_epoch_loss=8.414437\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:07 INFO 140719404451648] #quality_metric: host=algo-1, epoch=11, batch=15 train loss <loss>=8.42120418549\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:07 INFO 140719404451648] Epoch[11] Batch [15]#011Speed: 1556.58 samples/sec#011loss=8.421204\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:07 INFO 140719404451648] Epoch[11] Batch[20] avg_epoch_loss=8.384012\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:07 INFO 140719404451648] #quality_metric: host=algo-1, epoch=11, batch=20 train loss <loss>=8.28665027618\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:07 INFO 140719404451648] Epoch[11] Batch [20]#011Speed: 713.99 samples/sec#011loss=8.286650\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:07 INFO 140719404451648] Epoch[11] Batch[25] avg_epoch_loss=8.301715\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:07 INFO 140719404451648] #quality_metric: host=algo-1, epoch=11, batch=25 train loss <loss>=7.95606899261\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:07 INFO 140719404451648] Epoch[11] Batch [25]#011Speed: 1319.27 samples/sec#011loss=7.956069\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:07 INFO 140719404451648] Epoch[11] Batch[30] avg_epoch_loss=8.234599\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:07 INFO 140719404451648] #quality_metric: host=algo-1, epoch=11, batch=30 train loss <loss>=7.8855969429\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:07 INFO 140719404451648] Epoch[11] Batch [30]#011Speed: 775.24 samples/sec#011loss=7.885597\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:07 INFO 140719404451648] Epoch[11] Batch[35] avg_epoch_loss=8.178064\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:07 INFO 140719404451648] #quality_metric: host=algo-1, epoch=11, batch=35 train loss <loss>=7.82754516602\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:07 INFO 140719404451648] Epoch[11] Batch [35]#011Speed: 1568.03 samples/sec#011loss=7.827545\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] Epoch[11] Batch[40] avg_epoch_loss=8.149370\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] #quality_metric: host=algo-1, epoch=11, batch=40 train loss <loss>=7.94277620316\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] Epoch[11] Batch [40]#011Speed: 756.24 samples/sec#011loss=7.942776\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] Epoch[11] Batch[45] avg_epoch_loss=8.152179\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] #quality_metric: host=algo-1, epoch=11, batch=45 train loss <loss>=8.17521190643\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] Epoch[11] Batch [45]#011Speed: 1646.21 samples/sec#011loss=8.175212\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] Epoch[11] Batch[50] avg_epoch_loss=8.189799\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] #quality_metric: host=algo-1, epoch=11, batch=50 train loss <loss>=8.53589963913\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] Epoch[11] Batch [50]#011Speed: 1107.63 samples/sec#011loss=8.535900\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] processed a total of 1613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1644.1779136657715, \"sum\": 1644.1779136657715, \"min\": 1644.1779136657715}}, \"EndTime\": 1578472688.355011, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472686.710777}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=980.97707075 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] #quality_metric: host=algo-1, epoch=11, train loss <loss>=8.18979877584\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] Epoch[12] Batch[0] avg_epoch_loss=8.306465\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=8.30646514893\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] Epoch[12] Batch[5] avg_epoch_loss=8.360393\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=8.3603925705\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] Epoch[12] Batch [5]#011Speed: 1637.51 samples/sec#011loss=8.360393\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] Epoch[12] Batch[10] avg_epoch_loss=8.278234\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=8.17964334488\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] Epoch[12] Batch [10]#011Speed: 674.85 samples/sec#011loss=8.179643\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] Epoch[12] Batch[15] avg_epoch_loss=8.351628\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] #quality_metric: host=algo-1, epoch=12, batch=15 train loss <loss>=8.51309452057\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:08 INFO 140719404451648] Epoch[12] Batch [15]#011Speed: 1375.34 samples/sec#011loss=8.513095\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:09 INFO 140719404451648] Epoch[12] Batch[20] avg_epoch_loss=8.397925\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:09 INFO 140719404451648] #quality_metric: host=algo-1, epoch=12, batch=20 train loss <loss>=8.5460767746\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:09 INFO 140719404451648] Epoch[12] Batch [20]#011Speed: 715.94 samples/sec#011loss=8.546077\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:09 INFO 140719404451648] Epoch[12] Batch[25] avg_epoch_loss=8.354277\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:09 INFO 140719404451648] #quality_metric: host=algo-1, epoch=12, batch=25 train loss <loss>=8.17095317841\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:09 INFO 140719404451648] Epoch[12] Batch [25]#011Speed: 1662.15 samples/sec#011loss=8.170953\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:09 INFO 140719404451648] Epoch[12] Batch[30] avg_epoch_loss=8.317071\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:09 INFO 140719404451648] #quality_metric: host=algo-1, epoch=12, batch=30 train loss <loss>=8.12360134125\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:09 INFO 140719404451648] Epoch[12] Batch [30]#011Speed: 750.12 samples/sec#011loss=8.123601\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:09 INFO 140719404451648] Epoch[12] Batch[35] avg_epoch_loss=8.289703\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:09 INFO 140719404451648] #quality_metric: host=algo-1, epoch=12, batch=35 train loss <loss>=8.12001781464\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:09 INFO 140719404451648] Epoch[12] Batch [35]#011Speed: 1534.20 samples/sec#011loss=8.120018\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:09 INFO 140719404451648] Epoch[12] Batch[40] avg_epoch_loss=8.269705\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:09 INFO 140719404451648] #quality_metric: host=algo-1, epoch=12, batch=40 train loss <loss>=8.12572402954\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:09 INFO 140719404451648] Epoch[12] Batch [40]#011Speed: 743.77 samples/sec#011loss=8.125724\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:09 INFO 140719404451648] Epoch[12] Batch[45] avg_epoch_loss=8.233363\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:09 INFO 140719404451648] #quality_metric: host=algo-1, epoch=12, batch=45 train loss <loss>=7.9353562355\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:09 INFO 140719404451648] Epoch[12] Batch [45]#011Speed: 1319.72 samples/sec#011loss=7.935356\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] Epoch[12] Batch[50] avg_epoch_loss=8.204255\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] #quality_metric: host=algo-1, epoch=12, batch=50 train loss <loss>=7.93646297455\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] Epoch[12] Batch [50]#011Speed: 1127.79 samples/sec#011loss=7.936463\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] processed a total of 1607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1695.2059268951416, \"sum\": 1695.2059268951416, \"min\": 1695.2059268951416}}, \"EndTime\": 1578472690.050698, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472688.355078}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=947.904768026 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] #quality_metric: host=algo-1, epoch=12, train loss <loss>=8.20425502927\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] Epoch[13] Batch[0] avg_epoch_loss=8.482777\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=8.48277664185\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] Epoch[13] Batch[5] avg_epoch_loss=8.309211\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=8.30921061834\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] Epoch[13] Batch [5]#011Speed: 1329.65 samples/sec#011loss=8.309211\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] Epoch[13] Batch[10] avg_epoch_loss=8.423350\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=8.56031646729\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] Epoch[13] Batch [10]#011Speed: 784.45 samples/sec#011loss=8.560316\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] Epoch[13] Batch[15] avg_epoch_loss=8.421385\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] #quality_metric: host=algo-1, epoch=13, batch=15 train loss <loss>=8.41706256866\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] Epoch[13] Batch [15]#011Speed: 1293.67 samples/sec#011loss=8.417063\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] Epoch[13] Batch[20] avg_epoch_loss=8.448922\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] #quality_metric: host=algo-1, epoch=13, batch=20 train loss <loss>=8.5370423317\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] Epoch[13] Batch [20]#011Speed: 712.95 samples/sec#011loss=8.537042\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] Epoch[13] Batch[25] avg_epoch_loss=8.363493\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] #quality_metric: host=algo-1, epoch=13, batch=25 train loss <loss>=8.00469083786\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:10 INFO 140719404451648] Epoch[13] Batch [25]#011Speed: 1623.28 samples/sec#011loss=8.004691\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:11 INFO 140719404451648] Epoch[13] Batch[30] avg_epoch_loss=8.300298\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:11 INFO 140719404451648] #quality_metric: host=algo-1, epoch=13, batch=30 train loss <loss>=7.97168006897\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:11 INFO 140719404451648] Epoch[13] Batch [30]#011Speed: 781.22 samples/sec#011loss=7.971680\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:11 INFO 140719404451648] Epoch[13] Batch[35] avg_epoch_loss=8.226563\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:11 INFO 140719404451648] #quality_metric: host=algo-1, epoch=13, batch=35 train loss <loss>=7.76940937042\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:11 INFO 140719404451648] Epoch[13] Batch [35]#011Speed: 1499.29 samples/sec#011loss=7.769409\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:11 INFO 140719404451648] Epoch[13] Batch[40] avg_epoch_loss=8.194768\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:11 INFO 140719404451648] #quality_metric: host=algo-1, epoch=13, batch=40 train loss <loss>=7.96583919525\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:11 INFO 140719404451648] Epoch[13] Batch [40]#011Speed: 748.97 samples/sec#011loss=7.965839\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:11 INFO 140719404451648] Epoch[13] Batch[45] avg_epoch_loss=8.182672\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:11 INFO 140719404451648] #quality_metric: host=algo-1, epoch=13, batch=45 train loss <loss>=8.08348503113\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:11 INFO 140719404451648] Epoch[13] Batch [45]#011Speed: 1652.94 samples/sec#011loss=8.083485\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:11 INFO 140719404451648] processed a total of 1584 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1659.485101699829, \"sum\": 1659.485101699829, \"min\": 1659.485101699829}}, \"EndTime\": 1578472691.710656, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472690.050774}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:11 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=954.449174454 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:11 INFO 140719404451648] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:11 INFO 140719404451648] #quality_metric: host=algo-1, epoch=13, train loss <loss>=8.11329087257\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:11 INFO 140719404451648] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:11 INFO 140719404451648] Saved checkpoint to \"/opt/ml/model/state_ab27c1df-4d7d-4a50-81d3-a067bbbc4384-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 25.70796012878418, \"sum\": 25.70796012878418, \"min\": 25.70796012878418}}, \"EndTime\": 1578472691.736934, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472691.710733}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:11 INFO 140719404451648] Epoch[14] Batch[0] avg_epoch_loss=8.213596\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:11 INFO 140719404451648] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=8.21359634399\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:11 INFO 140719404451648] Epoch[14] Batch[5] avg_epoch_loss=8.111972\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:11 INFO 140719404451648] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=8.11197241147\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:11 INFO 140719404451648] Epoch[14] Batch [5]#011Speed: 1489.38 samples/sec#011loss=8.111972\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:12 INFO 140719404451648] Epoch[14] Batch[10] avg_epoch_loss=8.224469\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:12 INFO 140719404451648] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=8.35946531296\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:12 INFO 140719404451648] Epoch[14] Batch [10]#011Speed: 1647.80 samples/sec#011loss=8.359465\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:12 INFO 140719404451648] Epoch[14] Batch[15] avg_epoch_loss=8.224207\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:12 INFO 140719404451648] #quality_metric: host=algo-1, epoch=14, batch=15 train loss <loss>=8.22362995148\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:12 INFO 140719404451648] Epoch[14] Batch [15]#011Speed: 804.21 samples/sec#011loss=8.223630\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:12 INFO 140719404451648] Epoch[14] Batch[20] avg_epoch_loss=8.280920\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:12 INFO 140719404451648] #quality_metric: host=algo-1, epoch=14, batch=20 train loss <loss>=8.4624007225\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:12 INFO 140719404451648] Epoch[14] Batch [20]#011Speed: 813.99 samples/sec#011loss=8.462401\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:12 INFO 140719404451648] Epoch[14] Batch[25] avg_epoch_loss=8.241086\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:12 INFO 140719404451648] #quality_metric: host=algo-1, epoch=14, batch=25 train loss <loss>=8.073782444\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:12 INFO 140719404451648] Epoch[14] Batch [25]#011Speed: 1535.69 samples/sec#011loss=8.073782\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:12 INFO 140719404451648] Epoch[14] Batch[30] avg_epoch_loss=8.173372\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:12 INFO 140719404451648] #quality_metric: host=algo-1, epoch=14, batch=30 train loss <loss>=7.82126092911\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:12 INFO 140719404451648] Epoch[14] Batch [30]#011Speed: 755.50 samples/sec#011loss=7.821261\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:12 INFO 140719404451648] Epoch[14] Batch[35] avg_epoch_loss=8.143601\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:12 INFO 140719404451648] #quality_metric: host=algo-1, epoch=14, batch=35 train loss <loss>=7.95901985168\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:12 INFO 140719404451648] Epoch[14] Batch [35]#011Speed: 1346.17 samples/sec#011loss=7.959020\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] Epoch[14] Batch[40] avg_epoch_loss=8.112846\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] #quality_metric: host=algo-1, epoch=14, batch=40 train loss <loss>=7.89140701294\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] Epoch[14] Batch [40]#011Speed: 748.49 samples/sec#011loss=7.891407\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] Epoch[14] Batch[45] avg_epoch_loss=8.094034\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] #quality_metric: host=algo-1, epoch=14, batch=45 train loss <loss>=7.93978052139\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] Epoch[14] Batch [45]#011Speed: 1560.53 samples/sec#011loss=7.939781\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] Epoch[14] Batch[50] avg_epoch_loss=8.070700\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] #quality_metric: host=algo-1, epoch=14, batch=50 train loss <loss>=7.85603094101\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] Epoch[14] Batch [50]#011Speed: 1298.70 samples/sec#011loss=7.856031\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] processed a total of 1661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1649.8780250549316, \"sum\": 1649.8780250549316, \"min\": 1649.8780250549316}}, \"EndTime\": 1578472693.38692, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472691.736991}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=1006.67882722 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] #quality_metric: host=algo-1, epoch=14, train loss <loss>=8.05029579309\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] Saved checkpoint to \"/opt/ml/model/state_3dab7bda-393b-4d34-95d1-1973dc9461bc-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 21.701812744140625, \"sum\": 21.701812744140625, \"min\": 21.701812744140625}}, \"EndTime\": 1578472693.409179, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472693.386988}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] Epoch[15] Batch[0] avg_epoch_loss=8.136557\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=8.13655662537\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] Epoch[15] Batch[5] avg_epoch_loss=8.397938\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=8.3979382515\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] Epoch[15] Batch [5]#011Speed: 1558.48 samples/sec#011loss=8.397938\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] Epoch[15] Batch[10] avg_epoch_loss=8.337123\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=8.26414365768\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] Epoch[15] Batch [10]#011Speed: 788.83 samples/sec#011loss=8.264144\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] Epoch[15] Batch[15] avg_epoch_loss=8.408851\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] #quality_metric: host=algo-1, epoch=15, batch=15 train loss <loss>=8.56665210724\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:13 INFO 140719404451648] Epoch[15] Batch [15]#011Speed: 1555.09 samples/sec#011loss=8.566652\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:14 INFO 140719404451648] Epoch[15] Batch[20] avg_epoch_loss=8.333183\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:14 INFO 140719404451648] #quality_metric: host=algo-1, epoch=15, batch=20 train loss <loss>=8.09104833603\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:14 INFO 140719404451648] Epoch[15] Batch [20]#011Speed: 805.40 samples/sec#011loss=8.091048\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:14 INFO 140719404451648] Epoch[15] Batch[25] avg_epoch_loss=8.249337\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:14 INFO 140719404451648] #quality_metric: host=algo-1, epoch=15, batch=25 train loss <loss>=7.89717998505\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:14 INFO 140719404451648] Epoch[15] Batch [25]#011Speed: 1409.60 samples/sec#011loss=7.897180\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:14 INFO 140719404451648] Epoch[15] Batch[30] avg_epoch_loss=8.214027\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:14 INFO 140719404451648] #quality_metric: host=algo-1, epoch=15, batch=30 train loss <loss>=8.03041439056\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:14 INFO 140719404451648] Epoch[15] Batch [30]#011Speed: 752.87 samples/sec#011loss=8.030414\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:14 INFO 140719404451648] Epoch[15] Batch[35] avg_epoch_loss=8.177135\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:14 INFO 140719404451648] #quality_metric: host=algo-1, epoch=15, batch=35 train loss <loss>=7.94840917587\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:14 INFO 140719404451648] Epoch[15] Batch [35]#011Speed: 1554.65 samples/sec#011loss=7.948409\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:14 INFO 140719404451648] Epoch[15] Batch[40] avg_epoch_loss=8.143153\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:14 INFO 140719404451648] #quality_metric: host=algo-1, epoch=15, batch=40 train loss <loss>=7.89847955704\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:14 INFO 140719404451648] Epoch[15] Batch [40]#011Speed: 737.60 samples/sec#011loss=7.898480\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:14 INFO 140719404451648] Epoch[15] Batch[45] avg_epoch_loss=8.139895\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:14 INFO 140719404451648] #quality_metric: host=algo-1, epoch=15, batch=45 train loss <loss>=8.1131816864\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:14 INFO 140719404451648] Epoch[15] Batch [45]#011Speed: 1648.21 samples/sec#011loss=8.113182\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:14 INFO 140719404451648] processed a total of 1575 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1587.2490406036377, \"sum\": 1587.2490406036377, \"min\": 1587.2490406036377}}, \"EndTime\": 1578472694.99654, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472693.409239}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:14 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=992.212800631 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:14 INFO 140719404451648] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:14 INFO 140719404451648] #quality_metric: host=algo-1, epoch=15, train loss <loss>=8.08373339653\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:14 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:15 INFO 140719404451648] Epoch[16] Batch[0] avg_epoch_loss=8.021715\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:15 INFO 140719404451648] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=8.02171516418\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:15 INFO 140719404451648] Epoch[16] Batch[5] avg_epoch_loss=8.240626\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:15 INFO 140719404451648] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=8.24062601725\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:15 INFO 140719404451648] Epoch[16] Batch [5]#011Speed: 1316.98 samples/sec#011loss=8.240626\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:15 INFO 140719404451648] Epoch[16] Batch[10] avg_epoch_loss=8.346984\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:15 INFO 140719404451648] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=8.47461280823\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:15 INFO 140719404451648] Epoch[16] Batch [10]#011Speed: 761.90 samples/sec#011loss=8.474613\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:15 INFO 140719404451648] Epoch[16] Batch[15] avg_epoch_loss=8.409089\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:15 INFO 140719404451648] #quality_metric: host=algo-1, epoch=16, batch=15 train loss <loss>=8.54572153091\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:15 INFO 140719404451648] Epoch[16] Batch [15]#011Speed: 1594.85 samples/sec#011loss=8.545722\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:15 INFO 140719404451648] Epoch[16] Batch[20] avg_epoch_loss=8.402527\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:15 INFO 140719404451648] #quality_metric: host=algo-1, epoch=16, batch=20 train loss <loss>=8.38152751923\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:15 INFO 140719404451648] Epoch[16] Batch [20]#011Speed: 738.92 samples/sec#011loss=8.381528\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:15 INFO 140719404451648] Epoch[16] Batch[25] avg_epoch_loss=8.308141\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:15 INFO 140719404451648] #quality_metric: host=algo-1, epoch=16, batch=25 train loss <loss>=7.9117190361\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:15 INFO 140719404451648] Epoch[16] Batch [25]#011Speed: 1551.86 samples/sec#011loss=7.911719\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] Epoch[16] Batch[30] avg_epoch_loss=8.276311\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] #quality_metric: host=algo-1, epoch=16, batch=30 train loss <loss>=8.11079492569\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] Epoch[16] Batch [30]#011Speed: 766.13 samples/sec#011loss=8.110795\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] Epoch[16] Batch[35] avg_epoch_loss=8.196097\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] #quality_metric: host=algo-1, epoch=16, batch=35 train loss <loss>=7.69876899719\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] Epoch[16] Batch [35]#011Speed: 1558.63 samples/sec#011loss=7.698769\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] Epoch[16] Batch[40] avg_epoch_loss=8.170411\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] #quality_metric: host=algo-1, epoch=16, batch=40 train loss <loss>=7.98547124863\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] Epoch[16] Batch [40]#011Speed: 753.83 samples/sec#011loss=7.985471\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] Epoch[16] Batch[45] avg_epoch_loss=8.132822\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] #quality_metric: host=algo-1, epoch=16, batch=45 train loss <loss>=7.82459411621\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] Epoch[16] Batch [45]#011Speed: 1495.86 samples/sec#011loss=7.824594\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] Epoch[16] Batch[50] avg_epoch_loss=8.138925\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] #quality_metric: host=algo-1, epoch=16, batch=50 train loss <loss>=8.1950756073\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] Epoch[16] Batch [50]#011Speed: 1633.17 samples/sec#011loss=8.195076\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] processed a total of 1678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1690.0479793548584, \"sum\": 1690.0479793548584, \"min\": 1690.0479793548584}}, \"EndTime\": 1578472696.687106, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472694.996618}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=992.804273293 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] #quality_metric: host=algo-1, epoch=16, train loss <loss>=8.08679949563\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] Epoch[17] Batch[0] avg_epoch_loss=8.478051\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=8.47805118561\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] Epoch[17] Batch[5] avg_epoch_loss=8.105865\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=8.1058652401\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:16 INFO 140719404451648] Epoch[17] Batch [5]#011Speed: 1377.86 samples/sec#011loss=8.105865\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:17 INFO 140719404451648] Epoch[17] Batch[10] avg_epoch_loss=8.202908\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:17 INFO 140719404451648] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=8.31935901642\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:17 INFO 140719404451648] Epoch[17] Batch [10]#011Speed: 760.10 samples/sec#011loss=8.319359\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:17 INFO 140719404451648] Epoch[17] Batch[15] avg_epoch_loss=8.271001\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:17 INFO 140719404451648] #quality_metric: host=algo-1, epoch=17, batch=15 train loss <loss>=8.42080659866\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:17 INFO 140719404451648] Epoch[17] Batch [15]#011Speed: 1646.88 samples/sec#011loss=8.420807\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:17 INFO 140719404451648] Epoch[17] Batch[20] avg_epoch_loss=8.285229\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:17 INFO 140719404451648] #quality_metric: host=algo-1, epoch=17, batch=20 train loss <loss>=8.33075647354\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:17 INFO 140719404451648] Epoch[17] Batch [20]#011Speed: 736.35 samples/sec#011loss=8.330756\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:17 INFO 140719404451648] Epoch[17] Batch[25] avg_epoch_loss=8.228464\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:17 INFO 140719404451648] #quality_metric: host=algo-1, epoch=17, batch=25 train loss <loss>=7.99005451202\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:17 INFO 140719404451648] Epoch[17] Batch [25]#011Speed: 1654.79 samples/sec#011loss=7.990055\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:17 INFO 140719404451648] Epoch[17] Batch[30] avg_epoch_loss=8.194196\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:17 INFO 140719404451648] #quality_metric: host=algo-1, epoch=17, batch=30 train loss <loss>=8.0159986496\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:17 INFO 140719404451648] Epoch[17] Batch [30]#011Speed: 748.48 samples/sec#011loss=8.015999\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:17 INFO 140719404451648] Epoch[17] Batch[35] avg_epoch_loss=8.140703\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:17 INFO 140719404451648] #quality_metric: host=algo-1, epoch=17, batch=35 train loss <loss>=7.80904922485\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:17 INFO 140719404451648] Epoch[17] Batch [35]#011Speed: 1624.07 samples/sec#011loss=7.809049\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:18 INFO 140719404451648] Epoch[17] Batch[40] avg_epoch_loss=8.162584\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:18 INFO 140719404451648] #quality_metric: host=algo-1, epoch=17, batch=40 train loss <loss>=8.3201253891\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:18 INFO 140719404451648] Epoch[17] Batch [40]#011Speed: 688.68 samples/sec#011loss=8.320125\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:18 INFO 140719404451648] Epoch[17] Batch[45] avg_epoch_loss=8.195213\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:18 INFO 140719404451648] #quality_metric: host=algo-1, epoch=17, batch=45 train loss <loss>=8.46277523041\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:18 INFO 140719404451648] Epoch[17] Batch [45]#011Speed: 1319.86 samples/sec#011loss=8.462775\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:18 INFO 140719404451648] processed a total of 1560 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1636.5458965301514, \"sum\": 1636.5458965301514, \"min\": 1636.5458965301514}}, \"EndTime\": 1578472698.324189, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472696.687182}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:18 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=953.149123207 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:18 INFO 140719404451648] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:18 INFO 140719404451648] #quality_metric: host=algo-1, epoch=17, train loss <loss>=8.17429505562\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:18 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:18 INFO 140719404451648] Epoch[18] Batch[0] avg_epoch_loss=8.032692\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:18 INFO 140719404451648] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=8.03269195557\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:18 INFO 140719404451648] Epoch[18] Batch[5] avg_epoch_loss=8.321953\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:18 INFO 140719404451648] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=8.32195313772\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:18 INFO 140719404451648] Epoch[18] Batch [5]#011Speed: 1589.93 samples/sec#011loss=8.321953\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:18 INFO 140719404451648] Epoch[18] Batch[10] avg_epoch_loss=8.302549\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:18 INFO 140719404451648] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=8.27926416397\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:18 INFO 140719404451648] Epoch[18] Batch [10]#011Speed: 738.46 samples/sec#011loss=8.279264\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:18 INFO 140719404451648] Epoch[18] Batch[15] avg_epoch_loss=8.248917\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:18 INFO 140719404451648] #quality_metric: host=algo-1, epoch=18, batch=15 train loss <loss>=8.13092670441\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:18 INFO 140719404451648] Epoch[18] Batch [15]#011Speed: 1633.80 samples/sec#011loss=8.130927\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] Epoch[18] Batch[20] avg_epoch_loss=8.342557\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] #quality_metric: host=algo-1, epoch=18, batch=20 train loss <loss>=8.64220294952\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] Epoch[18] Batch [20]#011Speed: 757.46 samples/sec#011loss=8.642203\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] Epoch[18] Batch[25] avg_epoch_loss=8.259647\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] #quality_metric: host=algo-1, epoch=18, batch=25 train loss <loss>=7.91142635345\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] Epoch[18] Batch [25]#011Speed: 1559.76 samples/sec#011loss=7.911426\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] Epoch[18] Batch[30] avg_epoch_loss=8.230348\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] #quality_metric: host=algo-1, epoch=18, batch=30 train loss <loss>=8.07799425125\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] Epoch[18] Batch [30]#011Speed: 738.82 samples/sec#011loss=8.077994\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] Epoch[18] Batch[35] avg_epoch_loss=8.190061\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] #quality_metric: host=algo-1, epoch=18, batch=35 train loss <loss>=7.94027833939\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] Epoch[18] Batch [35]#011Speed: 1551.67 samples/sec#011loss=7.940278\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] Epoch[18] Batch[40] avg_epoch_loss=8.182619\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] #quality_metric: host=algo-1, epoch=18, batch=40 train loss <loss>=8.12903909683\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] Epoch[18] Batch [40]#011Speed: 723.09 samples/sec#011loss=8.129039\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] Epoch[18] Batch[45] avg_epoch_loss=8.198246\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] #quality_metric: host=algo-1, epoch=18, batch=45 train loss <loss>=8.32638607025\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] Epoch[18] Batch [45]#011Speed: 1420.83 samples/sec#011loss=8.326386\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] Epoch[18] Batch[50] avg_epoch_loss=8.173083\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] #quality_metric: host=algo-1, epoch=18, batch=50 train loss <loss>=7.94158582687\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] Epoch[18] Batch [50]#011Speed: 1248.73 samples/sec#011loss=7.941586\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] processed a total of 1629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1659.6050262451172, \"sum\": 1659.6050262451172, \"min\": 1659.6050262451172}}, \"EndTime\": 1578472699.984344, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472698.324287}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=981.493706824 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] #quality_metric: host=algo-1, epoch=18, train loss <loss>=8.17308309031\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:19 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:20 INFO 140719404451648] Epoch[19] Batch[0] avg_epoch_loss=8.335794\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:20 INFO 140719404451648] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=8.33579444885\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:20 INFO 140719404451648] Epoch[19] Batch[5] avg_epoch_loss=8.489257\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:20 INFO 140719404451648] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=8.48925669988\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:20 INFO 140719404451648] Epoch[19] Batch [5]#011Speed: 1344.30 samples/sec#011loss=8.489257\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:20 INFO 140719404451648] Epoch[19] Batch[10] avg_epoch_loss=8.522485\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:20 INFO 140719404451648] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=8.56235818863\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:20 INFO 140719404451648] Epoch[19] Batch [10]#011Speed: 788.03 samples/sec#011loss=8.562358\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:20 INFO 140719404451648] Epoch[19] Batch[15] avg_epoch_loss=8.511828\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:20 INFO 140719404451648] #quality_metric: host=algo-1, epoch=19, batch=15 train loss <loss>=8.48838453293\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:20 INFO 140719404451648] Epoch[19] Batch [15]#011Speed: 1669.59 samples/sec#011loss=8.488385\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:20 INFO 140719404451648] Epoch[19] Batch[20] avg_epoch_loss=8.459672\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:20 INFO 140719404451648] #quality_metric: host=algo-1, epoch=19, batch=20 train loss <loss>=8.29277324677\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:20 INFO 140719404451648] Epoch[19] Batch [20]#011Speed: 751.91 samples/sec#011loss=8.292773\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:20 INFO 140719404451648] Epoch[19] Batch[25] avg_epoch_loss=8.349845\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:20 INFO 140719404451648] #quality_metric: host=algo-1, epoch=19, batch=25 train loss <loss>=7.88856859207\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:20 INFO 140719404451648] Epoch[19] Batch [25]#011Speed: 1554.06 samples/sec#011loss=7.888569\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] Epoch[19] Batch[30] avg_epoch_loss=8.303022\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] #quality_metric: host=algo-1, epoch=19, batch=30 train loss <loss>=8.05954084396\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] Epoch[19] Batch [30]#011Speed: 725.33 samples/sec#011loss=8.059541\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] Epoch[19] Batch[35] avg_epoch_loss=8.233534\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] #quality_metric: host=algo-1, epoch=19, batch=35 train loss <loss>=7.8027100563\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] Epoch[19] Batch [35]#011Speed: 1664.17 samples/sec#011loss=7.802710\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] Epoch[19] Batch[40] avg_epoch_loss=8.177383\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] #quality_metric: host=algo-1, epoch=19, batch=40 train loss <loss>=7.77309656143\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] Epoch[19] Batch [40]#011Speed: 770.46 samples/sec#011loss=7.773097\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] Epoch[19] Batch[45] avg_epoch_loss=8.171958\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] #quality_metric: host=algo-1, epoch=19, batch=45 train loss <loss>=8.1274769783\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] Epoch[19] Batch [45]#011Speed: 1498.49 samples/sec#011loss=8.127477\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] Epoch[19] Batch[50] avg_epoch_loss=8.054371\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] #quality_metric: host=algo-1, epoch=19, batch=50 train loss <loss>=6.97256717682\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] Epoch[19] Batch [50]#011Speed: 1117.65 samples/sec#011loss=6.972567\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] processed a total of 1606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1638.597011566162, \"sum\": 1638.597011566162, \"min\": 1638.597011566162}}, \"EndTime\": 1578472701.623422, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472699.984418}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=980.051141512 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] #quality_metric: host=algo-1, epoch=19, train loss <loss>=8.05437100167\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] Epoch[20] Batch[0] avg_epoch_loss=8.500687\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=8.50068664551\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] Epoch[20] Batch[5] avg_epoch_loss=8.343606\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=8.34360551834\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:21 INFO 140719404451648] Epoch[20] Batch [5]#011Speed: 1345.64 samples/sec#011loss=8.343606\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:22 INFO 140719404451648] Epoch[20] Batch[10] avg_epoch_loss=8.262931\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:22 INFO 140719404451648] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=8.16612186432\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:22 INFO 140719404451648] Epoch[20] Batch [10]#011Speed: 679.55 samples/sec#011loss=8.166122\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:22 INFO 140719404451648] Epoch[20] Batch[15] avg_epoch_loss=8.212498\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:22 INFO 140719404451648] #quality_metric: host=algo-1, epoch=20, batch=15 train loss <loss>=8.1015460968\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:22 INFO 140719404451648] Epoch[20] Batch [15]#011Speed: 1665.49 samples/sec#011loss=8.101546\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:22 INFO 140719404451648] Epoch[20] Batch[20] avg_epoch_loss=8.198387\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:22 INFO 140719404451648] #quality_metric: host=algo-1, epoch=20, batch=20 train loss <loss>=8.15322914124\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:22 INFO 140719404451648] Epoch[20] Batch [20]#011Speed: 755.73 samples/sec#011loss=8.153229\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:22 INFO 140719404451648] Epoch[20] Batch[25] avg_epoch_loss=8.142277\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:22 INFO 140719404451648] #quality_metric: host=algo-1, epoch=20, batch=25 train loss <loss>=7.90661754608\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:22 INFO 140719404451648] Epoch[20] Batch [25]#011Speed: 1562.87 samples/sec#011loss=7.906618\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:22 INFO 140719404451648] Epoch[20] Batch[30] avg_epoch_loss=8.109435\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:22 INFO 140719404451648] #quality_metric: host=algo-1, epoch=20, batch=30 train loss <loss>=7.93865404129\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:22 INFO 140719404451648] Epoch[20] Batch [30]#011Speed: 778.73 samples/sec#011loss=7.938654\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:22 INFO 140719404451648] Epoch[20] Batch[35] avg_epoch_loss=8.082769\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:22 INFO 140719404451648] #quality_metric: host=algo-1, epoch=20, batch=35 train loss <loss>=7.9174446106\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:22 INFO 140719404451648] Epoch[20] Batch [35]#011Speed: 1626.31 samples/sec#011loss=7.917445\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] Epoch[20] Batch[40] avg_epoch_loss=8.038754\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] #quality_metric: host=algo-1, epoch=20, batch=40 train loss <loss>=7.72184648514\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] Epoch[20] Batch [40]#011Speed: 759.37 samples/sec#011loss=7.721846\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] Epoch[20] Batch[45] avg_epoch_loss=7.981935\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] #quality_metric: host=algo-1, epoch=20, batch=45 train loss <loss>=7.51601161957\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] Epoch[20] Batch [45]#011Speed: 1539.63 samples/sec#011loss=7.516012\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] Epoch[20] Batch[50] avg_epoch_loss=8.038788\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] #quality_metric: host=algo-1, epoch=20, batch=50 train loss <loss>=8.56183586121\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] Epoch[20] Batch [50]#011Speed: 1064.62 samples/sec#011loss=8.561836\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] processed a total of 1608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1658.9131355285645, \"sum\": 1658.9131355285645, \"min\": 1658.9131355285645}}, \"EndTime\": 1578472703.282831, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472701.623481}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=969.246378569 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] #quality_metric: host=algo-1, epoch=20, train loss <loss>=8.0387876361\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] Saved checkpoint to \"/opt/ml/model/state_e6a5424f-56e4-4c01-bad5-bb81e288807a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 25.57086944580078, \"sum\": 25.57086944580078, \"min\": 25.57086944580078}}, \"EndTime\": 1578472703.308926, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472703.282903}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] Epoch[21] Batch[0] avg_epoch_loss=8.431549\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=8.43154907227\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] Epoch[21] Batch[5] avg_epoch_loss=8.256176\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=8.25617647171\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] Epoch[21] Batch [5]#011Speed: 1434.05 samples/sec#011loss=8.256176\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] Epoch[21] Batch[10] avg_epoch_loss=8.370222\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=8.50707683563\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] Epoch[21] Batch [10]#011Speed: 711.16 samples/sec#011loss=8.507077\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] Epoch[21] Batch[15] avg_epoch_loss=8.445821\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] #quality_metric: host=algo-1, epoch=21, batch=15 train loss <loss>=8.61213912964\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:23 INFO 140719404451648] Epoch[21] Batch [15]#011Speed: 1602.98 samples/sec#011loss=8.612139\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] Epoch[21] Batch[20] avg_epoch_loss=8.395035\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] #quality_metric: host=algo-1, epoch=21, batch=20 train loss <loss>=8.23251848221\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] Epoch[21] Batch [20]#011Speed: 706.06 samples/sec#011loss=8.232518\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] Epoch[21] Batch[25] avg_epoch_loss=8.298471\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] #quality_metric: host=algo-1, epoch=21, batch=25 train loss <loss>=7.89290390015\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] Epoch[21] Batch [25]#011Speed: 1599.46 samples/sec#011loss=7.892904\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] Epoch[21] Batch[30] avg_epoch_loss=8.225876\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] #quality_metric: host=algo-1, epoch=21, batch=30 train loss <loss>=7.84838323593\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] Epoch[21] Batch [30]#011Speed: 711.45 samples/sec#011loss=7.848383\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] Epoch[21] Batch[35] avg_epoch_loss=8.161145\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] #quality_metric: host=algo-1, epoch=21, batch=35 train loss <loss>=7.75980930328\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] Epoch[21] Batch [35]#011Speed: 1675.04 samples/sec#011loss=7.759809\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] Epoch[21] Batch[40] avg_epoch_loss=8.130685\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] #quality_metric: host=algo-1, epoch=21, batch=40 train loss <loss>=7.91137094498\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] Epoch[21] Batch [40]#011Speed: 787.97 samples/sec#011loss=7.911371\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] Epoch[21] Batch[45] avg_epoch_loss=8.113221\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] #quality_metric: host=algo-1, epoch=21, batch=45 train loss <loss>=7.97001514435\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] Epoch[21] Batch [45]#011Speed: 1469.05 samples/sec#011loss=7.970015\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] Epoch[21] Batch[50] avg_epoch_loss=8.077392\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] #quality_metric: host=algo-1, epoch=21, batch=50 train loss <loss>=7.74777259827\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] Epoch[21] Batch [50]#011Speed: 1271.30 samples/sec#011loss=7.747773\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] processed a total of 1622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1647.632122039795, \"sum\": 1647.632122039795, \"min\": 1647.632122039795}}, \"EndTime\": 1578472704.95667, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472703.308991}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=984.381519474 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] #quality_metric: host=algo-1, epoch=21, train loss <loss>=8.07739228828\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:24 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:25 INFO 140719404451648] Epoch[22] Batch[0] avg_epoch_loss=7.790228\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:25 INFO 140719404451648] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=7.79022789001\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:25 INFO 140719404451648] Epoch[22] Batch[5] avg_epoch_loss=8.265625\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:25 INFO 140719404451648] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=8.26562547684\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:25 INFO 140719404451648] Epoch[22] Batch [5]#011Speed: 1478.43 samples/sec#011loss=8.265625\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:25 INFO 140719404451648] Epoch[22] Batch[10] avg_epoch_loss=8.292670\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:25 INFO 140719404451648] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=8.32512302399\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:25 INFO 140719404451648] Epoch[22] Batch [10]#011Speed: 689.91 samples/sec#011loss=8.325123\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:25 INFO 140719404451648] Epoch[22] Batch[15] avg_epoch_loss=8.359707\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:25 INFO 140719404451648] #quality_metric: host=algo-1, epoch=22, batch=15 train loss <loss>=8.50718784332\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:25 INFO 140719404451648] Epoch[22] Batch [15]#011Speed: 1596.42 samples/sec#011loss=8.507188\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:25 INFO 140719404451648] Epoch[22] Batch[20] avg_epoch_loss=8.303946\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:25 INFO 140719404451648] #quality_metric: host=algo-1, epoch=22, batch=20 train loss <loss>=8.12550973892\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:25 INFO 140719404451648] Epoch[22] Batch [20]#011Speed: 783.42 samples/sec#011loss=8.125510\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:25 INFO 140719404451648] Epoch[22] Batch[25] avg_epoch_loss=8.236683\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:25 INFO 140719404451648] #quality_metric: host=algo-1, epoch=22, batch=25 train loss <loss>=7.95417928696\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:25 INFO 140719404451648] Epoch[22] Batch [25]#011Speed: 1381.13 samples/sec#011loss=7.954179\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] Epoch[22] Batch[30] avg_epoch_loss=8.178977\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] #quality_metric: host=algo-1, epoch=22, batch=30 train loss <loss>=7.87890768051\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] Epoch[22] Batch [30]#011Speed: 721.30 samples/sec#011loss=7.878908\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] Epoch[22] Batch[35] avg_epoch_loss=8.089001\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] #quality_metric: host=algo-1, epoch=22, batch=35 train loss <loss>=7.53114748001\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] Epoch[22] Batch [35]#011Speed: 1560.62 samples/sec#011loss=7.531147\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] Epoch[22] Batch[40] avg_epoch_loss=8.054314\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] #quality_metric: host=algo-1, epoch=22, batch=40 train loss <loss>=7.80457258224\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] Epoch[22] Batch [40]#011Speed: 729.67 samples/sec#011loss=7.804573\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] Epoch[22] Batch[45] avg_epoch_loss=8.041361\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] #quality_metric: host=algo-1, epoch=22, batch=45 train loss <loss>=7.93514680862\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] Epoch[22] Batch [45]#011Speed: 1300.77 samples/sec#011loss=7.935147\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] Epoch[22] Batch[50] avg_epoch_loss=8.018434\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] #quality_metric: host=algo-1, epoch=22, batch=50 train loss <loss>=7.80750408173\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] Epoch[22] Batch [50]#011Speed: 1433.46 samples/sec#011loss=7.807504\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] processed a total of 1613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1674.5271682739258, \"sum\": 1674.5271682739258, \"min\": 1674.5271682739258}}, \"EndTime\": 1578472706.631673, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472704.956741}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=963.193220444 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] #quality_metric: host=algo-1, epoch=22, train loss <loss>=8.01843422534\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] Saved checkpoint to \"/opt/ml/model/state_c8f0668f-7ac3-4220-b014-b39d45475d27-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 21.498918533325195, \"sum\": 21.498918533325195, \"min\": 21.498918533325195}}, \"EndTime\": 1578472706.653768, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472706.631748}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] Epoch[23] Batch[0] avg_epoch_loss=8.807241\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=8.80724143982\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] Epoch[23] Batch[5] avg_epoch_loss=8.331680\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=8.33167982101\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:26 INFO 140719404451648] Epoch[23] Batch [5]#011Speed: 1271.68 samples/sec#011loss=8.331680\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:27 INFO 140719404451648] Epoch[23] Batch[10] avg_epoch_loss=8.320192\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:27 INFO 140719404451648] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=8.30640592575\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:27 INFO 140719404451648] Epoch[23] Batch [10]#011Speed: 754.81 samples/sec#011loss=8.306406\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:27 INFO 140719404451648] Epoch[23] Batch[15] avg_epoch_loss=8.321401\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:27 INFO 140719404451648] #quality_metric: host=algo-1, epoch=23, batch=15 train loss <loss>=8.3240603447\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:27 INFO 140719404451648] Epoch[23] Batch [15]#011Speed: 1623.29 samples/sec#011loss=8.324060\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:27 INFO 140719404451648] Epoch[23] Batch[20] avg_epoch_loss=8.291262\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:27 INFO 140719404451648] #quality_metric: host=algo-1, epoch=23, batch=20 train loss <loss>=8.19481906891\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:27 INFO 140719404451648] Epoch[23] Batch [20]#011Speed: 741.93 samples/sec#011loss=8.194819\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:27 INFO 140719404451648] Epoch[23] Batch[25] avg_epoch_loss=8.253245\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:27 INFO 140719404451648] #quality_metric: host=algo-1, epoch=23, batch=25 train loss <loss>=8.09357242584\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:27 INFO 140719404451648] Epoch[23] Batch [25]#011Speed: 1667.86 samples/sec#011loss=8.093572\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:27 INFO 140719404451648] Epoch[23] Batch[30] avg_epoch_loss=8.180262\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:27 INFO 140719404451648] #quality_metric: host=algo-1, epoch=23, batch=30 train loss <loss>=7.80075302124\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:27 INFO 140719404451648] Epoch[23] Batch [30]#011Speed: 758.80 samples/sec#011loss=7.800753\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:27 INFO 140719404451648] Epoch[23] Batch[35] avg_epoch_loss=8.111890\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:27 INFO 140719404451648] #quality_metric: host=algo-1, epoch=23, batch=35 train loss <loss>=7.68798065186\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:27 INFO 140719404451648] Epoch[23] Batch [35]#011Speed: 1604.88 samples/sec#011loss=7.687981\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:28 INFO 140719404451648] Epoch[23] Batch[40] avg_epoch_loss=8.118844\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:28 INFO 140719404451648] #quality_metric: host=algo-1, epoch=23, batch=40 train loss <loss>=8.16891679764\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:28 INFO 140719404451648] Epoch[23] Batch [40]#011Speed: 703.80 samples/sec#011loss=8.168917\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:28 INFO 140719404451648] Epoch[23] Batch[45] avg_epoch_loss=8.131449\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:28 INFO 140719404451648] #quality_metric: host=algo-1, epoch=23, batch=45 train loss <loss>=8.23480377197\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:28 INFO 140719404451648] Epoch[23] Batch [45]#011Speed: 1293.09 samples/sec#011loss=8.234804\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:28 INFO 140719404451648] processed a total of 1566 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1633.6219310760498, \"sum\": 1633.6219310760498, \"min\": 1633.6219310760498}}, \"EndTime\": 1578472708.287507, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472706.653829}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:28 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=958.541080957 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:28 INFO 140719404451648] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:28 INFO 140719404451648] #quality_metric: host=algo-1, epoch=23, train loss <loss>=8.08864197439\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:28 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:28 INFO 140719404451648] Epoch[24] Batch[0] avg_epoch_loss=8.864035\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:28 INFO 140719404451648] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=8.86403465271\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:28 INFO 140719404451648] Epoch[24] Batch[5] avg_epoch_loss=8.412449\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:28 INFO 140719404451648] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=8.41244935989\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:28 INFO 140719404451648] Epoch[24] Batch [5]#011Speed: 1421.10 samples/sec#011loss=8.412449\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:28 INFO 140719404451648] Epoch[24] Batch[10] avg_epoch_loss=8.420753\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:28 INFO 140719404451648] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=8.43071632385\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:28 INFO 140719404451648] Epoch[24] Batch [10]#011Speed: 723.41 samples/sec#011loss=8.430716\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:28 INFO 140719404451648] Epoch[24] Batch[15] avg_epoch_loss=8.531774\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:28 INFO 140719404451648] #quality_metric: host=algo-1, epoch=24, batch=15 train loss <loss>=8.77602157593\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:28 INFO 140719404451648] Epoch[24] Batch [15]#011Speed: 1548.45 samples/sec#011loss=8.776022\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:29 INFO 140719404451648] Epoch[24] Batch[20] avg_epoch_loss=8.426075\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:29 INFO 140719404451648] #quality_metric: host=algo-1, epoch=24, batch=20 train loss <loss>=8.08783893585\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:29 INFO 140719404451648] Epoch[24] Batch [20]#011Speed: 715.15 samples/sec#011loss=8.087839\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:29 INFO 140719404451648] Epoch[24] Batch[25] avg_epoch_loss=8.316739\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:29 INFO 140719404451648] #quality_metric: host=algo-1, epoch=24, batch=25 train loss <loss>=7.85752573013\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:29 INFO 140719404451648] Epoch[24] Batch [25]#011Speed: 1678.66 samples/sec#011loss=7.857526\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:29 INFO 140719404451648] Epoch[24] Batch[30] avg_epoch_loss=8.244793\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:29 INFO 140719404451648] #quality_metric: host=algo-1, epoch=24, batch=30 train loss <loss>=7.87067537308\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:29 INFO 140719404451648] Epoch[24] Batch [30]#011Speed: 718.71 samples/sec#011loss=7.870675\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:29 INFO 140719404451648] Epoch[24] Batch[35] avg_epoch_loss=8.174177\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:29 INFO 140719404451648] #quality_metric: host=algo-1, epoch=24, batch=35 train loss <loss>=7.73635797501\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:29 INFO 140719404451648] Epoch[24] Batch [35]#011Speed: 1656.98 samples/sec#011loss=7.736358\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:29 INFO 140719404451648] Epoch[24] Batch[40] avg_epoch_loss=8.145577\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:29 INFO 140719404451648] #quality_metric: host=algo-1, epoch=24, batch=40 train loss <loss>=7.93965473175\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:29 INFO 140719404451648] Epoch[24] Batch [40]#011Speed: 775.28 samples/sec#011loss=7.939655\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:29 INFO 140719404451648] Epoch[24] Batch[45] avg_epoch_loss=8.132284\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:29 INFO 140719404451648] #quality_metric: host=algo-1, epoch=24, batch=45 train loss <loss>=8.02328596115\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:29 INFO 140719404451648] Epoch[24] Batch [45]#011Speed: 1548.11 samples/sec#011loss=8.023286\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:29 INFO 140719404451648] processed a total of 1563 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1619.2221641540527, \"sum\": 1619.2221641540527, \"min\": 1619.2221641540527}}, \"EndTime\": 1578472709.90723, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472708.287583}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:29 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=965.219308517 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:29 INFO 140719404451648] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:29 INFO 140719404451648] #quality_metric: host=algo-1, epoch=24, train loss <loss>=8.09922354562\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:29 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:30 INFO 140719404451648] Epoch[25] Batch[0] avg_epoch_loss=7.683264\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:30 INFO 140719404451648] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=7.68326377869\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:30 INFO 140719404451648] Epoch[25] Batch[5] avg_epoch_loss=7.935895\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:30 INFO 140719404451648] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=7.9358950456\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:30 INFO 140719404451648] Epoch[25] Batch [5]#011Speed: 1551.53 samples/sec#011loss=7.935895\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:30 INFO 140719404451648] Epoch[25] Batch[10] avg_epoch_loss=8.104056\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:30 INFO 140719404451648] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=8.30584869385\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:30 INFO 140719404451648] Epoch[25] Batch [10]#011Speed: 754.58 samples/sec#011loss=8.305849\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:30 INFO 140719404451648] Epoch[25] Batch[15] avg_epoch_loss=8.274541\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:30 INFO 140719404451648] #quality_metric: host=algo-1, epoch=25, batch=15 train loss <loss>=8.6496099472\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:30 INFO 140719404451648] Epoch[25] Batch [15]#011Speed: 1562.23 samples/sec#011loss=8.649610\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:30 INFO 140719404451648] Epoch[25] Batch[20] avg_epoch_loss=8.240356\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:30 INFO 140719404451648] #quality_metric: host=algo-1, epoch=25, batch=20 train loss <loss>=8.13096389771\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:30 INFO 140719404451648] Epoch[25] Batch [20]#011Speed: 784.95 samples/sec#011loss=8.130964\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:30 INFO 140719404451648] Epoch[25] Batch[25] avg_epoch_loss=8.198738\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:30 INFO 140719404451648] #quality_metric: host=algo-1, epoch=25, batch=25 train loss <loss>=8.02394075394\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:30 INFO 140719404451648] Epoch[25] Batch [25]#011Speed: 1564.12 samples/sec#011loss=8.023941\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] Epoch[25] Batch[30] avg_epoch_loss=8.104509\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] #quality_metric: host=algo-1, epoch=25, batch=30 train loss <loss>=7.61451807022\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] Epoch[25] Batch [30]#011Speed: 636.25 samples/sec#011loss=7.614518\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] Epoch[25] Batch[35] avg_epoch_loss=8.034196\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] #quality_metric: host=algo-1, epoch=25, batch=35 train loss <loss>=7.59825878143\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] Epoch[25] Batch [35]#011Speed: 1519.21 samples/sec#011loss=7.598259\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] Epoch[25] Batch[40] avg_epoch_loss=8.034652\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] #quality_metric: host=algo-1, epoch=25, batch=40 train loss <loss>=8.03793029785\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] Epoch[25] Batch [40]#011Speed: 787.94 samples/sec#011loss=8.037930\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] Epoch[25] Batch[45] avg_epoch_loss=8.026234\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] #quality_metric: host=algo-1, epoch=25, batch=45 train loss <loss>=7.95720539093\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] Epoch[25] Batch [45]#011Speed: 1679.96 samples/sec#011loss=7.957205\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] Epoch[25] Batch[50] avg_epoch_loss=7.996024\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] #quality_metric: host=algo-1, epoch=25, batch=50 train loss <loss>=7.7180929184\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] Epoch[25] Batch [50]#011Speed: 1140.11 samples/sec#011loss=7.718093\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] processed a total of 1604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1642.4000263214111, \"sum\": 1642.4000263214111, \"min\": 1642.4000263214111}}, \"EndTime\": 1578472711.55019, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472709.907298}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=976.555489284 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] #quality_metric: host=algo-1, epoch=25, train loss <loss>=7.99602380453\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] Saved checkpoint to \"/opt/ml/model/state_6b6c44f9-e752-41f2-998b-9664d89e36fe-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 25.20298957824707, \"sum\": 25.20298957824707, \"min\": 25.20298957824707}}, \"EndTime\": 1578472711.575908, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472711.550264}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] Epoch[26] Batch[0] avg_epoch_loss=8.550875\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=8.55087471008\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] Epoch[26] Batch[5] avg_epoch_loss=8.432855\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=8.43285512924\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:31 INFO 140719404451648] Epoch[26] Batch [5]#011Speed: 1352.86 samples/sec#011loss=8.432855\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:32 INFO 140719404451648] Epoch[26] Batch[10] avg_epoch_loss=8.265993\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:32 INFO 140719404451648] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=8.06575784683\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:32 INFO 140719404451648] Epoch[26] Batch [10]#011Speed: 712.45 samples/sec#011loss=8.065758\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:32 INFO 140719404451648] Epoch[26] Batch[15] avg_epoch_loss=8.389024\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:32 INFO 140719404451648] #quality_metric: host=algo-1, epoch=26, batch=15 train loss <loss>=8.65969142914\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:32 INFO 140719404451648] Epoch[26] Batch [15]#011Speed: 1558.70 samples/sec#011loss=8.659691\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:32 INFO 140719404451648] Epoch[26] Batch[20] avg_epoch_loss=8.407040\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:32 INFO 140719404451648] #quality_metric: host=algo-1, epoch=26, batch=20 train loss <loss>=8.46469173431\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:32 INFO 140719404451648] Epoch[26] Batch [20]#011Speed: 742.87 samples/sec#011loss=8.464692\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:32 INFO 140719404451648] Epoch[26] Batch[25] avg_epoch_loss=8.347892\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:32 INFO 140719404451648] #quality_metric: host=algo-1, epoch=26, batch=25 train loss <loss>=8.09947156906\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:32 INFO 140719404451648] Epoch[26] Batch [25]#011Speed: 1537.52 samples/sec#011loss=8.099472\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:32 INFO 140719404451648] Epoch[26] Batch[30] avg_epoch_loss=8.291550\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:32 INFO 140719404451648] #quality_metric: host=algo-1, epoch=26, batch=30 train loss <loss>=7.9985707283\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:32 INFO 140719404451648] Epoch[26] Batch [30]#011Speed: 761.60 samples/sec#011loss=7.998571\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:32 INFO 140719404451648] Epoch[26] Batch[35] avg_epoch_loss=8.197870\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:32 INFO 140719404451648] #quality_metric: host=algo-1, epoch=26, batch=35 train loss <loss>=7.61705112457\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:32 INFO 140719404451648] Epoch[26] Batch [35]#011Speed: 1458.51 samples/sec#011loss=7.617051\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] Epoch[26] Batch[40] avg_epoch_loss=8.167631\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] #quality_metric: host=algo-1, epoch=26, batch=40 train loss <loss>=7.94991312027\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] Epoch[26] Batch [40]#011Speed: 679.11 samples/sec#011loss=7.949913\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] Epoch[26] Batch[45] avg_epoch_loss=8.161701\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] #quality_metric: host=algo-1, epoch=26, batch=45 train loss <loss>=8.11307935715\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] Epoch[26] Batch [45]#011Speed: 1415.13 samples/sec#011loss=8.113079\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] Epoch[26] Batch[50] avg_epoch_loss=8.123253\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] #quality_metric: host=algo-1, epoch=26, batch=50 train loss <loss>=7.76952810287\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] Epoch[26] Batch [50]#011Speed: 1335.49 samples/sec#011loss=7.769528\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] processed a total of 1678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1731.1558723449707, \"sum\": 1731.1558723449707, \"min\": 1731.1558723449707}}, \"EndTime\": 1578472713.307172, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472711.575966}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=969.234108849 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] #quality_metric: host=algo-1, epoch=26, train loss <loss>=8.08901053555\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] Epoch[27] Batch[0] avg_epoch_loss=7.840493\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=7.84049272537\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] Epoch[27] Batch[5] avg_epoch_loss=8.149062\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=8.14906191826\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] Epoch[27] Batch [5]#011Speed: 1663.65 samples/sec#011loss=8.149062\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] Epoch[27] Batch[10] avg_epoch_loss=8.175716\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=8.2077003479\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] Epoch[27] Batch [10]#011Speed: 777.15 samples/sec#011loss=8.207700\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] Epoch[27] Batch[15] avg_epoch_loss=8.327356\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] #quality_metric: host=algo-1, epoch=27, batch=15 train loss <loss>=8.66096553802\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:33 INFO 140719404451648] Epoch[27] Batch [15]#011Speed: 1578.35 samples/sec#011loss=8.660966\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] Epoch[27] Batch[20] avg_epoch_loss=8.276720\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] #quality_metric: host=algo-1, epoch=27, batch=20 train loss <loss>=8.11468391418\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] Epoch[27] Batch [20]#011Speed: 749.62 samples/sec#011loss=8.114684\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] Epoch[27] Batch[25] avg_epoch_loss=8.238136\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] #quality_metric: host=algo-1, epoch=27, batch=25 train loss <loss>=8.07608251572\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] Epoch[27] Batch [25]#011Speed: 1576.42 samples/sec#011loss=8.076083\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] Epoch[27] Batch[30] avg_epoch_loss=8.186866\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] #quality_metric: host=algo-1, epoch=27, batch=30 train loss <loss>=7.92026386261\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] Epoch[27] Batch [30]#011Speed: 799.48 samples/sec#011loss=7.920264\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] Epoch[27] Batch[35] avg_epoch_loss=8.161071\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] #quality_metric: host=algo-1, epoch=27, batch=35 train loss <loss>=8.0011382103\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] Epoch[27] Batch [35]#011Speed: 1585.37 samples/sec#011loss=8.001138\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] Epoch[27] Batch[40] avg_epoch_loss=8.133556\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] #quality_metric: host=algo-1, epoch=27, batch=40 train loss <loss>=7.93545150757\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] Epoch[27] Batch [40]#011Speed: 795.45 samples/sec#011loss=7.935452\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] Epoch[27] Batch[45] avg_epoch_loss=8.063019\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] #quality_metric: host=algo-1, epoch=27, batch=45 train loss <loss>=7.48461894989\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] Epoch[27] Batch [45]#011Speed: 1578.55 samples/sec#011loss=7.484619\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] Epoch[27] Batch[50] avg_epoch_loss=8.035099\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] #quality_metric: host=algo-1, epoch=27, batch=50 train loss <loss>=7.77823553085\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] Epoch[27] Batch [50]#011Speed: 1042.60 samples/sec#011loss=7.778236\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] processed a total of 1688 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1651.9567966461182, \"sum\": 1651.9567966461182, \"min\": 1651.9567966461182}}, \"EndTime\": 1578472714.959614, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472713.307247}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=1021.75095172 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] #quality_metric: host=algo-1, epoch=27, train loss <loss>=8.03069385493\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:34 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:35 INFO 140719404451648] Epoch[28] Batch[0] avg_epoch_loss=7.922973\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:35 INFO 140719404451648] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=7.92297315598\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:35 INFO 140719404451648] Epoch[28] Batch[5] avg_epoch_loss=8.287401\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:35 INFO 140719404451648] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=8.28740088145\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:35 INFO 140719404451648] Epoch[28] Batch [5]#011Speed: 1692.87 samples/sec#011loss=8.287401\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:35 INFO 140719404451648] Epoch[28] Batch[10] avg_epoch_loss=8.286345\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:35 INFO 140719404451648] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=8.28507757187\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:35 INFO 140719404451648] Epoch[28] Batch [10]#011Speed: 634.84 samples/sec#011loss=8.285078\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:35 INFO 140719404451648] Epoch[28] Batch[15] avg_epoch_loss=8.398379\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:35 INFO 140719404451648] #quality_metric: host=algo-1, epoch=28, batch=15 train loss <loss>=8.64485263824\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:35 INFO 140719404451648] Epoch[28] Batch [15]#011Speed: 1733.63 samples/sec#011loss=8.644853\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:35 INFO 140719404451648] Epoch[28] Batch[20] avg_epoch_loss=8.353342\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:35 INFO 140719404451648] #quality_metric: host=algo-1, epoch=28, batch=20 train loss <loss>=8.20922679901\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:35 INFO 140719404451648] Epoch[28] Batch [20]#011Speed: 774.08 samples/sec#011loss=8.209227\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:35 INFO 140719404451648] Epoch[28] Batch[25] avg_epoch_loss=8.224635\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:35 INFO 140719404451648] #quality_metric: host=algo-1, epoch=28, batch=25 train loss <loss>=7.68406324387\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:35 INFO 140719404451648] Epoch[28] Batch [25]#011Speed: 1656.32 samples/sec#011loss=7.684063\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:36 INFO 140719404451648] Epoch[28] Batch[30] avg_epoch_loss=8.166805\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:36 INFO 140719404451648] #quality_metric: host=algo-1, epoch=28, batch=30 train loss <loss>=7.86609134674\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:36 INFO 140719404451648] Epoch[28] Batch [30]#011Speed: 750.87 samples/sec#011loss=7.866091\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:36 INFO 140719404451648] Epoch[28] Batch[35] avg_epoch_loss=8.082523\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:36 INFO 140719404451648] #quality_metric: host=algo-1, epoch=28, batch=35 train loss <loss>=7.55997123718\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:36 INFO 140719404451648] Epoch[28] Batch [35]#011Speed: 1611.64 samples/sec#011loss=7.559971\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:38:36 INFO 140719404451648] Epoch[28] Batch[40] avg_epoch_loss=8.063135\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:36 INFO 140719404451648] #quality_metric: host=algo-1, epoch=28, batch=40 train loss <loss>=7.9235449791\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:36 INFO 140719404451648] Epoch[28] Batch [40]#011Speed: 745.22 samples/sec#011loss=7.923545\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:36 INFO 140719404451648] Epoch[28] Batch[45] avg_epoch_loss=8.066389\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:36 INFO 140719404451648] #quality_metric: host=algo-1, epoch=28, batch=45 train loss <loss>=8.09307346344\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:36 INFO 140719404451648] Epoch[28] Batch [45]#011Speed: 1353.10 samples/sec#011loss=8.093073\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:36 INFO 140719404451648] processed a total of 1574 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1636.0838413238525, \"sum\": 1636.0838413238525, \"min\": 1636.0838413238525}}, \"EndTime\": 1578472716.5962, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472714.95969}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:36 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=961.981611731 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:36 INFO 140719404451648] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:36 INFO 140719404451648] #quality_metric: host=algo-1, epoch=28, train loss <loss>=8.01200106621\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:36 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:36 INFO 140719404451648] Epoch[29] Batch[0] avg_epoch_loss=7.927207\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:36 INFO 140719404451648] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=7.92720651627\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:36 INFO 140719404451648] Epoch[29] Batch[5] avg_epoch_loss=8.238516\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:36 INFO 140719404451648] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=8.23851641019\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:36 INFO 140719404451648] Epoch[29] Batch [5]#011Speed: 1339.50 samples/sec#011loss=8.238516\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:37 INFO 140719404451648] Epoch[29] Batch[10] avg_epoch_loss=8.190087\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:37 INFO 140719404451648] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=8.13197135925\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:37 INFO 140719404451648] Epoch[29] Batch [10]#011Speed: 744.44 samples/sec#011loss=8.131971\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:37 INFO 140719404451648] Epoch[29] Batch[15] avg_epoch_loss=8.214909\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:37 INFO 140719404451648] #quality_metric: host=algo-1, epoch=29, batch=15 train loss <loss>=8.2695183754\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:37 INFO 140719404451648] Epoch[29] Batch [15]#011Speed: 1589.43 samples/sec#011loss=8.269518\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:37 INFO 140719404451648] Epoch[29] Batch[20] avg_epoch_loss=8.287533\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:37 INFO 140719404451648] #quality_metric: host=algo-1, epoch=29, batch=20 train loss <loss>=8.51992721558\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:37 INFO 140719404451648] Epoch[29] Batch [20]#011Speed: 797.24 samples/sec#011loss=8.519927\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:37 INFO 140719404451648] Epoch[29] Batch[25] avg_epoch_loss=8.284930\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:37 INFO 140719404451648] #quality_metric: host=algo-1, epoch=29, batch=25 train loss <loss>=8.27399921417\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:37 INFO 140719404451648] Epoch[29] Batch [25]#011Speed: 1699.32 samples/sec#011loss=8.273999\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:37 INFO 140719404451648] Epoch[29] Batch[30] avg_epoch_loss=8.245049\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:37 INFO 140719404451648] #quality_metric: host=algo-1, epoch=29, batch=30 train loss <loss>=8.03766899109\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:37 INFO 140719404451648] Epoch[29] Batch [30]#011Speed: 771.63 samples/sec#011loss=8.037669\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:37 INFO 140719404451648] Epoch[29] Batch[35] avg_epoch_loss=8.162139\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:37 INFO 140719404451648] #quality_metric: host=algo-1, epoch=29, batch=35 train loss <loss>=7.64809684753\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:37 INFO 140719404451648] Epoch[29] Batch [35]#011Speed: 1458.88 samples/sec#011loss=7.648097\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:37 INFO 140719404451648] Epoch[29] Batch[40] avg_epoch_loss=8.103224\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:37 INFO 140719404451648] #quality_metric: host=algo-1, epoch=29, batch=40 train loss <loss>=7.67903289795\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:37 INFO 140719404451648] Epoch[29] Batch [40]#011Speed: 749.89 samples/sec#011loss=7.679033\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] Epoch[29] Batch[45] avg_epoch_loss=8.081298\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] #quality_metric: host=algo-1, epoch=29, batch=45 train loss <loss>=7.90150766373\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] Epoch[29] Batch [45]#011Speed: 1718.88 samples/sec#011loss=7.901508\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] Epoch[29] Batch[50] avg_epoch_loss=8.053324\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] #quality_metric: host=algo-1, epoch=29, batch=50 train loss <loss>=7.79596261978\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] Epoch[29] Batch [50]#011Speed: 1133.10 samples/sec#011loss=7.795963\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] processed a total of 1629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1632.469892501831, \"sum\": 1632.469892501831, \"min\": 1632.469892501831}}, \"EndTime\": 1578472718.2292, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472716.596292}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=997.808437731 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] #quality_metric: host=algo-1, epoch=29, train loss <loss>=8.05332400752\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] Epoch[30] Batch[0] avg_epoch_loss=8.342668\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=8.34266757965\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] Epoch[30] Batch[5] avg_epoch_loss=8.283994\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=8.28399356206\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] Epoch[30] Batch [5]#011Speed: 1709.09 samples/sec#011loss=8.283994\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] Epoch[30] Batch[10] avg_epoch_loss=8.237489\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=8.18168449402\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] Epoch[30] Batch [10]#011Speed: 775.60 samples/sec#011loss=8.181684\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] Epoch[30] Batch[15] avg_epoch_loss=8.349946\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] #quality_metric: host=algo-1, epoch=30, batch=15 train loss <loss>=8.5973493576\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] Epoch[30] Batch [15]#011Speed: 1554.78 samples/sec#011loss=8.597349\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] Epoch[30] Batch[20] avg_epoch_loss=8.353981\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] #quality_metric: host=algo-1, epoch=30, batch=20 train loss <loss>=8.36689386368\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:38 INFO 140719404451648] Epoch[30] Batch [20]#011Speed: 715.22 samples/sec#011loss=8.366894\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:39 INFO 140719404451648] Epoch[30] Batch[25] avg_epoch_loss=8.249940\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:39 INFO 140719404451648] #quality_metric: host=algo-1, epoch=30, batch=25 train loss <loss>=7.81296949387\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:39 INFO 140719404451648] Epoch[30] Batch [25]#011Speed: 1298.25 samples/sec#011loss=7.812969\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:39 INFO 140719404451648] Epoch[30] Batch[30] avg_epoch_loss=8.195908\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:39 INFO 140719404451648] #quality_metric: host=algo-1, epoch=30, batch=30 train loss <loss>=7.91494235992\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:39 INFO 140719404451648] Epoch[30] Batch [30]#011Speed: 706.18 samples/sec#011loss=7.914942\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:39 INFO 140719404451648] Epoch[30] Batch[35] avg_epoch_loss=8.133122\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:39 INFO 140719404451648] #quality_metric: host=algo-1, epoch=30, batch=35 train loss <loss>=7.74384975433\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:39 INFO 140719404451648] Epoch[30] Batch [35]#011Speed: 1457.42 samples/sec#011loss=7.743850\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:39 INFO 140719404451648] Epoch[30] Batch[40] avg_epoch_loss=8.091315\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:39 INFO 140719404451648] #quality_metric: host=algo-1, epoch=30, batch=40 train loss <loss>=7.7903046608\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:39 INFO 140719404451648] Epoch[30] Batch [40]#011Speed: 770.42 samples/sec#011loss=7.790305\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:39 INFO 140719404451648] Epoch[30] Batch[45] avg_epoch_loss=8.070402\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:39 INFO 140719404451648] #quality_metric: host=algo-1, epoch=30, batch=45 train loss <loss>=7.89891061783\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:39 INFO 140719404451648] Epoch[30] Batch [45]#011Speed: 1335.20 samples/sec#011loss=7.898911\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:39 INFO 140719404451648] Epoch[30] Batch[50] avg_epoch_loss=8.031470\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:39 INFO 140719404451648] #quality_metric: host=algo-1, epoch=30, batch=50 train loss <loss>=7.6733007431\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:39 INFO 140719404451648] Epoch[30] Batch [50]#011Speed: 1177.53 samples/sec#011loss=7.673301\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:39 INFO 140719404451648] processed a total of 1602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1687.4330043792725, \"sum\": 1687.4330043792725, \"min\": 1687.4330043792725}}, \"EndTime\": 1578472719.917133, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472718.229275}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:39 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=949.310800593 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:39 INFO 140719404451648] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:39 INFO 140719404451648] #quality_metric: host=algo-1, epoch=30, train loss <loss>=8.03147035487\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:39 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:40 INFO 140719404451648] Epoch[31] Batch[0] avg_epoch_loss=8.496540\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:40 INFO 140719404451648] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=8.49654006958\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:40 INFO 140719404451648] Epoch[31] Batch[5] avg_epoch_loss=8.308446\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:40 INFO 140719404451648] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=8.30844640732\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:40 INFO 140719404451648] Epoch[31] Batch [5]#011Speed: 1625.11 samples/sec#011loss=8.308446\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:40 INFO 140719404451648] Epoch[31] Batch[10] avg_epoch_loss=8.403654\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:40 INFO 140719404451648] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=8.51790390015\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:40 INFO 140719404451648] Epoch[31] Batch [10]#011Speed: 749.91 samples/sec#011loss=8.517904\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:40 INFO 140719404451648] Epoch[31] Batch[15] avg_epoch_loss=8.378494\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:40 INFO 140719404451648] #quality_metric: host=algo-1, epoch=31, batch=15 train loss <loss>=8.32313966751\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:40 INFO 140719404451648] Epoch[31] Batch [15]#011Speed: 1558.71 samples/sec#011loss=8.323140\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:40 INFO 140719404451648] Epoch[31] Batch[20] avg_epoch_loss=8.385916\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:40 INFO 140719404451648] #quality_metric: host=algo-1, epoch=31, batch=20 train loss <loss>=8.40966930389\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:40 INFO 140719404451648] Epoch[31] Batch [20]#011Speed: 773.04 samples/sec#011loss=8.409669\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:40 INFO 140719404451648] Epoch[31] Batch[25] avg_epoch_loss=8.285014\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:40 INFO 140719404451648] #quality_metric: host=algo-1, epoch=31, batch=25 train loss <loss>=7.86122589111\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:40 INFO 140719404451648] Epoch[31] Batch [25]#011Speed: 1557.72 samples/sec#011loss=7.861226\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:40 INFO 140719404451648] Epoch[31] Batch[30] avg_epoch_loss=8.249524\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:40 INFO 140719404451648] #quality_metric: host=algo-1, epoch=31, batch=30 train loss <loss>=8.0649731636\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:40 INFO 140719404451648] Epoch[31] Batch [30]#011Speed: 763.50 samples/sec#011loss=8.064973\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:41 INFO 140719404451648] Epoch[31] Batch[35] avg_epoch_loss=8.217191\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:41 INFO 140719404451648] #quality_metric: host=algo-1, epoch=31, batch=35 train loss <loss>=8.0167257309\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:41 INFO 140719404451648] Epoch[31] Batch [35]#011Speed: 1454.56 samples/sec#011loss=8.016726\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:41 INFO 140719404451648] Epoch[31] Batch[40] avg_epoch_loss=8.176055\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:41 INFO 140719404451648] #quality_metric: host=algo-1, epoch=31, batch=40 train loss <loss>=7.87987976074\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:41 INFO 140719404451648] Epoch[31] Batch [40]#011Speed: 708.75 samples/sec#011loss=7.879880\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:41 INFO 140719404451648] Epoch[31] Batch[45] avg_epoch_loss=8.164840\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:41 INFO 140719404451648] #quality_metric: host=algo-1, epoch=31, batch=45 train loss <loss>=8.07287302017\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:41 INFO 140719404451648] Epoch[31] Batch [45]#011Speed: 1403.65 samples/sec#011loss=8.072873\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:41 INFO 140719404451648] Epoch[31] Batch[50] avg_epoch_loss=8.080982\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:41 INFO 140719404451648] #quality_metric: host=algo-1, epoch=31, batch=50 train loss <loss>=7.30949373245\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:41 INFO 140719404451648] Epoch[31] Batch [50]#011Speed: 1136.73 samples/sec#011loss=7.309494\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:41 INFO 140719404451648] processed a total of 1611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1654.7999382019043, \"sum\": 1654.7999382019043, \"min\": 1654.7999382019043}}, \"EndTime\": 1578472721.572435, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472719.91721}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:41 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=973.465661577 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:41 INFO 140719404451648] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:41 INFO 140719404451648] #quality_metric: host=algo-1, epoch=31, train loss <loss>=8.08098233915\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:41 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:41 INFO 140719404451648] Epoch[32] Batch[0] avg_epoch_loss=8.007033\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:41 INFO 140719404451648] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=8.00703334808\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:41 INFO 140719404451648] Epoch[32] Batch[5] avg_epoch_loss=8.145619\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:41 INFO 140719404451648] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=8.14561915398\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:41 INFO 140719404451648] Epoch[32] Batch [5]#011Speed: 1329.42 samples/sec#011loss=8.145619\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:42 INFO 140719404451648] Epoch[32] Batch[10] avg_epoch_loss=8.164766\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:42 INFO 140719404451648] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=8.18774280548\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:42 INFO 140719404451648] Epoch[32] Batch [10]#011Speed: 716.31 samples/sec#011loss=8.187743\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:42 INFO 140719404451648] Epoch[32] Batch[15] avg_epoch_loss=8.303250\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:42 INFO 140719404451648] #quality_metric: host=algo-1, epoch=32, batch=15 train loss <loss>=8.60791435242\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:42 INFO 140719404451648] Epoch[32] Batch [15]#011Speed: 1549.97 samples/sec#011loss=8.607914\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:42 INFO 140719404451648] Epoch[32] Batch[20] avg_epoch_loss=8.233907\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:42 INFO 140719404451648] #quality_metric: host=algo-1, epoch=32, batch=20 train loss <loss>=8.0120098114\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:42 INFO 140719404451648] Epoch[32] Batch [20]#011Speed: 762.84 samples/sec#011loss=8.012010\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:42 INFO 140719404451648] Epoch[32] Batch[25] avg_epoch_loss=8.185105\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:42 INFO 140719404451648] #quality_metric: host=algo-1, epoch=32, batch=25 train loss <loss>=7.98013591766\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:42 INFO 140719404451648] Epoch[32] Batch [25]#011Speed: 1470.12 samples/sec#011loss=7.980136\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:42 INFO 140719404451648] Epoch[32] Batch[30] avg_epoch_loss=8.147714\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:42 INFO 140719404451648] #quality_metric: host=algo-1, epoch=32, batch=30 train loss <loss>=7.95327882767\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:42 INFO 140719404451648] Epoch[32] Batch [30]#011Speed: 791.55 samples/sec#011loss=7.953279\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:42 INFO 140719404451648] Epoch[32] Batch[35] avg_epoch_loss=8.136541\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:42 INFO 140719404451648] #quality_metric: host=algo-1, epoch=32, batch=35 train loss <loss>=8.06727218628\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:42 INFO 140719404451648] Epoch[32] Batch [35]#011Speed: 1697.70 samples/sec#011loss=8.067272\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:42 INFO 140719404451648] Epoch[32] Batch[40] avg_epoch_loss=8.077285\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:42 INFO 140719404451648] #quality_metric: host=algo-1, epoch=32, batch=40 train loss <loss>=7.65064096451\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:42 INFO 140719404451648] Epoch[32] Batch [40]#011Speed: 785.00 samples/sec#011loss=7.650641\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] Epoch[32] Batch[45] avg_epoch_loss=8.061352\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] #quality_metric: host=algo-1, epoch=32, batch=45 train loss <loss>=7.93070259094\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] Epoch[32] Batch [45]#011Speed: 1492.54 samples/sec#011loss=7.930703\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] Epoch[32] Batch[50] avg_epoch_loss=8.008810\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] #quality_metric: host=algo-1, epoch=32, batch=50 train loss <loss>=7.52542638779\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] Epoch[32] Batch [50]#011Speed: 1023.13 samples/sec#011loss=7.525426\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] processed a total of 1607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1658.107042312622, \"sum\": 1658.107042312622, \"min\": 1658.107042312622}}, \"EndTime\": 1578472723.23106, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472721.57251}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=969.109196639 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] #quality_metric: host=algo-1, epoch=32, train loss <loss>=8.00881047342\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] Epoch[33] Batch[0] avg_epoch_loss=8.440786\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=8.44078636169\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] Epoch[33] Batch[5] avg_epoch_loss=8.305179\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=8.30517903964\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] Epoch[33] Batch [5]#011Speed: 1311.58 samples/sec#011loss=8.305179\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] Epoch[33] Batch[10] avg_epoch_loss=8.169111\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] #quality_metric: host=algo-1, epoch=33, batch=10 train loss <loss>=8.00582952499\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] Epoch[33] Batch [10]#011Speed: 1314.77 samples/sec#011loss=8.005830\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] Epoch[33] Batch[15] avg_epoch_loss=8.271604\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] #quality_metric: host=algo-1, epoch=33, batch=15 train loss <loss>=8.49708919525\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] Epoch[33] Batch [15]#011Speed: 702.96 samples/sec#011loss=8.497089\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] Epoch[33] Batch[20] avg_epoch_loss=8.254696\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] #quality_metric: host=algo-1, epoch=33, batch=20 train loss <loss>=8.20059080124\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:43 INFO 140719404451648] Epoch[33] Batch [20]#011Speed: 1333.77 samples/sec#011loss=8.200591\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:44 INFO 140719404451648] Epoch[33] Batch[25] avg_epoch_loss=8.180192\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:44 INFO 140719404451648] #quality_metric: host=algo-1, epoch=33, batch=25 train loss <loss>=7.86727514267\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:44 INFO 140719404451648] Epoch[33] Batch [25]#011Speed: 629.44 samples/sec#011loss=7.867275\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:44 INFO 140719404451648] Epoch[33] Batch[30] avg_epoch_loss=8.107057\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:44 INFO 140719404451648] #quality_metric: host=algo-1, epoch=33, batch=30 train loss <loss>=7.72675409317\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:44 INFO 140719404451648] Epoch[33] Batch [30]#011Speed: 819.26 samples/sec#011loss=7.726754\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:44 INFO 140719404451648] Epoch[33] Batch[35] avg_epoch_loss=8.068327\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:44 INFO 140719404451648] #quality_metric: host=algo-1, epoch=33, batch=35 train loss <loss>=7.82820358276\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:44 INFO 140719404451648] Epoch[33] Batch [35]#011Speed: 1574.29 samples/sec#011loss=7.828204\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:44 INFO 140719404451648] Epoch[33] Batch[40] avg_epoch_loss=8.036378\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:44 INFO 140719404451648] #quality_metric: host=algo-1, epoch=33, batch=40 train loss <loss>=7.8063454628\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:44 INFO 140719404451648] Epoch[33] Batch [40]#011Speed: 805.89 samples/sec#011loss=7.806345\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:44 INFO 140719404451648] Epoch[33] Batch[45] avg_epoch_loss=8.048309\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:44 INFO 140719404451648] #quality_metric: host=algo-1, epoch=33, batch=45 train loss <loss>=8.14614076614\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:44 INFO 140719404451648] Epoch[33] Batch [45]#011Speed: 1557.68 samples/sec#011loss=8.146141\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:44 INFO 140719404451648] processed a total of 1570 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1703.0940055847168, \"sum\": 1703.0940055847168, \"min\": 1703.0940055847168}}, \"EndTime\": 1578472724.934688, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472723.231138}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:44 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=921.79524677 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:44 INFO 140719404451648] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:44 INFO 140719404451648] #quality_metric: host=algo-1, epoch=33, train loss <loss>=7.91617156029\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:44 INFO 140719404451648] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:44 INFO 140719404451648] Saved checkpoint to \"/opt/ml/model/state_a61dde86-2933-418c-8b4a-dac1c04f4694-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.338991165161133, \"sum\": 17.338991165161133, \"min\": 17.338991165161133}}, \"EndTime\": 1578472724.952613, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472724.934755}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:45 INFO 140719404451648] Epoch[34] Batch[0] avg_epoch_loss=8.255233\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:45 INFO 140719404451648] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=8.25523281097\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:45 INFO 140719404451648] Epoch[34] Batch[5] avg_epoch_loss=8.058067\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:45 INFO 140719404451648] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=8.05806708336\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:45 INFO 140719404451648] Epoch[34] Batch [5]#011Speed: 1547.96 samples/sec#011loss=8.058067\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:45 INFO 140719404451648] Epoch[34] Batch[10] avg_epoch_loss=8.132093\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:45 INFO 140719404451648] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=8.22092380524\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:45 INFO 140719404451648] Epoch[34] Batch [10]#011Speed: 750.32 samples/sec#011loss=8.220924\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:45 INFO 140719404451648] Epoch[34] Batch[15] avg_epoch_loss=8.211813\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:45 INFO 140719404451648] #quality_metric: host=algo-1, epoch=34, batch=15 train loss <loss>=8.38719768524\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:45 INFO 140719404451648] Epoch[34] Batch [15]#011Speed: 1525.51 samples/sec#011loss=8.387198\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:45 INFO 140719404451648] Epoch[34] Batch[20] avg_epoch_loss=8.230643\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:45 INFO 140719404451648] #quality_metric: host=algo-1, epoch=34, batch=20 train loss <loss>=8.29089870453\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:45 INFO 140719404451648] Epoch[34] Batch [20]#011Speed: 707.34 samples/sec#011loss=8.290899\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:45 INFO 140719404451648] Epoch[34] Batch[25] avg_epoch_loss=8.176769\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:45 INFO 140719404451648] #quality_metric: host=algo-1, epoch=34, batch=25 train loss <loss>=7.95049734116\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:45 INFO 140719404451648] Epoch[34] Batch [25]#011Speed: 1654.45 samples/sec#011loss=7.950497\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:46 INFO 140719404451648] Epoch[34] Batch[30] avg_epoch_loss=8.152546\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:46 INFO 140719404451648] #quality_metric: host=algo-1, epoch=34, batch=30 train loss <loss>=8.0265871048\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:46 INFO 140719404451648] Epoch[34] Batch [30]#011Speed: 770.74 samples/sec#011loss=8.026587\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:46 INFO 140719404451648] Epoch[34] Batch[35] avg_epoch_loss=8.117769\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:46 INFO 140719404451648] #quality_metric: host=algo-1, epoch=34, batch=35 train loss <loss>=7.90215015411\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:46 INFO 140719404451648] Epoch[34] Batch [35]#011Speed: 1301.71 samples/sec#011loss=7.902150\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:38:46 INFO 140719404451648] Epoch[34] Batch[40] avg_epoch_loss=8.077487\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:46 INFO 140719404451648] #quality_metric: host=algo-1, epoch=34, batch=40 train loss <loss>=7.78745450974\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:46 INFO 140719404451648] Epoch[34] Batch [40]#011Speed: 736.30 samples/sec#011loss=7.787455\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:46 INFO 140719404451648] Epoch[34] Batch[45] avg_epoch_loss=8.047185\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:46 INFO 140719404451648] #quality_metric: host=algo-1, epoch=34, batch=45 train loss <loss>=7.79870786667\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:46 INFO 140719404451648] Epoch[34] Batch [45]#011Speed: 1425.33 samples/sec#011loss=7.798708\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:46 INFO 140719404451648] processed a total of 1573 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1655.832052230835, \"sum\": 1655.832052230835, \"min\": 1655.832052230835}}, \"EndTime\": 1578472726.608543, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472724.952657}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:46 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=949.913612178 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:46 INFO 140719404451648] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:46 INFO 140719404451648] #quality_metric: host=algo-1, epoch=34, train loss <loss>=8.02224925995\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:46 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:46 INFO 140719404451648] Epoch[35] Batch[0] avg_epoch_loss=8.861622\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:46 INFO 140719404451648] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=8.86162185669\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:46 INFO 140719404451648] Epoch[35] Batch[5] avg_epoch_loss=8.245965\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:46 INFO 140719404451648] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=8.24596516291\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:46 INFO 140719404451648] Epoch[35] Batch [5]#011Speed: 1482.36 samples/sec#011loss=8.245965\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:47 INFO 140719404451648] Epoch[35] Batch[10] avg_epoch_loss=8.221015\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:47 INFO 140719404451648] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=8.19107398987\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:47 INFO 140719404451648] Epoch[35] Batch [10]#011Speed: 694.29 samples/sec#011loss=8.191074\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:47 INFO 140719404451648] Epoch[35] Batch[15] avg_epoch_loss=8.399243\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:47 INFO 140719404451648] #quality_metric: host=algo-1, epoch=35, batch=15 train loss <loss>=8.79134559631\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:47 INFO 140719404451648] Epoch[35] Batch [15]#011Speed: 1435.65 samples/sec#011loss=8.791346\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:47 INFO 140719404451648] Epoch[35] Batch[20] avg_epoch_loss=8.335166\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:47 INFO 140719404451648] #quality_metric: host=algo-1, epoch=35, batch=20 train loss <loss>=8.13012008667\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:47 INFO 140719404451648] Epoch[35] Batch [20]#011Speed: 717.97 samples/sec#011loss=8.130120\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:47 INFO 140719404451648] Epoch[35] Batch[25] avg_epoch_loss=8.266853\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:47 INFO 140719404451648] #quality_metric: host=algo-1, epoch=35, batch=25 train loss <loss>=7.97993831635\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:47 INFO 140719404451648] Epoch[35] Batch [25]#011Speed: 1289.34 samples/sec#011loss=7.979938\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:47 INFO 140719404451648] Epoch[35] Batch[30] avg_epoch_loss=8.187007\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:47 INFO 140719404451648] #quality_metric: host=algo-1, epoch=35, batch=30 train loss <loss>=7.77180595398\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:47 INFO 140719404451648] Epoch[35] Batch [30]#011Speed: 723.06 samples/sec#011loss=7.771806\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:47 INFO 140719404451648] Epoch[35] Batch[35] avg_epoch_loss=8.098667\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:47 INFO 140719404451648] #quality_metric: host=algo-1, epoch=35, batch=35 train loss <loss>=7.55096006393\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:47 INFO 140719404451648] Epoch[35] Batch [35]#011Speed: 1585.70 samples/sec#011loss=7.550960\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] Epoch[35] Batch[40] avg_epoch_loss=8.070986\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] #quality_metric: host=algo-1, epoch=35, batch=40 train loss <loss>=7.87168226242\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] Epoch[35] Batch [40]#011Speed: 735.94 samples/sec#011loss=7.871682\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] Epoch[35] Batch[45] avg_epoch_loss=8.068227\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] #quality_metric: host=algo-1, epoch=35, batch=45 train loss <loss>=8.04560470581\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] Epoch[35] Batch [45]#011Speed: 1552.60 samples/sec#011loss=8.045605\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] Epoch[35] Batch[50] avg_epoch_loss=8.046248\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] #quality_metric: host=algo-1, epoch=35, batch=50 train loss <loss>=7.8440366745\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] Epoch[35] Batch [50]#011Speed: 1126.85 samples/sec#011loss=7.844037\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] processed a total of 1643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1740.0438785552979, \"sum\": 1740.0438785552979, \"min\": 1740.0438785552979}}, \"EndTime\": 1578472728.3491, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472726.608616}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=944.169293994 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] #quality_metric: host=algo-1, epoch=35, train loss <loss>=8.03206309905\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] Epoch[36] Batch[0] avg_epoch_loss=8.490129\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=8.49012851715\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] Epoch[36] Batch[5] avg_epoch_loss=8.281859\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=8.28185868263\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] Epoch[36] Batch [5]#011Speed: 1505.16 samples/sec#011loss=8.281859\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] Epoch[36] Batch[10] avg_epoch_loss=8.309813\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=8.34335718155\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] Epoch[36] Batch [10]#011Speed: 760.26 samples/sec#011loss=8.343357\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] Epoch[36] Batch[15] avg_epoch_loss=8.338564\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] #quality_metric: host=algo-1, epoch=36, batch=15 train loss <loss>=8.40181732178\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:48 INFO 140719404451648] Epoch[36] Batch [15]#011Speed: 1733.99 samples/sec#011loss=8.401817\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] Epoch[36] Batch[20] avg_epoch_loss=8.272222\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] #quality_metric: host=algo-1, epoch=36, batch=20 train loss <loss>=8.0599281311\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] Epoch[36] Batch [20]#011Speed: 757.77 samples/sec#011loss=8.059928\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] Epoch[36] Batch[25] avg_epoch_loss=8.232001\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] #quality_metric: host=algo-1, epoch=36, batch=25 train loss <loss>=8.06307401657\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] Epoch[36] Batch [25]#011Speed: 1734.04 samples/sec#011loss=8.063074\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] Epoch[36] Batch[30] avg_epoch_loss=8.147118\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] #quality_metric: host=algo-1, epoch=36, batch=30 train loss <loss>=7.70572576523\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] Epoch[36] Batch [30]#011Speed: 776.59 samples/sec#011loss=7.705726\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] Epoch[36] Batch[35] avg_epoch_loss=8.143159\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] #quality_metric: host=algo-1, epoch=36, batch=35 train loss <loss>=8.11861352921\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] Epoch[36] Batch [35]#011Speed: 1741.19 samples/sec#011loss=8.118614\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] Epoch[36] Batch[40] avg_epoch_loss=8.077839\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] #quality_metric: host=algo-1, epoch=36, batch=40 train loss <loss>=7.60753517151\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] Epoch[36] Batch [40]#011Speed: 734.84 samples/sec#011loss=7.607535\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] Epoch[36] Batch[45] avg_epoch_loss=8.066379\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] #quality_metric: host=algo-1, epoch=36, batch=45 train loss <loss>=7.97240695953\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] Epoch[36] Batch [45]#011Speed: 1564.13 samples/sec#011loss=7.972407\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] Epoch[36] Batch[50] avg_epoch_loss=7.990472\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] #quality_metric: host=algo-1, epoch=36, batch=50 train loss <loss>=7.29212465286\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] Epoch[36] Batch [50]#011Speed: 1135.59 samples/sec#011loss=7.292125\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] processed a total of 1620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1611.6669178009033, \"sum\": 1611.6669178009033, \"min\": 1611.6669178009033}}, \"EndTime\": 1578472729.961265, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472728.349175}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=1005.10743028 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] #quality_metric: host=algo-1, epoch=36, train loss <loss>=7.9904718773\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:49 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:50 INFO 140719404451648] Epoch[37] Batch[0] avg_epoch_loss=8.720211\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:50 INFO 140719404451648] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=8.72021102905\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:50 INFO 140719404451648] Epoch[37] Batch[5] avg_epoch_loss=8.116020\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:50 INFO 140719404451648] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=8.11601956685\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:50 INFO 140719404451648] Epoch[37] Batch [5]#011Speed: 1590.76 samples/sec#011loss=8.116020\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:50 INFO 140719404451648] Epoch[37] Batch[10] avg_epoch_loss=8.290296\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:50 INFO 140719404451648] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=8.49942817688\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:50 INFO 140719404451648] Epoch[37] Batch [10]#011Speed: 727.05 samples/sec#011loss=8.499428\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:50 INFO 140719404451648] Epoch[37] Batch[15] avg_epoch_loss=8.302809\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:50 INFO 140719404451648] #quality_metric: host=algo-1, epoch=37, batch=15 train loss <loss>=8.33033714294\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:50 INFO 140719404451648] Epoch[37] Batch [15]#011Speed: 1441.48 samples/sec#011loss=8.330337\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:50 INFO 140719404451648] Epoch[37] Batch[20] avg_epoch_loss=8.308403\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:50 INFO 140719404451648] #quality_metric: host=algo-1, epoch=37, batch=20 train loss <loss>=8.32630500793\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:50 INFO 140719404451648] Epoch[37] Batch [20]#011Speed: 759.47 samples/sec#011loss=8.326305\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:50 INFO 140719404451648] Epoch[37] Batch[25] avg_epoch_loss=8.195736\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:50 INFO 140719404451648] #quality_metric: host=algo-1, epoch=37, batch=25 train loss <loss>=7.72253484726\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:50 INFO 140719404451648] Epoch[37] Batch [25]#011Speed: 1556.12 samples/sec#011loss=7.722535\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:51 INFO 140719404451648] Epoch[37] Batch[30] avg_epoch_loss=8.113528\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:51 INFO 140719404451648] #quality_metric: host=algo-1, epoch=37, batch=30 train loss <loss>=7.68604297638\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:51 INFO 140719404451648] Epoch[37] Batch [30]#011Speed: 791.47 samples/sec#011loss=7.686043\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:51 INFO 140719404451648] Epoch[37] Batch[35] avg_epoch_loss=8.111257\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:51 INFO 140719404451648] #quality_metric: host=algo-1, epoch=37, batch=35 train loss <loss>=8.0971780777\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:51 INFO 140719404451648] Epoch[37] Batch [35]#011Speed: 1298.19 samples/sec#011loss=8.097178\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:51 INFO 140719404451648] Epoch[37] Batch[40] avg_epoch_loss=8.109540\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:51 INFO 140719404451648] #quality_metric: host=algo-1, epoch=37, batch=40 train loss <loss>=8.09717960358\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:51 INFO 140719404451648] Epoch[37] Batch [40]#011Speed: 709.80 samples/sec#011loss=8.097180\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:51 INFO 140719404451648] Epoch[37] Batch[45] avg_epoch_loss=8.130134\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:51 INFO 140719404451648] #quality_metric: host=algo-1, epoch=37, batch=45 train loss <loss>=8.29900064468\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:51 INFO 140719404451648] Epoch[37] Batch [45]#011Speed: 1323.33 samples/sec#011loss=8.299001\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:51 INFO 140719404451648] processed a total of 1589 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1657.322883605957, \"sum\": 1657.322883605957, \"min\": 1657.322883605957}}, \"EndTime\": 1578472731.619125, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472729.961337}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:51 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=958.717364226 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:51 INFO 140719404451648] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:51 INFO 140719404451648] #quality_metric: host=algo-1, epoch=37, train loss <loss>=8.05138980865\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:51 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:51 INFO 140719404451648] Epoch[38] Batch[0] avg_epoch_loss=8.361221\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:51 INFO 140719404451648] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=8.36122131348\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:51 INFO 140719404451648] Epoch[38] Batch[5] avg_epoch_loss=8.235148\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:51 INFO 140719404451648] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=8.23514771461\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:51 INFO 140719404451648] Epoch[38] Batch [5]#011Speed: 1315.80 samples/sec#011loss=8.235148\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:52 INFO 140719404451648] Epoch[38] Batch[10] avg_epoch_loss=8.324724\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:52 INFO 140719404451648] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=8.43221445084\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:52 INFO 140719404451648] Epoch[38] Batch [10]#011Speed: 738.05 samples/sec#011loss=8.432214\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:52 INFO 140719404451648] Epoch[38] Batch[15] avg_epoch_loss=8.292500\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:52 INFO 140719404451648] #quality_metric: host=algo-1, epoch=38, batch=15 train loss <loss>=8.22160892487\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:52 INFO 140719404451648] Epoch[38] Batch [15]#011Speed: 1546.25 samples/sec#011loss=8.221609\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:52 INFO 140719404451648] Epoch[38] Batch[20] avg_epoch_loss=8.291696\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:52 INFO 140719404451648] #quality_metric: host=algo-1, epoch=38, batch=20 train loss <loss>=8.2891204834\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:52 INFO 140719404451648] Epoch[38] Batch [20]#011Speed: 796.76 samples/sec#011loss=8.289120\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:52 INFO 140719404451648] Epoch[38] Batch[25] avg_epoch_loss=8.248966\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:52 INFO 140719404451648] #quality_metric: host=algo-1, epoch=38, batch=25 train loss <loss>=8.06950244904\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:52 INFO 140719404451648] Epoch[38] Batch [25]#011Speed: 1553.37 samples/sec#011loss=8.069502\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:52 INFO 140719404451648] Epoch[38] Batch[30] avg_epoch_loss=8.198469\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:52 INFO 140719404451648] #quality_metric: host=algo-1, epoch=38, batch=30 train loss <loss>=7.93588123322\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:52 INFO 140719404451648] Epoch[38] Batch [30]#011Speed: 736.90 samples/sec#011loss=7.935881\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:52 INFO 140719404451648] Epoch[38] Batch[35] avg_epoch_loss=8.155434\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:52 INFO 140719404451648] #quality_metric: host=algo-1, epoch=38, batch=35 train loss <loss>=7.8886177063\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:52 INFO 140719404451648] Epoch[38] Batch [35]#011Speed: 787.80 samples/sec#011loss=7.888618\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] Epoch[38] Batch[40] avg_epoch_loss=8.156633\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] #quality_metric: host=algo-1, epoch=38, batch=40 train loss <loss>=8.16526679993\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] Epoch[38] Batch [40]#011Speed: 1567.32 samples/sec#011loss=8.165267\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] Epoch[38] Batch[45] avg_epoch_loss=8.091098\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] #quality_metric: host=algo-1, epoch=38, batch=45 train loss <loss>=7.55371465683\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] Epoch[38] Batch [45]#011Speed: 1139.32 samples/sec#011loss=7.553715\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] processed a total of 1496 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1556.623935699463, \"sum\": 1556.623935699463, \"min\": 1556.623935699463}}, \"EndTime\": 1578472733.17634, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472731.619192}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=960.980771896 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] #quality_metric: host=algo-1, epoch=38, train loss <loss>=8.10438524409\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] Epoch[39] Batch[0] avg_epoch_loss=7.916080\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=7.91607999802\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] Epoch[39] Batch[5] avg_epoch_loss=8.187722\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=8.18772244453\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] Epoch[39] Batch [5]#011Speed: 1487.80 samples/sec#011loss=8.187722\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] Epoch[39] Batch[10] avg_epoch_loss=8.165283\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=8.1383562088\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] Epoch[39] Batch [10]#011Speed: 814.70 samples/sec#011loss=8.138356\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] Epoch[39] Batch[15] avg_epoch_loss=8.223479\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] #quality_metric: host=algo-1, epoch=39, batch=15 train loss <loss>=8.35151062012\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] Epoch[39] Batch [15]#011Speed: 1553.32 samples/sec#011loss=8.351511\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] Epoch[39] Batch[20] avg_epoch_loss=8.183651\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] #quality_metric: host=algo-1, epoch=39, batch=20 train loss <loss>=8.05619955063\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:53 INFO 140719404451648] Epoch[39] Batch [20]#011Speed: 818.48 samples/sec#011loss=8.056200\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] Epoch[39] Batch[25] avg_epoch_loss=8.118939\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] #quality_metric: host=algo-1, epoch=39, batch=25 train loss <loss>=7.84714860916\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] Epoch[39] Batch [25]#011Speed: 1343.64 samples/sec#011loss=7.847149\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] Epoch[39] Batch[30] avg_epoch_loss=8.060337\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] #quality_metric: host=algo-1, epoch=39, batch=30 train loss <loss>=7.75560483932\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] Epoch[39] Batch [30]#011Speed: 720.20 samples/sec#011loss=7.755605\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] Epoch[39] Batch[35] avg_epoch_loss=8.043215\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] #quality_metric: host=algo-1, epoch=39, batch=35 train loss <loss>=7.93705997467\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] Epoch[39] Batch [35]#011Speed: 1522.97 samples/sec#011loss=7.937060\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] Epoch[39] Batch[40] avg_epoch_loss=8.012060\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] #quality_metric: host=algo-1, epoch=39, batch=40 train loss <loss>=7.78774757385\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] Epoch[39] Batch [40]#011Speed: 811.72 samples/sec#011loss=7.787748\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] Epoch[39] Batch[45] avg_epoch_loss=7.974349\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] #quality_metric: host=algo-1, epoch=39, batch=45 train loss <loss>=7.66511859894\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] Epoch[39] Batch [45]#011Speed: 1530.72 samples/sec#011loss=7.665119\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] Epoch[39] Batch[50] avg_epoch_loss=7.853158\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] #quality_metric: host=algo-1, epoch=39, batch=50 train loss <loss>=6.73819484711\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] Epoch[39] Batch [50]#011Speed: 1124.37 samples/sec#011loss=6.738195\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] processed a total of 1601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1624.6061325073242, \"sum\": 1624.6061325073242, \"min\": 1624.6061325073242}}, \"EndTime\": 1578472734.801489, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472733.176421}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=985.402960987 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] #quality_metric: host=algo-1, epoch=39, train loss <loss>=7.85315762314\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] Saved checkpoint to \"/opt/ml/model/state_b44d8482-ae21-4715-9cc6-0f5ee04d1907-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 25.532007217407227, \"sum\": 25.532007217407227, \"min\": 25.532007217407227}}, \"EndTime\": 1578472734.827559, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472734.801564}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] Epoch[40] Batch[0] avg_epoch_loss=9.194665\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:54 INFO 140719404451648] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=9.19466495514\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:55 INFO 140719404451648] Epoch[40] Batch[5] avg_epoch_loss=8.613663\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:55 INFO 140719404451648] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=8.61366335551\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:55 INFO 140719404451648] Epoch[40] Batch [5]#011Speed: 1585.90 samples/sec#011loss=8.613663\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:55 INFO 140719404451648] Epoch[40] Batch[10] avg_epoch_loss=8.505587\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:55 INFO 140719404451648] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=8.37589492798\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:55 INFO 140719404451648] Epoch[40] Batch [10]#011Speed: 665.93 samples/sec#011loss=8.375895\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:55 INFO 140719404451648] Epoch[40] Batch[15] avg_epoch_loss=8.546226\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:55 INFO 140719404451648] #quality_metric: host=algo-1, epoch=40, batch=15 train loss <loss>=8.63563213348\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:55 INFO 140719404451648] Epoch[40] Batch [15]#011Speed: 1639.68 samples/sec#011loss=8.635632\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:55 INFO 140719404451648] Epoch[40] Batch[20] avg_epoch_loss=8.518683\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:55 INFO 140719404451648] #quality_metric: host=algo-1, epoch=40, batch=20 train loss <loss>=8.43054466248\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:55 INFO 140719404451648] Epoch[40] Batch [20]#011Speed: 703.93 samples/sec#011loss=8.430545\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:55 INFO 140719404451648] Epoch[40] Batch[25] avg_epoch_loss=8.379789\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:55 INFO 140719404451648] #quality_metric: host=algo-1, epoch=40, batch=25 train loss <loss>=7.79643735886\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:55 INFO 140719404451648] Epoch[40] Batch [25]#011Speed: 1537.04 samples/sec#011loss=7.796437\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:55 INFO 140719404451648] Epoch[40] Batch[30] avg_epoch_loss=8.330880\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:55 INFO 140719404451648] #quality_metric: host=algo-1, epoch=40, batch=30 train loss <loss>=8.07655267715\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:55 INFO 140719404451648] Epoch[40] Batch [30]#011Speed: 655.23 samples/sec#011loss=8.076553\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:56 INFO 140719404451648] Epoch[40] Batch[35] avg_epoch_loss=8.243524\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:56 INFO 140719404451648] #quality_metric: host=algo-1, epoch=40, batch=35 train loss <loss>=7.70191326141\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:56 INFO 140719404451648] Epoch[40] Batch [35]#011Speed: 1591.55 samples/sec#011loss=7.701913\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:56 INFO 140719404451648] Epoch[40] Batch[40] avg_epoch_loss=8.195044\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:56 INFO 140719404451648] #quality_metric: host=algo-1, epoch=40, batch=40 train loss <loss>=7.84598703384\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:56 INFO 140719404451648] Epoch[40] Batch [40]#011Speed: 668.59 samples/sec#011loss=7.845987\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:38:56 INFO 140719404451648] Epoch[40] Batch[45] avg_epoch_loss=8.164194\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:56 INFO 140719404451648] #quality_metric: host=algo-1, epoch=40, batch=45 train loss <loss>=7.91122837067\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:56 INFO 140719404451648] Epoch[40] Batch [45]#011Speed: 1690.57 samples/sec#011loss=7.911228\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:56 INFO 140719404451648] Epoch[40] Batch[50] avg_epoch_loss=8.128291\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:56 INFO 140719404451648] #quality_metric: host=algo-1, epoch=40, batch=50 train loss <loss>=7.79797668457\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:56 INFO 140719404451648] Epoch[40] Batch [50]#011Speed: 1479.41 samples/sec#011loss=7.797977\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:56 INFO 140719404451648] processed a total of 1651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1716.019868850708, \"sum\": 1716.019868850708, \"min\": 1716.019868850708}}, \"EndTime\": 1578472736.543699, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472734.827628}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:56 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=962.055670558 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:56 INFO 140719404451648] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:56 INFO 140719404451648] #quality_metric: host=algo-1, epoch=40, train loss <loss>=8.10859699433\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:56 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:56 INFO 140719404451648] Epoch[41] Batch[0] avg_epoch_loss=7.853685\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:56 INFO 140719404451648] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=7.85368490219\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:56 INFO 140719404451648] Epoch[41] Batch[5] avg_epoch_loss=8.043770\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:56 INFO 140719404451648] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=8.04376999537\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:56 INFO 140719404451648] Epoch[41] Batch [5]#011Speed: 1687.73 samples/sec#011loss=8.043770\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:57 INFO 140719404451648] Epoch[41] Batch[10] avg_epoch_loss=8.073685\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:57 INFO 140719404451648] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=8.10958223343\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:57 INFO 140719404451648] Epoch[41] Batch [10]#011Speed: 639.87 samples/sec#011loss=8.109582\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:57 INFO 140719404451648] Epoch[41] Batch[15] avg_epoch_loss=8.219676\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:57 INFO 140719404451648] #quality_metric: host=algo-1, epoch=41, batch=15 train loss <loss>=8.54085788727\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:57 INFO 140719404451648] Epoch[41] Batch [15]#011Speed: 1479.47 samples/sec#011loss=8.540858\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:57 INFO 140719404451648] Epoch[41] Batch[20] avg_epoch_loss=8.231661\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:57 INFO 140719404451648] #quality_metric: host=algo-1, epoch=41, batch=20 train loss <loss>=8.27001028061\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:57 INFO 140719404451648] Epoch[41] Batch [20]#011Speed: 704.81 samples/sec#011loss=8.270010\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:57 INFO 140719404451648] Epoch[41] Batch[25] avg_epoch_loss=8.174314\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:57 INFO 140719404451648] #quality_metric: host=algo-1, epoch=41, batch=25 train loss <loss>=7.93345975876\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:57 INFO 140719404451648] Epoch[41] Batch [25]#011Speed: 1709.37 samples/sec#011loss=7.933460\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:57 INFO 140719404451648] Epoch[41] Batch[30] avg_epoch_loss=8.124043\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:57 INFO 140719404451648] #quality_metric: host=algo-1, epoch=41, batch=30 train loss <loss>=7.86263113022\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:57 INFO 140719404451648] Epoch[41] Batch [30]#011Speed: 784.18 samples/sec#011loss=7.862631\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:57 INFO 140719404451648] Epoch[41] Batch[35] avg_epoch_loss=8.060744\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:57 INFO 140719404451648] #quality_metric: host=algo-1, epoch=41, batch=35 train loss <loss>=7.66829042435\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:57 INFO 140719404451648] Epoch[41] Batch [35]#011Speed: 1495.30 samples/sec#011loss=7.668290\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:57 INFO 140719404451648] Epoch[41] Batch[40] avg_epoch_loss=8.061924\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:57 INFO 140719404451648] #quality_metric: host=algo-1, epoch=41, batch=40 train loss <loss>=8.07041730881\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:57 INFO 140719404451648] Epoch[41] Batch [40]#011Speed: 747.15 samples/sec#011loss=8.070417\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:58 INFO 140719404451648] Epoch[41] Batch[45] avg_epoch_loss=8.059780\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:58 INFO 140719404451648] #quality_metric: host=algo-1, epoch=41, batch=45 train loss <loss>=8.04220571518\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:58 INFO 140719404451648] Epoch[41] Batch [45]#011Speed: 1323.43 samples/sec#011loss=8.042206\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:58 INFO 140719404451648] Epoch[41] Batch[50] avg_epoch_loss=8.067408\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:58 INFO 140719404451648] #quality_metric: host=algo-1, epoch=41, batch=50 train loss <loss>=8.13758611679\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:58 INFO 140719404451648] Epoch[41] Batch [50]#011Speed: 1176.65 samples/sec#011loss=8.137586\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:58 INFO 140719404451648] processed a total of 1605 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1682.9309463500977, \"sum\": 1682.9309463500977, \"min\": 1682.9309463500977}}, \"EndTime\": 1578472738.227167, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472736.543767}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:58 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=953.631038144 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:58 INFO 140719404451648] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:58 INFO 140719404451648] #quality_metric: host=algo-1, epoch=41, train loss <loss>=8.06740831861\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:58 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:58 INFO 140719404451648] Epoch[42] Batch[0] avg_epoch_loss=7.958144\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:58 INFO 140719404451648] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=7.95814371109\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:58 INFO 140719404451648] Epoch[42] Batch[5] avg_epoch_loss=8.210370\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:58 INFO 140719404451648] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=8.21037014325\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:58 INFO 140719404451648] Epoch[42] Batch [5]#011Speed: 1304.66 samples/sec#011loss=8.210370\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:58 INFO 140719404451648] Epoch[42] Batch[10] avg_epoch_loss=8.160836\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:58 INFO 140719404451648] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=8.10139474869\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:58 INFO 140719404451648] Epoch[42] Batch [10]#011Speed: 785.01 samples/sec#011loss=8.101395\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:58 INFO 140719404451648] Epoch[42] Batch[15] avg_epoch_loss=8.292755\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:58 INFO 140719404451648] #quality_metric: host=algo-1, epoch=42, batch=15 train loss <loss>=8.58297595978\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:58 INFO 140719404451648] Epoch[42] Batch [15]#011Speed: 1555.36 samples/sec#011loss=8.582976\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] Epoch[42] Batch[20] avg_epoch_loss=8.254106\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] #quality_metric: host=algo-1, epoch=42, batch=20 train loss <loss>=8.13043022156\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] Epoch[42] Batch [20]#011Speed: 752.93 samples/sec#011loss=8.130430\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] Epoch[42] Batch[25] avg_epoch_loss=8.150719\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] #quality_metric: host=algo-1, epoch=42, batch=25 train loss <loss>=7.71649599075\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] Epoch[42] Batch [25]#011Speed: 1513.76 samples/sec#011loss=7.716496\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] Epoch[42] Batch[30] avg_epoch_loss=8.153599\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] #quality_metric: host=algo-1, epoch=42, batch=30 train loss <loss>=8.16857299805\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] Epoch[42] Batch [30]#011Speed: 753.04 samples/sec#011loss=8.168573\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] Epoch[42] Batch[35] avg_epoch_loss=8.127400\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] #quality_metric: host=algo-1, epoch=42, batch=35 train loss <loss>=7.96496629715\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] Epoch[42] Batch [35]#011Speed: 1581.86 samples/sec#011loss=7.964966\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] Epoch[42] Batch[40] avg_epoch_loss=8.104945\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] #quality_metric: host=algo-1, epoch=42, batch=40 train loss <loss>=7.9432682991\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] Epoch[42] Batch [40]#011Speed: 780.58 samples/sec#011loss=7.943268\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] Epoch[42] Batch[45] avg_epoch_loss=8.142585\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] #quality_metric: host=algo-1, epoch=42, batch=45 train loss <loss>=8.45122909546\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] Epoch[42] Batch [45]#011Speed: 1727.34 samples/sec#011loss=8.451229\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] processed a total of 1594 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1599.2379188537598, \"sum\": 1599.2379188537598, \"min\": 1599.2379188537598}}, \"EndTime\": 1578472739.826898, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472738.227242}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=996.656243427 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] #quality_metric: host=algo-1, epoch=42, train loss <loss>=8.10540016174\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] Epoch[43] Batch[0] avg_epoch_loss=8.204645\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:38:59 INFO 140719404451648] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=8.20464515686\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:00 INFO 140719404451648] Epoch[43] Batch[5] avg_epoch_loss=8.340139\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:00 INFO 140719404451648] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=8.34013907115\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:00 INFO 140719404451648] Epoch[43] Batch [5]#011Speed: 1556.77 samples/sec#011loss=8.340139\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:00 INFO 140719404451648] Epoch[43] Batch[10] avg_epoch_loss=8.303599\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:00 INFO 140719404451648] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=8.25975112915\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:00 INFO 140719404451648] Epoch[43] Batch [10]#011Speed: 746.52 samples/sec#011loss=8.259751\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:00 INFO 140719404451648] Epoch[43] Batch[15] avg_epoch_loss=8.371211\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:00 INFO 140719404451648] #quality_metric: host=algo-1, epoch=43, batch=15 train loss <loss>=8.51995811462\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:00 INFO 140719404451648] Epoch[43] Batch [15]#011Speed: 1305.76 samples/sec#011loss=8.519958\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:00 INFO 140719404451648] Epoch[43] Batch[20] avg_epoch_loss=8.292872\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:00 INFO 140719404451648] #quality_metric: host=algo-1, epoch=43, batch=20 train loss <loss>=8.04218673706\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:00 INFO 140719404451648] Epoch[43] Batch [20]#011Speed: 688.46 samples/sec#011loss=8.042187\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:00 INFO 140719404451648] Epoch[43] Batch[25] avg_epoch_loss=8.232779\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:00 INFO 140719404451648] #quality_metric: host=algo-1, epoch=43, batch=25 train loss <loss>=7.98038549423\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:00 INFO 140719404451648] Epoch[43] Batch [25]#011Speed: 1337.35 samples/sec#011loss=7.980385\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:00 INFO 140719404451648] Epoch[43] Batch[30] avg_epoch_loss=8.175646\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:00 INFO 140719404451648] #quality_metric: host=algo-1, epoch=43, batch=30 train loss <loss>=7.87855682373\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:00 INFO 140719404451648] Epoch[43] Batch [30]#011Speed: 753.69 samples/sec#011loss=7.878557\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:01 INFO 140719404451648] Epoch[43] Batch[35] avg_epoch_loss=8.151752\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:01 INFO 140719404451648] #quality_metric: host=algo-1, epoch=43, batch=35 train loss <loss>=8.00361022949\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:01 INFO 140719404451648] Epoch[43] Batch [35]#011Speed: 1557.63 samples/sec#011loss=8.003610\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:01 INFO 140719404451648] Epoch[43] Batch[40] avg_epoch_loss=8.113565\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:01 INFO 140719404451648] #quality_metric: host=algo-1, epoch=43, batch=40 train loss <loss>=7.83861761093\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:01 INFO 140719404451648] Epoch[43] Batch [40]#011Speed: 757.76 samples/sec#011loss=7.838618\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:01 INFO 140719404451648] Epoch[43] Batch[45] avg_epoch_loss=8.059378\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:01 INFO 140719404451648] #quality_metric: host=algo-1, epoch=43, batch=45 train loss <loss>=7.61504640579\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:01 INFO 140719404451648] Epoch[43] Batch [45]#011Speed: 1233.19 samples/sec#011loss=7.615046\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:01 INFO 140719404451648] processed a total of 1532 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1626.1770725250244, \"sum\": 1626.1770725250244, \"min\": 1626.1770725250244}}, \"EndTime\": 1578472741.453572, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472739.826973}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:01 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=942.028820274 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:01 INFO 140719404451648] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:01 INFO 140719404451648] #quality_metric: host=algo-1, epoch=43, train loss <loss>=8.03977012634\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:01 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:01 INFO 140719404451648] Epoch[44] Batch[0] avg_epoch_loss=8.004128\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:01 INFO 140719404451648] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=8.00412845612\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:01 INFO 140719404451648] Epoch[44] Batch[5] avg_epoch_loss=8.093622\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:01 INFO 140719404451648] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=8.09362236659\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:01 INFO 140719404451648] Epoch[44] Batch [5]#011Speed: 1548.27 samples/sec#011loss=8.093622\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:01 INFO 140719404451648] Epoch[44] Batch[10] avg_epoch_loss=8.265227\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:01 INFO 140719404451648] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=8.47115325928\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:01 INFO 140719404451648] Epoch[44] Batch [10]#011Speed: 815.83 samples/sec#011loss=8.471153\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:02 INFO 140719404451648] Epoch[44] Batch[15] avg_epoch_loss=8.351798\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:02 INFO 140719404451648] #quality_metric: host=algo-1, epoch=44, batch=15 train loss <loss>=8.54225387573\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:02 INFO 140719404451648] Epoch[44] Batch [15]#011Speed: 1250.21 samples/sec#011loss=8.542254\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:02 INFO 140719404451648] Epoch[44] Batch[20] avg_epoch_loss=8.374583\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:02 INFO 140719404451648] #quality_metric: host=algo-1, epoch=44, batch=20 train loss <loss>=8.44749593735\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:02 INFO 140719404451648] Epoch[44] Batch [20]#011Speed: 711.51 samples/sec#011loss=8.447496\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:02 INFO 140719404451648] Epoch[44] Batch[25] avg_epoch_loss=8.287855\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:02 INFO 140719404451648] #quality_metric: host=algo-1, epoch=44, batch=25 train loss <loss>=7.92359380722\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:02 INFO 140719404451648] Epoch[44] Batch [25]#011Speed: 1515.22 samples/sec#011loss=7.923594\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:02 INFO 140719404451648] Epoch[44] Batch[30] avg_epoch_loss=8.209671\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:02 INFO 140719404451648] #quality_metric: host=algo-1, epoch=44, batch=30 train loss <loss>=7.80311813354\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:02 INFO 140719404451648] Epoch[44] Batch [30]#011Speed: 816.74 samples/sec#011loss=7.803118\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:02 INFO 140719404451648] Epoch[44] Batch[35] avg_epoch_loss=8.174355\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:02 INFO 140719404451648] #quality_metric: host=algo-1, epoch=44, batch=35 train loss <loss>=7.95539054871\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:02 INFO 140719404451648] Epoch[44] Batch [35]#011Speed: 1568.47 samples/sec#011loss=7.955391\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:02 INFO 140719404451648] Epoch[44] Batch[40] avg_epoch_loss=8.146224\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:02 INFO 140719404451648] #quality_metric: host=algo-1, epoch=44, batch=40 train loss <loss>=7.94368610382\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:02 INFO 140719404451648] Epoch[44] Batch [40]#011Speed: 823.53 samples/sec#011loss=7.943686\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:02 INFO 140719404451648] Epoch[44] Batch[45] avg_epoch_loss=8.113218\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:02 INFO 140719404451648] #quality_metric: host=algo-1, epoch=44, batch=45 train loss <loss>=7.84256811142\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:02 INFO 140719404451648] Epoch[44] Batch [45]#011Speed: 1043.76 samples/sec#011loss=7.842568\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:03 INFO 140719404451648] processed a total of 1559 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1601.0959148406982, \"sum\": 1601.0959148406982, \"min\": 1601.0959148406982}}, \"EndTime\": 1578472743.055197, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472741.453642}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:03 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=973.644703332 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:03 INFO 140719404451648] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:03 INFO 140719404451648] #quality_metric: host=algo-1, epoch=44, train loss <loss>=8.09568937457\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:03 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:03 INFO 140719404451648] Epoch[45] Batch[0] avg_epoch_loss=8.560302\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:03 INFO 140719404451648] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=8.5603017807\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:03 INFO 140719404451648] Epoch[45] Batch[5] avg_epoch_loss=8.510312\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:03 INFO 140719404451648] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=8.51031176249\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:03 INFO 140719404451648] Epoch[45] Batch [5]#011Speed: 1345.94 samples/sec#011loss=8.510312\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:03 INFO 140719404451648] Epoch[45] Batch[10] avg_epoch_loss=8.412617\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:03 INFO 140719404451648] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=8.29538288116\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:03 INFO 140719404451648] Epoch[45] Batch [10]#011Speed: 687.81 samples/sec#011loss=8.295383\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:03 INFO 140719404451648] Epoch[45] Batch[15] avg_epoch_loss=8.472448\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:03 INFO 140719404451648] #quality_metric: host=algo-1, epoch=45, batch=15 train loss <loss>=8.6040763855\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:03 INFO 140719404451648] Epoch[45] Batch [15]#011Speed: 1724.14 samples/sec#011loss=8.604076\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:03 INFO 140719404451648] Epoch[45] Batch[20] avg_epoch_loss=8.477419\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:03 INFO 140719404451648] #quality_metric: host=algo-1, epoch=45, batch=20 train loss <loss>=8.49332790375\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:03 INFO 140719404451648] Epoch[45] Batch [20]#011Speed: 709.28 samples/sec#011loss=8.493328\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:03 INFO 140719404451648] Epoch[45] Batch[25] avg_epoch_loss=8.369829\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:03 INFO 140719404451648] #quality_metric: host=algo-1, epoch=45, batch=25 train loss <loss>=7.917948246\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:03 INFO 140719404451648] Epoch[45] Batch [25]#011Speed: 1309.03 samples/sec#011loss=7.917948\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:04 INFO 140719404451648] Epoch[45] Batch[30] avg_epoch_loss=8.270995\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:04 INFO 140719404451648] #quality_metric: host=algo-1, epoch=45, batch=30 train loss <loss>=7.75705804825\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:04 INFO 140719404451648] Epoch[45] Batch [30]#011Speed: 712.87 samples/sec#011loss=7.757058\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:04 INFO 140719404451648] Epoch[45] Batch[35] avg_epoch_loss=8.236376\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:04 INFO 140719404451648] #quality_metric: host=algo-1, epoch=45, batch=35 train loss <loss>=8.02173871994\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:04 INFO 140719404451648] Epoch[45] Batch [35]#011Speed: 1559.00 samples/sec#011loss=8.021739\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:04 INFO 140719404451648] Epoch[45] Batch[40] avg_epoch_loss=8.187233\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:04 INFO 140719404451648] #quality_metric: host=algo-1, epoch=45, batch=40 train loss <loss>=7.83340024948\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:04 INFO 140719404451648] Epoch[45] Batch [40]#011Speed: 767.95 samples/sec#011loss=7.833400\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:04 INFO 140719404451648] Epoch[45] Batch[45] avg_epoch_loss=8.152667\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:04 INFO 140719404451648] #quality_metric: host=algo-1, epoch=45, batch=45 train loss <loss>=7.86923103333\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:04 INFO 140719404451648] Epoch[45] Batch [45]#011Speed: 1632.47 samples/sec#011loss=7.869231\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:04 INFO 140719404451648] Epoch[45] Batch[50] avg_epoch_loss=8.017267\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:04 INFO 140719404451648] #quality_metric: host=algo-1, epoch=45, batch=50 train loss <loss>=6.77158370018\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:04 INFO 140719404451648] Epoch[45] Batch [50]#011Speed: 1097.27 samples/sec#011loss=6.771584\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:04 INFO 140719404451648] processed a total of 1610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1698.462963104248, \"sum\": 1698.462963104248, \"min\": 1698.462963104248}}, \"EndTime\": 1578472744.754209, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472743.055271}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:04 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=947.854533991 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:04 INFO 140719404451648] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:04 INFO 140719404451648] #quality_metric: host=algo-1, epoch=45, train loss <loss>=8.01726679241\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:04 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:04 INFO 140719404451648] Epoch[46] Batch[0] avg_epoch_loss=7.877215\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:04 INFO 140719404451648] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=7.8772149086\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:05 INFO 140719404451648] Epoch[46] Batch[5] avg_epoch_loss=8.205503\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:05 INFO 140719404451648] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=8.20550306638\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:05 INFO 140719404451648] Epoch[46] Batch [5]#011Speed: 1585.76 samples/sec#011loss=8.205503\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:05 INFO 140719404451648] Epoch[46] Batch[10] avg_epoch_loss=8.308150\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:05 INFO 140719404451648] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=8.43132610321\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:05 INFO 140719404451648] Epoch[46] Batch [10]#011Speed: 712.89 samples/sec#011loss=8.431326\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:05 INFO 140719404451648] Epoch[46] Batch[15] avg_epoch_loss=8.313843\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:05 INFO 140719404451648] #quality_metric: host=algo-1, epoch=46, batch=15 train loss <loss>=8.32636623383\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:05 INFO 140719404451648] Epoch[46] Batch [15]#011Speed: 1507.06 samples/sec#011loss=8.326366\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:05 INFO 140719404451648] Epoch[46] Batch[20] avg_epoch_loss=8.240759\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:05 INFO 140719404451648] #quality_metric: host=algo-1, epoch=46, batch=20 train loss <loss>=8.00689182281\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:05 INFO 140719404451648] Epoch[46] Batch [20]#011Speed: 743.98 samples/sec#011loss=8.006892\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:05 INFO 140719404451648] Epoch[46] Batch[25] avg_epoch_loss=8.184847\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:05 INFO 140719404451648] #quality_metric: host=algo-1, epoch=46, batch=25 train loss <loss>=7.95001831055\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:05 INFO 140719404451648] Epoch[46] Batch [25]#011Speed: 1344.83 samples/sec#011loss=7.950018\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:05 INFO 140719404451648] Epoch[46] Batch[30] avg_epoch_loss=8.120853\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:05 INFO 140719404451648] #quality_metric: host=algo-1, epoch=46, batch=30 train loss <loss>=7.78808546066\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:05 INFO 140719404451648] Epoch[46] Batch [30]#011Speed: 724.54 samples/sec#011loss=7.788085\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:06 INFO 140719404451648] Epoch[46] Batch[35] avg_epoch_loss=8.100595\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:06 INFO 140719404451648] #quality_metric: host=algo-1, epoch=46, batch=35 train loss <loss>=7.97499198914\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:06 INFO 140719404451648] Epoch[46] Batch [35]#011Speed: 1351.12 samples/sec#011loss=7.974992\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:06 INFO 140719404451648] Epoch[46] Batch[40] avg_epoch_loss=8.083953\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:06 INFO 140719404451648] #quality_metric: host=algo-1, epoch=46, batch=40 train loss <loss>=7.96413145065\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:06 INFO 140719404451648] Epoch[46] Batch [40]#011Speed: 740.12 samples/sec#011loss=7.964131\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:39:06 INFO 140719404451648] Epoch[46] Batch[45] avg_epoch_loss=8.038152\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:06 INFO 140719404451648] #quality_metric: host=algo-1, epoch=46, batch=45 train loss <loss>=7.66257896423\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:06 INFO 140719404451648] Epoch[46] Batch [45]#011Speed: 1337.76 samples/sec#011loss=7.662579\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:06 INFO 140719404451648] processed a total of 1589 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1729.1438579559326, \"sum\": 1729.1438579559326, \"min\": 1729.1438579559326}}, \"EndTime\": 1578472746.483839, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472744.754283}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:06 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=918.897653007 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:06 INFO 140719404451648] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:06 INFO 140719404451648] #quality_metric: host=algo-1, epoch=46, train loss <loss>=7.99062914848\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:06 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:06 INFO 140719404451648] Epoch[47] Batch[0] avg_epoch_loss=8.768483\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:06 INFO 140719404451648] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=8.76848316193\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:06 INFO 140719404451648] Epoch[47] Batch[5] avg_epoch_loss=8.385720\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:06 INFO 140719404451648] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=8.38572041194\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:06 INFO 140719404451648] Epoch[47] Batch [5]#011Speed: 1315.51 samples/sec#011loss=8.385720\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:06 INFO 140719404451648] Epoch[47] Batch[10] avg_epoch_loss=8.334250\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:06 INFO 140719404451648] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=8.2724855423\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:06 INFO 140719404451648] Epoch[47] Batch [10]#011Speed: 732.51 samples/sec#011loss=8.272486\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:07 INFO 140719404451648] Epoch[47] Batch[15] avg_epoch_loss=8.416050\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:07 INFO 140719404451648] #quality_metric: host=algo-1, epoch=47, batch=15 train loss <loss>=8.59601154327\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:07 INFO 140719404451648] Epoch[47] Batch [15]#011Speed: 1329.85 samples/sec#011loss=8.596012\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:07 INFO 140719404451648] Epoch[47] Batch[20] avg_epoch_loss=8.417791\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:07 INFO 140719404451648] #quality_metric: host=algo-1, epoch=47, batch=20 train loss <loss>=8.42336177826\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:07 INFO 140719404451648] Epoch[47] Batch [20]#011Speed: 762.30 samples/sec#011loss=8.423362\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:07 INFO 140719404451648] Epoch[47] Batch[25] avg_epoch_loss=8.322091\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:07 INFO 140719404451648] #quality_metric: host=algo-1, epoch=47, batch=25 train loss <loss>=7.92014808655\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:07 INFO 140719404451648] Epoch[47] Batch [25]#011Speed: 1567.24 samples/sec#011loss=7.920148\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:07 INFO 140719404451648] Epoch[47] Batch[30] avg_epoch_loss=8.285821\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:07 INFO 140719404451648] #quality_metric: host=algo-1, epoch=47, batch=30 train loss <loss>=8.09721822739\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:07 INFO 140719404451648] Epoch[47] Batch [30]#011Speed: 776.94 samples/sec#011loss=8.097218\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:07 INFO 140719404451648] Epoch[47] Batch[35] avg_epoch_loss=8.175137\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:07 INFO 140719404451648] #quality_metric: host=algo-1, epoch=47, batch=35 train loss <loss>=7.48889865875\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:07 INFO 140719404451648] Epoch[47] Batch [35]#011Speed: 1567.05 samples/sec#011loss=7.488899\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:07 INFO 140719404451648] Epoch[47] Batch[40] avg_epoch_loss=8.130060\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:07 INFO 140719404451648] #quality_metric: host=algo-1, epoch=47, batch=40 train loss <loss>=7.80550022125\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:07 INFO 140719404451648] Epoch[47] Batch [40]#011Speed: 753.60 samples/sec#011loss=7.805500\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] Epoch[47] Batch[45] avg_epoch_loss=8.109698\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] #quality_metric: host=algo-1, epoch=47, batch=45 train loss <loss>=7.94272851944\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] Epoch[47] Batch [45]#011Speed: 1265.29 samples/sec#011loss=7.942729\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] Epoch[47] Batch[50] avg_epoch_loss=8.086140\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] #quality_metric: host=algo-1, epoch=47, batch=50 train loss <loss>=7.86941375732\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] Epoch[47] Batch [50]#011Speed: 1162.49 samples/sec#011loss=7.869414\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] processed a total of 1659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1713.6178016662598, \"sum\": 1713.6178016662598, \"min\": 1713.6178016662598}}, \"EndTime\": 1578472748.198044, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472746.483913}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=968.068203774 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] #quality_metric: host=algo-1, epoch=47, train loss <loss>=8.06778263129\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] Epoch[48] Batch[0] avg_epoch_loss=8.165056\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=8.16505622864\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] Epoch[48] Batch[5] avg_epoch_loss=8.086419\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=8.08641926448\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] Epoch[48] Batch [5]#011Speed: 1320.03 samples/sec#011loss=8.086419\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] Epoch[48] Batch[10] avg_epoch_loss=8.067488\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=8.04477024078\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] Epoch[48] Batch [10]#011Speed: 744.13 samples/sec#011loss=8.044770\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] Epoch[48] Batch[15] avg_epoch_loss=8.163075\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] #quality_metric: host=algo-1, epoch=48, batch=15 train loss <loss>=8.37336568832\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] Epoch[48] Batch [15]#011Speed: 1434.50 samples/sec#011loss=8.373366\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] Epoch[48] Batch[20] avg_epoch_loss=8.194838\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] #quality_metric: host=algo-1, epoch=48, batch=20 train loss <loss>=8.29648189545\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:08 INFO 140719404451648] Epoch[48] Batch [20]#011Speed: 755.45 samples/sec#011loss=8.296482\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:09 INFO 140719404451648] Epoch[48] Batch[25] avg_epoch_loss=8.188161\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:09 INFO 140719404451648] #quality_metric: host=algo-1, epoch=48, batch=25 train loss <loss>=8.16011371613\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:09 INFO 140719404451648] Epoch[48] Batch [25]#011Speed: 1524.26 samples/sec#011loss=8.160114\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:09 INFO 140719404451648] Epoch[48] Batch[30] avg_epoch_loss=8.126026\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:09 INFO 140719404451648] #quality_metric: host=algo-1, epoch=48, batch=30 train loss <loss>=7.80292434692\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:09 INFO 140719404451648] Epoch[48] Batch [30]#011Speed: 773.42 samples/sec#011loss=7.802924\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:09 INFO 140719404451648] Epoch[48] Batch[35] avg_epoch_loss=8.083228\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:09 INFO 140719404451648] #quality_metric: host=algo-1, epoch=48, batch=35 train loss <loss>=7.81788158417\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:09 INFO 140719404451648] Epoch[48] Batch [35]#011Speed: 1506.95 samples/sec#011loss=7.817882\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:09 INFO 140719404451648] Epoch[48] Batch[40] avg_epoch_loss=8.038544\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:09 INFO 140719404451648] #quality_metric: host=algo-1, epoch=48, batch=40 train loss <loss>=7.71682052612\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:09 INFO 140719404451648] Epoch[48] Batch [40]#011Speed: 793.41 samples/sec#011loss=7.716821\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:09 INFO 140719404451648] Epoch[48] Batch[45] avg_epoch_loss=7.988714\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:09 INFO 140719404451648] #quality_metric: host=algo-1, epoch=48, batch=45 train loss <loss>=7.58011083603\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:09 INFO 140719404451648] Epoch[48] Batch [45]#011Speed: 1556.84 samples/sec#011loss=7.580111\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:09 INFO 140719404451648] processed a total of 1570 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1624.8440742492676, \"sum\": 1624.8440742492676, \"min\": 1624.8440742492676}}, \"EndTime\": 1578472749.823444, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472748.198109}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:09 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=966.181772351 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:09 INFO 140719404451648] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:09 INFO 140719404451648] #quality_metric: host=algo-1, epoch=48, train loss <loss>=7.96171033859\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:09 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:09 INFO 140719404451648] Epoch[49] Batch[0] avg_epoch_loss=8.294203\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:09 INFO 140719404451648] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=8.29420280457\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:10 INFO 140719404451648] Epoch[49] Batch[5] avg_epoch_loss=8.187640\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:10 INFO 140719404451648] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=8.18763995171\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:10 INFO 140719404451648] Epoch[49] Batch [5]#011Speed: 1548.68 samples/sec#011loss=8.187640\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:10 INFO 140719404451648] Epoch[49] Batch[10] avg_epoch_loss=8.339873\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:10 INFO 140719404451648] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=8.52255191803\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:10 INFO 140719404451648] Epoch[49] Batch [10]#011Speed: 808.38 samples/sec#011loss=8.522552\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:10 INFO 140719404451648] Epoch[49] Batch[15] avg_epoch_loss=8.282926\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:10 INFO 140719404451648] #quality_metric: host=algo-1, epoch=49, batch=15 train loss <loss>=8.15764408112\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:10 INFO 140719404451648] Epoch[49] Batch [15]#011Speed: 1519.86 samples/sec#011loss=8.157644\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:10 INFO 140719404451648] Epoch[49] Batch[20] avg_epoch_loss=8.288897\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:10 INFO 140719404451648] #quality_metric: host=algo-1, epoch=49, batch=20 train loss <loss>=8.30800266266\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:10 INFO 140719404451648] Epoch[49] Batch [20]#011Speed: 739.97 samples/sec#011loss=8.308003\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:10 INFO 140719404451648] Epoch[49] Batch[25] avg_epoch_loss=8.243163\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:10 INFO 140719404451648] #quality_metric: host=algo-1, epoch=49, batch=25 train loss <loss>=8.05108318329\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:10 INFO 140719404451648] Epoch[49] Batch [25]#011Speed: 1348.22 samples/sec#011loss=8.051083\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:10 INFO 140719404451648] Epoch[49] Batch[30] avg_epoch_loss=8.167752\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:10 INFO 140719404451648] #quality_metric: host=algo-1, epoch=49, batch=30 train loss <loss>=7.77561264038\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:10 INFO 140719404451648] Epoch[49] Batch [30]#011Speed: 752.00 samples/sec#011loss=7.775613\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] Epoch[49] Batch[35] avg_epoch_loss=8.096157\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] #quality_metric: host=algo-1, epoch=49, batch=35 train loss <loss>=7.65226678848\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] Epoch[49] Batch [35]#011Speed: 1507.56 samples/sec#011loss=7.652267\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] Epoch[49] Batch[40] avg_epoch_loss=8.067110\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] #quality_metric: host=algo-1, epoch=49, batch=40 train loss <loss>=7.85797548294\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] Epoch[49] Batch [40]#011Speed: 771.67 samples/sec#011loss=7.857975\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] Epoch[49] Batch[45] avg_epoch_loss=8.074584\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] #quality_metric: host=algo-1, epoch=49, batch=45 train loss <loss>=8.13586473465\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] Epoch[49] Batch [45]#011Speed: 1558.45 samples/sec#011loss=8.135865\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] processed a total of 1589 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1620.500087738037, \"sum\": 1620.500087738037, \"min\": 1620.500087738037}}, \"EndTime\": 1578472751.444349, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472749.823515}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=980.496153559 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] #quality_metric: host=algo-1, epoch=49, train loss <loss>=7.99813947678\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] Epoch[50] Batch[0] avg_epoch_loss=8.411602\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=8.41160202026\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] Epoch[50] Batch[5] avg_epoch_loss=8.247113\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=8.24711283048\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] Epoch[50] Batch [5]#011Speed: 1499.25 samples/sec#011loss=8.247113\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] Epoch[50] Batch[10] avg_epoch_loss=8.351990\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=8.47784252167\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] Epoch[50] Batch [10]#011Speed: 777.64 samples/sec#011loss=8.477843\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] Epoch[50] Batch[15] avg_epoch_loss=8.386357\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] #quality_metric: host=algo-1, epoch=50, batch=15 train loss <loss>=8.46196479797\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:11 INFO 140719404451648] Epoch[50] Batch [15]#011Speed: 1487.17 samples/sec#011loss=8.461965\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:12 INFO 140719404451648] Epoch[50] Batch[20] avg_epoch_loss=8.332851\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:12 INFO 140719404451648] #quality_metric: host=algo-1, epoch=50, batch=20 train loss <loss>=8.16163063049\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:12 INFO 140719404451648] Epoch[50] Batch [20]#011Speed: 765.58 samples/sec#011loss=8.161631\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:12 INFO 140719404451648] Epoch[50] Batch[25] avg_epoch_loss=8.280112\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:12 INFO 140719404451648] #quality_metric: host=algo-1, epoch=50, batch=25 train loss <loss>=8.05861148834\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:12 INFO 140719404451648] Epoch[50] Batch [25]#011Speed: 1476.33 samples/sec#011loss=8.058611\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:12 INFO 140719404451648] Epoch[50] Batch[30] avg_epoch_loss=8.261855\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:12 INFO 140719404451648] #quality_metric: host=algo-1, epoch=50, batch=30 train loss <loss>=8.16691350937\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:12 INFO 140719404451648] Epoch[50] Batch [30]#011Speed: 807.93 samples/sec#011loss=8.166914\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:12 INFO 140719404451648] Epoch[50] Batch[35] avg_epoch_loss=8.222152\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:12 INFO 140719404451648] #quality_metric: host=algo-1, epoch=50, batch=35 train loss <loss>=7.97599401474\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:12 INFO 140719404451648] Epoch[50] Batch [35]#011Speed: 1534.53 samples/sec#011loss=7.975994\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:12 INFO 140719404451648] Epoch[50] Batch[40] avg_epoch_loss=8.203317\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:12 INFO 140719404451648] #quality_metric: host=algo-1, epoch=50, batch=40 train loss <loss>=8.06770973206\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:12 INFO 140719404451648] Epoch[50] Batch [40]#011Speed: 787.90 samples/sec#011loss=8.067710\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:12 INFO 140719404451648] Epoch[50] Batch[45] avg_epoch_loss=8.157765\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:12 INFO 140719404451648] #quality_metric: host=algo-1, epoch=50, batch=45 train loss <loss>=7.78423471451\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:12 INFO 140719404451648] Epoch[50] Batch [45]#011Speed: 1504.79 samples/sec#011loss=7.784235\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:13 INFO 140719404451648] Epoch[50] Batch[50] avg_epoch_loss=8.110539\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:13 INFO 140719404451648] #quality_metric: host=algo-1, epoch=50, batch=50 train loss <loss>=7.67606496811\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:13 INFO 140719404451648] Epoch[50] Batch [50]#011Speed: 1077.34 samples/sec#011loss=7.676065\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:13 INFO 140719404451648] processed a total of 1657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1656.9859981536865, \"sum\": 1656.9859981536865, \"min\": 1656.9859981536865}}, \"EndTime\": 1578472753.101929, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472751.444425}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:13 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=999.945718907 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:13 INFO 140719404451648] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:13 INFO 140719404451648] #quality_metric: host=algo-1, epoch=50, train loss <loss>=8.08664307228\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:13 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:13 INFO 140719404451648] Epoch[51] Batch[0] avg_epoch_loss=7.984125\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:13 INFO 140719404451648] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=7.98412466049\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:13 INFO 140719404451648] Epoch[51] Batch[5] avg_epoch_loss=8.283219\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:13 INFO 140719404451648] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=8.28321909904\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:13 INFO 140719404451648] Epoch[51] Batch [5]#011Speed: 1547.42 samples/sec#011loss=8.283219\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:13 INFO 140719404451648] Epoch[51] Batch[10] avg_epoch_loss=8.337244\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:13 INFO 140719404451648] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=8.40207481384\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:13 INFO 140719404451648] Epoch[51] Batch [10]#011Speed: 702.58 samples/sec#011loss=8.402075\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:13 INFO 140719404451648] Epoch[51] Batch[15] avg_epoch_loss=8.457576\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:13 INFO 140719404451648] #quality_metric: host=algo-1, epoch=51, batch=15 train loss <loss>=8.72230567932\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:13 INFO 140719404451648] Epoch[51] Batch [15]#011Speed: 1314.60 samples/sec#011loss=8.722306\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:13 INFO 140719404451648] Epoch[51] Batch[20] avg_epoch_loss=8.435480\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:13 INFO 140719404451648] #quality_metric: host=algo-1, epoch=51, batch=20 train loss <loss>=8.36477050781\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:13 INFO 140719404451648] Epoch[51] Batch [20]#011Speed: 736.43 samples/sec#011loss=8.364771\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:14 INFO 140719404451648] Epoch[51] Batch[25] avg_epoch_loss=8.315298\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:14 INFO 140719404451648] #quality_metric: host=algo-1, epoch=51, batch=25 train loss <loss>=7.81053590775\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:14 INFO 140719404451648] Epoch[51] Batch [25]#011Speed: 1293.44 samples/sec#011loss=7.810536\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:14 INFO 140719404451648] Epoch[51] Batch[30] avg_epoch_loss=8.205130\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:14 INFO 140719404451648] #quality_metric: host=algo-1, epoch=51, batch=30 train loss <loss>=7.63225812912\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:14 INFO 140719404451648] Epoch[51] Batch [30]#011Speed: 688.32 samples/sec#011loss=7.632258\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:14 INFO 140719404451648] Epoch[51] Batch[35] avg_epoch_loss=8.156856\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:14 INFO 140719404451648] #quality_metric: host=algo-1, epoch=51, batch=35 train loss <loss>=7.85755767822\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:14 INFO 140719404451648] Epoch[51] Batch [35]#011Speed: 1293.11 samples/sec#011loss=7.857558\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:14 INFO 140719404451648] Epoch[51] Batch[40] avg_epoch_loss=8.118727\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:14 INFO 140719404451648] #quality_metric: host=algo-1, epoch=51, batch=40 train loss <loss>=7.84419593811\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:14 INFO 140719404451648] Epoch[51] Batch [40]#011Speed: 712.04 samples/sec#011loss=7.844196\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:14 INFO 140719404451648] Epoch[51] Batch[45] avg_epoch_loss=8.088350\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:14 INFO 140719404451648] #quality_metric: host=algo-1, epoch=51, batch=45 train loss <loss>=7.83926277161\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:14 INFO 140719404451648] Epoch[51] Batch [45]#011Speed: 1332.99 samples/sec#011loss=7.839263\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:14 INFO 140719404451648] processed a total of 1590 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1733.74605178833, \"sum\": 1733.74605178833, \"min\": 1733.74605178833}}, \"EndTime\": 1578472754.836253, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472753.101993}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:14 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=917.019969177 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:14 INFO 140719404451648] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:14 INFO 140719404451648] #quality_metric: host=algo-1, epoch=51, train loss <loss>=8.04340554237\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:14 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:14 INFO 140719404451648] Epoch[52] Batch[0] avg_epoch_loss=8.455771\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:14 INFO 140719404451648] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=8.45577144623\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:15 INFO 140719404451648] Epoch[52] Batch[5] avg_epoch_loss=8.133417\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:15 INFO 140719404451648] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=8.13341705004\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:15 INFO 140719404451648] Epoch[52] Batch [5]#011Speed: 1529.99 samples/sec#011loss=8.133417\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:15 INFO 140719404451648] Epoch[52] Batch[10] avg_epoch_loss=8.303236\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:15 INFO 140719404451648] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=8.50701847076\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:15 INFO 140719404451648] Epoch[52] Batch [10]#011Speed: 775.62 samples/sec#011loss=8.507018\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:15 INFO 140719404451648] Epoch[52] Batch[15] avg_epoch_loss=8.381206\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:15 INFO 140719404451648] #quality_metric: host=algo-1, epoch=52, batch=15 train loss <loss>=8.55273895264\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:15 INFO 140719404451648] Epoch[52] Batch [15]#011Speed: 1531.95 samples/sec#011loss=8.552739\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:15 INFO 140719404451648] Epoch[52] Batch[20] avg_epoch_loss=8.381454\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:15 INFO 140719404451648] #quality_metric: host=algo-1, epoch=52, batch=20 train loss <loss>=8.38224840164\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:15 INFO 140719404451648] Epoch[52] Batch [20]#011Speed: 714.45 samples/sec#011loss=8.382248\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:15 INFO 140719404451648] Epoch[52] Batch[25] avg_epoch_loss=8.264993\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:15 INFO 140719404451648] #quality_metric: host=algo-1, epoch=52, batch=25 train loss <loss>=7.77585935593\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:15 INFO 140719404451648] Epoch[52] Batch [25]#011Speed: 1498.84 samples/sec#011loss=7.775859\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:15 INFO 140719404451648] Epoch[52] Batch[30] avg_epoch_loss=8.202523\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:15 INFO 140719404451648] #quality_metric: host=algo-1, epoch=52, batch=30 train loss <loss>=7.87767734528\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:15 INFO 140719404451648] Epoch[52] Batch [30]#011Speed: 713.09 samples/sec#011loss=7.877677\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:16 INFO 140719404451648] Epoch[52] Batch[35] avg_epoch_loss=8.121198\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:16 INFO 140719404451648] #quality_metric: host=algo-1, epoch=52, batch=35 train loss <loss>=7.6169798851\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:16 INFO 140719404451648] Epoch[52] Batch [35]#011Speed: 1323.22 samples/sec#011loss=7.616980\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:16 INFO 140719404451648] Epoch[52] Batch[40] avg_epoch_loss=8.059789\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:16 INFO 140719404451648] #quality_metric: host=algo-1, epoch=52, batch=40 train loss <loss>=7.61764354706\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:16 INFO 140719404451648] Epoch[52] Batch [40]#011Speed: 689.72 samples/sec#011loss=7.617644\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:39:16 INFO 140719404451648] Epoch[52] Batch[45] avg_epoch_loss=8.041937\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:16 INFO 140719404451648] #quality_metric: host=algo-1, epoch=52, batch=45 train loss <loss>=7.89555616379\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:16 INFO 140719404451648] Epoch[52] Batch [45]#011Speed: 1396.06 samples/sec#011loss=7.895556\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:16 INFO 140719404451648] Epoch[52] Batch[50] avg_epoch_loss=8.009840\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:16 INFO 140719404451648] #quality_metric: host=algo-1, epoch=52, batch=50 train loss <loss>=7.71454925537\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:16 INFO 140719404451648] Epoch[52] Batch [50]#011Speed: 1089.32 samples/sec#011loss=7.714549\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:16 INFO 140719404451648] processed a total of 1660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1736.6859912872314, \"sum\": 1736.6859912872314, \"min\": 1736.6859912872314}}, \"EndTime\": 1578472756.573552, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472754.836345}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:16 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=955.782870037 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:16 INFO 140719404451648] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:16 INFO 140719404451648] #quality_metric: host=algo-1, epoch=52, train loss <loss>=8.00206285257\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:16 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:16 INFO 140719404451648] Epoch[53] Batch[0] avg_epoch_loss=8.603992\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:16 INFO 140719404451648] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=8.60399150848\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:16 INFO 140719404451648] Epoch[53] Batch[5] avg_epoch_loss=8.176278\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:16 INFO 140719404451648] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=8.17627819379\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:16 INFO 140719404451648] Epoch[53] Batch [5]#011Speed: 1336.97 samples/sec#011loss=8.176278\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:17 INFO 140719404451648] Epoch[53] Batch[10] avg_epoch_loss=8.288799\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:17 INFO 140719404451648] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=8.42382316589\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:17 INFO 140719404451648] Epoch[53] Batch [10]#011Speed: 726.50 samples/sec#011loss=8.423823\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:17 INFO 140719404451648] Epoch[53] Batch[15] avg_epoch_loss=8.318487\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:17 INFO 140719404451648] #quality_metric: host=algo-1, epoch=53, batch=15 train loss <loss>=8.38380289078\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:17 INFO 140719404451648] Epoch[53] Batch [15]#011Speed: 1257.75 samples/sec#011loss=8.383803\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:17 INFO 140719404451648] Epoch[53] Batch[20] avg_epoch_loss=8.373432\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:17 INFO 140719404451648] #quality_metric: host=algo-1, epoch=53, batch=20 train loss <loss>=8.54925479889\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:17 INFO 140719404451648] Epoch[53] Batch [20]#011Speed: 752.98 samples/sec#011loss=8.549255\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:17 INFO 140719404451648] Epoch[53] Batch[25] avg_epoch_loss=8.262960\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:17 INFO 140719404451648] #quality_metric: host=algo-1, epoch=53, batch=25 train loss <loss>=7.79897756577\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:17 INFO 140719404451648] Epoch[53] Batch [25]#011Speed: 1519.87 samples/sec#011loss=7.798978\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:17 INFO 140719404451648] Epoch[53] Batch[30] avg_epoch_loss=8.166050\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:17 INFO 140719404451648] #quality_metric: host=algo-1, epoch=53, batch=30 train loss <loss>=7.6621181488\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:17 INFO 140719404451648] Epoch[53] Batch [30]#011Speed: 775.36 samples/sec#011loss=7.662118\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:17 INFO 140719404451648] Epoch[53] Batch[35] avg_epoch_loss=8.093491\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:17 INFO 140719404451648] #quality_metric: host=algo-1, epoch=53, batch=35 train loss <loss>=7.6436249733\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:17 INFO 140719404451648] Epoch[53] Batch [35]#011Speed: 1515.21 samples/sec#011loss=7.643625\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] Epoch[53] Batch[40] avg_epoch_loss=8.081957\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] #quality_metric: host=algo-1, epoch=53, batch=40 train loss <loss>=7.99891338348\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] Epoch[53] Batch [40]#011Speed: 794.97 samples/sec#011loss=7.998913\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] Epoch[53] Batch[45] avg_epoch_loss=8.083196\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] #quality_metric: host=algo-1, epoch=53, batch=45 train loss <loss>=8.09335823059\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] Epoch[53] Batch [45]#011Speed: 1428.26 samples/sec#011loss=8.093358\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] processed a total of 1564 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1627.1381378173828, \"sum\": 1627.1381378173828, \"min\": 1627.1381378173828}}, \"EndTime\": 1578472758.201298, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472756.573625}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=961.134851795 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] #quality_metric: host=algo-1, epoch=53, train loss <loss>=8.04619751171\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] Epoch[54] Batch[0] avg_epoch_loss=7.757607\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=7.75760746002\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] Epoch[54] Batch[5] avg_epoch_loss=8.039482\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=8.03948163986\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] Epoch[54] Batch [5]#011Speed: 1489.80 samples/sec#011loss=8.039482\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] Epoch[54] Batch[10] avg_epoch_loss=8.208790\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=8.41195983887\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] Epoch[54] Batch [10]#011Speed: 653.90 samples/sec#011loss=8.411960\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] Epoch[54] Batch[15] avg_epoch_loss=8.204502\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] #quality_metric: host=algo-1, epoch=54, batch=15 train loss <loss>=8.19506969452\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] Epoch[54] Batch [15]#011Speed: 1726.07 samples/sec#011loss=8.195070\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] Epoch[54] Batch[20] avg_epoch_loss=8.152280\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] #quality_metric: host=algo-1, epoch=54, batch=20 train loss <loss>=7.98517045975\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:18 INFO 140719404451648] Epoch[54] Batch [20]#011Speed: 771.03 samples/sec#011loss=7.985170\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:19 INFO 140719404451648] Epoch[54] Batch[25] avg_epoch_loss=8.089498\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:19 INFO 140719404451648] #quality_metric: host=algo-1, epoch=54, batch=25 train loss <loss>=7.82581062317\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:19 INFO 140719404451648] Epoch[54] Batch [25]#011Speed: 1550.24 samples/sec#011loss=7.825811\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:19 INFO 140719404451648] Epoch[54] Batch[30] avg_epoch_loss=8.024855\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:19 INFO 140719404451648] #quality_metric: host=algo-1, epoch=54, batch=30 train loss <loss>=7.68871364594\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:19 INFO 140719404451648] Epoch[54] Batch [30]#011Speed: 783.79 samples/sec#011loss=7.688714\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:19 INFO 140719404451648] Epoch[54] Batch[35] avg_epoch_loss=7.989701\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:19 INFO 140719404451648] #quality_metric: host=algo-1, epoch=54, batch=35 train loss <loss>=7.77174806595\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:19 INFO 140719404451648] Epoch[54] Batch [35]#011Speed: 1394.34 samples/sec#011loss=7.771748\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:19 INFO 140719404451648] Epoch[54] Batch[40] avg_epoch_loss=7.953479\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:19 INFO 140719404451648] #quality_metric: host=algo-1, epoch=54, batch=40 train loss <loss>=7.69268131256\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:19 INFO 140719404451648] Epoch[54] Batch [40]#011Speed: 736.19 samples/sec#011loss=7.692681\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:19 INFO 140719404451648] Epoch[54] Batch[45] avg_epoch_loss=7.936486\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:19 INFO 140719404451648] #quality_metric: host=algo-1, epoch=54, batch=45 train loss <loss>=7.79714069366\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:19 INFO 140719404451648] Epoch[54] Batch [45]#011Speed: 1372.20 samples/sec#011loss=7.797141\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:19 INFO 140719404451648] processed a total of 1591 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1660.5150699615479, \"sum\": 1660.5150699615479, \"min\": 1660.5150699615479}}, \"EndTime\": 1578472759.862396, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472758.201366}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:19 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=958.069586893 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:19 INFO 140719404451648] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:19 INFO 140719404451648] #quality_metric: host=algo-1, epoch=54, train loss <loss>=7.89273336411\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:19 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:19 INFO 140719404451648] Epoch[55] Batch[0] avg_epoch_loss=7.113537\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:19 INFO 140719404451648] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=7.11353731155\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:20 INFO 140719404451648] Epoch[55] Batch[5] avg_epoch_loss=8.079171\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:20 INFO 140719404451648] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=8.07917102178\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:20 INFO 140719404451648] Epoch[55] Batch [5]#011Speed: 1332.48 samples/sec#011loss=8.079171\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:20 INFO 140719404451648] Epoch[55] Batch[10] avg_epoch_loss=8.139121\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:20 INFO 140719404451648] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=8.21106176376\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:20 INFO 140719404451648] Epoch[55] Batch [10]#011Speed: 732.11 samples/sec#011loss=8.211062\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:20 INFO 140719404451648] Epoch[55] Batch[15] avg_epoch_loss=8.208615\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:20 INFO 140719404451648] #quality_metric: host=algo-1, epoch=55, batch=15 train loss <loss>=8.36150045395\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:20 INFO 140719404451648] Epoch[55] Batch [15]#011Speed: 1437.60 samples/sec#011loss=8.361500\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:20 INFO 140719404451648] Epoch[55] Batch[20] avg_epoch_loss=8.144988\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:20 INFO 140719404451648] #quality_metric: host=algo-1, epoch=55, batch=20 train loss <loss>=7.94138088226\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:20 INFO 140719404451648] Epoch[55] Batch [20]#011Speed: 738.11 samples/sec#011loss=7.941381\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:20 INFO 140719404451648] Epoch[55] Batch[25] avg_epoch_loss=8.101029\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:20 INFO 140719404451648] #quality_metric: host=algo-1, epoch=55, batch=25 train loss <loss>=7.91640396118\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:20 INFO 140719404451648] Epoch[55] Batch [25]#011Speed: 1335.99 samples/sec#011loss=7.916404\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] Epoch[55] Batch[30] avg_epoch_loss=8.058589\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] #quality_metric: host=algo-1, epoch=55, batch=30 train loss <loss>=7.83789834976\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] Epoch[55] Batch [30]#011Speed: 734.23 samples/sec#011loss=7.837898\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] Epoch[55] Batch[35] avg_epoch_loss=8.026055\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] #quality_metric: host=algo-1, epoch=55, batch=35 train loss <loss>=7.82434587479\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] Epoch[55] Batch [35]#011Speed: 1340.27 samples/sec#011loss=7.824346\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] Epoch[55] Batch[40] avg_epoch_loss=8.015014\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] #quality_metric: host=algo-1, epoch=55, batch=40 train loss <loss>=7.93551988602\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] Epoch[55] Batch [40]#011Speed: 713.89 samples/sec#011loss=7.935520\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] Epoch[55] Batch[45] avg_epoch_loss=7.986446\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] #quality_metric: host=algo-1, epoch=55, batch=45 train loss <loss>=7.75218458176\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] Epoch[55] Batch [45]#011Speed: 1292.06 samples/sec#011loss=7.752185\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] Epoch[55] Batch[50] avg_epoch_loss=7.967895\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] #quality_metric: host=algo-1, epoch=55, batch=50 train loss <loss>=7.7972243309\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] Epoch[55] Batch [50]#011Speed: 1086.98 samples/sec#011loss=7.797224\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] processed a total of 1647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1782.2070121765137, \"sum\": 1782.2070121765137, \"min\": 1782.2070121765137}}, \"EndTime\": 1578472761.645185, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472759.862473}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=924.077461774 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] #quality_metric: host=algo-1, epoch=55, train loss <loss>=7.96362679738\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] Epoch[56] Batch[0] avg_epoch_loss=8.182780\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=8.18278026581\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] Epoch[56] Batch[5] avg_epoch_loss=8.163651\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=8.16365067164\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:21 INFO 140719404451648] Epoch[56] Batch [5]#011Speed: 1527.43 samples/sec#011loss=8.163651\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:22 INFO 140719404451648] Epoch[56] Batch[10] avg_epoch_loss=8.337120\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:22 INFO 140719404451648] #quality_metric: host=algo-1, epoch=56, batch=10 train loss <loss>=8.54528388977\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:22 INFO 140719404451648] Epoch[56] Batch [10]#011Speed: 680.49 samples/sec#011loss=8.545284\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:22 INFO 140719404451648] Epoch[56] Batch[15] avg_epoch_loss=8.337167\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:22 INFO 140719404451648] #quality_metric: host=algo-1, epoch=56, batch=15 train loss <loss>=8.33726825714\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:22 INFO 140719404451648] Epoch[56] Batch [15]#011Speed: 1652.74 samples/sec#011loss=8.337268\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:22 INFO 140719404451648] Epoch[56] Batch[20] avg_epoch_loss=8.285165\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:22 INFO 140719404451648] #quality_metric: host=algo-1, epoch=56, batch=20 train loss <loss>=8.11875858307\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:22 INFO 140719404451648] Epoch[56] Batch [20]#011Speed: 758.65 samples/sec#011loss=8.118759\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:22 INFO 140719404451648] Epoch[56] Batch[25] avg_epoch_loss=8.238679\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:22 INFO 140719404451648] #quality_metric: host=algo-1, epoch=56, batch=25 train loss <loss>=8.04344167709\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:22 INFO 140719404451648] Epoch[56] Batch [25]#011Speed: 1365.57 samples/sec#011loss=8.043442\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:22 INFO 140719404451648] Epoch[56] Batch[30] avg_epoch_loss=8.165899\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:22 INFO 140719404451648] #quality_metric: host=algo-1, epoch=56, batch=30 train loss <loss>=7.78744058609\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:22 INFO 140719404451648] Epoch[56] Batch [30]#011Speed: 764.71 samples/sec#011loss=7.787441\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:22 INFO 140719404451648] Epoch[56] Batch[35] avg_epoch_loss=8.106293\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:22 INFO 140719404451648] #quality_metric: host=algo-1, epoch=56, batch=35 train loss <loss>=7.73673391342\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:22 INFO 140719404451648] Epoch[56] Batch [35]#011Speed: 1726.35 samples/sec#011loss=7.736734\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:23 INFO 140719404451648] Epoch[56] Batch[40] avg_epoch_loss=8.086764\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:23 INFO 140719404451648] #quality_metric: host=algo-1, epoch=56, batch=40 train loss <loss>=7.9461602211\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:23 INFO 140719404451648] Epoch[56] Batch [40]#011Speed: 747.19 samples/sec#011loss=7.946160\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:23 INFO 140719404451648] Epoch[56] Batch[45] avg_epoch_loss=8.062529\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:23 INFO 140719404451648] #quality_metric: host=algo-1, epoch=56, batch=45 train loss <loss>=7.86379642487\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:23 INFO 140719404451648] Epoch[56] Batch [45]#011Speed: 1422.87 samples/sec#011loss=7.863796\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:23 INFO 140719404451648] processed a total of 1552 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1609.3590259552002, \"sum\": 1609.3590259552002, \"min\": 1609.3590259552002}}, \"EndTime\": 1578472763.255066, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472761.645261}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:23 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=964.298515458 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:23 INFO 140719404451648] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:23 INFO 140719404451648] #quality_metric: host=algo-1, epoch=56, train loss <loss>=7.98665234507\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:23 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:23 INFO 140719404451648] Epoch[57] Batch[0] avg_epoch_loss=8.602268\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:23 INFO 140719404451648] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=8.60226821899\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:23 INFO 140719404451648] Epoch[57] Batch[5] avg_epoch_loss=8.290491\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:23 INFO 140719404451648] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=8.29049142202\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:23 INFO 140719404451648] Epoch[57] Batch [5]#011Speed: 1538.41 samples/sec#011loss=8.290491\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:23 INFO 140719404451648] Epoch[57] Batch[10] avg_epoch_loss=8.300574\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:23 INFO 140719404451648] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=8.31267232895\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:23 INFO 140719404451648] Epoch[57] Batch [10]#011Speed: 735.69 samples/sec#011loss=8.312672\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:23 INFO 140719404451648] Epoch[57] Batch[15] avg_epoch_loss=8.356218\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:23 INFO 140719404451648] #quality_metric: host=algo-1, epoch=57, batch=15 train loss <loss>=8.4786359787\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:23 INFO 140719404451648] Epoch[57] Batch [15]#011Speed: 1322.99 samples/sec#011loss=8.478636\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] Epoch[57] Batch[20] avg_epoch_loss=8.268982\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] #quality_metric: host=algo-1, epoch=57, batch=20 train loss <loss>=7.98982543945\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] Epoch[57] Batch [20]#011Speed: 735.40 samples/sec#011loss=7.989825\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] Epoch[57] Batch[25] avg_epoch_loss=8.234897\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] #quality_metric: host=algo-1, epoch=57, batch=25 train loss <loss>=8.09173984528\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] Epoch[57] Batch [25]#011Speed: 1427.69 samples/sec#011loss=8.091740\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] Epoch[57] Batch[30] avg_epoch_loss=8.177196\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] #quality_metric: host=algo-1, epoch=57, batch=30 train loss <loss>=7.87714948654\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] Epoch[57] Batch [30]#011Speed: 745.08 samples/sec#011loss=7.877149\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] Epoch[57] Batch[35] avg_epoch_loss=8.103384\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] #quality_metric: host=algo-1, epoch=57, batch=35 train loss <loss>=7.64574918747\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] Epoch[57] Batch [35]#011Speed: 1354.47 samples/sec#011loss=7.645749\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] Epoch[57] Batch[40] avg_epoch_loss=8.065170\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] #quality_metric: host=algo-1, epoch=57, batch=40 train loss <loss>=7.79002857208\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] Epoch[57] Batch [40]#011Speed: 799.97 samples/sec#011loss=7.790029\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] Epoch[57] Batch[45] avg_epoch_loss=8.030069\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] #quality_metric: host=algo-1, epoch=57, batch=45 train loss <loss>=7.74224395752\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] Epoch[57] Batch [45]#011Speed: 1561.75 samples/sec#011loss=7.742244\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] Epoch[57] Batch[50] avg_epoch_loss=8.009472\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] #quality_metric: host=algo-1, epoch=57, batch=50 train loss <loss>=7.81998329163\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] Epoch[57] Batch [50]#011Speed: 1151.50 samples/sec#011loss=7.819983\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] processed a total of 1620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1672.8439331054688, \"sum\": 1672.8439331054688, \"min\": 1672.8439331054688}}, \"EndTime\": 1578472764.928485, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472763.25513}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=968.347098004 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] #quality_metric: host=algo-1, epoch=57, train loss <loss>=8.00947233275\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:24 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:25 INFO 140719404451648] Epoch[58] Batch[0] avg_epoch_loss=7.730131\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:25 INFO 140719404451648] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=7.73013114929\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:25 INFO 140719404451648] Epoch[58] Batch[5] avg_epoch_loss=8.155943\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:25 INFO 140719404451648] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=8.15594291687\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:25 INFO 140719404451648] Epoch[58] Batch [5]#011Speed: 1531.37 samples/sec#011loss=8.155943\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:25 INFO 140719404451648] Epoch[58] Batch[10] avg_epoch_loss=8.199401\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:25 INFO 140719404451648] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=8.25155029297\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:25 INFO 140719404451648] Epoch[58] Batch [10]#011Speed: 742.44 samples/sec#011loss=8.251550\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:25 INFO 140719404451648] Epoch[58] Batch[15] avg_epoch_loss=8.255006\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:25 INFO 140719404451648] #quality_metric: host=algo-1, epoch=58, batch=15 train loss <loss>=8.37733802795\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:25 INFO 140719404451648] Epoch[58] Batch [15]#011Speed: 1582.84 samples/sec#011loss=8.377338\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:25 INFO 140719404451648] Epoch[58] Batch[20] avg_epoch_loss=8.244647\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:25 INFO 140719404451648] #quality_metric: host=algo-1, epoch=58, batch=20 train loss <loss>=8.21149597168\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:25 INFO 140719404451648] Epoch[58] Batch [20]#011Speed: 791.55 samples/sec#011loss=8.211496\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:25 INFO 140719404451648] Epoch[58] Batch[25] avg_epoch_loss=8.154633\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:25 INFO 140719404451648] #quality_metric: host=algo-1, epoch=58, batch=25 train loss <loss>=7.77657566071\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:25 INFO 140719404451648] Epoch[58] Batch [25]#011Speed: 1259.73 samples/sec#011loss=7.776576\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:26 INFO 140719404451648] Epoch[58] Batch[30] avg_epoch_loss=8.112463\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:26 INFO 140719404451648] #quality_metric: host=algo-1, epoch=58, batch=30 train loss <loss>=7.89317932129\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:26 INFO 140719404451648] Epoch[58] Batch [30]#011Speed: 710.50 samples/sec#011loss=7.893179\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:26 INFO 140719404451648] Epoch[58] Batch[35] avg_epoch_loss=8.068317\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:26 INFO 140719404451648] #quality_metric: host=algo-1, epoch=58, batch=35 train loss <loss>=7.79461107254\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:26 INFO 140719404451648] Epoch[58] Batch [35]#011Speed: 1309.65 samples/sec#011loss=7.794611\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:39:26 INFO 140719404451648] Epoch[58] Batch[40] avg_epoch_loss=8.059427\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:26 INFO 140719404451648] #quality_metric: host=algo-1, epoch=58, batch=40 train loss <loss>=7.99541721344\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:26 INFO 140719404451648] Epoch[58] Batch [40]#011Speed: 718.03 samples/sec#011loss=7.995417\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:26 INFO 140719404451648] Epoch[58] Batch[45] avg_epoch_loss=8.053584\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:26 INFO 140719404451648] #quality_metric: host=algo-1, epoch=58, batch=45 train loss <loss>=8.00567169189\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:26 INFO 140719404451648] Epoch[58] Batch [45]#011Speed: 1573.57 samples/sec#011loss=8.005672\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:26 INFO 140719404451648] processed a total of 1555 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1631.404161453247, \"sum\": 1631.404161453247, \"min\": 1631.404161453247}}, \"EndTime\": 1578472766.560419, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472764.928557}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:26 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=953.099488579 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:26 INFO 140719404451648] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:26 INFO 140719404451648] #quality_metric: host=algo-1, epoch=58, train loss <loss>=7.98904878266\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:26 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:26 INFO 140719404451648] Epoch[59] Batch[0] avg_epoch_loss=8.019376\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:26 INFO 140719404451648] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=8.01937580109\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:26 INFO 140719404451648] Epoch[59] Batch[5] avg_epoch_loss=8.018907\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:26 INFO 140719404451648] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=8.01890714963\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:26 INFO 140719404451648] Epoch[59] Batch [5]#011Speed: 1452.35 samples/sec#011loss=8.018907\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:27 INFO 140719404451648] Epoch[59] Batch[10] avg_epoch_loss=8.217435\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:27 INFO 140719404451648] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=8.45566911697\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:27 INFO 140719404451648] Epoch[59] Batch [10]#011Speed: 776.33 samples/sec#011loss=8.455669\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:27 INFO 140719404451648] Epoch[59] Batch[15] avg_epoch_loss=8.271604\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:27 INFO 140719404451648] #quality_metric: host=algo-1, epoch=59, batch=15 train loss <loss>=8.3907740593\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:27 INFO 140719404451648] Epoch[59] Batch [15]#011Speed: 1538.63 samples/sec#011loss=8.390774\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:27 INFO 140719404451648] Epoch[59] Batch[20] avg_epoch_loss=8.252121\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:27 INFO 140719404451648] #quality_metric: host=algo-1, epoch=59, batch=20 train loss <loss>=8.18977451324\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:27 INFO 140719404451648] Epoch[59] Batch [20]#011Speed: 763.63 samples/sec#011loss=8.189775\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:27 INFO 140719404451648] Epoch[59] Batch[25] avg_epoch_loss=8.218205\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:27 INFO 140719404451648] #quality_metric: host=algo-1, epoch=59, batch=25 train loss <loss>=8.07575826645\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:27 INFO 140719404451648] Epoch[59] Batch [25]#011Speed: 1306.59 samples/sec#011loss=8.075758\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:27 INFO 140719404451648] Epoch[59] Batch[30] avg_epoch_loss=8.152149\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:27 INFO 140719404451648] #quality_metric: host=algo-1, epoch=59, batch=30 train loss <loss>=7.80865793228\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:27 INFO 140719404451648] Epoch[59] Batch [30]#011Speed: 722.58 samples/sec#011loss=7.808658\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:27 INFO 140719404451648] Epoch[59] Batch[35] avg_epoch_loss=8.117449\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:27 INFO 140719404451648] #quality_metric: host=algo-1, epoch=59, batch=35 train loss <loss>=7.90231189728\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:27 INFO 140719404451648] Epoch[59] Batch [35]#011Speed: 1287.60 samples/sec#011loss=7.902312\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] Epoch[59] Batch[40] avg_epoch_loss=8.068480\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] #quality_metric: host=algo-1, epoch=59, batch=40 train loss <loss>=7.71590452194\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] Epoch[59] Batch [40]#011Speed: 742.49 samples/sec#011loss=7.715905\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] Epoch[59] Batch[45] avg_epoch_loss=8.046943\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] #quality_metric: host=algo-1, epoch=59, batch=45 train loss <loss>=7.87033653259\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] Epoch[59] Batch [45]#011Speed: 1710.12 samples/sec#011loss=7.870337\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] Epoch[59] Batch[50] avg_epoch_loss=7.985123\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] #quality_metric: host=algo-1, epoch=59, batch=50 train loss <loss>=7.41638126373\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] Epoch[59] Batch [50]#011Speed: 1102.94 samples/sec#011loss=7.416381\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] processed a total of 1653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1706.4299583435059, \"sum\": 1706.4299583435059, \"min\": 1706.4299583435059}}, \"EndTime\": 1578472768.267369, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472766.560497}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=968.626651934 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] #quality_metric: host=algo-1, epoch=59, train loss <loss>=7.98385431216\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] Epoch[60] Batch[0] avg_epoch_loss=8.438289\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=8.43828868866\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] Epoch[60] Batch[5] avg_epoch_loss=8.317897\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=8.31789692243\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] Epoch[60] Batch [5]#011Speed: 1650.62 samples/sec#011loss=8.317897\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] Epoch[60] Batch[10] avg_epoch_loss=8.326129\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=8.336008358\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] Epoch[60] Batch [10]#011Speed: 745.78 samples/sec#011loss=8.336008\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] Epoch[60] Batch[15] avg_epoch_loss=8.404820\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] #quality_metric: host=algo-1, epoch=60, batch=15 train loss <loss>=8.57793941498\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:28 INFO 140719404451648] Epoch[60] Batch [15]#011Speed: 1726.35 samples/sec#011loss=8.577939\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:29 INFO 140719404451648] Epoch[60] Batch[20] avg_epoch_loss=8.358680\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:29 INFO 140719404451648] #quality_metric: host=algo-1, epoch=60, batch=20 train loss <loss>=8.21103248596\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:29 INFO 140719404451648] Epoch[60] Batch [20]#011Speed: 779.86 samples/sec#011loss=8.211032\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:29 INFO 140719404451648] Epoch[60] Batch[25] avg_epoch_loss=8.302929\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:29 INFO 140719404451648] #quality_metric: host=algo-1, epoch=60, batch=25 train loss <loss>=8.06877593994\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:29 INFO 140719404451648] Epoch[60] Batch [25]#011Speed: 1740.40 samples/sec#011loss=8.068776\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:29 INFO 140719404451648] Epoch[60] Batch[30] avg_epoch_loss=8.236679\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:29 INFO 140719404451648] #quality_metric: host=algo-1, epoch=60, batch=30 train loss <loss>=7.89217596054\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:29 INFO 140719404451648] Epoch[60] Batch [30]#011Speed: 810.26 samples/sec#011loss=7.892176\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:29 INFO 140719404451648] Epoch[60] Batch[35] avg_epoch_loss=8.161006\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:29 INFO 140719404451648] #quality_metric: host=algo-1, epoch=60, batch=35 train loss <loss>=7.69183559418\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:29 INFO 140719404451648] Epoch[60] Batch [35]#011Speed: 1633.50 samples/sec#011loss=7.691836\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:29 INFO 140719404451648] Epoch[60] Batch[40] avg_epoch_loss=8.128083\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:29 INFO 140719404451648] #quality_metric: host=algo-1, epoch=60, batch=40 train loss <loss>=7.89103736877\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:29 INFO 140719404451648] Epoch[60] Batch [40]#011Speed: 665.98 samples/sec#011loss=7.891037\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:29 INFO 140719404451648] Epoch[60] Batch[45] avg_epoch_loss=8.088955\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:29 INFO 140719404451648] #quality_metric: host=algo-1, epoch=60, batch=45 train loss <loss>=7.76810245514\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:29 INFO 140719404451648] Epoch[60] Batch [45]#011Speed: 1733.27 samples/sec#011loss=7.768102\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:29 INFO 140719404451648] processed a total of 1584 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1573.603868484497, \"sum\": 1573.603868484497, \"min\": 1573.603868484497}}, \"EndTime\": 1578472769.841473, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472768.267443}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:29 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=1006.53611902 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:29 INFO 140719404451648] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:29 INFO 140719404451648] #quality_metric: host=algo-1, epoch=60, train loss <loss>=8.07368247986\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:29 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:30 INFO 140719404451648] Epoch[61] Batch[0] avg_epoch_loss=8.142613\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:30 INFO 140719404451648] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=8.14261341095\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:30 INFO 140719404451648] Epoch[61] Batch[5] avg_epoch_loss=8.065359\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:30 INFO 140719404451648] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=8.0653591156\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:30 INFO 140719404451648] Epoch[61] Batch [5]#011Speed: 1544.45 samples/sec#011loss=8.065359\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:30 INFO 140719404451648] Epoch[61] Batch[10] avg_epoch_loss=8.088126\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:30 INFO 140719404451648] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=8.11544618607\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:30 INFO 140719404451648] Epoch[61] Batch [10]#011Speed: 796.10 samples/sec#011loss=8.115446\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:30 INFO 140719404451648] Epoch[61] Batch[15] avg_epoch_loss=8.167975\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:30 INFO 140719404451648] #quality_metric: host=algo-1, epoch=61, batch=15 train loss <loss>=8.34364147186\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:30 INFO 140719404451648] Epoch[61] Batch [15]#011Speed: 1511.38 samples/sec#011loss=8.343641\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:30 INFO 140719404451648] Epoch[61] Batch[20] avg_epoch_loss=8.110532\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:30 INFO 140719404451648] #quality_metric: host=algo-1, epoch=61, batch=20 train loss <loss>=7.92671537399\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:30 INFO 140719404451648] Epoch[61] Batch [20]#011Speed: 798.05 samples/sec#011loss=7.926715\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:30 INFO 140719404451648] Epoch[61] Batch[25] avg_epoch_loss=8.073200\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:30 INFO 140719404451648] #quality_metric: host=algo-1, epoch=61, batch=25 train loss <loss>=7.91640510559\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:30 INFO 140719404451648] Epoch[61] Batch [25]#011Speed: 1212.13 samples/sec#011loss=7.916405\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:30 INFO 140719404451648] Epoch[61] Batch[30] avg_epoch_loss=8.032121\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:30 INFO 140719404451648] #quality_metric: host=algo-1, epoch=61, batch=30 train loss <loss>=7.81851215363\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:30 INFO 140719404451648] Epoch[61] Batch [30]#011Speed: 783.78 samples/sec#011loss=7.818512\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:31 INFO 140719404451648] Epoch[61] Batch[35] avg_epoch_loss=8.011659\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:31 INFO 140719404451648] #quality_metric: host=algo-1, epoch=61, batch=35 train loss <loss>=7.88479328156\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:31 INFO 140719404451648] Epoch[61] Batch [35]#011Speed: 1551.92 samples/sec#011loss=7.884793\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:31 INFO 140719404451648] Epoch[61] Batch[40] avg_epoch_loss=8.001580\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:31 INFO 140719404451648] #quality_metric: host=algo-1, epoch=61, batch=40 train loss <loss>=7.92901163101\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:31 INFO 140719404451648] Epoch[61] Batch [40]#011Speed: 729.14 samples/sec#011loss=7.929012\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:31 INFO 140719404451648] Epoch[61] Batch[45] avg_epoch_loss=8.005502\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:31 INFO 140719404451648] #quality_metric: host=algo-1, epoch=61, batch=45 train loss <loss>=8.03766088486\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:31 INFO 140719404451648] Epoch[61] Batch [45]#011Speed: 1519.44 samples/sec#011loss=8.037661\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:31 INFO 140719404451648] processed a total of 1583 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1643.2349681854248, \"sum\": 1643.2349681854248, \"min\": 1643.2349681854248}}, \"EndTime\": 1578472771.485217, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472769.841548}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:31 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=963.277978417 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:31 INFO 140719404451648] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:31 INFO 140719404451648] #quality_metric: host=algo-1, epoch=61, train loss <loss>=7.97190761566\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:31 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:31 INFO 140719404451648] Epoch[62] Batch[0] avg_epoch_loss=7.873965\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:31 INFO 140719404451648] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=7.87396526337\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:31 INFO 140719404451648] Epoch[62] Batch[5] avg_epoch_loss=7.936345\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:31 INFO 140719404451648] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=7.93634454409\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:31 INFO 140719404451648] Epoch[62] Batch [5]#011Speed: 1566.47 samples/sec#011loss=7.936345\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:31 INFO 140719404451648] Epoch[62] Batch[10] avg_epoch_loss=7.993476\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:31 INFO 140719404451648] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=8.06203346252\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:31 INFO 140719404451648] Epoch[62] Batch [10]#011Speed: 801.86 samples/sec#011loss=8.062033\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:32 INFO 140719404451648] Epoch[62] Batch[15] avg_epoch_loss=8.138880\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:32 INFO 140719404451648] #quality_metric: host=algo-1, epoch=62, batch=15 train loss <loss>=8.45877056122\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:32 INFO 140719404451648] Epoch[62] Batch [15]#011Speed: 1560.15 samples/sec#011loss=8.458771\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:32 INFO 140719404451648] Epoch[62] Batch[20] avg_epoch_loss=8.158059\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:32 INFO 140719404451648] #quality_metric: host=algo-1, epoch=62, batch=20 train loss <loss>=8.21942977905\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:32 INFO 140719404451648] Epoch[62] Batch [20]#011Speed: 803.64 samples/sec#011loss=8.219430\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:32 INFO 140719404451648] Epoch[62] Batch[25] avg_epoch_loss=8.113855\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:32 INFO 140719404451648] #quality_metric: host=algo-1, epoch=62, batch=25 train loss <loss>=7.92819900513\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:32 INFO 140719404451648] Epoch[62] Batch [25]#011Speed: 1556.00 samples/sec#011loss=7.928199\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:32 INFO 140719404451648] Epoch[62] Batch[30] avg_epoch_loss=8.065185\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:32 INFO 140719404451648] #quality_metric: host=algo-1, epoch=62, batch=30 train loss <loss>=7.81210269928\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:32 INFO 140719404451648] Epoch[62] Batch [30]#011Speed: 654.40 samples/sec#011loss=7.812103\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:32 INFO 140719404451648] Epoch[62] Batch[35] avg_epoch_loss=8.034786\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:32 INFO 140719404451648] #quality_metric: host=algo-1, epoch=62, batch=35 train loss <loss>=7.84630870819\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:32 INFO 140719404451648] Epoch[62] Batch [35]#011Speed: 1659.80 samples/sec#011loss=7.846309\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:32 INFO 140719404451648] Epoch[62] Batch[40] avg_epoch_loss=7.995009\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:32 INFO 140719404451648] #quality_metric: host=algo-1, epoch=62, batch=40 train loss <loss>=7.70861692429\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:32 INFO 140719404451648] Epoch[62] Batch [40]#011Speed: 753.86 samples/sec#011loss=7.708617\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:32 INFO 140719404451648] Epoch[62] Batch[45] avg_epoch_loss=7.964100\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:32 INFO 140719404451648] #quality_metric: host=algo-1, epoch=62, batch=45 train loss <loss>=7.71064100266\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:32 INFO 140719404451648] Epoch[62] Batch [45]#011Speed: 1505.51 samples/sec#011loss=7.710641\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:33 INFO 140719404451648] Epoch[62] Batch[50] avg_epoch_loss=7.981749\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:33 INFO 140719404451648] #quality_metric: host=algo-1, epoch=62, batch=50 train loss <loss>=8.14412584305\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:33 INFO 140719404451648] Epoch[62] Batch [50]#011Speed: 1104.06 samples/sec#011loss=8.144126\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:33 INFO 140719404451648] processed a total of 1619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1652.022123336792, \"sum\": 1652.022123336792, \"min\": 1652.022123336792}}, \"EndTime\": 1578472773.137764, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472771.485293}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:33 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=979.947730373 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:33 INFO 140719404451648] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:33 INFO 140719404451648] #quality_metric: host=algo-1, epoch=62, train loss <loss>=7.98174916062\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:33 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:33 INFO 140719404451648] Epoch[63] Batch[0] avg_epoch_loss=8.189412\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:33 INFO 140719404451648] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=8.189412117\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:33 INFO 140719404451648] Epoch[63] Batch[5] avg_epoch_loss=8.289690\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:33 INFO 140719404451648] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=8.28969049454\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:33 INFO 140719404451648] Epoch[63] Batch [5]#011Speed: 1480.71 samples/sec#011loss=8.289690\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:33 INFO 140719404451648] Epoch[63] Batch[10] avg_epoch_loss=8.285254\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:33 INFO 140719404451648] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=8.27993049622\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:33 INFO 140719404451648] Epoch[63] Batch [10]#011Speed: 723.76 samples/sec#011loss=8.279930\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:33 INFO 140719404451648] Epoch[63] Batch[15] avg_epoch_loss=8.267491\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:33 INFO 140719404451648] #quality_metric: host=algo-1, epoch=63, batch=15 train loss <loss>=8.22841062546\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:33 INFO 140719404451648] Epoch[63] Batch [15]#011Speed: 1574.88 samples/sec#011loss=8.228411\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:33 INFO 140719404451648] Epoch[63] Batch[20] avg_epoch_loss=8.251598\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:33 INFO 140719404451648] #quality_metric: host=algo-1, epoch=63, batch=20 train loss <loss>=8.20074310303\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:33 INFO 140719404451648] Epoch[63] Batch [20]#011Speed: 770.38 samples/sec#011loss=8.200743\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] Epoch[63] Batch[25] avg_epoch_loss=8.195046\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] #quality_metric: host=algo-1, epoch=63, batch=25 train loss <loss>=7.95752763748\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] Epoch[63] Batch [25]#011Speed: 1736.09 samples/sec#011loss=7.957528\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] Epoch[63] Batch[30] avg_epoch_loss=8.165012\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] #quality_metric: host=algo-1, epoch=63, batch=30 train loss <loss>=8.00883331299\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] Epoch[63] Batch [30]#011Speed: 768.73 samples/sec#011loss=8.008833\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] Epoch[63] Batch[35] avg_epoch_loss=8.083733\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] #quality_metric: host=algo-1, epoch=63, batch=35 train loss <loss>=7.57980670929\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] Epoch[63] Batch [35]#011Speed: 1547.30 samples/sec#011loss=7.579807\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] Epoch[63] Batch[40] avg_epoch_loss=8.058575\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] #quality_metric: host=algo-1, epoch=63, batch=40 train loss <loss>=7.87743654251\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] Epoch[63] Batch [40]#011Speed: 761.03 samples/sec#011loss=7.877437\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] Epoch[63] Batch[45] avg_epoch_loss=8.062927\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] #quality_metric: host=algo-1, epoch=63, batch=45 train loss <loss>=8.09861354828\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] Epoch[63] Batch [45]#011Speed: 1538.76 samples/sec#011loss=8.098614\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] Epoch[63] Batch[50] avg_epoch_loss=8.017459\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] #quality_metric: host=algo-1, epoch=63, batch=50 train loss <loss>=7.5991481781\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] Epoch[63] Batch [50]#011Speed: 1331.55 samples/sec#011loss=7.599148\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] processed a total of 1651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1632.256031036377, \"sum\": 1632.256031036377, \"min\": 1632.256031036377}}, \"EndTime\": 1578472774.770511, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472773.137837}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=1011.41906116 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] #quality_metric: host=algo-1, epoch=63, train loss <loss>=8.00191207115\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] Epoch[64] Batch[0] avg_epoch_loss=8.604453\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=8.60445308685\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] Epoch[64] Batch[5] avg_epoch_loss=8.166846\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=8.16684603691\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:34 INFO 140719404451648] Epoch[64] Batch [5]#011Speed: 1504.73 samples/sec#011loss=8.166846\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:35 INFO 140719404451648] Epoch[64] Batch[10] avg_epoch_loss=8.183949\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:35 INFO 140719404451648] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=8.20447292328\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:35 INFO 140719404451648] Epoch[64] Batch [10]#011Speed: 777.33 samples/sec#011loss=8.204473\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:35 INFO 140719404451648] Epoch[64] Batch[15] avg_epoch_loss=8.123789\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:35 INFO 140719404451648] #quality_metric: host=algo-1, epoch=64, batch=15 train loss <loss>=7.99143686295\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:35 INFO 140719404451648] Epoch[64] Batch [15]#011Speed: 1681.68 samples/sec#011loss=7.991437\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:35 INFO 140719404451648] Epoch[64] Batch[20] avg_epoch_loss=8.142838\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:35 INFO 140719404451648] #quality_metric: host=algo-1, epoch=64, batch=20 train loss <loss>=8.20379552841\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:35 INFO 140719404451648] Epoch[64] Batch [20]#011Speed: 759.57 samples/sec#011loss=8.203796\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:35 INFO 140719404451648] Epoch[64] Batch[25] avg_epoch_loss=8.026322\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:35 INFO 140719404451648] #quality_metric: host=algo-1, epoch=64, batch=25 train loss <loss>=7.53695545197\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:35 INFO 140719404451648] Epoch[64] Batch [25]#011Speed: 1586.13 samples/sec#011loss=7.536955\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:35 INFO 140719404451648] Epoch[64] Batch[30] avg_epoch_loss=8.005821\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:35 INFO 140719404451648] #quality_metric: host=algo-1, epoch=64, batch=30 train loss <loss>=7.89921388626\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:35 INFO 140719404451648] Epoch[64] Batch [30]#011Speed: 731.16 samples/sec#011loss=7.899214\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:35 INFO 140719404451648] Epoch[64] Batch[35] avg_epoch_loss=7.965437\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:35 INFO 140719404451648] #quality_metric: host=algo-1, epoch=64, batch=35 train loss <loss>=7.71505422592\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:35 INFO 140719404451648] Epoch[64] Batch [35]#011Speed: 1536.57 samples/sec#011loss=7.715054\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] Epoch[64] Batch[40] avg_epoch_loss=7.937013\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] #quality_metric: host=algo-1, epoch=64, batch=40 train loss <loss>=7.73235998154\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] Epoch[64] Batch [40]#011Speed: 672.83 samples/sec#011loss=7.732360\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] Epoch[64] Batch[45] avg_epoch_loss=7.946030\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] #quality_metric: host=algo-1, epoch=64, batch=45 train loss <loss>=8.01996936798\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] Epoch[64] Batch [45]#011Speed: 1664.57 samples/sec#011loss=8.019969\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] Epoch[64] Batch[50] avg_epoch_loss=7.867576\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] #quality_metric: host=algo-1, epoch=64, batch=50 train loss <loss>=7.14580659866\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] Epoch[64] Batch [50]#011Speed: 1180.13 samples/sec#011loss=7.145807\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] processed a total of 1605 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1634.0630054473877, \"sum\": 1634.0630054473877, \"min\": 1634.0630054473877}}, \"EndTime\": 1578472776.405125, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472774.770576}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=982.148207133 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] #quality_metric: host=algo-1, epoch=64, train loss <loss>=7.86757647757\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] Epoch[65] Batch[0] avg_epoch_loss=8.409348\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=8.40934848785\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] Epoch[65] Batch[5] avg_epoch_loss=8.271132\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=8.2711323897\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] Epoch[65] Batch [5]#011Speed: 1648.13 samples/sec#011loss=8.271132\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] Epoch[65] Batch[10] avg_epoch_loss=8.370968\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=8.49077129364\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] Epoch[65] Batch [10]#011Speed: 783.28 samples/sec#011loss=8.490771\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] Epoch[65] Batch[15] avg_epoch_loss=8.353986\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] #quality_metric: host=algo-1, epoch=65, batch=15 train loss <loss>=8.31662473679\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:36 INFO 140719404451648] Epoch[65] Batch [15]#011Speed: 1551.88 samples/sec#011loss=8.316625\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:37 INFO 140719404451648] Epoch[65] Batch[20] avg_epoch_loss=8.341381\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:37 INFO 140719404451648] #quality_metric: host=algo-1, epoch=65, batch=20 train loss <loss>=8.30104351044\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:37 INFO 140719404451648] Epoch[65] Batch [20]#011Speed: 822.88 samples/sec#011loss=8.301044\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:37 INFO 140719404451648] Epoch[65] Batch[25] avg_epoch_loss=8.242706\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:37 INFO 140719404451648] #quality_metric: host=algo-1, epoch=65, batch=25 train loss <loss>=7.82827224731\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:37 INFO 140719404451648] Epoch[65] Batch [25]#011Speed: 1555.68 samples/sec#011loss=7.828272\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:37 INFO 140719404451648] Epoch[65] Batch[30] avg_epoch_loss=8.186897\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:37 INFO 140719404451648] #quality_metric: host=algo-1, epoch=65, batch=30 train loss <loss>=7.89669084549\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:37 INFO 140719404451648] Epoch[65] Batch [30]#011Speed: 687.67 samples/sec#011loss=7.896691\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:37 INFO 140719404451648] Epoch[65] Batch[35] avg_epoch_loss=8.139716\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:37 INFO 140719404451648] #quality_metric: host=algo-1, epoch=65, batch=35 train loss <loss>=7.8471912384\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:37 INFO 140719404451648] Epoch[65] Batch [35]#011Speed: 1670.25 samples/sec#011loss=7.847191\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:37 INFO 140719404451648] Epoch[65] Batch[40] avg_epoch_loss=8.075398\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:37 INFO 140719404451648] #quality_metric: host=algo-1, epoch=65, batch=40 train loss <loss>=7.61230888367\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:37 INFO 140719404451648] Epoch[65] Batch [40]#011Speed: 803.97 samples/sec#011loss=7.612309\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:37 INFO 140719404451648] Epoch[65] Batch[45] avg_epoch_loss=8.065109\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:37 INFO 140719404451648] #quality_metric: host=algo-1, epoch=65, batch=45 train loss <loss>=7.98074188232\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:37 INFO 140719404451648] Epoch[65] Batch [45]#011Speed: 1720.93 samples/sec#011loss=7.980742\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:37 INFO 140719404451648] processed a total of 1563 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1573.6749172210693, \"sum\": 1573.6749172210693, \"min\": 1573.6749172210693}}, \"EndTime\": 1578472777.979301, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472776.405199}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:37 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=993.152167909 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:37 INFO 140719404451648] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:37 INFO 140719404451648] #quality_metric: host=algo-1, epoch=65, train loss <loss>=8.03965057646\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:37 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:38 INFO 140719404451648] Epoch[66] Batch[0] avg_epoch_loss=8.433434\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:38 INFO 140719404451648] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=8.43343448639\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:38 INFO 140719404451648] Epoch[66] Batch[5] avg_epoch_loss=8.137746\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:38 INFO 140719404451648] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=8.13774601618\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:38 INFO 140719404451648] Epoch[66] Batch [5]#011Speed: 1720.91 samples/sec#011loss=8.137746\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:38 INFO 140719404451648] Epoch[66] Batch[10] avg_epoch_loss=8.333440\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:38 INFO 140719404451648] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=8.56827373505\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:38 INFO 140719404451648] Epoch[66] Batch [10]#011Speed: 745.39 samples/sec#011loss=8.568274\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:38 INFO 140719404451648] Epoch[66] Batch[15] avg_epoch_loss=8.311669\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:38 INFO 140719404451648] #quality_metric: host=algo-1, epoch=66, batch=15 train loss <loss>=8.26377029419\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:38 INFO 140719404451648] Epoch[66] Batch [15]#011Speed: 1559.99 samples/sec#011loss=8.263770\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:38 INFO 140719404451648] Epoch[66] Batch[20] avg_epoch_loss=8.235598\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:38 INFO 140719404451648] #quality_metric: host=algo-1, epoch=66, batch=20 train loss <loss>=7.99217405319\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:38 INFO 140719404451648] Epoch[66] Batch [20]#011Speed: 773.19 samples/sec#011loss=7.992174\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:38 INFO 140719404451648] Epoch[66] Batch[25] avg_epoch_loss=8.163864\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:38 INFO 140719404451648] #quality_metric: host=algo-1, epoch=66, batch=25 train loss <loss>=7.86257991791\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:38 INFO 140719404451648] Epoch[66] Batch [25]#011Speed: 1558.01 samples/sec#011loss=7.862580\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] Epoch[66] Batch[30] avg_epoch_loss=8.099507\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] #quality_metric: host=algo-1, epoch=66, batch=30 train loss <loss>=7.76485242844\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] Epoch[66] Batch [30]#011Speed: 787.37 samples/sec#011loss=7.764852\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] Epoch[66] Batch[35] avg_epoch_loss=8.079026\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] #quality_metric: host=algo-1, epoch=66, batch=35 train loss <loss>=7.95203857422\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] Epoch[66] Batch [35]#011Speed: 1475.50 samples/sec#011loss=7.952039\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] Epoch[66] Batch[40] avg_epoch_loss=8.031039\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] #quality_metric: host=algo-1, epoch=66, batch=40 train loss <loss>=7.68553609848\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] Epoch[66] Batch [40]#011Speed: 719.49 samples/sec#011loss=7.685536\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] Epoch[66] Batch[45] avg_epoch_loss=8.002510\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] #quality_metric: host=algo-1, epoch=66, batch=45 train loss <loss>=7.76856718063\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] Epoch[66] Batch [45]#011Speed: 1616.68 samples/sec#011loss=7.768567\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] processed a total of 1593 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1617.2618865966797, \"sum\": 1617.2618865966797, \"min\": 1617.2618865966797}}, \"EndTime\": 1578472779.597131, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472777.979372}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=984.92992704 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] #quality_metric: host=algo-1, epoch=66, train loss <loss>=7.97963848114\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] Epoch[67] Batch[0] avg_epoch_loss=7.788769\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=7.78876924515\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] Epoch[67] Batch[5] avg_epoch_loss=7.947347\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=7.94734748205\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] Epoch[67] Batch [5]#011Speed: 1640.59 samples/sec#011loss=7.947347\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] Epoch[67] Batch[10] avg_epoch_loss=7.982620\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=8.02494754791\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:39 INFO 140719404451648] Epoch[67] Batch [10]#011Speed: 1723.19 samples/sec#011loss=8.024948\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:40 INFO 140719404451648] Epoch[67] Batch[15] avg_epoch_loss=8.176939\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:40 INFO 140719404451648] #quality_metric: host=algo-1, epoch=67, batch=15 train loss <loss>=8.60444030762\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:40 INFO 140719404451648] Epoch[67] Batch [15]#011Speed: 742.71 samples/sec#011loss=8.604440\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:40 INFO 140719404451648] Epoch[67] Batch[20] avg_epoch_loss=8.223592\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:40 INFO 140719404451648] #quality_metric: host=algo-1, epoch=67, batch=20 train loss <loss>=8.37288322449\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:40 INFO 140719404451648] Epoch[67] Batch [20]#011Speed: 809.72 samples/sec#011loss=8.372883\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:40 INFO 140719404451648] Epoch[67] Batch[25] avg_epoch_loss=8.147520\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:40 INFO 140719404451648] #quality_metric: host=algo-1, epoch=67, batch=25 train loss <loss>=7.82801675797\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:40 INFO 140719404451648] Epoch[67] Batch [25]#011Speed: 1549.49 samples/sec#011loss=7.828017\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:40 INFO 140719404451648] Epoch[67] Batch[30] avg_epoch_loss=8.099627\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:40 INFO 140719404451648] #quality_metric: host=algo-1, epoch=67, batch=30 train loss <loss>=7.85058546066\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:40 INFO 140719404451648] Epoch[67] Batch [30]#011Speed: 723.71 samples/sec#011loss=7.850585\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:40 INFO 140719404451648] Epoch[67] Batch[35] avg_epoch_loss=8.047518\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:40 INFO 140719404451648] #quality_metric: host=algo-1, epoch=67, batch=35 train loss <loss>=7.72443904877\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:40 INFO 140719404451648] Epoch[67] Batch [35]#011Speed: 1335.79 samples/sec#011loss=7.724439\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] Epoch[67] Batch[40] avg_epoch_loss=8.033833\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] #quality_metric: host=algo-1, epoch=67, batch=40 train loss <loss>=7.93529787064\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] Epoch[67] Batch [40]#011Speed: 745.85 samples/sec#011loss=7.935298\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] Epoch[67] Batch[45] avg_epoch_loss=8.010835\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] #quality_metric: host=algo-1, epoch=67, batch=45 train loss <loss>=7.82225780487\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] Epoch[67] Batch [45]#011Speed: 1671.86 samples/sec#011loss=7.822258\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] processed a total of 1555 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1578.495979309082, \"sum\": 1578.495979309082, \"min\": 1578.495979309082}}, \"EndTime\": 1578472781.176139, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472779.597207}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=985.046368812 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] #quality_metric: host=algo-1, epoch=67, train loss <loss>=7.95846586811\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] Epoch[68] Batch[0] avg_epoch_loss=7.850092\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=7.8500919342\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] Epoch[68] Batch[5] avg_epoch_loss=8.380156\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=8.38015556335\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] Epoch[68] Batch [5]#011Speed: 1553.02 samples/sec#011loss=8.380156\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] Epoch[68] Batch[10] avg_epoch_loss=8.306773\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=8.21871452332\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] Epoch[68] Batch [10]#011Speed: 670.29 samples/sec#011loss=8.218715\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] Epoch[68] Batch[15] avg_epoch_loss=8.381034\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] #quality_metric: host=algo-1, epoch=68, batch=15 train loss <loss>=8.54440603256\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] Epoch[68] Batch [15]#011Speed: 1640.91 samples/sec#011loss=8.544406\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] Epoch[68] Batch[20] avg_epoch_loss=8.380016\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] #quality_metric: host=algo-1, epoch=68, batch=20 train loss <loss>=8.37676143646\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:41 INFO 140719404451648] Epoch[68] Batch [20]#011Speed: 757.48 samples/sec#011loss=8.376761\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] Epoch[68] Batch[25] avg_epoch_loss=8.273474\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] #quality_metric: host=algo-1, epoch=68, batch=25 train loss <loss>=7.82599601746\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] Epoch[68] Batch [25]#011Speed: 1700.41 samples/sec#011loss=7.825996\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] Epoch[68] Batch[30] avg_epoch_loss=8.172835\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] #quality_metric: host=algo-1, epoch=68, batch=30 train loss <loss>=7.64951133728\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] Epoch[68] Batch [30]#011Speed: 785.44 samples/sec#011loss=7.649511\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] Epoch[68] Batch[35] avg_epoch_loss=8.129332\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] #quality_metric: host=algo-1, epoch=68, batch=35 train loss <loss>=7.85961227417\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] Epoch[68] Batch [35]#011Speed: 1556.86 samples/sec#011loss=7.859612\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] Epoch[68] Batch[40] avg_epoch_loss=8.114527\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] #quality_metric: host=algo-1, epoch=68, batch=40 train loss <loss>=8.00793275833\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] Epoch[68] Batch [40]#011Speed: 797.34 samples/sec#011loss=8.007933\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] Epoch[68] Batch[45] avg_epoch_loss=8.105676\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] #quality_metric: host=algo-1, epoch=68, batch=45 train loss <loss>=8.03309764862\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] Epoch[68] Batch [45]#011Speed: 1730.89 samples/sec#011loss=8.033098\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] processed a total of 1560 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1581.8750858306885, \"sum\": 1581.8750858306885, \"min\": 1581.8750858306885}}, \"EndTime\": 1578472782.758563, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472781.176215}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=986.10349882 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] #quality_metric: host=algo-1, epoch=68, train loss <loss>=8.04886841287\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] Epoch[69] Batch[0] avg_epoch_loss=7.796903\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=7.79690265656\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] Epoch[69] Batch[5] avg_epoch_loss=7.931645\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=7.9316453139\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:42 INFO 140719404451648] Epoch[69] Batch [5]#011Speed: 1545.03 samples/sec#011loss=7.931645\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:43 INFO 140719404451648] Epoch[69] Batch[10] avg_epoch_loss=8.127173\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:43 INFO 140719404451648] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=8.36180648804\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:43 INFO 140719404451648] Epoch[69] Batch [10]#011Speed: 760.58 samples/sec#011loss=8.361806\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:43 INFO 140719404451648] Epoch[69] Batch[15] avg_epoch_loss=8.203287\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:43 INFO 140719404451648] #quality_metric: host=algo-1, epoch=69, batch=15 train loss <loss>=8.37073659897\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:43 INFO 140719404451648] Epoch[69] Batch [15]#011Speed: 1627.03 samples/sec#011loss=8.370737\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:43 INFO 140719404451648] Epoch[69] Batch[20] avg_epoch_loss=8.226505\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:43 INFO 140719404451648] #quality_metric: host=algo-1, epoch=69, batch=20 train loss <loss>=8.30080337524\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:43 INFO 140719404451648] Epoch[69] Batch [20]#011Speed: 730.78 samples/sec#011loss=8.300803\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:43 INFO 140719404451648] Epoch[69] Batch[25] avg_epoch_loss=8.168076\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:43 INFO 140719404451648] #quality_metric: host=algo-1, epoch=69, batch=25 train loss <loss>=7.92267208099\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:43 INFO 140719404451648] Epoch[69] Batch [25]#011Speed: 1324.21 samples/sec#011loss=7.922672\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:43 INFO 140719404451648] Epoch[69] Batch[30] avg_epoch_loss=8.142618\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:43 INFO 140719404451648] #quality_metric: host=algo-1, epoch=69, batch=30 train loss <loss>=8.01024122238\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:43 INFO 140719404451648] Epoch[69] Batch [30]#011Speed: 719.20 samples/sec#011loss=8.010241\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:43 INFO 140719404451648] Epoch[69] Batch[35] avg_epoch_loss=8.032626\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:43 INFO 140719404451648] #quality_metric: host=algo-1, epoch=69, batch=35 train loss <loss>=7.35067224503\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:43 INFO 140719404451648] Epoch[69] Batch [35]#011Speed: 1497.41 samples/sec#011loss=7.350672\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] Epoch[69] Batch[40] avg_epoch_loss=8.025368\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] #quality_metric: host=algo-1, epoch=69, batch=40 train loss <loss>=7.97310791016\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] Epoch[69] Batch [40]#011Speed: 722.16 samples/sec#011loss=7.973108\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] Epoch[69] Batch[45] avg_epoch_loss=8.026823\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] #quality_metric: host=algo-1, epoch=69, batch=45 train loss <loss>=8.03875608444\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] Epoch[69] Batch [45]#011Speed: 1380.75 samples/sec#011loss=8.038756\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] Epoch[69] Batch[50] avg_epoch_loss=7.987735\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] #quality_metric: host=algo-1, epoch=69, batch=50 train loss <loss>=7.62812404633\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] Epoch[69] Batch [50]#011Speed: 1342.30 samples/sec#011loss=7.628124\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] processed a total of 1664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1700.27494430542, \"sum\": 1700.27494430542, \"min\": 1700.27494430542}}, \"EndTime\": 1578472784.459352, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472782.758638}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=978.605967384 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] #quality_metric: host=algo-1, epoch=69, train loss <loss>=7.96552211505\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] Epoch[70] Batch[0] avg_epoch_loss=8.515164\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=8.51516437531\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] Epoch[70] Batch[5] avg_epoch_loss=8.094921\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=8.09492055575\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] Epoch[70] Batch [5]#011Speed: 1647.14 samples/sec#011loss=8.094921\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] Epoch[70] Batch[10] avg_epoch_loss=8.273977\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=8.48884410858\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] Epoch[70] Batch [10]#011Speed: 784.46 samples/sec#011loss=8.488844\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] Epoch[70] Batch[15] avg_epoch_loss=8.325592\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] #quality_metric: host=algo-1, epoch=70, batch=15 train loss <loss>=8.43914499283\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:44 INFO 140719404451648] Epoch[70] Batch [15]#011Speed: 1525.39 samples/sec#011loss=8.439145\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:45 INFO 140719404451648] Epoch[70] Batch[20] avg_epoch_loss=8.326474\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:45 INFO 140719404451648] #quality_metric: host=algo-1, epoch=70, batch=20 train loss <loss>=8.32929725647\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:45 INFO 140719404451648] Epoch[70] Batch [20]#011Speed: 777.90 samples/sec#011loss=8.329297\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:45 INFO 140719404451648] Epoch[70] Batch[25] avg_epoch_loss=8.256736\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:45 INFO 140719404451648] #quality_metric: host=algo-1, epoch=70, batch=25 train loss <loss>=7.96383619308\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:45 INFO 140719404451648] Epoch[70] Batch [25]#011Speed: 1560.40 samples/sec#011loss=7.963836\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:45 INFO 140719404451648] Epoch[70] Batch[30] avg_epoch_loss=8.166928\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:45 INFO 140719404451648] #quality_metric: host=algo-1, epoch=70, batch=30 train loss <loss>=7.69992427826\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:45 INFO 140719404451648] Epoch[70] Batch [30]#011Speed: 715.45 samples/sec#011loss=7.699924\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:45 INFO 140719404451648] Epoch[70] Batch[35] avg_epoch_loss=8.114971\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:45 INFO 140719404451648] #quality_metric: host=algo-1, epoch=70, batch=35 train loss <loss>=7.79283685684\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:45 INFO 140719404451648] Epoch[70] Batch [35]#011Speed: 1566.60 samples/sec#011loss=7.792837\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:45 INFO 140719404451648] Epoch[70] Batch[40] avg_epoch_loss=8.081826\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:45 INFO 140719404451648] #quality_metric: host=algo-1, epoch=70, batch=40 train loss <loss>=7.84318666458\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:45 INFO 140719404451648] Epoch[70] Batch [40]#011Speed: 776.50 samples/sec#011loss=7.843187\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:45 INFO 140719404451648] Epoch[70] Batch[45] avg_epoch_loss=8.062587\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:45 INFO 140719404451648] #quality_metric: host=algo-1, epoch=70, batch=45 train loss <loss>=7.90482635498\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:45 INFO 140719404451648] Epoch[70] Batch [45]#011Speed: 1264.35 samples/sec#011loss=7.904826\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:46 INFO 140719404451648] processed a total of 1593 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1617.2549724578857, \"sum\": 1617.2549724578857, \"min\": 1617.2549724578857}}, \"EndTime\": 1578472786.077142, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472784.459424}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:46 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=984.938348099 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:46 INFO 140719404451648] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:46 INFO 140719404451648] #quality_metric: host=algo-1, epoch=70, train loss <loss>=8.01032813072\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:46 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:46 INFO 140719404451648] Epoch[71] Batch[0] avg_epoch_loss=8.125782\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:46 INFO 140719404451648] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=8.12578201294\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:46 INFO 140719404451648] Epoch[71] Batch[5] avg_epoch_loss=8.074159\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:46 INFO 140719404451648] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=8.07415898641\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:46 INFO 140719404451648] Epoch[71] Batch [5]#011Speed: 1497.82 samples/sec#011loss=8.074159\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:39:46 INFO 140719404451648] Epoch[71] Batch[10] avg_epoch_loss=8.214693\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:46 INFO 140719404451648] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=8.38333358765\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:46 INFO 140719404451648] Epoch[71] Batch [10]#011Speed: 732.11 samples/sec#011loss=8.383334\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:46 INFO 140719404451648] Epoch[71] Batch[15] avg_epoch_loss=8.311353\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:46 INFO 140719404451648] #quality_metric: host=algo-1, epoch=71, batch=15 train loss <loss>=8.52400665283\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:46 INFO 140719404451648] Epoch[71] Batch [15]#011Speed: 1352.60 samples/sec#011loss=8.524007\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:46 INFO 140719404451648] Epoch[71] Batch[20] avg_epoch_loss=8.208146\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:46 INFO 140719404451648] #quality_metric: host=algo-1, epoch=71, batch=20 train loss <loss>=7.87788162231\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:46 INFO 140719404451648] Epoch[71] Batch [20]#011Speed: 781.00 samples/sec#011loss=7.877882\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:46 INFO 140719404451648] Epoch[71] Batch[25] avg_epoch_loss=8.127091\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:46 INFO 140719404451648] #quality_metric: host=algo-1, epoch=71, batch=25 train loss <loss>=7.78665943146\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:46 INFO 140719404451648] Epoch[71] Batch [25]#011Speed: 1723.53 samples/sec#011loss=7.786659\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:47 INFO 140719404451648] Epoch[71] Batch[30] avg_epoch_loss=8.103570\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:47 INFO 140719404451648] #quality_metric: host=algo-1, epoch=71, batch=30 train loss <loss>=7.98126001358\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:47 INFO 140719404451648] Epoch[71] Batch [30]#011Speed: 808.37 samples/sec#011loss=7.981260\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:47 INFO 140719404451648] Epoch[71] Batch[35] avg_epoch_loss=8.061324\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:47 INFO 140719404451648] #quality_metric: host=algo-1, epoch=71, batch=35 train loss <loss>=7.79939908981\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:47 INFO 140719404451648] Epoch[71] Batch [35]#011Speed: 820.40 samples/sec#011loss=7.799399\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:47 INFO 140719404451648] Epoch[71] Batch[40] avg_epoch_loss=8.042979\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:47 INFO 140719404451648] #quality_metric: host=algo-1, epoch=71, batch=40 train loss <loss>=7.91090021133\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:47 INFO 140719404451648] Epoch[71] Batch [40]#011Speed: 1586.75 samples/sec#011loss=7.910900\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:47 INFO 140719404451648] Epoch[71] Batch[45] avg_epoch_loss=8.025608\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:47 INFO 140719404451648] #quality_metric: host=algo-1, epoch=71, batch=45 train loss <loss>=7.88316268921\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:47 INFO 140719404451648] Epoch[71] Batch [45]#011Speed: 1122.41 samples/sec#011loss=7.883163\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:47 INFO 140719404451648] processed a total of 1536 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1546.2830066680908, \"sum\": 1546.2830066680908, \"min\": 1546.2830066680908}}, \"EndTime\": 1578472787.623986, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472786.077209}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:47 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=993.27909852 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:47 INFO 140719404451648] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:47 INFO 140719404451648] #quality_metric: host=algo-1, epoch=71, train loss <loss>=8.01976308227\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:47 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:47 INFO 140719404451648] Epoch[72] Batch[0] avg_epoch_loss=8.404764\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:47 INFO 140719404451648] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=8.40476417542\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:47 INFO 140719404451648] Epoch[72] Batch[5] avg_epoch_loss=8.234185\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:47 INFO 140719404451648] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=8.23418537776\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:47 INFO 140719404451648] Epoch[72] Batch [5]#011Speed: 1546.43 samples/sec#011loss=8.234185\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:48 INFO 140719404451648] Epoch[72] Batch[10] avg_epoch_loss=8.156461\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:48 INFO 140719404451648] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=8.06319065094\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:48 INFO 140719404451648] Epoch[72] Batch [10]#011Speed: 785.43 samples/sec#011loss=8.063191\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:48 INFO 140719404451648] Epoch[72] Batch[15] avg_epoch_loss=8.279720\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:48 INFO 140719404451648] #quality_metric: host=algo-1, epoch=72, batch=15 train loss <loss>=8.55089130402\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:48 INFO 140719404451648] Epoch[72] Batch [15]#011Speed: 1640.27 samples/sec#011loss=8.550891\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:48 INFO 140719404451648] Epoch[72] Batch[20] avg_epoch_loss=8.244304\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:48 INFO 140719404451648] #quality_metric: host=algo-1, epoch=72, batch=20 train loss <loss>=8.13097190857\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:48 INFO 140719404451648] Epoch[72] Batch [20]#011Speed: 764.23 samples/sec#011loss=8.130972\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:48 INFO 140719404451648] Epoch[72] Batch[25] avg_epoch_loss=8.175245\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:48 INFO 140719404451648] #quality_metric: host=algo-1, epoch=72, batch=25 train loss <loss>=7.88519935608\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:48 INFO 140719404451648] Epoch[72] Batch [25]#011Speed: 1313.64 samples/sec#011loss=7.885199\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:48 INFO 140719404451648] Epoch[72] Batch[30] avg_epoch_loss=8.128829\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:48 INFO 140719404451648] #quality_metric: host=algo-1, epoch=72, batch=30 train loss <loss>=7.88746175766\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:48 INFO 140719404451648] Epoch[72] Batch [30]#011Speed: 713.66 samples/sec#011loss=7.887462\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:48 INFO 140719404451648] Epoch[72] Batch[35] avg_epoch_loss=8.094962\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:48 INFO 140719404451648] #quality_metric: host=algo-1, epoch=72, batch=35 train loss <loss>=7.88499164581\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:48 INFO 140719404451648] Epoch[72] Batch [35]#011Speed: 1641.04 samples/sec#011loss=7.884992\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] Epoch[72] Batch[40] avg_epoch_loss=8.088794\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] #quality_metric: host=algo-1, epoch=72, batch=40 train loss <loss>=8.04438171387\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] Epoch[72] Batch [40]#011Speed: 772.24 samples/sec#011loss=8.044382\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] Epoch[72] Batch[45] avg_epoch_loss=8.076031\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] #quality_metric: host=algo-1, epoch=72, batch=45 train loss <loss>=7.9713766098\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] Epoch[72] Batch [45]#011Speed: 1683.96 samples/sec#011loss=7.971377\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] processed a total of 1525 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1558.7749481201172, \"sum\": 1558.7749481201172, \"min\": 1558.7749481201172}}, \"EndTime\": 1578472789.183299, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472787.624061}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=978.265193835 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] #quality_metric: host=algo-1, epoch=72, train loss <loss>=8.01636259754\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] Epoch[73] Batch[0] avg_epoch_loss=8.193197\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=8.19319725037\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] Epoch[73] Batch[5] avg_epoch_loss=8.007924\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=8.00792368253\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] Epoch[73] Batch [5]#011Speed: 1541.93 samples/sec#011loss=8.007924\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] Epoch[73] Batch[10] avg_epoch_loss=8.054026\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=8.1093495369\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] Epoch[73] Batch [10]#011Speed: 770.45 samples/sec#011loss=8.109350\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] Epoch[73] Batch[15] avg_epoch_loss=8.205805\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] #quality_metric: host=algo-1, epoch=73, batch=15 train loss <loss>=8.53971710205\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] Epoch[73] Batch [15]#011Speed: 1724.40 samples/sec#011loss=8.539717\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] Epoch[73] Batch[20] avg_epoch_loss=8.223675\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] #quality_metric: host=algo-1, epoch=73, batch=20 train loss <loss>=8.28086023331\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:49 INFO 140719404451648] Epoch[73] Batch [20]#011Speed: 767.23 samples/sec#011loss=8.280860\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] Epoch[73] Batch[25] avg_epoch_loss=8.146603\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] #quality_metric: host=algo-1, epoch=73, batch=25 train loss <loss>=7.82290019989\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] Epoch[73] Batch [25]#011Speed: 1487.43 samples/sec#011loss=7.822900\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] Epoch[73] Batch[30] avg_epoch_loss=8.085832\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] #quality_metric: host=algo-1, epoch=73, batch=30 train loss <loss>=7.76982374191\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] Epoch[73] Batch [30]#011Speed: 748.37 samples/sec#011loss=7.769824\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] Epoch[73] Batch[35] avg_epoch_loss=8.036825\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] #quality_metric: host=algo-1, epoch=73, batch=35 train loss <loss>=7.73298015594\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] Epoch[73] Batch [35]#011Speed: 1637.88 samples/sec#011loss=7.732980\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] Epoch[73] Batch[40] avg_epoch_loss=8.011277\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] #quality_metric: host=algo-1, epoch=73, batch=40 train loss <loss>=7.82732896805\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] Epoch[73] Batch [40]#011Speed: 750.78 samples/sec#011loss=7.827329\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] Epoch[73] Batch[45] avg_epoch_loss=8.009850\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] #quality_metric: host=algo-1, epoch=73, batch=45 train loss <loss>=7.99815235138\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] Epoch[73] Batch [45]#011Speed: 1389.61 samples/sec#011loss=7.998152\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] Epoch[73] Batch[50] avg_epoch_loss=7.982445\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] #quality_metric: host=algo-1, epoch=73, batch=50 train loss <loss>=7.73031702042\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] Epoch[73] Batch [50]#011Speed: 1208.99 samples/sec#011loss=7.730317\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] processed a total of 1634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1647.8400230407715, \"sum\": 1647.8400230407715, \"min\": 1647.8400230407715}}, \"EndTime\": 1578472790.83163, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472789.183371}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=991.540428228 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] #quality_metric: host=algo-1, epoch=73, train loss <loss>=7.9585404121\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] Epoch[74] Batch[0] avg_epoch_loss=7.506382\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:50 INFO 140719404451648] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=7.50638151169\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:51 INFO 140719404451648] Epoch[74] Batch[5] avg_epoch_loss=7.842337\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:51 INFO 140719404451648] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=7.84233673414\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:51 INFO 140719404451648] Epoch[74] Batch [5]#011Speed: 1457.56 samples/sec#011loss=7.842337\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:51 INFO 140719404451648] Epoch[74] Batch[10] avg_epoch_loss=8.081712\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:51 INFO 140719404451648] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=8.36896190643\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:51 INFO 140719404451648] Epoch[74] Batch [10]#011Speed: 830.14 samples/sec#011loss=8.368962\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:51 INFO 140719404451648] Epoch[74] Batch[15] avg_epoch_loss=8.192807\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:51 INFO 140719404451648] #quality_metric: host=algo-1, epoch=74, batch=15 train loss <loss>=8.4372171402\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:51 INFO 140719404451648] Epoch[74] Batch [15]#011Speed: 1579.84 samples/sec#011loss=8.437217\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:51 INFO 140719404451648] Epoch[74] Batch[20] avg_epoch_loss=8.223375\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:51 INFO 140719404451648] #quality_metric: host=algo-1, epoch=74, batch=20 train loss <loss>=8.3211933136\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:51 INFO 140719404451648] Epoch[74] Batch [20]#011Speed: 762.83 samples/sec#011loss=8.321193\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:51 INFO 140719404451648] Epoch[74] Batch[25] avg_epoch_loss=8.136758\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:51 INFO 140719404451648] #quality_metric: host=algo-1, epoch=74, batch=25 train loss <loss>=7.77296524048\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:51 INFO 140719404451648] Epoch[74] Batch [25]#011Speed: 1669.21 samples/sec#011loss=7.772965\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:51 INFO 140719404451648] Epoch[74] Batch[30] avg_epoch_loss=8.088428\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:51 INFO 140719404451648] #quality_metric: host=algo-1, epoch=74, batch=30 train loss <loss>=7.83711223602\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:51 INFO 140719404451648] Epoch[74] Batch [30]#011Speed: 738.72 samples/sec#011loss=7.837112\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] Epoch[74] Batch[35] avg_epoch_loss=8.028056\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] #quality_metric: host=algo-1, epoch=74, batch=35 train loss <loss>=7.65374755859\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] Epoch[74] Batch [35]#011Speed: 1553.44 samples/sec#011loss=7.653748\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] Epoch[74] Batch[40] avg_epoch_loss=8.005894\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] #quality_metric: host=algo-1, epoch=74, batch=40 train loss <loss>=7.84632558823\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] Epoch[74] Batch [40]#011Speed: 731.22 samples/sec#011loss=7.846326\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] Epoch[74] Batch[45] avg_epoch_loss=7.967880\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] #quality_metric: host=algo-1, epoch=74, batch=45 train loss <loss>=7.65616645813\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] Epoch[74] Batch [45]#011Speed: 1718.25 samples/sec#011loss=7.656166\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] processed a total of 1588 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1606.978178024292, \"sum\": 1606.978178024292, \"min\": 1606.978178024292}}, \"EndTime\": 1578472792.439116, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472790.831696}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=988.123734832 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] #quality_metric: host=algo-1, epoch=74, train loss <loss>=7.93475832939\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] Epoch[75] Batch[0] avg_epoch_loss=8.450936\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=8.45093631744\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] Epoch[75] Batch[5] avg_epoch_loss=8.149124\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=8.14912366867\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] Epoch[75] Batch [5]#011Speed: 1527.72 samples/sec#011loss=8.149124\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] Epoch[75] Batch[10] avg_epoch_loss=8.221481\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=8.30830926895\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] Epoch[75] Batch [10]#011Speed: 728.65 samples/sec#011loss=8.308309\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] Epoch[75] Batch[15] avg_epoch_loss=8.253908\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] #quality_metric: host=algo-1, epoch=75, batch=15 train loss <loss>=8.32524929047\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:52 INFO 140719404451648] Epoch[75] Batch [15]#011Speed: 1519.24 samples/sec#011loss=8.325249\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:53 INFO 140719404451648] Epoch[75] Batch[20] avg_epoch_loss=8.258117\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:53 INFO 140719404451648] #quality_metric: host=algo-1, epoch=75, batch=20 train loss <loss>=8.2715839386\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:53 INFO 140719404451648] Epoch[75] Batch [20]#011Speed: 721.97 samples/sec#011loss=8.271584\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:53 INFO 140719404451648] Epoch[75] Batch[25] avg_epoch_loss=8.167702\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:53 INFO 140719404451648] #quality_metric: host=algo-1, epoch=75, batch=25 train loss <loss>=7.78795690536\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:53 INFO 140719404451648] Epoch[75] Batch [25]#011Speed: 1652.28 samples/sec#011loss=7.787957\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:53 INFO 140719404451648] Epoch[75] Batch[30] avg_epoch_loss=8.143324\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:53 INFO 140719404451648] #quality_metric: host=algo-1, epoch=75, batch=30 train loss <loss>=8.01655912399\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:53 INFO 140719404451648] Epoch[75] Batch [30]#011Speed: 709.37 samples/sec#011loss=8.016559\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:53 INFO 140719404451648] Epoch[75] Batch[35] avg_epoch_loss=8.106792\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:53 INFO 140719404451648] #quality_metric: host=algo-1, epoch=75, batch=35 train loss <loss>=7.88029222488\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:53 INFO 140719404451648] Epoch[75] Batch [35]#011Speed: 1459.76 samples/sec#011loss=7.880292\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:53 INFO 140719404451648] Epoch[75] Batch[40] avg_epoch_loss=8.074599\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:53 INFO 140719404451648] #quality_metric: host=algo-1, epoch=75, batch=40 train loss <loss>=7.84281568527\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:53 INFO 140719404451648] Epoch[75] Batch [40]#011Speed: 737.54 samples/sec#011loss=7.842816\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:53 INFO 140719404451648] Epoch[75] Batch[45] avg_epoch_loss=8.076949\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:53 INFO 140719404451648] #quality_metric: host=algo-1, epoch=75, batch=45 train loss <loss>=8.09621572495\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:53 INFO 140719404451648] Epoch[75] Batch [45]#011Speed: 1537.59 samples/sec#011loss=8.096216\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] Epoch[75] Batch[50] avg_epoch_loss=8.039944\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] #quality_metric: host=algo-1, epoch=75, batch=50 train loss <loss>=7.69950027466\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] Epoch[75] Batch [50]#011Speed: 1258.18 samples/sec#011loss=7.699500\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] processed a total of 1613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1662.8119945526123, \"sum\": 1662.8119945526123, \"min\": 1662.8119945526123}}, \"EndTime\": 1578472794.102431, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472792.43919}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=969.980517268 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] #quality_metric: host=algo-1, epoch=75, train loss <loss>=8.03994419995\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] Epoch[76] Batch[0] avg_epoch_loss=8.174165\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=8.17416477203\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] Epoch[76] Batch[5] avg_epoch_loss=8.324098\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=8.32409779231\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] Epoch[76] Batch [5]#011Speed: 1556.75 samples/sec#011loss=8.324098\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] Epoch[76] Batch[10] avg_epoch_loss=8.200622\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=8.0524515152\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] Epoch[76] Batch [10]#011Speed: 796.21 samples/sec#011loss=8.052452\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] Epoch[76] Batch[15] avg_epoch_loss=8.260654\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] #quality_metric: host=algo-1, epoch=76, batch=15 train loss <loss>=8.39272356033\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] Epoch[76] Batch [15]#011Speed: 1344.64 samples/sec#011loss=8.392724\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] Epoch[76] Batch[20] avg_epoch_loss=8.282674\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] #quality_metric: host=algo-1, epoch=76, batch=20 train loss <loss>=8.35313911438\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] Epoch[76] Batch [20]#011Speed: 766.26 samples/sec#011loss=8.353139\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] Epoch[76] Batch[25] avg_epoch_loss=8.218496\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] #quality_metric: host=algo-1, epoch=76, batch=25 train loss <loss>=7.94894552231\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:54 INFO 140719404451648] Epoch[76] Batch [25]#011Speed: 1723.13 samples/sec#011loss=7.948946\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] Epoch[76] Batch[30] avg_epoch_loss=8.144249\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] #quality_metric: host=algo-1, epoch=76, batch=30 train loss <loss>=7.75816965103\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] Epoch[76] Batch [30]#011Speed: 736.14 samples/sec#011loss=7.758170\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] Epoch[76] Batch[35] avg_epoch_loss=8.079389\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] #quality_metric: host=algo-1, epoch=76, batch=35 train loss <loss>=7.67725515366\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] Epoch[76] Batch [35]#011Speed: 1606.89 samples/sec#011loss=7.677255\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] Epoch[76] Batch[40] avg_epoch_loss=8.007947\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] #quality_metric: host=algo-1, epoch=76, batch=40 train loss <loss>=7.49356336594\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] Epoch[76] Batch [40]#011Speed: 774.83 samples/sec#011loss=7.493563\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] Epoch[76] Batch[45] avg_epoch_loss=8.008683\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] #quality_metric: host=algo-1, epoch=76, batch=45 train loss <loss>=8.01471834183\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] Epoch[76] Batch [45]#011Speed: 1680.71 samples/sec#011loss=8.014718\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] Epoch[76] Batch[50] avg_epoch_loss=7.989756\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] #quality_metric: host=algo-1, epoch=76, batch=50 train loss <loss>=7.81562986374\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] Epoch[76] Batch [50]#011Speed: 1119.74 samples/sec#011loss=7.815630\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] processed a total of 1640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1648.6618518829346, \"sum\": 1648.6618518829346, \"min\": 1648.6618518829346}}, \"EndTime\": 1578472795.751602, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472794.102506}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=994.674929477 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] #quality_metric: host=algo-1, epoch=76, train loss <loss>=7.99511930576\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] Epoch[77] Batch[0] avg_epoch_loss=8.565084\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=8.5650844574\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] Epoch[77] Batch[5] avg_epoch_loss=8.259108\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=8.25910751025\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:55 INFO 140719404451648] Epoch[77] Batch [5]#011Speed: 1417.99 samples/sec#011loss=8.259108\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:56 INFO 140719404451648] Epoch[77] Batch[10] avg_epoch_loss=8.305513\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:56 INFO 140719404451648] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=8.36119937897\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:56 INFO 140719404451648] Epoch[77] Batch [10]#011Speed: 835.30 samples/sec#011loss=8.361199\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:56 INFO 140719404451648] Epoch[77] Batch[15] avg_epoch_loss=8.373370\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:56 INFO 140719404451648] #quality_metric: host=algo-1, epoch=77, batch=15 train loss <loss>=8.52265510559\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:56 INFO 140719404451648] Epoch[77] Batch [15]#011Speed: 1554.95 samples/sec#011loss=8.522655\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:56 INFO 140719404451648] Epoch[77] Batch[20] avg_epoch_loss=8.312377\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:56 INFO 140719404451648] #quality_metric: host=algo-1, epoch=77, batch=20 train loss <loss>=8.11719970703\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:56 INFO 140719404451648] Epoch[77] Batch [20]#011Speed: 790.10 samples/sec#011loss=8.117200\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:56 INFO 140719404451648] Epoch[77] Batch[25] avg_epoch_loss=8.209380\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:56 INFO 140719404451648] #quality_metric: host=algo-1, epoch=77, batch=25 train loss <loss>=7.77679481506\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:56 INFO 140719404451648] Epoch[77] Batch [25]#011Speed: 1458.91 samples/sec#011loss=7.776795\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:56 INFO 140719404451648] Epoch[77] Batch[30] avg_epoch_loss=8.123692\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:56 INFO 140719404451648] #quality_metric: host=algo-1, epoch=77, batch=30 train loss <loss>=7.67811479568\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:56 INFO 140719404451648] Epoch[77] Batch [30]#011Speed: 744.87 samples/sec#011loss=7.678115\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:56 INFO 140719404451648] Epoch[77] Batch[35] avg_epoch_loss=8.087613\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:56 INFO 140719404451648] #quality_metric: host=algo-1, epoch=77, batch=35 train loss <loss>=7.86392402649\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:56 INFO 140719404451648] Epoch[77] Batch [35]#011Speed: 1552.63 samples/sec#011loss=7.863924\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:57 INFO 140719404451648] Epoch[77] Batch[40] avg_epoch_loss=8.040471\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:57 INFO 140719404451648] #quality_metric: host=algo-1, epoch=77, batch=40 train loss <loss>=7.70104427338\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:57 INFO 140719404451648] Epoch[77] Batch [40]#011Speed: 775.10 samples/sec#011loss=7.701044\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:57 INFO 140719404451648] Epoch[77] Batch[45] avg_epoch_loss=7.985879\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:57 INFO 140719404451648] #quality_metric: host=algo-1, epoch=77, batch=45 train loss <loss>=7.53822755814\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:57 INFO 140719404451648] Epoch[77] Batch [45]#011Speed: 1516.21 samples/sec#011loss=7.538228\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:57 INFO 140719404451648] processed a total of 1578 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1587.8169536590576, \"sum\": 1587.8169536590576, \"min\": 1587.8169536590576}}, \"EndTime\": 1578472797.339942, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472795.751683}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:57 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=993.741525263 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:57 INFO 140719404451648] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:57 INFO 140719404451648] #quality_metric: host=algo-1, epoch=77, train loss <loss>=7.95823691368\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:57 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:57 INFO 140719404451648] Epoch[78] Batch[0] avg_epoch_loss=8.706795\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:57 INFO 140719404451648] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=8.70679473877\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:57 INFO 140719404451648] Epoch[78] Batch[5] avg_epoch_loss=8.152445\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:57 INFO 140719404451648] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=8.15244483948\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:57 INFO 140719404451648] Epoch[78] Batch [5]#011Speed: 1568.61 samples/sec#011loss=8.152445\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:57 INFO 140719404451648] Epoch[78] Batch[10] avg_epoch_loss=8.084587\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:57 INFO 140719404451648] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=8.00315742493\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:57 INFO 140719404451648] Epoch[78] Batch [10]#011Speed: 791.14 samples/sec#011loss=8.003157\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:57 INFO 140719404451648] Epoch[78] Batch[15] avg_epoch_loss=8.132096\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:57 INFO 140719404451648] #quality_metric: host=algo-1, epoch=78, batch=15 train loss <loss>=8.23661470413\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:57 INFO 140719404451648] Epoch[78] Batch [15]#011Speed: 1567.11 samples/sec#011loss=8.236615\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:58 INFO 140719404451648] Epoch[78] Batch[20] avg_epoch_loss=8.083560\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:58 INFO 140719404451648] #quality_metric: host=algo-1, epoch=78, batch=20 train loss <loss>=7.92824745178\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:58 INFO 140719404451648] Epoch[78] Batch [20]#011Speed: 797.09 samples/sec#011loss=7.928247\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:58 INFO 140719404451648] Epoch[78] Batch[25] avg_epoch_loss=8.036553\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:58 INFO 140719404451648] #quality_metric: host=algo-1, epoch=78, batch=25 train loss <loss>=7.83912296295\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:58 INFO 140719404451648] Epoch[78] Batch [25]#011Speed: 1558.42 samples/sec#011loss=7.839123\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:58 INFO 140719404451648] Epoch[78] Batch[30] avg_epoch_loss=7.976835\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:58 INFO 140719404451648] #quality_metric: host=algo-1, epoch=78, batch=30 train loss <loss>=7.66630039215\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:58 INFO 140719404451648] Epoch[78] Batch [30]#011Speed: 780.58 samples/sec#011loss=7.666300\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:58 INFO 140719404451648] Epoch[78] Batch[35] avg_epoch_loss=7.932276\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:58 INFO 140719404451648] #quality_metric: host=algo-1, epoch=78, batch=35 train loss <loss>=7.6560131073\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:58 INFO 140719404451648] Epoch[78] Batch [35]#011Speed: 1345.91 samples/sec#011loss=7.656013\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:58 INFO 140719404451648] Epoch[78] Batch[40] avg_epoch_loss=7.950676\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:58 INFO 140719404451648] #quality_metric: host=algo-1, epoch=78, batch=40 train loss <loss>=8.08315286636\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:58 INFO 140719404451648] Epoch[78] Batch [40]#011Speed: 653.66 samples/sec#011loss=8.083153\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:58 INFO 140719404451648] Epoch[78] Batch[45] avg_epoch_loss=7.951290\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:58 INFO 140719404451648] #quality_metric: host=algo-1, epoch=78, batch=45 train loss <loss>=7.95632410049\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:58 INFO 140719404451648] Epoch[78] Batch [45]#011Speed: 1394.46 samples/sec#011loss=7.956324\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:58 INFO 140719404451648] processed a total of 1584 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1625.377893447876, \"sum\": 1625.377893447876, \"min\": 1625.377893447876}}, \"EndTime\": 1578472798.96594, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472797.340029}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:58 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=974.477705729 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:58 INFO 140719404451648] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:58 INFO 140719404451648] #quality_metric: host=algo-1, epoch=78, train loss <loss>=7.90015192032\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:58 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:59 INFO 140719404451648] Epoch[79] Batch[0] avg_epoch_loss=7.718473\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:59 INFO 140719404451648] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=7.71847343445\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:59 INFO 140719404451648] Epoch[79] Batch[5] avg_epoch_loss=8.218770\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:59 INFO 140719404451648] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=8.2187696298\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:59 INFO 140719404451648] Epoch[79] Batch [5]#011Speed: 1343.88 samples/sec#011loss=8.218770\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:59 INFO 140719404451648] Epoch[79] Batch[10] avg_epoch_loss=8.326764\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:59 INFO 140719404451648] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=8.45635719299\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:59 INFO 140719404451648] Epoch[79] Batch [10]#011Speed: 719.37 samples/sec#011loss=8.456357\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:59 INFO 140719404451648] Epoch[79] Batch[15] avg_epoch_loss=8.338084\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:59 INFO 140719404451648] #quality_metric: host=algo-1, epoch=79, batch=15 train loss <loss>=8.36298770905\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:59 INFO 140719404451648] Epoch[79] Batch [15]#011Speed: 1304.68 samples/sec#011loss=8.362988\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:59 INFO 140719404451648] Epoch[79] Batch[20] avg_epoch_loss=8.272980\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:59 INFO 140719404451648] #quality_metric: host=algo-1, epoch=79, batch=20 train loss <loss>=8.0646490097\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:59 INFO 140719404451648] Epoch[79] Batch [20]#011Speed: 754.63 samples/sec#011loss=8.064649\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:59 INFO 140719404451648] Epoch[79] Batch[25] avg_epoch_loss=8.204198\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:59 INFO 140719404451648] #quality_metric: host=algo-1, epoch=79, batch=25 train loss <loss>=7.9153131485\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:39:59 INFO 140719404451648] Epoch[79] Batch [25]#011Speed: 1337.08 samples/sec#011loss=7.915313\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] Epoch[79] Batch[30] avg_epoch_loss=8.126508\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] #quality_metric: host=algo-1, epoch=79, batch=30 train loss <loss>=7.72252159119\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] Epoch[79] Batch [30]#011Speed: 753.93 samples/sec#011loss=7.722522\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] Epoch[79] Batch[35] avg_epoch_loss=8.068052\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] #quality_metric: host=algo-1, epoch=79, batch=35 train loss <loss>=7.70561971664\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] Epoch[79] Batch [35]#011Speed: 1289.29 samples/sec#011loss=7.705620\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] Epoch[79] Batch[40] avg_epoch_loss=8.010363\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] #quality_metric: host=algo-1, epoch=79, batch=40 train loss <loss>=7.59500799179\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] Epoch[79] Batch [40]#011Speed: 786.12 samples/sec#011loss=7.595008\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] Epoch[79] Batch[45] avg_epoch_loss=8.007623\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] #quality_metric: host=algo-1, epoch=79, batch=45 train loss <loss>=7.98514719009\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] Epoch[79] Batch [45]#011Speed: 1579.56 samples/sec#011loss=7.985147\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] Epoch[79] Batch[50] avg_epoch_loss=7.996974\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] #quality_metric: host=algo-1, epoch=79, batch=50 train loss <loss>=7.89900379181\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] Epoch[79] Batch [50]#011Speed: 1022.16 samples/sec#011loss=7.899004\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] processed a total of 1643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1747.0431327819824, \"sum\": 1747.0431327819824, \"min\": 1747.0431327819824}}, \"EndTime\": 1578472800.713576, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472798.96601}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] #throughput_metric: host=algo-1, train throughput=940.391357764 records/second\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] #quality_metric: host=algo-1, epoch=79, train loss <loss>=7.9747598538\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] loss did not improve\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] Loading parameters from best epoch (39)\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.deserialize.time\": {\"count\": 1, \"max\": 10.775089263916016, \"sum\": 10.775089263916016, \"min\": 10.775089263916016}}, \"EndTime\": 1578472800.724967, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472800.713641}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] stopping training now\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] Final loss: 7.85315762314 (occurred at epoch 39)\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] #quality_metric: host=algo-1, train final_loss <loss>=7.85315762314\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 WARNING 140719404451648] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 61.05494499206543, \"sum\": 61.05494499206543, \"min\": 61.05494499206543}}, \"EndTime\": 1578472800.786777, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472800.725022}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 94.34795379638672, \"sum\": 94.34795379638672, \"min\": 94.34795379638672}}, \"EndTime\": 1578472800.820035, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472800.786826}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 4.988908767700195, \"sum\": 4.988908767700195, \"min\": 4.988908767700195}}, \"EndTime\": 1578472800.82513, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472800.820101}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:00 INFO 140719404451648] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 0.03814697265625, \"sum\": 0.03814697265625, \"min\": 0.03814697265625}}, \"EndTime\": 1578472800.825805, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472800.825173}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/08/2020 08:40:04 INFO 140719404451648] Number of test batches scored: 10\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:07 INFO 140719404451648] Number of test batches scored: 20\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:11 INFO 140719404451648] Number of test batches scored: 30\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:14 INFO 140719404451648] Number of test batches scored: 40\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:18 INFO 140719404451648] Number of test batches scored: 50\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.score.time\": {\"count\": 1, \"max\": 17684.168100357056, \"sum\": 17684.168100357056, \"min\": 17684.168100357056}}, \"EndTime\": 1578472818.509934, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472800.825862}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:18 INFO 140719404451648] #test_score (algo-1, RMSE): 27316.6311246\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:18 INFO 140719404451648] #test_score (algo-1, mean_wQuantileLoss): 0.30615774\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:18 INFO 140719404451648] #test_score (algo-1, wQuantileLoss[0.1]): 0.22424385\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:18 INFO 140719404451648] #test_score (algo-1, wQuantileLoss[0.2]): 0.32853135\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:18 INFO 140719404451648] #test_score (algo-1, wQuantileLoss[0.3]): 0.3737993\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:18 INFO 140719404451648] #test_score (algo-1, wQuantileLoss[0.4]): 0.38582057\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:18 INFO 140719404451648] #test_score (algo-1, wQuantileLoss[0.5]): 0.37591258\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:18 INFO 140719404451648] #test_score (algo-1, wQuantileLoss[0.6]): 0.35001475\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:18 INFO 140719404451648] #test_score (algo-1, wQuantileLoss[0.7]): 0.30638695\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:18 INFO 140719404451648] #test_score (algo-1, wQuantileLoss[0.8]): 0.24737252\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:18 INFO 140719404451648] #test_score (algo-1, wQuantileLoss[0.9]): 0.16333759\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:18 INFO 140719404451648] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.30615773797\u001b[0m\n",
      "\u001b[34m[01/08/2020 08:40:18 INFO 140719404451648] #quality_metric: host=algo-1, test RMSE <loss>=27316.6311246\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 151578.42421531677, \"sum\": 151578.42421531677, \"min\": 151578.42421531677}, \"setuptime\": {\"count\": 1, \"max\": 8.350133895874023, \"sum\": 8.350133895874023, \"min\": 8.350133895874023}}, \"EndTime\": 1578472818.519013, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1578472818.509997}\n",
      "\u001b[0m\n",
      "\n",
      "2020-01-08 08:40:27 Uploading - Uploading generated training model\n",
      "2020-01-08 08:40:27 Completed - Training job completed\n",
      "Training seconds: 196\n",
      "Billable seconds: 196\n",
      "CPU times: user 842 ms, sys: 64.8 ms, total: 906 ms\n",
      "Wall time: 5min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator_new_features = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.2xlarge',\n",
    "    base_job_name='deepar-stores-sales-demo',\n",
    "    output_path=s3_output_path_new_features\n",
    ")\n",
    "\n",
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \"epochs\": \"400\",\n",
    "    \"learning_rate\": \"5E-4\",\n",
    "    \"mini_batch_size\": \"32\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"num_dynamic_feat\": \"auto\",  # this will use the `dynamic_feat` field if it's present in the data\n",
    "}\n",
    "estimator_new_features.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "estimator_new_features.fit(\n",
    "    inputs={\n",
    "        \"train\": \"{}/train/\".format(s3_data_path_new_features),\n",
    "        \"test\": \"{}/test/\".format(s3_data_path_new_features)\n",
    "    }, \n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we spawn an endpoint to visualize our forecasts on examples we send on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------!CPU times: user 411 ms, sys: 48.6 ms, total: 460 ms\n",
      "Wall time: 9min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictor_new_features = estimator_new_features.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    predictor_cls=DeepARPredictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the new predictor to predict the same time series. You can see this time we need pass **cat**, **dynamic_feat** to the predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  app.launch_new_instance()\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:19: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:46: FutureWarning: Creating a DatetimeIndex by passing range endpoints is deprecated.  Use `pandas.date_range` instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.9</th>\n",
       "      <th>0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-09-24</th>\n",
       "      <td>4257.673828</td>\n",
       "      <td>9508.309570</td>\n",
       "      <td>6869.964844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-25</th>\n",
       "      <td>5208.489258</td>\n",
       "      <td>10759.224609</td>\n",
       "      <td>8243.987305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-26</th>\n",
       "      <td>5824.386719</td>\n",
       "      <td>12997.717773</td>\n",
       "      <td>9094.528320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-27</th>\n",
       "      <td>5073.639648</td>\n",
       "      <td>11853.121094</td>\n",
       "      <td>8779.248047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-28</th>\n",
       "      <td>4850.179199</td>\n",
       "      <td>13309.260742</td>\n",
       "      <td>9518.050781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-29</th>\n",
       "      <td>4668.913086</td>\n",
       "      <td>12292.461914</td>\n",
       "      <td>8552.868164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-30</th>\n",
       "      <td>4652.054199</td>\n",
       "      <td>9129.027344</td>\n",
       "      <td>7303.651855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0.1           0.9          0.5\n",
       "2019-09-24  4257.673828   9508.309570  6869.964844\n",
       "2019-09-25  5208.489258  10759.224609  8243.987305\n",
       "2019-09-26  5824.386719  12997.717773  9094.528320\n",
       "2019-09-27  5073.639648  11853.121094  8779.248047\n",
       "2019-09-28  4850.179199  13309.260742  9518.050781\n",
       "2019-09-29  4668.913086  12292.461914  8552.868164\n",
       "2019-09-30  4652.054199   9129.027344  7303.651855"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_id = 120\n",
    "predictor_new_features.predict(\n",
    "    ts=timeseries[store_id][start_dataset:end_test-1], \n",
    "    cat=cat_timeseries[store_id].tolist(),\n",
    "    dynamic_feat=predict_dynamic_feat, \n",
    "    quantiles=[0.1, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can query the endpoint to see predictions for arbitrary time series and time points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72bb9ffa89684a098083a1be10c1b53e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=120, description='customer_id', max=1603, style=SliderStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "@interact_manual(\n",
    "    customer_id=IntSlider(min=0, max=1603, value=120, style=style), \n",
    "#     forecast_day=IntSlider(min=0, max=7, value=0,step=1, style=style),\n",
    "    confidence=IntSlider(min=60, max=95, value=80, step=5, style=style),\n",
    "    history_days_plot=IntSlider(min=1, max=50, value=7, style=style),\n",
    "    show_samples=Checkbox(value=False),\n",
    "    continuous_update=False\n",
    ")\n",
    "def plot_interact(customer_id, confidence, history_days_plot, show_samples):\n",
    "    target = timeseries[customer_id]\n",
    "    dynamic_feat = predict_dynamic_feat\n",
    "    cat=cat_timeseries[store_id].tolist()\n",
    "    plot(\n",
    "        predictor_new_features,\n",
    "        target_ts=target,\n",
    "        forecast_date= start_predict -1,\n",
    "        cat=cat,\n",
    "        dynamic_feat=dynamic_feat,\n",
    "        show_samples=show_samples,\n",
    "        plot_history=history_days_plot,\n",
    "        confidence=confidence\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:6: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:19: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:46: FutureWarning: Creating a DatetimeIndex by passing range endpoints is deprecated.  Use `pandas.date_range` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.3 s, sys: 132 ms, total: 5.43 s\n",
      "Wall time: 58.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "preds_new = []\n",
    "quantiles=[0.10, 0.5, 0.90]\n",
    "\n",
    "for i, ts_dict in enumerate(timeseries):\n",
    "    ts = ts_dict[start_dataset:end_test-1]\n",
    "    if ts.shape[0] == 0:\n",
    "        preds_new.append(None)\n",
    "        continue\n",
    "    cat = cat_timeseries[i].tolist()\n",
    "    dynamic_feat = predict_dynamic_feat   \n",
    "    pred = predictor_new_features.predict(ts, cat=cat, dynamic_feat=dynamic_feat, quantiles=quantiles)\n",
    "    preds_new.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predict result and label data into a csv for later use\n",
    "df_new = pd.DataFrame()\n",
    "for i in range(len(timeseries)):\n",
    "    y =  timeseries[i][start_predict:end_predict].fillna(0)\n",
    "    y_hat = preds_new[i]['0.5']\n",
    "    dd = pd.DataFrame({'store_id':i,'y_label': y, 'y_pred': y_hat})\n",
    "    df_new = pd.concat([df_new, dd])\n",
    "df_new.index.name='date'\n",
    "df_new.to_csv(\"data/deepar-new-features-predict-result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 24\n",
      "RMSE: 1747.5466138892214\n",
      "MAE: 1580.5113281249999\n",
      "Target Mean: 5569.585714285714\n",
      "                 y_pred  y_label\n",
      "2019-09-24  4128.005371   7026.0\n",
      "2019-09-25  4450.132812   4043.6\n",
      "2019-09-26  4376.869141   6221.2\n",
      "2019-09-27  4871.150391   5847.8\n",
      "2019-09-28  6839.270508   5126.7\n",
      "2019-09-29  6986.127930   5775.6\n",
      "2019-09-30  2931.227051   4946.2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 31\n",
      "RMSE: 2083.425849160119\n",
      "MAE: 1708.9270089285567\n",
      "Target Mean: 9007.67142857143\n",
      "                 y_pred  y_label\n",
      "2019-09-24  7375.972168   7383.9\n",
      "2019-09-25  6947.657227   8558.8\n",
      "2019-09-26  6410.788574   9763.9\n",
      "2019-09-27  6179.758789   8243.4\n",
      "2019-09-28  7992.852539   9221.3\n",
      "2019-09-29  9907.239258  10352.9\n",
      "2019-09-30  6276.942383   9529.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 36\n",
      "RMSE: 5180.198995418675\n",
      "MAE: 3824.5450613839284\n",
      "Target Mean: 18153.442857142858\n",
      "                  y_pred  y_label\n",
      "2019-09-24  13529.896484  13646.5\n",
      "2019-09-25  12956.284180  16744.0\n",
      "2019-09-26  12954.523438  15419.9\n",
      "2019-09-27  15751.960938  18162.3\n",
      "2019-09-28  25792.523438  26111.2\n",
      "2019-09-29  22394.568359  15189.3\n",
      "2019-09-30  11333.064453  21800.9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtgAAAGLCAYAAAD9IeXBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xl8XHW9+P/XmS2TZCZJkzZd0iWllG50bymyiMBlEZHtB7aKu8BlUVx+Iuj3ekWt96tXf4Jw9SpeZBEUVC6CioqVIrJ0b+m+L2mSZp8kM5PMej6/P86cSdJmmS3NnPT9fDx4kMycmXOmSWbe533en/dbU0ohhBBCCCGEyA3bSB+AEEIIIYQQo4kE2EIIIYQQQuSQBNhCCCGEEELkkATYQgghhBBC5JAE2EIIIYQQQuSQBNhCCCGEEELkkATYQgghhBBC5JAE2EIIIYQQQuSQBNhCCCGEEELkkGOkDyBTY8eOVdXV1SN9GEIIIYQQYhTbvHlzi1JqXDqPsWyAXV1dzaZNm0b6MIQQQgghxCimadqxdB8jJSJCCCGEEELkkATYQgghhBBC5JAE2EIIIYQQQuSQZWuwhRBCCDG6RaNRamtrCYVCI30o4gzgdruZPHkyTqcz6+eSAFsIIYQQeam2thav10t1dTWapo304YhRTClFa2srtbW1TJ8+PevnkxIRIYQQQuSlUChERUWFBNdi2GmaRkVFRc6ulkiALYQQQoi8JcG1OF1y+bsmAbYQQgghhBA5JAG2EEIIIUQ/2tvb+clPfnJa9vX666/z9ttv93vfSy+9xIIFC1i0aBHLli3jzTffTN5XU1PDlVdeyZw5c5g7dy5Hjx49LccrBicBthBCCCFEPzIJsJVS6Lqe9r4GC7Avv/xy3n33XbZt28YvfvELbrvttuR9H//4x7nvvvvYs2cPGzZsoLKyMu19i9yTLiJCCCGEyHvf/MMudtd35vQ5504q4RsfnDfg/Q888ACHDh1i0aJFXHHFFXzjG9/g+uuvx+fzEY1GWb16Nddffz1Hjx7lqquuYsWKFWzevJlXXnmFNWvW8L3vfY+ysjIWLlxIQUEB//Vf/0VzczN33nknNTU1ADz88MNUVVXx05/+FLvdzjPPPMOjjz7KxRdfnDwOj8eT/DoYDCZrhXfv3k0sFuOKK644ZTsxsiTAFkIIIYTox3e/+1127tzJtm3bAIjFYrz44ouUlJTQ0tLC+eefz3XXXQfAgQMHeOqppzj//POpr6/n29/+Nlu2bMHr9XLZZZexcOFCAD7/+c/zxS9+kYsuuoiamhquuuoq9uzZw5133onH4+HLX/5yv8fy4osv8tWvfpWmpib+9Kc/AbB//37Kysq46aabOHLkCP/yL//Cd7/7Xex2+2n41xGDkQBbCCGEEHlvsEzz6aKU4mtf+xpvvPEGNpuNuro6GhsbAZg2bRrnn38+ABs2bOCSSy6hvLwcgFtuuYX9+/cDsGbNGnbv3p18zs7OTgKBwJD7vvHGG7nxxht54403+PrXv86aNWuIxWL885//ZOvWrUydOpWVK1fy5JNP8pnPfCbXL31U0/UoNlv2w2V6kwBbCCGEECIFzz77LM3NzWzevBmn00l1dXWyb3JxcXFKz6HrOuvWrcPtdmd0DO9973s5fPgwLS0tTJ48mUWLFnHWWWcBcMMNN7Bu3ToJsNOgVJxIpJGCgipp0yeEEEIIMdy8Xi9+vz/5fUdHB5WVlTidTtauXcuxY8f6fdzy5cv5xz/+gc/nIxaL8cILLyTvu/LKK3n00UeT35vlJyfvq7eDBw+ilAJgy5YthMNhKioqWL58Oe3t7TQ3NwPw2muvMXfu3Oxe9BlG1yNAHEh/YepgJMAWQgghhOhHRUUFF154Ieeeey733Xcft956K5s2bWL+/Pk8/fTTzJ49u9/HVVVV8bWvfY3zzjuPCy+8kOrqakpLSwF45JFH2LRpEwsWLGDu3Ln89Kc/BeCDH/wgL774IosWLeKf//xnn+d74YUXOPfcc1m0aBH33HMPzz//PJqmYbfb+cEPfsDll1/O/PnzUUpx++23D+8/yiijVASl4skTmFzRcv2Ep8uyZcvUpk2bRvowhBBCCDFM9uzZw5w5c0b6MDISCATweDzEYjFuvPFGPv3pT3PjjTeO9GGJk4TDDeh6kIKCqdhszn5/5zRN26yUWpbO80oGWwghhBAixx588EEWLVrEueeey/Tp07nhhhtG+pDESZRSKBXCCIdzWyIiixyFEEIIIXLsBz/4wUgfghiCUlGMQg4t5yUiksEWQgghhBBnHGOBoxlYS4AthBBCCCFEVnQ9hKaZobAE2EIIIYQQQmRF17sBY+qlUtKmTwghhBBCiIwpFUOpWGK4jEIy2EIIIYQQFuXxeACor6/n5ptvHnTbhx9+mK6uruT311xzDe3t7cN6fOl6/fXXufbaawF4+eWX+e53vzvCR5QaXY8CWq//JIMthBBCCJE34vF42o+ZNGkSv/vd7wbd5uQA+5VXXqGsrCztfZ0u1113HQ888MBIH0ZKdD3c5/tcl4hImz4hhBBC5L8/PwANO3L7nBPmw/sHzrgePXqUq6++mqVLl7JlyxbmzZvH008/TVFREdXV1axcuZK//e1vfOUrX2H58uXcc889NDc3U1RUxM9//nNmz57NkSNH+MhHPkIgEOD666/v89zXXnstO3fuJB6Pc//99/OXv/wFm83G7bffjlKK+vp6Lr30UsaOHcvatWuprq5m06ZNjB07lh/+8If84he/AOC2227jC1/4AkePHuX9738/F110EW+//TZVVVW89NJLFBYW9nldn/zkJyksLGTr1q00NTXxi1/8gqeffpp33nmHFStW8OSTTwLw6quv8o1vfINwOMyMGTN44okn8Hg8/OUvf+ELX/gCRUVFXHTRRcnnffLJJ9m0aRP/9V//xR/+8AdWr15NJBKhoqKCZ599lvHjx/Pggw9SU1PD4cOHqamp4Qtf+AL33ntvDn+oqdH1LjTNqL82ykTSP0kajGSwhRBCCCEGsG/fPu6++2727NlDSUkJP/nJT5L3VVRUsGXLFlatWsUdd9zBo48+yubNm/nBD37A3XffDcDnP/957rrrLnbs2MHEiRP73cdjjz3G0aNH2bZtG9u3b+fWW2/l3nvvZdKkSaxdu5a1a9f22X7z5s088cQTrF+/nnXr1vHzn/+crVu3AnDgwAHuuecedu3aRVlZGS+88EK/+/T5fLzzzjs89NBDXHfddXzxi19k165d7Nixg23bttHS0sLq1atZs2YNW7ZsYdmyZfzwhz8kFApx++2384c//IHNmzfT0NDQ7/NfdNFFrFu3jq1bt7Jq1Sr+8z//M3nf3r17+etf/8qGDRv45je/STQaTf0HkgNK6eh6pFcHEclgCyGEEOJMNEimeThNmTKFCy+8EICPfvSjPPLII3z5y18GYOXKlYAxFv3tt9/mlltuST4uHDZKEN56661kkPuxj32M+++//5R9rFmzhjvvvBOHwwjLysvLBz2mN998kxtvvJHi4mIAbrrpJv75z39y3XXXMX36dBYtWgTA0qVLOXr0aL/P8cEPfhBN05g/fz7jx49n/vz5AMybN4+jR49SW1vL7t27k689Eonwnve8h7179zJ9+nRmzpyZ/Dd57LHHTnn+2tpaVq5cyYkTJ4hEIkyfPj153wc+8AEKCgooKCigsrKSxsZGJk+ePOhrziWlzIBe6/V/CbCFEEIIIU4Lo3yg/+/NAFfXdcrKyti2bVtKzzGcCgoKkl/b7Xa6u7sH3c5ms/V5jM1mIxaLYbfbueKKK/j1r3/d53EDvcaTfe5zn+NLX/oS1113Ha+//joPPvjggMcYi8VSes5c6TtgBoxJjrLIUQghhBDitKipqeGdd94B4Fe/+lWfmmNTSUkJ06dP57e//S0ASineffddAC688EKee+45AJ599tl+93HFFVfws5/9LBlotrW1AeD1evH7/adsf/HFF/P73/+erq4ugsEgL774IhdffHGWr7Sv888/n7feeouDBw8CEAwG2b9/P7Nnz+bo0aMcOnQI4JQA3NTR0UFVVRUATz31VE6PLVu63t2nPMQgbfqEEEIIIU6LWbNm8eMf/5g5c+bg8/m46667+t3u2Wef5fHHH2fhwoXMmzePl156CYAf/ehH/PjHP2b+/PnU1dX1+9jbbruNqVOnsmDBAhYuXMivfvUrAO644w6uvvpqLr300j7bL1myhE9+8pOcd955rFixgttuu43Fixfn8FXDuHHjePLJJ/nwhz/MggULkuUhbrebxx57jA984AMsWbKEysrKfh//4IMPcsstt7B06VLGjh2b02PLhlIKXQ9hDpgx5D6DrSmV24j9dFm2bJnatGnTSB+GEEIIIYbJnj17mDNnzojtv3enDzE66HqMcLgWm83V61aFUjHc7mn9/s5pmrZZKbUsnf1IBlsIIYQQQpwRlIoMcLtOLpPOEmALIYQQQvSjurpastejjFEecjJzEaoE2EIIIYQQQqTFWOBo7+ceDQmwhRBCCCGESIMxYCbaTwcR834JsIUQQgghhEhZT/31QH3Jc9dJRAJsIYQQQggx6p06YOZkuctgyyRHIYQQQljC4cP/Tjhck7PnKyiYyllnfWvQbR566CH+53/+JzlW/IknnsDtdnPkyBFWrVpFa2srS5cu5Ze//CUul4tHH32Un/3sZ0ydOpXf//73uFwu3nzzTV544QUeeuihnB17f+677z5eeeUVrrnmGmbMmEFRUREf//jH+2wzkq0HL7jgAt5+++1Bt3n44Ye54447KCoqyvn+e9df33bbF7jmmn/hppuuTd6fyxIRCbCFEEIIYQnhcA1ud3XOni8UOjro/XV1dTzyyCPs3r2bwsJCPvShD/Hcc8/xyU9+kvvvv58vfvGLrFq1ijvvvJPHH3+cu+66i2effZbt27fzH//xH/z1r3/l2muv5dvf/vaAEw9z6bHHHqOtrQ27vb9FfCNvqOAajAD7ox/9aFoBdjweH/I19wyYGSz0lRIRIYQQQohhF4vF6O7uJhaL0dXVxaRJk1BK8dprr3HzzTcD8IlPfILf//73gBHIRaNRurq6cDqdPPPMM7z//e+nvLx8wH08/fTTySmOH/vYxwAj03zZZZexYMECLr/8cmpqjMz9Jz/5Se69914uuOACzjrrLH73u98BcN111xEIBFi6dCnPP/88Dz74ID/4wQ8A2Lx5MwsXLmThwoX8+Mc/Tu43Ho9z3333sXz5chYsWMDPfvYzAF5//XXe9773cfPNNzN79mxuvfXWZHZ348aNXHDBBSxcuJDzzjsPv98/4POczOPxDPr8jzzyCPX19Vx66aXJ6ZWvvvoq73nPe1iyZAm33HILgUAAMFoo3n///SxZsoTvf//7nHfeecn9HD16lPnz5wPwrW99i+XLlzN//rncffcDQ/y0ZZGjEEIIIcSwqqqq4stf/jJTp05l4sSJlJaWcuWVV9La2kpZWRkOh5ENnTx5cnIM+mc/+1nOP/98ampquPDCC3niiSe45557BtzHrl27WL16Na+99hrvvvsuP/rRjwD43Oc+xyc+8Qm2b9/Orbfeyr333pt8zIkTJ3jzzTf54x//yAMPGEHjyy+/TGFhIdu2bWPlypV99vGpT32KRx99lHfffbfP7Y8//jilpaVs3LiRjRs38vOf/5wjR44AsHXrVh5++GF2797N4cOHeeutt4hEIqxcuZIf/ehHvPvuu6xZs4bCwsJBn2cg/T3/vffey6RJk1i7di1r166lpaWF1atXs2bNGrZs2cKyZcv44Q9/mHyOiooKtmzZwgMPPEAkEknu8/nnn0/+G3z2s59l48aNvPvuBkKhEK+88rcBjkhJFxEhhBBCiOHm8/l46aWXOHLkCPX19QSDQZ555plBH/Oxj32MrVu38swzz/DQQw9x77338uc//5mbb76ZL37xi+h63zKE1157jVtuuYWxY8cCJDPd77zzDh/5yEeSz/nmm28mH3PDDTdgs9mYO3cujY2Ngx5Pe3s77e3tvPe9700+l+nVV1/l6aefZtGiRaxYsYLW1lYOHDgAwHnnncfkyZOx2WwsWrSIo0ePsm/fPiZOnMjy5csBKCkpweFwDPo8A+nv+U+2bt06du/ezYUXXsiiRYt46qmnOHbsWPL+3icSH/rQh3j++eeBvgH22rVrWbFiBQsXLuf1199h9+79gxxV7kpEpAZbCCGEEKIfa9asYfr06YwbNw6Am266ibfffptbb72V9vZ2YrEYDoeD2tpaqqqq+jy2vr6eDRs28O///u9ccsklvPbaa6xevZq///3vXHHFFVkdV0FBQfLrbLKuSikeffRRrrrqqj63v/766332YbfbicViaT/PYFJ5fqUUV1xxxYD168XFxcmvV65cyS233MJNN92EpmnMnDmTUCjE3XffzaZNmxg3TmP16v+PUCg8wBFpKCU12EIIIYQQw2rq1KmsW7eOrq4ulFL8/e9/Z86cOWiaxqWXXpqsf37qqae4/vrr+zz261//Ot/6ltGhpLu7G03TsNlsdHV19dnusssu47e//S2tra0AtLW1AUbHjeeeew6AZ599losvvjij11BWVkZZWVkyA/7ss88m77vqqqv47//+b6LRKAD79+8nGAwO+FyzZs3ixIkTbNy4EQC/308sFkv7eQbj9Xrx+/0AnH/++bz11lscPHgQgGAwyP79/WegZ8yYgd1u59vf/nYyex0KGWPRKyrG4Pe38+KLfx5i75LBFkIIIcQZpqBg6pCdP9J9vsGsWLGCm2++mSVLluBwOFi8eDF33HEHAN/73vdYtWoV//Zv/8bixYv5zGc+k3zc1q1bAViyZAkAH/nIR5g/fz5TpkzhK1/5Sp99zJs3j//zf/4Pl1xyCXa7ncWLF/Pkk0/y6KOP8qlPfYrvf//7jBs3jieeeCLj1/nEE0/w6U9/Gk3TuPLKK5O333bbbRw9epQlS5aglGLcuHHJxZr9cblcPP/883zuc5+ju7ubwsJC1qxZk/bzDOaOO+7g6quvTtZiP/nkk3z4wx8mHDYyz6tXr+acc87p97ErV67kvvvuS9Zil5WVcfvttzN//gIqK8tZunThgPvVtNxmsLVcFnSfTsuWLVObNm0a6cMQQgghxDDZs2cPc+bMGenDEBYXi3UQjfqw2VwDbqNUDJvNzaFDraf8zmmatlkptSydfaZcIqJpml3TtK2apv0x8f10TdPWa5p2UNO05zVNcyVuL0h8fzBxf3Wv5/hq4vZ9mqZd1ev2qxO3HdQ0bageKkIIIYQQQqQkHu9G04YOeUeqBvvzwJ5e338PeEgpdTbgA8xrI58BfInbH0psh6Zpc4FVwDzgauAniaDdDvwYeD8wF/hwYlshhBBCCCEyppRCqVByguPANE77oBlN0yYDHwD+J/G9BlwG/C6xyVPADYmvr098T+L+yxPbXw88p5QKK6WOAAeB8xL/HVRKHVZKRYDnEtsKIYQQ4gxn1VJWkR+UimH8CmlDbKmh6/Gc7TfVDPbDwFfoCe0rgHallNlTpRYw+9NUAccBEvd3JLZP3n7SYwa6/RSapt2hadomTdM2NTc3p3joQgghhLAit9tNa2urBNkiC6llpZVS+HxB3G53TvY6ZBcRTdOuBZqUUps1TXtfTvaaIaXUY8BjYCxyHMljEUIIIcTwmjx5MrW1tUhSTWRK1yPE4/4USkQU0Mzs2dfkZL+ptOm7ELhO07RrADdQAvwIKNM0zZHIUk8G6hLb1wFTgFpN0xxAKdDa63ZT78cMdLsQQgghzlBOp5Pp06eP9GEIC+voWEd9/eO43dMG3U4pRTh8DIfjgznZ75AlIkqpryqlJiulqjEWKb6mlLoVWAvcnNjsE8BLia9fTnxP4v7XlHFt52VgVaLLyHRgJrAB2AjMTHQlcSX28XJOXp0QQgghhDhjxeOdKW2naRqapqHrkZzsN5tBM/cDz2mathrYCjyeuP1x4Jeaph0E2jACZpRSuzRN+w2wG4gB9yil4gCapn0W+CtgB36hlNqVxXEJIYQQQghBNNqGpjlT3FpDqTBGwUZ20gqwlVKvA68nvj6M0QHk5G1CwC0DPP47wHf6uf0V4JV0jkUIIYQQQojBxGJtgw6Y6St3Gex0+mALIYQQQghhGdGoL60Mtq6Hc7JfCbCFEEIIIcSoFI+3kxg2nhJjJEv2JMAWQgghhBCjUizWic2WagZbSQZbCCGEEEKIgeh6JBEwD9UDu4dksIUQQgghhBhAPB5E0+xo2lBj0k2SwRZCCCGEEGJA8XgwzUco6SIihBBCCCHEQHQ9vQBbKdD17pzsWwJsIYQQQggx6hgZbJXy9ppmzyDr3T8JsIUQQgghxKgTjwdRKr0AO92s90AkwBZCCCGEEKOOMSY9nVDXTjzelZN9S4AthBBCCCFGnVisLa0hM5rmkABbCCGEEEKIgcRi6YxJN0tEJMAWQgghhBCiX7FYOzZbOhlsu3QREUIIIYQQYiCxWEdaJSJGDbYE2EIIIYQQYpj4ghFC0fhIH0ZGlNKJxTrTLBFxSAZbCCGEEEIMj3AszlUPv8FDf9s/0oeSEV3vRtNIY0y6WSISysn+JcAWQgghhBB9/G13I03+MHXtucnonm7GwJj0wlyjpV8cXY9lvX8JsIUQQgghRB/PbzwOQGco+2BzJGQzkVGpSNb7lwBbCCGEEEIkHW/r4p8HWgDwh6IjfDSZyTzAtqHr4az378j6GYQQQgghxKjx203H0TRYMLkMv2Uz2AFAz+ixksEWQgghhBA5E9cVv9lUy3tnjmP2eC+d3VbNYHdm+EgtJxlsCbCFEEIIIQQAb+xvpqEzxKrlUygpdFg2gx2N+oDUW/T1UOi6ZLCFEEIIIUSOPLexhrEeF5fPGY/X7aQ7Gicaz6zUYiTFYm1pTXHsTSnJYAshhBBCiBxo8of4+54m/p8lk3E5bHjdxlI9K2axYzFfWkNmekgGWwghhBBC5MgLm+uI6YoPLZ8CQInbCFCt2EkkFmtPc0x6D6nBFkIIIYQQWVNK8fzGGs6rLmfGOA+AxTPYHdhs6WewldKli4gQQgghhMje+iNtHG3tYmUiew3gTWSwrdZJRNcjiSy0PYNH24jHu7I+BgmwhRBCCCHOcM9vPI63wME18ycmbyspNDLYVpvmaATINjRNS/uxmmZH1zOfAmmSAFsIIYQQ4gzW0RXllR0nuH7xJApdPVlfswa702I12PF4IKPgGowAO5sx6yYJsEW/dF2xs65jpA9DCCGEEMPspXfrCMd0Vi2f2ud2q9ZgZ5OBNgJsKRERw+T32+q49tE3qfVl/0smhBBCiPyklOLXG44zb1IJ51aV9rnPU2AG2FbLYAcBleGjHei6BNhimKw/3AZAY2f2rWqEEEIIkZ921nWy50Qnq3otbjQ57DaKXXY6u62VwY7HgyiV2XAcyWCLYbWlxgdAR3f2rWqEEEIIkZ+e21iD22njukVV/d5fUui0XAbb6IGdSQcRc5Fjd9bHIAG2OEVHd5QDTQEA2rus9UclhBBCiNR0RWK8vK2ea+ZPpLSw/57RXrfDcjXY0WhrxkNmJMAWw2ZrInsNRrAthBBCiNHnlR0N+MOxUxY39uZ1Oy3XRSTzMemgaQ7icQmwxTDYUtOOLdHdRjLYQgghxOj0/MYazhpbzPLqMQNuU2LBDHYs1o7NllkGG+woFUKpTBdJGiTAFqfYWuNj1oQSStwOyWALIYQQo1BHd5SNR33csLhq0J7RXrdVa7AzzWBrKAVKZfeaJcAWfei6YltNO0umllFa5KS9SxY5CiGEEKONOf58Yql70O28boelJjkqpROP+zMOsA0aup5d/CMBtujjQFMAfzjGkqljKCt0SQZbCCGEGIUCYSNoNntdD8TsIpJtycTpYixQVGha5iGukcXOrk2xBNiij83HjAWOS6aNoazISbsE2EIIIcSokwyw3YMH2F63g2hcEY5l1lf6dDOGzGQf3koGW+TUlhof5cUuqiuKKC100iGLHIUQQohRJxBKLYPtdRulFp0WSbgZAXa2NHRdMtgih7bU+FgytQxN04wA2yJ/UEKI/KfriljcGlkwIUa7lEtEEhluq9Rh5ybAViglGWyRI+1dEQ43B1k81WjXY5aIWKXuSgiR3x743+386y83j/RhCCFIvUSkJJHBtkonEV0PAtmfyGebwR78X1WcUbbWtAOwxAywC13EdUUgHEteIhJCiEzta/Czr9FPLK7jsEt+R4iRFEwE2MVDlohYK4Mdi/lz8CxKSkRE7mw+5sNu01g4pRQgOTZVhs1YW5M/RFQuy4s80NYVIRTVOdSci0u4QohsmMNjil1DdxExtrdGLBCNtgHZJQWVkhIRkUNbanzMmeilKPHHVlpk/IJKHbZ1dUViXPr91/nV+pqRPhQhaAsYH1g76jpG+EiEEIFwjCKXHbtt4CEz0JPBtso0x1isDZst26vuing8lNUzSIAtAIjrinePtyfLQwDKCiXAtrp9DX6CkTh7TnSO9KGIM1woGicYiQOwUwJsIUZcMBwbcoEjWK+LSCzmQ9MyHZNusqPrXVk9gwTYAugJxHoH2GYGW0pErGt/o1GLdqw1uzeKwTy7/hhXP/yGLIYVg/L1mgp7JgfYbcEIT7x1RP5exIjzh2NDLnAEKHbZsWlWymBnPibdpGn2rLuRSIAtAKM8BDgpg22cAUoG27r2NhgBdk3b8AXY22ra2dvgxx+2xpuvGBltQSPAnljqZld9J3H9zAwwn1l3jG/+YTfH27pH+lDEGS7VDLamaXjdTjotUoMdi3Vgs2WXwdY0yWCLHNlyzMdYj4sp5YXJ28rMDHZ3doX+YuTsSwTYJzq6iQzTFK5Gv7HSuqEju3o1MbqZAfYl54yjOxrncHNghI9oZKw73ArI+6oYeYFQagE2QEmhwxIZbF2PoushwJ7V80gGW+SMMWBmDJrWs9jB7bRT4LDJNEcL29fgp8hlR1dQ1z48GbOmTiOwPiEBthhE7wAbzsyFjuFYPHm1UK4MWl9HVxTdwldiAuHYkC36TN4CpyW6iMTjQTTN3ieWyYSmOdD17D4zJcAWtAbCHG3AHfdKAAAgAElEQVTtYsm0MafcV1rolBpsi2r2h2kNRpIBzXCViTQlMtiNEmCLQZgB9rLqcgqd9jMywN5e20EoalxJkgDb2pr8Id7z3b/z4ta6kT6UjAXCMbypBthuB53dVshg56oFqJSIiBw4ecBMb2VFMi7dqszykCvnjQegpjX3vYcjMT0ZOEkGWwymLRhB06C82MXcSSVn5ELH9YnyEJAA2+r+srOBrkh8WNe3DLdAioscweiFbYUa7NyMSTdLRCTAFlnaUuPDYdNYMLn0lPvKCl1SK2hRexuM1nwXzxxHgcM2LB8EzYGeSVcNnbJoSwysLRhhTJELu01jflXpGbnQcd3hNqorigAJsK3uj9tPAFgi6OyPUopgOiUibmvUYBsBdvbvK0aJiPTBFlnafMzHvEkluJ2nLgookRIRy9rX4Gesp4CxngKmlBcNS4Bt1l+DZLDF4IwA21g4fW5VKV2ROEdazpyFjpGYzuZjPt43qxKXwyYBtoU1dobYeLQNwBJlE/0Jx3SicZX6IkeLdBHJXYBtlxrskfDqrga++r/bR/owciIW19le28HifspDwCgRsUpzedHXvkY/syd4AZhWXjQsvbAbO40M9qRSt3QREYNqC0aoKC4A4NyqEgB21p05A5B21LXTHY2zYno5pYXyvmplr+w4gVJQ4nZY9kQpkGirmnqA7SAQjuX9os5YrB2lchHa2tD1CEpl3n1LAuw07ajt4HO/3sqvNxyntdflcava2+CnOxrvd4EjGNMc2y36BnImi+uK/Y1+ZiUC7CnlRRxv68r5cItmvxFUL5hcJhlsMai2YIQxxUYG++xxHtxO2xm10HHdYSPjeV4iwLZqYCbgT9tPMHuClzkTSyyR1e1PMM0A2+t2ohQEI/mdsY9GW3IwJp1EFxINXc+8RHbIAFvTNLemaRs0TXtX07RdmqZ9M3H7dE3T1muadlDTtOe1xFxKTdMKEt8fTNxf3eu5vpq4fZ+maVf1uv3qxG0HNU17IONXM8ya/WHu+OWm5MWH/Y3Wv7zZM2CmrN/7SwuddEXihGPx03lYIks1bV2EonoywJ5aXkQwEk8uSMyVxs4wdpvGvEkldHRH6Y7I74noX1swQnkig+2w25gzseQMC7BbOWe8hwpPgQTYFnaio5tNx3xcu2CisfDPoj9Hs5461UWO3sR2nXleh52bMekGTbOhVOaJ1FQy2GHgMqXUQmARcLWmaecD3wMeUkqdDfiAzyS2/wzgS9z+UGI7NE2bC6wC5gFXAz/RNM2uaZod+DHwfmAu8OHEtnklEtO565nN+Loi/PetSwA42OQf4aPK3pZjPiq9BVSVFfZ7vzlsRj4MrGVfYoFjskQksbDqWI7rsJv8IcZ6XFSNMX5/Gjoliy1OpesKX1eEiuKeD775VaXsru/M+0vOuRCNG/XXK6ZXAEiAbWGv7GgA4Jr5Ey1d6pNuBruk0IgF8r0Xdi7GpPc2rBlsZTBTtc7Efwq4DPhd4vangBsSX1+f+J7E/ZdrRq79euA5pVRYKXUEOAicl/jvoFLqsFIqAjyX2DZvKKX4xss72XTMx/dvXshlsyvxFjg40GT9DPbmGh9Lp40ZsCl7aZHxgWjVN5Ez1d4GP5oGMyt7MtgAx3McYDd2hhlf4mZCiRswsjtCnKyjO4quYEyvAPvcqlIC4RhHhqF9ZL7ZUddBVyTO+WdJgG11f9xez9yJJZw1zpNY+JffGd2BpFuDbWaw872TSC7GpPfQ0PXhzWCTyDRvA5qAvwGHgHallPkvXQtUJb6uAo4DJO7vACp6337SYwa6vb/juEPTtE2apm1qbm5O5dBz4pn1Nfx6w3Huft8MPrhwEpqmcfZ4D/sbrZ3BbvaHOd7W3W//a1NZ4qxVOolYy74GP9UVxRS6jM4wUxIBdq4XOjb5w1R6C5hQagTYstBR9Kety8gCnZzBBs6Iftjre9VfQyLAlvdUy6n1dbG1pp0PLJgIGOPDA+EYsXjmC+FGihlgp96mz4gF8jnZppQiHu/MYQZbYeR9M5NSgK2UiiulFgGTMTLOszPeYxaUUo8ppZYppZaNGzfutOxz3eFWvvnyLi6bXcn/e+Ws5O3nVHo5aPEMdrL+elr/9ddgfBCABNhWs6/Bz6zx3uT3bqed8SUFOW/V19QZorLEnQywR2qhYygat+SH3JnCrP3vncE+u9KDy2FjR+3oD7DXHW7l7EoP47xGDXpJoRO/BToyiL7+nCgPuTYRYJcmyybyO6vbHzPA9qY6aMYCGWyjrZ5C03LXv2PYM9gmpVQ7sBZ4D1CmaZr5k5kMmPNC64ApAIn7S4HW3ref9JiBbh9xtb4u7n52C9Mqinh41SLstp4yipnjPbQEIjlfNHY6banx4bRrzJt06oAZk9RgW08oGudoazC5wNE0Nce9sCMxndZghEpvAUUuB6WFThpHqAb75p++zff+sndE9i2GZr5P9s5gOxMLHXfWj+4AOxbX2XS0jRWJ7DUYgZlS+R2siFP9cccJ5leVMq2iGDB6Q4M1h80EQul3EYH8rsE2emDnsjneMGewNU0bp2laWeLrQuAKYA9GoH1zYrNPAC8lvn458T2J+19TRm+wl4FViS4j04GZwAZgIzAz0ZXEhbEQ8uWMX1GOdEVi3PH0ZqJxnZ9/fFnyD8k0M5EdPGDhMpGtx9qZN6m03wEzprJC4wNRWvVZx4HGALrqWeBomlpeTE0OS0RaEm0qxyfqryeWukckg93RFWVnXaflryiNZv1lsAHmV5Wwq250L3TcWd9JsFf9NfRkPiVxYR3H27p493hPeQj0LPyz4s8xGI6haVDkGvjzvzcrdBHJ1Zj03oY7gz0RWKtp2naMYPhvSqk/AvcDX9I07SBGjfXjie0fByoSt38JeABAKbUL+A2wG/gLcE+i9CQGfBb4K0bg/pvEtiNGKcV9v93O3oZOHv3wYs4a5zllm5mVxm1WXegYiem8W9vO0gH6X5u8bgeaBh1d1s3Un2nMEen9ZbAbOkOEorlppWdmqysTl73Hl4zMsJldJ4wMaKuFryaNdv1lsMGow/aHYznvbpNP1h9uBWDFWX0z2GDNwOxM9acdxmj0D8zvCbDNn6MVpzn6wzE8LseADQ5O5nbacTlseZ2t1/XcBthK6Vl1ERny2oBSajuwuJ/bD2PUY598ewi4ZYDn+g7wnX5ufwV4JYXjPS2eeOsof9pxgq++fzbvm1XZ7zYTS914ChyWzWDvOdFJOKYPusARwGbTKHHLsBkr2dfgx+20JS9jmqZWGK30an3dnF156kljupr8p2awd9Wf/sl8uxP7bA2M7gD7528cJqrr3P2+s0f6UNLWFoxQ5LKfcrXs3MRCxx11HUwfW9zfQy1v/ZE2zhpXTKXXnbzN6gG2UorOUCz5Os4Ef9p+goWTS5MLxsFY5AjWLRFJdYGjqcTtyOuTCSODncu1OFpW49JlkmM/1u5rYvYEL3e896wBt9E0jbMrPZbNYKeywNFUViQtpaxkX6OfmZXePmsGwCgRAahpy81ZftNJGewJpW5aAmEisdO72NDsQtESCOd8UmW+2Frj4z/+vIffba4d6UPJSFswwpiiU1tnnTPei8tuG7WdROK6YuORtmT/a5PVA+y/7mpg+XfWnDFlWcdag+yo6+DaBZP63G6Wjlrx5xiMxFIeMmPyup15XYMdi3Xm9DNA0+xZlZ1IgN2PZn+YyWMKh7x0MrPSY9lpjntOdDLW42Jiaf8DZnorK3RKFxEL2dvg55zx3lNuN3th56oOu8kfxqZBhccIsCcmOok0+U9vmYiZNQ/HdIKjcJJkJKbz1f/dgVLQ4s+8HnAktQUjVHhODbCddhuzJ3pHbSeR3fWd+MMxzu9VHgLWD7APtwSJxHQee+PQSB/KaWGWh7x//oQ+t/eUiFjv5+gPxVJe4GgqcTvyemFuNNqW0yEzmmbPquxEAux+tAQijE0EDYM5Z7yXlkAYnwVrPw82BZjRT215f0oKpUTEKtqCEZr94VMWOAKM9bgoctlzVu/a2BlinLcgmSmfkDhZO5112N2ROIeaA8lJpK0Bawagg3nsjUPsbfCzdNoYOkMxwjHrnUQMlMEGo0xkZ33HqLz6sC5Rf917gSNYP8A2P/Ne3Fp3RvS+/9P2EyyeWsbkMUV9bi9y2bHbNEuWiATD6QfYXrczr19rPJ67MekGO/F45p+XEmCfJK4r2oLhlALss8cbAerBZmtlsZVSHGoOplyHW1bksuQZ+plooAWOYJQ1TS0vytk0R2PITE9d6cQR6IW9p6ETXcF7zzH64reMsjrsw80BHnntIB+YP5Gbl04GrFlr3haMnLLA0TS/qhR/KJbzHu35YP2RVqaPLU6uUzC5nTZcdptlA+zWYARPgQNdweNvHh7pwxlWR1qC7Krv7LO40aRpmmWncgYyCLBLCvM/g527KY6gaQ4JsHPJ1xVBV0a2byhmJxGrTXRsCUTo6I6mHmAXOmmXLiKWsK/B+F3sL4MNxkTHXAUyxpj0nhNRM4g4nRmtXYna3UsSAfZoymDruuKr/7sDt8PGN66bmzzpb7Hga2wLRk5p0Wea32uh42gS1xXrj/Ttf23SNI0SiwZmYGSwq8cW8cEFE/nV+ppR/fnwp+31AH3a8/WW7wv/BpLJIkdvQb7XYLcPQ4mIBNg5Y2aHKlLIYFeVFVLssnPAYnXY5sKUVANs8wx9NPeqHS32NfgZU+RMTow72bREgJ2Ly/HN/hDjemWwS9wOilz205rB3lXfyZgiJ/MnG0GalQc/new3m46z/kgbX7tmDpVed/Kk32oBdnckTnc0TvkAAba50HG0Bdh7TnTiD8VOKQ8xlRY6LHtlsC0Yoby4gDvfN4NgJM4v3zk20oc0bP64/QTLpo0ZcL1SSWF+l00MJBCOpTzF0eTN85OJWKwzxxlsu3QRySXzwyuVEpGeTiLWymCbJS2pl4g40RUEIvn7hyUMexv8zJrgHXCB7tSKIkJRneYsF8tF4zotgUifDLamaUwodZ/WaY476zuYN6k0WX4wWnphN3WG+I9X9rBiejkrlxuDbpMZbL+1XmNbV/89sE0uh41ZE7yjrpPIun76X/dWWuikvdtaP0tTa6LkZ/aEEi6bXcmTbx+lexQuMD7YFGBvg3/A7DVgyRIRpVSGJSJOuqNxovHT2ykqFboeTQTDqQ3OSY2deFwC7JwxA+xx3tTOgmaO91oug32oKYCnwMGEk+oCB5JckCOdRPKariv2N/qZPaFkwG3MHq7ZlomYAXrvGmwwpzlm/oaUjkhMZ39DgHlVJbiddrwFDstldwfy4B92EYrp/N+b5idPlsyrEs0We41tgf6nOPZ2blUJO+ty22JrpK0/0sa0iqIBM59WDMxMvl6LVu963wxagxF+u/n4CB9V7r2y4wSaBtf0U39tKnE7LXclIhTV0RXpl4gkMt6BPKzD1vUuNM2W8uCcVGiaQzLYuWQGDqlksMGow27yhy0VfBodRIpT/kU0A2xp1Zffan3ddEXi/S5wNE1LBNjHsmzV1zNkpu/fyYSSwtNWg32gyU8krjNvklEeUuFxWXIB4Mn+truRV3Y08PnLZ/aZIut22vFY8CRiqAw2GJ1EOrqjHG87PSdnw03XFRsGqL82WTXADkXjBCPxZNvF5dXlLJ02hp/943BeZjaz8aftJ1heXX7KItXeSgodeT0+vD/+sPF7l0kfbMjPwTpGv+rcBddglohk/nkmAfZJWoMRHDYt5QlVM8ebI9OtUyZysCnAjDQm+ZUlMhVWvZx5phisg4ipakwhmpZ9BrtnTHrfD54JpQU0+sPET0O9vtn/+txJRsa+vNhFa9BawefJ/KEoX//9zgEHXY31uCzXKaUt8TMZLIM92hY67m3w09EdHbD+GhIBtgWTFr7ECVPvtot3XTKDuvZu/rT9xEgdVs5tPtbGvkY/1w5SHgJYcrGqmYH2FKRXTlGSCMjzsZNIPJ77SgJNswFxdD2z1ysB9kla/GEqPK6Us7szK41gxioTHf2hKA2doZR7YINRgw3W7dl6pjA7iPQ3ZMZU4LAzscSddau+ATPYpYXEdXVasqy76joodtmpToyEr/AUWD6D/f2/7qPRH+L/3jQfp/3Ut+exngLLDZtpCxrvG4NlsGdN8OK0a6MmwO6pvx48wPaHY5ZbPG7+jfVetHrZ7ErOGe/hp/84NCrKfNqCEe799Taqygq5flHVoNuWuJ1EYjqhqHVq0INh41g9Bel13Mj3DPZw/e4pldnnigTYJ2kJpNYD21RVVkih026ZVn2Hmo2pRKkucASjTR9IiUi+29voZ0p54ZALV6ZWFGU9bKapM9RniqNp4mls1bervpO5k0qwJQbdWDG729vmY238ct0xPvGeahZPHdPvNmM9BdarwQ6Gsdu05Fjp/hQ47Jwz3suu+tERYK8/0sqU8sLkAKT+lBQ6USo/s4GDMTPYvQNsm03jX987g70Nfl7f1zxSh5YTcV3x+ee20uwP89OPLh3yanZJYf4GnQNJlohkWIOdj51EjBKR4ShRsqHrmb3nSoB9klSnOJpsNo2Z4z3J1nf5Lt0WfdDzBiIZ7Py2r8HPrPEDL3A0Tc1BL+ymTuNE1JziaJpwmobNxHXF7hOdyfprgIriAqOPvcUygqZv/3EPk0oL+fJVswbcZqzXZb0a7GCUMUXO5InQQOZXlbKjzvoTHfVk/+uBs9dg3WmOZivMk9suXrdoEpNK3fz369Yen/7I3w/wzwMtfPP6ecn2n4Ox4rj0ngx2egG2+VrzsRd2LNZObjuI9JAMdo60ppnBBiNYtUonkYNNAZx2LbnYLRVupx2307pTx84E4VicIy3BAQfM9Datophmf5iuLNouNvpDVJac+ndiTnNsGOZOIkdbg3RF4syb1HNCUeFxEdeVJX9P9cQJwwcWTBz0Q2+sp4D2rqilFpO1BcMD9sDubV5VKe1dUWp91l7ouL/JT3vX4PXXYN0AOzkr4qSfqdNu4/b3nsWGo21sOto2EoeWtbX7mnjktQPcvHQyqxLtMYdi1iV35GFWdyCBjBc55m8NdizWis2WuyEzPTTJYOeCUiqRwU6vUfnMSi8NnSFLvFEebApQXVGMo5/6zsGUFbpG9bQuqzvYFCCuq0EXOJrMVn3ZdGxo6gwz3nvqyvryYhcuu40Tw9wL2+yZ3CeDnTgxtuJCx9ZghEhMH7SkAHq6G1mp1twXjPZZEDcQc6Gj1fthrzuUqL8epIMIWDfA9nVFsGn0WzqxcvkUxhQ5+ek/rJfFPt7WxRee28bsCSV8+/pzU16HZcUSEXORY3GaixzNk/98fK3RqA9Ny92QmR4KXZcMdtY6QzEicT3tDPY5iU4iVigTOdwcSKs8xFRa6JQa7Dw21Ij03qbmoBd20wAZbE3TGF9aMOw12LvrO3HZbckuPgBji81Jh9YJPk117cbJTqoBtpXKRFqD4WRLt8HMnuDFYbP+Qsd9jX7Ki13JE9mBlFp08Xhrogd2fyU/RS4Hn7igmjV7miyzLgmM1oN3P7sFXSl++tElFLpSDzytWCISSJSIeNNc5Oiw2yh22fM0g53bMem9KSUZ7KwlpzimOGTGlOwkkudvKJGYzrG2rswC7CIn7RZ6AznT7Gvw47LbqB5bPOS2Pb2wgxntKxrXaQ1GTmnRZ5pYUjjsNdg76zsSnSd63sIqLJjdNdUlyiImDRFgmwOwrLTQsa3XUJLBuJ12Zo73Wj7AbugIJUulBmPZDHYwMmjLxU+8p5pCp91SWexv/mEXO+o6+OGHFjGtYuj30N7MxbvWCrCj2DRwO9MPAb1uZ17WYMfjHTkdk95DMtg5YX4wp5vBnjymELfTlvet+o62BonrKqMAu6zQetOqziR7G/zMqPT029rtZGVFTrwFjoxb9bUEwijFgMMXhntculKKXfWdnFvVd0FneXJcunWCT1O9mcEek2IG2yKt+uK6or07OmiLvt7mV5Uk+5tb1YlRHmC3BiOD1tSPKXbx4fOm8vK2+uTvdT77zabj/HrDce5+3wyumDs+7ceXFJo12Nb5OQbDcTwFjoymHnrdjrzrIqKUIhbrGLYMttRg50Ayg51mgG2zacZCxzwPsM0SlnR6YJvKiqREJJ8ZI9KHLg8Bo4xjShadRBo7zTHp/f+dGOPSQ8PWDaKuvZv2rihzJ/Vd4T+myImmWbdExFvgGLIlWE+JiDVeY3tXBKUGHzLT2/SxHtqCEQLh/PoAT0djZ2jQyX+mQqcdp12zVGAGRga7fIgrEqvOm0JMV8l+4PlqV30HX//9Ti6YUcGXrjgno+cocBhNAKw0zdEfiiV7WqerpNCZbPOXL3S9G6VUYjBMbimlSxeRXDAD7FTqBU82s9Kb9yUiB5sCaFpmAXZpoVMmOeapjq4oJzpCKS1wNE3Lohd2UyI7PVgGOxLT8Q3TCdnJExxNDruNMUUuWi1UPmGq9XUPWR4CUFzgoNBpt0wNdn89kwczqSzR5tECmc/+hKJxfF3RlDLYmqZZclx6WzBC+RCfkWeNLcZltyXXhuSjju4odz2zhbIiJ498eHHaC/97K3Fb6wpvIBxNe4GjKR8z2PF4cNDg+nuvV/Pq/sG7+gzMRjye2WelBNi9tPjDaBpDnp33Z+Z4Dyc6QnlZm2Q62BQwBuOksYDDVFbkIhS11rSqM8W+xIldOgH21PIiatu6M+oZ3ZgoT+hvkSPAhBKzF/bwBEm76jqw2zTmTDy153dFscuaNdjt3UOWh5is1Au7p6VbalcFzUWedRYNsBuHOPk8WYnFSu90XeHrigxZ8uOw25hR6Um+N+WjP7xbT01bF4+sWpz2VeuTWe1EySwRyURJHtZgG0Nm+heJaby6fyxvHS3L6Lk1zY6uZ7ZeSQLsXpoDxqWvTM5krTAy/WBTZh1EwJorpc8U+xqMjG6qJSJgTHOMxHUa/enXSjebUxwH+JCdUDq80xx31ncyY1wxbuepJ4oVHldyEIaV1Ld3D9lBxDTWU2CZANvMYI8pTu1ytJnFr28f/kmgw8Fc3DuxNLWfpdUCs47uKLoipUWrs8Z72J/HGeyati4KHDbOG6KdYipKCp152bpuIP5wjOIMA2yv25F3XURisVaU6n82QF2nmy/bn+fs9l0ZPbem2QcN4AcjAXYvmQyZMSVb9eXpwBldVxxuCWRUHgI9AbZ0Esk/exv8lLgdycxxKqYmO4mkf+mrsTNMhadgwBNRM7hoGKaFjrvqOzh3Uv8T1io8BbRYbJFjIByjozuaegbbU0CL3xonEa3B9DLYlV5jOmhde3aTRkeKeVI5oTS112u1ADv580yhjHLWhBLqO/J3PsTxti4mjynMaKHfyUrysGxiMMFwLDk0Jl1et3EykU8TV32+tdjt/Xd/qfG5uM3+J27tfgkyOGYjwJYSkay1BMJpt+gzTR5TRIHDxoGm/Dxjr2vvJhTVM85glyV6tspCx/yzr8HP7AklaX1QZNMLu8kfYvwA5SEA4xJB0nBksJv9YRo7w8yd1P9I+LEWLBFJtUWfyVIZ7GB6GWyH3caEErdlM9jmSeWEUZrBTl6RSCWDPcH4rMnXtUm1vm4mj0l9ovFgrPZzDIRimZeIFDqIxhXhWH5Mk41GWwkGd+Jw9H8lwtcSxaXFmUE9tubmDPbgQNclwM5aSyCScqblZHabxoxxHvbnaQbb7CCScYBdaLyhWulN5EyglGJfoz+t+mswgjm7TaMmwwz2QD2wwfhbqPQWDEsv7F31Ro/kc6v6z2CXFxfQ0R0lkidv/qmoT3HIjGmcx0VbV4SYBcaltwYjeAocFDhSX/dRVVZo2Rrsho4QngJHysGL1QIz8+Q1lUWr54w33pPytQ77uK+LKeWp/c0NxWolIsGsSkTya3JlZ+cmQBtwkWOo12ec88C+tJ9fSkRypCWLEhEwykTydZpjMsDOtkRExqXnlfqOEP5QjHPSDLCddhuTytwZZrDDg2awwajDHo4MttlBZKAMtnnp2meh39PaRDA5OeVFjgUoBW0WeI1twUjK2WvTpDK3Jfon96ehI5Rcg5CK0kRglsli45Fg/l2lUiJSVVaIp8CRl3XY/lCU9q5ozjLYZheRfCqbGIiuKwKRGN6MFzkmxqXnQUmMUjo+399wOscOuI3mN37/9umTKa/ZA3p6iQljkWNmn2USYCd0RWJ0ReIZl4gAzBzvpa69Oy97uB5qDlBR7Eq5H+3JrDjWd2uNjxt/8tawj+0eSVtrfADMHyCjO5ipGfTCjsV1WoNhxg2SwQajk8hwdBHZVd/BtIqi5PS0k431mOPSrVFCAUaJiNOuMS7Fk/ueYTPWCLDL07wqOKmskIaOEHGLBJ29nehMbciMqbTQiVLGojMrMBcQp1Iiomka54z3sDcPA+zaRFnWlByWiOiKvPzsP1lXNI5SZJzBNt9786GTSHf3IaLR1gHrr5UCV5dx1fPHsetxR4IU1h9Lax9GgC0lIlnJdIpjbzMT5Rf5mMU+2BRgRoblIQDeAgc2zVoB9qOvHWRrTTvf/ENmq4etYMORNopc9lN6Qqdianlx2gF2SyCSmOI4dAbbHEiTSzvrOpk3yGu14rj0uvZuJpYWYrOlVkPfM2wm/08i2oIRyovSzWAXEtMVzRaZVtlbY0dqQ2ZMJRbrztQaiFDssvfbwac/syZ42d/oz7vMrhlgp3rVaCjmNEcrDJsJJk4CPBkvcjQelw+dRDo63sRmG/j9paXLyQS9lS57MX/WV9BlL8JzaE9a+9A0B/G4ZLCz0pyc4phdBhuMqXr5RCnFwebMW/SBMa2ytNA60xwPNQd4bW8T1RVF/HlnA3/f0zjShzQsNhxpY+m0MRm1lpxaXkRbMJJWJsLs8ztYDTYY0xwD4VhOsxwd3VFq2rqYN0AHEehpHWilcenptOgDa2XpfRlksHt6YVurk0gsrtPkTz+DDdZJXPi6ImldBT1nvBdfVzT5+Zovji2ZXbUAACAASURBVCcSC1PKc1ciAtY4UTID40wXOeZLDXY83kVHx9s4nZUDblPjc1OltRAqLsXlgs3Fiyk6fhAtks7vox2lJMDOSos/szHpvU0tL8LlsOVdBrs1GKG9K5px/bXJmOaY/28gAE++dRSX3cav7zifmZUe/v2lXXRFRv6MO5d8wQh7G/ysyLCP67QK48PleFvqpRxNib+ToTPYiVZ9OSzP2Z2ovx51GWxf6kNmwKjBhvwPsJVStAYjaU/GNf8t6izWSaQlEEFXqQ+ZAesF2K3BoYfM9GYuvs63iY61vm6KXHbGpHl1ZSBW+jkmM9hZdBGBkc9gBwLbUSqKpg38OmraC5msNYPXQ6Unwt/s78EWj1N87GDK+9E0DaVA00i7n6ME2Almf89sAmyzk0i+tSXKtoOIqbTIZYlFjh1dUX63uZbrFk1iYmkh/3HTfOrau/nRmgMjfWg5tfFoGwArzspsBGxPq77UV0ink8EGctpJxOwgMlgGu8TtwGnXkn/P+S4SM4b9pNqiD4xyLZfDRkuen0R0R+OEY3pK9bq9mb87VlvoaK45GNUZ7GB6GexZ4/MzwD7u62LKmKKc9MAGa5X6BLIMsL15UoPt8/0Nu33wtUfH2wuo0lqwlXqpLI7wTuQcoiVleA6nVyZidCmRADtjZgY73WzLyWZW5l+rvlwF2GUWGev76401dEfjfPrC6QAsry5n1fIp/M+bR5JZ0NFgw5E2XA4bCyanv8ARei6PplOH3dQZQtOGLqUyh97kMoO9q76T8SUFjPMOfBKsaRoVxQW05nl219TYGUIpmJxGgK1pxoLIljyvUe4Zk57ee6rX7aTE7bBcgJ3umHSwXoBtLFpN/edZ4SlgrMeVd2WTRg/s3NRfQ68SkTyoSx6KmXnOdJFjscuOTRvZLiLh8Am6uw/hcAw+/rzTF8WtRYl7vIzzRGgOFhA4aw6FDcexB1KPBTRNMthZaQmEKXGn16+1PzMrPdS1dycvw+SDg00Bilz2tDIr/bFCiUg0rvPU20d5z1kVfVq5PfD+2ZQVOvnaizss2Z2gP+uPtLF4SlnGv7OlhU7KipzpBdh+o5XlUDXfZpCRy2mOg01w7K3cQsNmzMVW6ZSIgHGCk291rSdLdpzIoHPRpLJCywXYPWPSR3eAne4J06wJ3rzKYCulqG3ryln9NVjr52jGJplOctQ0Da/bOaIZ7M7O9YBtyCsQ8Q4juRj1lFDpidAecuKbOgcAz5G9aexRQ9PSj5clwE5oCUSyKg8xmQsd86kO+1CzMSI928thZUX5v8jxr7saONER4tMXTe9ze1mRi3+7dg7bjrfzqw01I3R0ueMPRdlV35FxeYhpanlRWuPSGztDVA6SQTa5HDbGelw5KxHpjsQ52BRgXgrtCCs8LlosUiJiDlRJp0QEzGmO+f0azT7d6WQ8TcawGWvVYDd0hnDZbWm93iKXHYdNs0Rg1h2J0x2Np33CdM54L/sbA3nT67uzO4Y/HMtpBtuT7A2d/z/HbEtEwAjOR6oGW9dj+Hx/x+kcN+h23VEbxd1GWWGsuIRxxcb7Ub2tklDlJKObSBrdbSSDnYXmLIfMmGaOT4yHzaMA+2BTdh1ETGUWGIrw+JtHmFZRxOWzT11ZfMOiKi48u4L//PNemnKYWR0Jm4/50BUZL3A0TSkvSq6oT4UxZCa1DJ0xbCY3Wci9DZ3oavAFjqaxHuuUiJhj0tO9umSFceltaUz9O9mkskLqfNbqItLQEWJ8aUFaiQxN0ywzzdHszJN2Bnu8l+5oPHm1ZqQdT/xe5WrIDBjrr7xuhyV+jmaAnWmJCBhlXCPVRaS7ex/xeAC7ffATpOPtbqo0YzR6LJHBBmgKuAjMmIOrow1XW1PK+7XZJMDOWGsgnNWQGdO08iJcdhsHmvLjklggHONERygnAXaJORQhT+vMttT42FrTzqcuqO63p7Cmaay+YT7huM63/rh7BI4wd9YfacNh01g8dfAatKFMKy+i1ted8thtY0x6aieiE0oKc5bB3pmonR9oRHpvFRYqEalv72actyDlvsKmsV4XbcFIXp/s+rLJYI8ppDOU2zaPw+1ER4iJJelnRa0SYPuCxjGmu2g12UkkT+qwa5MBdu4y2JCY5miB39dAOIbTrlHgyDz8K3E7RqzevL39H9hsQyckjne4may1EHW6Ua6CngA76CI47RyUzZ5GT2wlJSLZyFWJiMNu46xxxRzIk4WOhxKZ9BlZtugDo8wCoL07P4OXX7x5BK/bwS3Lpgy4zfSxxXz20rP54/YTvL4v9bPXfLPhSBvzJ5dS5Mo8CwFGiUhMVykFwuYUx8oUM9gTS905q8HeXd9BWZGTSSlkeis8BXRH45Zoy1jX3p12eQgYGey4rvJ6JHxrMILDpiVHK6fD/DfJZRea4dbYGWJ8ButcSiyyeDyZwU6zEcDMZCeR/FhgbrYlzWUNNpg/x/x/zwmEYhQXOLIqGTVqsE//a43FOvH7Nw06Gt1U43MzRWsm7jF+/8wSkeaAC73ATdeU6XiO7Et5dLqUiGQoEtPp6I5SkeZAhIGcXenJmwz2oebcdBABo0QE8nMhR317N3/e2cCq5VOGvPT1r5ecxYxxxXz9pZ10R+Kn6QhzpzsSZ3ttOyumZ1d/DTA12Qt76Mvx5hTHlDPYpW7au6KEotn/G++s6+TcSaUpfSiYAYAVsth17d1pdRAx9UxzzN/XaLZ0y+SDvKrMCFTrLLLQUSnjJDWTheSWyWB3pT4mvTdPgYPJYwrZlydJp1pfF163I7kwMVdKCx2WOFEKhmNZ1V9DIoM9Aq/V79+CUjqaNvQVv5r2QqY5mol7jLLCAoei1B2lKWD8/gbOmos91JXS6HSllATYmTLPzHNRIgLGoo7jbd15kUE72BTAYdOSQ0WyUZZoyp+PCx2ffucYSik+cUH1kNsWOOx858b5HG/r5pHXrNcbe2uNj2hcZV1/DT29sI+lEGA3+dNrQ5arVn3RuM6+Bn9K9dfQ00Iw33th67qirj29ITMmK4xLT3coSW9mBtsqnUTau6JEYnpaLfpMVgmwe9oupp+ImjXey/486SRy3Ned0/prk1VKRPy5CLALT38XEaUUPt+rOBypfe7V+AqYRAsxT8/nRqUnQlPQeE/qqqomXuDGcyiVclEpEcmY+caRixIRMFr1QX50EjnYFKB6bDHODEZpn8w848+3Vn1dkRi/3lDD1edOSPmN8/yzKrhl6WR+/sZhDjeP/M8pHeuPtGHTYGn1mKyfa2JpIU67llKrvsZOI5hLNYOdq2EzB5sCROJ6n7aLgzFHc+f7QsfWYIRITE9rTLppnDf/x6X7gpG0s52mSq8bu02zTICdSYs+k1UCbF9XBLtNS07yS8esCV4ONQeIxFK7HD+can1dTMlx/TVYp9QnFxlsr9uBPxw7rWtAwuHjhMP12O3eIbfVFQQ6Y7hVmFhxz+fGuOIIzYkMNnY7wepZFB0/lMLodDs2mwTYGTH7yeYswM6jVn0HmwNZj0g3lSYy2B15Vvf5wpY6OrqjycEyqfrsZWcT0xXrj7QN05ENjw1H2pg7qSQ53CAbdpvG9LHFbK9t///ZO+8wuc7y7P/O9Lp1tqvsrnbVrWLJslUN7sYGOzgQcAK2aSGUQCBAko+ELyEJGFL4TAIhdmxwEiAYg+24d8vdlmXVVVutpF1tnW1Td/r5/jhzZlfaNnPmnJkjaX7X5cv27MzsmZ2Zc573ee/nvue9b84d7HLZCzu/IimbiPSpyF1TvUtElFr0weS5yqvjsJnRUIwqhcFdRoNAfZkt47Kid5SEzMiUpwszPQ+sgvR+VjqUSX6W1btJpERODGefGqsFoijSM6pNB/tcWSgFo4mMraBSymyS4UGogLv0Pt9rCEJ22vGhoIXa1AjA9A52cPKcFFyyIh2dPvdOtiCUCmzFyIloNSoV2IurHZiNQtGt+mKJFKdGwqror0GfZvqplMh9r55g7YJyNizOraO7oNKBxWQo+kk/F6KJJLu7x9jUnL/+WubaVfW8fnxkXuvCQX80qxRHmXqVOtgd/X5sZgMtnuw+x7IGezik3+ITJi36lHSwy+1mzEZB1xrskVCMKoUdbJCcRPrOES/sfDvYKRGCOpAUzsVIULnkZ2mdPpxERkMxJuJJFlZp0MG2mQnFklk7MhULecgxH+SQmkINOqZSMcbHX8Rsnm6/OxPdYzaahGEAEq7JjnetK0YwZmIiLpW+UU99VtHpgmAsSUSUIl+k8o1JlzEbDbR4iu8kcmokRDIlqlZgW01G7GajrjTYLx310uUN8YltLTl3VowGgeZqxzlVYO8/7SOaSLFJBf21zE3rGkmJ8Oi+/jnvN+SPUO2cP8VRxmGRBony1WB39PlZVl+GcQbrxdl+r8Ni1H0HW5Y/KNFgy5HwepWIJJLS4LgSiz4ZKWzm3OhgD/gjCALUZCmfmkqmcaGj8+pMjIVjVDqV7ZotqXFhMghFdxLpSS9qNdFg2wtbdColGE3gzrvAlqPhC/OZDYUOkEpFMBiyO590j9tZkPHAnrR2lZ1EMl1sQUhHp5+eMzpdEEylDrZSRoJR7GZj3qu6qbTXuuksspOILFFRq8CGdJqjjjrY9756groyK++7qEHR45urnedUgS3LWdQssNtq3axqLOPhvX1z3m8okL0Htkx9mS2vAlsURTr6/axsyE4eIlPtsuheg907PoHLalJkYwfSULZeC+yxdLGYT9OisUKyeUzqXDoBMOCboMZlVTTrUqbDncGZkIZWle3yWkxS0+nIQHGbTrIHthYdbD3u8M5EUJUhx8ItJlKpOENDv8Jkyj7zoXvcRqvJS8pkJmWZ/MxODZuRCbYuB+aOTi91sPNgWKWQmam01broHg2rYlGmFLnAbq1xqvacetKZHRkI8PKxYT6+uVnxEGdLjZPukfA5cREHqcBeWufKqzM4Ezeta2Rvzzgn51hsDPoj1JXlWGDn6YXd54vgm4hnPeAoU+206t5F5PTYBE0VdsV+tHpOc1Rq6TaVxgo7yZSY0f7rmQF/VJE8BCYLM70PyI2FYnmdd5bWuzlaZImI7IGtlYsIFK6rq4RkSiQcS6ogEZFeayGcRPz+14jF+nMusJeYByX99ZTz69SwGZmEu4KIpx7H6RNzPGNJg60YtUJmptJe5yIlQpe3eN3RTm+Qpgp73mEkU6lwmHWzlfmLt7qxmgzcummR4udoqXYSS6bOCbeCRDLFOydHVe1ey7x/bSOCAI/M0cWWOti5FREN5ba8NNjygGOuHWyPS/9pjkot+mQ8LivDAX2+xklLt/wKbDg3rPoGfBOKBhzh3Oh8JlMi4xNxKvN4P5fXuekeDRfVvvb0WJhKhznvDu5MlGUWSvqViMhDie48hxzlx2v9WpPJEENDv8JsrsvpcT0+SYM9dcARwOOIIyBOOomkiZdXYgrNvvgrdbDzYDgYVb/ArpWE9cUMnOkcCrJERXkISBcDPSQ5plIij+/v573LavM66bd4pO7+uSAT6ej3E4olVQmYOZuGcjubmqt4aE8voji9m59IphgORhV1sIeDUcX2XB19fgQBltfPb800FamDrc/urkzf+ISiAUcZj0t6jTO9X8Um08HOU4MNUqdf7ygNmYEp7kw6LrDHw1LIVD4LpqXp7/DRIs4maeWBDefGQimYlnTk28EuK1AHe3T0KZLJMEZj9u9ZMGpkNGyhJjlyhkUfgMkoUuWInyERAUg63BjDwVlTHUsa7DyQCmx1t9ybPQ6MBqFog46plMhxFS36ZCrsFl0MOb7TPcZQIMr1F9Xn9TwtNedOgf2WBvrrqdy0rokub4iDfdOHPUZC6RTHHLt0DeU2RBHF2/wd/T5aqp05XxCq0h1sPRafIOkgfRNxRRZ9Mh6XhXhS1OUFXZbnqNPB1rdEJBRNEIgkFMWkw7lRmI2G8l8wLUs7iRQzcOb0WFgT/TVM6pL1LBEJRaUCWw0fbAC/hhrsWMzLyMijWCyNOT2ue9xGGSFsqci0DjakvbBDZ36OE04XgihinJg5D2LfQEWpg62EZEpkNKS+RMRqMrK42lG0Dnbv+ASReErVAUdIS0R0cCF4bF8/FpOBK1fktnV0NjUuK06L8ZwosN/oGqW52qF4K3o+rl9dj9ko8PCe3mk/k31+cx1ylI91UKEOu6Pfz4oc9dcgFXaJlKjb7dqMRV8eEhHZsUKPOuzRtESkIg8NtssqudDoXSIizxgo7WA7LUaMBkEX59XZUGPBtLDKgc1sKJpVXyolcroAHWw9a+kDcoGdp0TEZjZiMRo0XUwMD/8GSfucm3NN9/ikRV98pgL7LC9sgIRTWvyZwjN/Np88UluKSlfCWDhGSlQvZGYqS2vdRfPCPu5V30EEJJ1ZNJEq6vBmKiXy5IEBLl9ak/dKXBAEWmr07ySSSom8fXJUE3mITKXTwuVLa3hkb9+0oc+hdIpjrsV9Q7lUQCrRYfsm4vSMTuSsv4YpUeI6lYlkLPrylIgAeHWowx4Lx3DbTFhM+V1iGivsui+wB33KQ2ZAOgfpaXh8JsZC+Q+tGg0CS+vcHClSB1uWqmmR4ghgNxsx6XyhpFYHG6SOvVYuIhMTXfh8r2Gx5O4O1jNuZ5FhCGCaRASg1ikV2FM3NxMOqcA2zqLDPj7iQMlm6AVfYA+rnOI4lfY6F6dGwkQThS9GtbDoA6mDDRRVJvJuzzgD/gjvy1MeInMuWPUdHQrgm4hrJg+RuWldE4P+aEaOIjOYlnjUKtBgA4qs+g73pwcclXSwXfpOczytYoGtxw62ZOmWv+yuqcKmey/syZAZ5e+l3gvsTAc7Tynl0jp30TrYPWmLPq062IIgSHHpOpaIyBpsNQpst82sSYEtiikGB3+OweBCEHIvUXvGbayyDwDMKBGpdcWIJIwEY8bMbUm5gx2a3hCNJwVOjtkBci6xSwV2QN2Qmam01bpIpkRODs+s69GS494gVU6L6nZuFXbp+Yp5MXh8fz8WY/7yEJlWj5PTY2HFg3iF4M0ubfXXMletqMNhMfLI3jNlIkOZFMfcCuwymxT6oqSD3ZEusFcp6GDLfr169cLuHZvAbBRyltxMRZ4bUbPA7hlV51w1ForlpdeVORc62LJEpD4P6VaZzgtsNTrYIOmwvYFoRtNdSORhWa002CAvlPQpS4MpEhFVCmyTJnKYQGAPExPHMJs9ih7fPW6jzTJIymgiZZv+XtfM4IWdslhJmUwzSkROjdtIpJSVyhd8gS07DWjSwS6ik8jxoRBLVPS/lpF1ZuPh4nQGRVHkif39bG/3ZCaZ86XZ4yQlQrdKxYUWvHVilKYKOwurtOm+yNgtRq5dVc/j+wfO2HkZCkSodlpy9hsXBEHywlZSYPf58bgsitLx5OJTr17YveMTNJTbMWSZTjkTlQ4LRoOgWoH9zqkxtn/vBV44MpT3c6nVwW6ssOOPJArit6uUAV+EcrsZu8U4/51nodxu1rV2dyQUw23NX/KzLOMkUvhrorx4bKrQ7hxaplHRqRaqSkRsZtW/l6lUjKGh/8ZkqlaUD5BICvT6rSwyeKd5YMvUnp3mCCAIJBzuGSUincPKPy8XfIHtDUgXpxoNCuzWGicGgaI4iXQNB2n1qCsPgSkSkSKdRPb0jNPniyhObpwJvVv1iaLImye08b+eiQ+sa8Q3EWfn0eHMbYP+3D2wZRoUhs109PtZ2Viu6EQrd0/1KhHJ16IPwGAQqHZaVPPCfmxfPwDPdgzm/VxjoVje3U6YlNDo2UlkwK/cok9G7xKRsXCMKhV2eeUCuxg67NNjE3hc1rwWQvNxrkhE1EitdtvU12CPj+8kHh/BZMp91xKgP2AhkTJQK45kBhfPRg6bOdtJJOl0YQpPr9WOjziwGJXtbl/wBfZwMIbFaMhY7KiJzWxkUZUjo4cuFL5wnOFgjCW12nWwixU288SBAcxGgatWqiMPgckCe64Uw2LSNRxiOBgtWIG9rc1DldPCQ1PcRIYCkZz11zJ1CuLSY4kUxwaDigYcAcxGA+V2s269sHvHJvKy6JNRK81RFEWeOijpFl8+NjzPved/rtGQOgXZuRA2M+CL5O3sU2436brAHlVpwVTrtlJuNxdFhy05iGgnDwH9S32CsQQWkyHvnQhIS0RUXEwkEgG83l9jsSifreoel97fitjYjPprgCpHHIMgTncScbhnDJs5PuKgtVrZ7napwA5GqXZZFMcVz0dbbeHjYY8PpyPSNexgF+MkIooij+3rZ1ubJ1Poq0GFw0Klw0yXTgtsrf2vz8ZsNHDDRQ082zFIML2lOOiPUpdHB3vQH8kpjv64N0gsmVI04ChTrdM0x1gixWAgkpdFn4zHrU6B3dHvp3d8gtVNZXSPhjk1ovy7EIoliSVTVKnYwdbzoKNaHWx/JKFb3/aRoDqSH0EQWFbvLooXds9YWHOJXZnNrFtrUJA62G6VUizLVB5yHBl5DFGMYTAo/y71jNtwEMESn5i1wDYawOOc2arPOBE6I2xGFKFzxEFbqcBWxki6wNaK9joXJ4ZDxJOFG6CT49lbNdBgu6wmjAahKGmO+3t99I5PcL2K8hCZFo9Ttx3st06M4nFZafWo/37Oxk3rGokmUjx9cIBEMsVIMKq4g11fbieREnMKm1EakT4Vj1Od4lNtBv0RRBEWqNLBtjCswiLiqYODGAT4v+9fBcDOo17FzyV7YKsxYF3jtmIyCLrtYMczCaf5F9jJlJhZ0OqNsXBMtYH5ZWknkUIuJpIpkb7xQnSw1e3qqk0wmlBFHgKSi0g4llSltolGBxgbezrnUJmz6R63sdIuSd1msuiTmSlsJpkJm5msA4aCFgJRk3YFtiAICwVBeEEQhA5BEA4KgvCl9O1VgiA8IwjCsfS/K9O3C4Ig3CUIQqcgCPsEQbh4ynPdlr7/MUEQbpty+wZBEPanH3OXoFU7eQaGg+qHzEylvdZFIiXm1RHKlS5vEJNB0GS1Lnu2FsOm77H9/ZgMAteoKA+Rafbo06pPFEXe7Brh0pYqzXZZZmLD4koWVNp5eE8fIyHJKz7XFEeZdQsqAHglB+lBR78fm9mQke8oodpl0eWQo+xmoIZEpMZlxRvMPy796YMDbFxclXnfd+YhE5FlOWo0LowGaUhWrwX2UCCKKCoPmZHRc5qjKIqMhNQrsJfWuwlEEoqchZQy6I8QT4os1MiiT6bcbiZW5JyIuQhFE6oMOMJkcmUwjy52PD7OyMjTdHd/F0GwIAj5HVv3uI01zj5gZos+mdqZwmYcslXf5O5K54j0edGyg50AviqK4krgMuDzgiCsBP4MeE4UxXbgufT/A1wPtKf/+QzwY5AKcuBbwKXAJuBbclGevs+npzzuOkWvRgFSTLp2BfbSdDxsIQcdu7whFlU7cnZ8yJaKIujMJPeQAba0efJKh5uNVo+TAX+EcExfHaTTYxP0+SIFk4fICILAB9Y28krncMYuT6ml3OqmMpoq7BmNbzZ09PlZXl+GMQ+XDUkior8Otix3UEUi4rISS6Qy9ltKODUS4vBAgGtW1SEIAjuW1vD68RHFnamxsDqWbjKSVZ8+hxwHfNJ7qTQmXUbPBXY4liSWSKnawQYKqsOWF7Wad7Bt+k5zDETUK7Dd6deaq0xEFFOEQofp7f0Rx49/haGhXyAI5ry019LzShrs5VZpSHvOAjvdwT4jbGaGNMfOEQcCIq3Vyhb481Zgoij2i6K4O/3fAeAQ0ATcBPwsfbefATen//sm4H5R4g2gQhCEBuBa4BlRFEdFURwDngGuS/+sTBTFN0SpDXP/lOfSFFEUGdG4g72kxoUgUNBER60cRGSKMchxsM9P92iYG1QKlzmblvTfqxie5XOx61Rh9ddTuWldE8mUyH2vngTyS6q7dlU9O48NZ7UFLopi2kFEuTwEJC/ssXCcRAHlWdkgx6Tn2/UE8Lilokd2Q1LC0welC9K1q6Tv1o52D8Fogne7xxU9n6x7l73I82VBhV23GuzJkJn83ssyHRfYsme1Gr7mMKXALqAOW7bo01yDLcel61QmEool8o5Jl3Gnnyfb15pI+BgdfZbjx79Od/edBIP7sFiasNkWYzTmL3/0RUwEoiYWG72IBiNJ++zPWeOKEU8aGI9M/i2STqkGME4Jmzk+YqepPIrdXAAXEUEQmoH1wJtAnSiK/ekfDQDyvn0T0DPlYafTt811++kZbp/p939GEIRdgiDs8nqVawRl/BMJYslUxjNXC+wWIwsq7QUrsJMpkZMjYU08sGUqHIWXiDy+vx+jQeDqldoU2M0e6cSrN5nI/tOSVELeCSkky+rdLK93Z/S4+YSiXLe6nlgixYtZeCz3jk/gm4jnpb+GSS/ssSKmjs5E3/gENW4rNnP+dmGZNMc8CuynDg6woqEsU3xsXuLBaBB4+Ziyc2ymg+1UZxC5scLOgD+iu4USTCaU5hMyA5MdbD12PuUCW40hR4Byh5n6MltBBx1Pj00gCNBYkf+idi70vBMBkpxDNYmILfvFhNf7EJ2df8LQ0H8DYLMtxmKpRxDUs0zsGZfe2waGpW70HJLKjFXf1LAZs5WUyXyGROT4iIMlCuUhkEOBLQiCC3gQ+LIoiv6pP0t3njWfWBBF8d9FUdwoiuLGmpqavJ9vWMOQmam017o5VqDtsN6xCWKJlCYDjjIVdnNBhxxFUeTx/f1sbq1WPZlSprk6bdVXQK18Nhzo9bGyIT+pRD58YN3k0ImSwBeZDYsr8bgsPHlgfplIZsAx3w52+nutN6u+3nF1LPpgaly6su+jNxDlne4xrl01OddQbjezbmGF4kHHkZBkfarWhbyxwk4yJTKUxyJCKwZ8EWxmQ96uRnouzNTuYIOkwy6kRKRnLEyd24bVpJ0HNkhBM4BunUTUHXKUnicbiUgw+C5GYyVW62KMRm1217vTBXZlfHROeQhMFthDobPCZpzujEQkGDXS57cp6dJTmQAAIABJREFU1l9DlgW2IAhmpOL6v0VR/E365sG0vIP0v+XWVC+wcMrDF6Rvm+v2BTPcrjly10f7AttF13CoIB2Y416pU76kRjuJSIXDUlAf7EP9AU6OhFUNlzkbp9VEXZk148CiB1IpkYN9PlY3lRftGN6/RiqwPa7cUxynIu8+vHB4aN4BoI5+P4IAy+vz69pX6TRspnd8QhUHEZhaYCsrPp89NIgowjVn7QztaK9hX68vE5GdC1JMulm1oVy566jHQUfJos+e92vVc4E9onIHG6Tv9rGhYE7Wnflweiysuf4a9C8RCUYTmcI4X3LVm2s9pN89bsdiTGGf8M1bYNc4p3ewAZIOV0Yi0jUqfV7aPBoW2GlHj/8ADomi+E9TfvQIIDuB3AY8POX2j6fdRC4DfGkpyVPANYIgVKaHG68Bnkr/zC8IwmXp3/XxKc+lKXLXR9YxakVbrYtYIkXPmPYXCLnAbtWwwC5Le7bme3IcD8eyGip84kA/BgGuWaW+e8hUWjxOXXWwT46ECMWSRS2wF1Y52NRSpYp28brV9YRiSV7tnNuhoqPPT4vHicOS34VAlojoyapPFEV6xydUGXAEaRFhEJS/xqcODrCwys6KhjMXM9uXehBFeGWe92omRkMxqlTSX4O+vbClkJn8X6tsf6rHAlteZKm5e7i0zk0skSrY+bZndEJz/TXoe6GUSKaIxFM48zyvysguImqnOSqle9xGa5kfUyQ8p0UfQIU9gdmQmtELW5aI5OsgAtl1sLcCHwOuEARhT/qf9wHfBa4WBOEYcFX6/wEeB7qATuBu4HMAoiiOAt8G3k7/8zfp20jf5570Y44DTyh+RTkgX5Q072Cn9bOFCJzpGg5R4TBrJqUASSIC+ekFx8MxrvnnnVzxDy/Nad8miiKP7e/nstZqzd+nFo9LVxrs/b0+AFY3Fq/ABvjR71/Mj37/4vnvOA+bW6tx20zzykQ6+v15669hcshOTx3s4WCMWCJFowoDjiDtDFQ5LYoK7EAkzmudI1y7sn5ad2lNUzllNpMiHfZISJ1QEplGHcelyx3sfJHtT/VYmI2EYpiNgmqSH5gcdCyEDjuRTDHgjxSmg61jF5FQVNo5VGvIUf486KnAXudOe2C75t79NAjSoONQ6OwC25UOm0nSOeygwhan2qH8vZz3Ly2K4ivAbL39K2e4vwh8fpbnuhe4d4bbdwGr5zsWtRkJRjEI6tlJzUZbrdRN7hwKcu0qTX8VXd6g5oEkU9Mcleryvv3oIUZDMRZWOfiD/3iTO7Y2843rlk8b/Do6GKTLG+KOrS15H/d8tHgcjIZi+MJxyh3qJUUq5WCfH4vRQHuddrsR2aDWwsZiMnD1ijqeOTRIPJmaUXLim4hzemyCWy9dlPfvK7ebMRoEXWmwJy361OumeVxWvIHcFxEvHvESS6a4dvX0wWGT0cC2dg87jw4jimJO27tjoRgLVHx9TquJCoeZ3nF9OfykUiKD/vxj0mWkAlsfxcpUxtIe2Gpu8bfXuTAaBDr6/ZoEh02l3yelyGrtgQ3SOc5uNuLXSdE5lUBUKhTVSnI0GQ04LEZdyGFiSYGBgJUV9VKBHZ9HIgLpsJlpEhE3AmAMh6QER094rlnJebmgkxy9QenEofUAmctqorHcVpBBxy5vSFN5CExug40rXKW/dNTLg7tP80fvWcLjf7yd27c0c9+rJ3n/D1/hQLprK/PY/n4EAa5bpY17yFRkq74TOpGJHOj1sbzBrZmfeTG4dnU94+F4Jv79bA7155/gKGNId3f11MGWLfqaVNJgg1RgK+lgP3VwgGqnhYsXVc748+3tNQz4I3Tm6ICkdgcboLFcf17Yo+EY8aSoit0iFMf+NBtGQjHVm1A2s5H2Whd7T/vmv3Oe9IxJC7NCdLBBkk4UckYpW2SLVLWGHEGOSy/+a+31WUmJAq1maRRwPokIzBI2k/bCFgJBTo7ZWVKV36L+/LlyK0DrkJmptNe5NbfqC0TiDAWimjqIwGQHezyce+ESjCb4i9/sp63WxReuaMNuMfJ/P7CK+z+xCX8kzu/86FX+9YXOjL77if39bGquysvBIltaMlZ9hfMsnw1RFDnQW9wBRy3Y0V6D3WycVSailoOITLVTnShxtehTMWRGRopLz63AjiaSvHjEy9Ur62ZtMGxv9wDklOoYT6YIRBKqF2RS2Iy+NNiyRZ+6HeziFytnMxaOqZLKeTZrF1Sw7/S45pHpp0elz00hNNggFZ166OqeTShdYKslEQHJSUQPEpHucel82sQwomAg6Zi/yVjjjDEcNjPVeyKRfpxvOEI8aWBJHgOOUCqwC1dg17ro1HhqWtYPaxkyA1Bul062Si4G33vyMH2+Ce68Zc0Zlkk7ltbw1Jd3cM3Ker7/1BF+7yev89yhQY4NBblhjbZbiDILqxwYBDihg7CZntEJ/JFE0fXXamO3GHnPshqeOjhAaobvQke/H4/LSq1bnaLF47IyqjOJiMtqyth5qYHcwc6lUHnt+AjBaCITLjMTCyodtNY4c7LrywzEqVyQNVXYdDfkOKBSyIxMud2sS+3uqAYdbIC1CysYD8fpGdX2fT09FsYgQL1K79N8lNv1WWDLhbDLqp5Vodtm0sVrlT2wqxOjJJwuMMxf2ta6YiRTBsYmJuWgcgc7OCJdM/IZcIQLvMCWUhy11V/LtNe5iCZSmS1iLZAt5rQMmQHlk9JvnRjl/tdPcfuWZjYsnr4tXeGw8C+3rucHv7eOI4MBPvmzXQWThwBYTUaaKu26GHQ80JcecGxSp5OrJ65bXc9QIMq7PdOTAjv68k9wnEqV05KxGdMDp8cmaKrI39ZtKh63lUg8RSg2t/3hVJ4+OIDTYmTzkuo577ejvYY3T4zMa60oM5re1arSoIMdiCR0cTGX6fenQ2ZUK7BNuuxgjwSjqkt+ANYskJoHe04rSwzNlp6xCRrK7QWT2ulV6pMZcrSqN19UZjfrpINto9YVxRqe36JPJuOFPUUmIlqspMwWEr4QZmOKRRX5ydIu6AJ7OBjNhFFoTVuttDI6NqSdDvu4N4jRILCoWtutsIwGOwedWSSe5M8e3MeCSjtfu3bZrPcTBIGb1zfx5Jd38J5lNdy0tpFalbZgs6HF4+KkHgrsXh8mg8CyPL2g9ch7l9diNgo8dfBMmUgskeLYUEAV/bVMtUtnGmwVLfpkck1zTKZEnukY5D3La+dNk9yx1EMknmLXybGsnns0qL6lG0w6ifTrSIc94JvAaBBU2wWVJSJaSyZyIZ5M4Y8kVLVdlFlW78ZqMrBvhoW2mhTKA1umzGbSZdBMMD3kqK5ERB8Fds+4jUUVEUyhQFb6a5BcRAC8ZzuJOFwYwwFaqybId012wRbY4ViCcCxZMImI7CSipQ67yxtiYaVd87Qqi8mA02LMqcD+wbPH6BoO8d0PrsnK37ipws5P79jEDz6yPp9DzZlWj5MTw6GiX+T29/pYWufW/L0sBmU2M1vbPDx5YOCMv3PnUJB4UlS1g+1xWQlGE1l3YLWmb3xC9bjmXP2+3+0eYzgYm1MeInNZazVmY/ax6XIHW23Nrrwo0ZOTyIAvSp3bqtqQfLndTDIl5rQToTVy7H2VSrH3UzEbDaxsLGOfxoOOPaMTqrrazIdetfQZiYhKPtiQlogU+bWKoqTBbi4PYgwHs+9gO6d3sAESDjeumC9veQhcwAX2cNrWqlASkXK7mboyq6Ze2Me9Qc0dRGQqHJasTyL7T/u4++Uufm/jQralB6f0SnO1g2A0gbeI4SSiKHKwz39eykNkrltVT/domEP9k9+HDhUdRGTkrW09yESC0QS+iThNFepe7HNNc3zq4ABmo8B7ltXMe1+HxcTGxVW8lKUOOxOrrbJEZDJsRkcdbP8EdSrqevUYUjIWko5Fiw42SIOOB/p8ms0mRRNJBgMRFlYVsINtl5w1ZpoxKSayRMSpoga7TAcd7CNeJ+G4kTXOfgSycxABcFuT2EzJaQV20FpGnTjGklKBrRy5gPIUwJ1Cpr3WnbPlVbakUiInR0Kae2DLSDqz+YuWeDLF1x/cR7XTwl/csKIAR5YfLekFyskiDjr2+yKMhmLnnYPIVK5aWYdBgCenyEQ6+vzYzAZaVPwMyxKwER2kOWYs+lTerpYddrxZSGFEUeTpjkG2LPFkQjHmY/tSD4cHAgz55y9uZTlOpco+8jUuK2ajoCsnkQFfRLUBR5hSYOvI4k32kK/UoIMNkg47HEtqdl3sG48gihS0g11mM5MSIZRFSnEhCUbj2MwGTCpq0d02E7Fkqqg7hA/sq8NpSbC9uhsg6w62kA6bOVsiMihW4cFHe2X+zdALtsCWL7gejVbmM9GWdhLRYmXb55sgEk8VroNtN2clEfm3F49zqN/P3968OnMB0TMt1VJxV0yrvkyC43lcYHtcVi5pruLJA/2Z2zr6fSyvL1PVl16WKuhBh52x6FPRAxsm9c7ZaLCPDAY4NRLOSh4is6Nd6nRnE5s+Fo5RbjerehEHydO8vtymuwJbLYs+kJoWoM8OdrVG18k1CyoA2KvRoOPptAf2wgJqsPW4EwEQjCZVHXAEMm5IxRo+HghYeLGrihuXe3FFpevmfCmOU6l1TvfCPpmowSCILLUP5X18F2yBLXvjetyFkYiA5CQSjiXp86l/kZAdRLT2wJapcMyvMzs2GOCHz3dy45oGrimQE0i+NFXaMRsF1az6jg0G2JvjEM/BXh8GAVbUn78SEYDrV9dzdDDIcW8QURRVdxCByQW0kiAWtTmtUYFtNhqodJizeo1PHRhEEOCqlbVZP//KhjKqnZas7Pq0CJmRkcJm9FFgByJxQrGkNh1sHRVmssWl2kOrMq0eJ26riX0aFdiyBeCCAnlggxQ0A+hu0DEYTeBWccARJheFxZKJPLi/DkEQ+eBFQ5iCfkRBIOHIvsCucU1Pczw8IZ0b3XF/3sd3ARfY0olDq5X5TCytk51E1O+Odnml5yxUgV1uN8+Z5DgcjPKnD+zFaZWCZM4VjAaBxdVO1TrYX39wH5+6f1dOGsMDfX7aal3YLeffgONU5EXXUwcH6B2XfL/V1F/DZAd7VAca7N6xCcxGgVoNZGnZpjk+3THAxYsqc/IZNxgEtrd7eKVzeN7dt7FQjEqNirGmCv2kOaodMgOTBXaxh8amIs8uVKgs+ZExGARWN5VrNuh4eiyMySBQX0AnKll6pSdLSZCCZtTUXwOZgr0Yn9lg1Mhjh2t4b+sYta4YppCfpN0JxuxfY60zxkjYTCI5uWu6JyDlbphCJYmIYoaDUcrtZiymwv0J2tLyjc5BDQrs4RBuq4maArmilDvM+MLTLaVEUeR/9/ZxzT/v5FB/gO988KKCObWoRXO1UxUv7PFwjL0943gDUd45lZ3NGUgWfedbwMxMNFbYWbuwgqcODKie4CjjsBixmgy6GHLsHZf8eA0qSmBkpAJ77tfYMxrmYJ+fa1fV5fz829trGA7GMoOoMxFPphjwRzTrdjZV2hnwR0hMjV4rEgN+OWRGvd0IPXawx0KS5EdLD+m1Cys41O8nmlBfx9szNkFjhV1V2dl86FHqAxCMJHCpGJMOk4uJYnSwHz1Uw0TcyIfXSnM8pqA/a/21TK0rhojAcFh6HeGYgT2BRun5wqUCWzGFDJmRqXRa8LismnhhH/cGaa11qRpgMRcVdguxZIqJKcMN3kCUP/qv3XzxF++ysMrBo3+8jetWFyaFUU1aa5ycHAnnrZV/pXMY+Ske398/953TDPkjDAWi57X+eirXrapn72kfzx6SpAvLVfb9FgQh6+6u1mhh0Sfjcc//Gu95uQtBICf9tYwcm/7yDLHpkXiS+18/yXu+/yJd3hDrFlbk/PzZ0FhhJ5kSGczS71tL+tMdbDU7oy6rCaNB0FVhNhKKabZgklm7oJx4UjzDUUgtTo+FC+ogAvrciQAIRNUvsN1FKrDjSYEHD9SxvtFPezrO3BQM5FxgZ7yw0zKR46MOQtiJGa0YQ/k3Qi/YAttbwJCZqbTXujSSiIRYUiAHETiz2yKKIg/v6eXqf36J548M8WfXL+fBz27OSGLONZqrncQSqby18juPeimzmbhqRS1PHpg5GvxsJhMcL4wCW+6mPri7lxaPMyuP9FzRS9hM79iE6hZ9Mh6XZc4hxze7RvjZ66e4bXMzi6tzP0/UltlYXu8+ww87GE3wk5eOs+3OF/irhw/SUG7jvjsu4XPvWaLoNcyHHDajBx32YLrAri1T7xoiCAJlNn2lOY6FtS+w16QXZFrosHtGJ1ig0XduNiYlIvrSYIc0KbCLM+T44vEqhkOWTPeaVApTOPuQGZlMmmPaSaRzWPqsJJzukkQkH4aD0YLJKabSXueiczCoapBJOJag3xcpmP4aJjV5RweDfPr+d/jSL/fQ4nHy+B9v57OXL1HdRaCQyDZx+Vj1iaLIS0e9bGv38P61jQz4I7zbM79M5ECvH0FQXyqhV1prXCyrc5NMiarrr2WqnZaM3VixeLZjkMFARHWLPhmPy0oolmRihpCSiViSrz+4j0VVDr5+3ewpqvNx+dIadp0co983wQ+ePcrW7z7Pd544zIoGN7/8zGU88NnNvHdZrWa7aE3p7n8+BXYommDLd57j4T29eR1Lf1oKM18SZq7oLaRkJBhT3dP8bBrLbXhcFvb2qKvDjsSTDAejBe9gu20mBEGHEpFoQtUUR5g65Fi41yqK8Kt9dSyumGDTQukzYwoHEUQxd4nIWWEzx0fslNni4HJiCpc62IoZDkQLLhEBqYMdiCYyGj41mHQQKYxFH0g2fQCf+OnbvHzMyzdvWMGvP7slk1h5LiMvVPIZdDw6GGTQH+XypTVcsbwWi9HA4/sH5n3c/l4fLR6n6p0GPXPtakmyoNWiotplLVoHezgY5Qs/382n7t/Fsjo3H964QJPfUzNH2Mw/PH2EUyNh7rwluxTV2djeXkMsmWL7nS/wg2ePsamlioc+v5X//OSlXNZarbk8TdY79+ZRYL/RNUKfL8JvdudXYA/6IpoMzumtwB4La+cKIyMIAmsWVKjewZYt+grpgQ3S4KbLWvyEw7MJRhM4Vb6uOC1GDEJ+EpHXT5Vz688v4og3u/dpd6+bzhEnH1o7gCytNwWl2ZB4jgW2w5LCaUlMSkRGHCypmiDpdGMsdbCVEUuk8EcSRRm+a6tNO4moOOjYNVxYiz6QBo4EAdYvrOCJL23nU9tbCzpIoiW1bisOizEvqz7Z0mzH0hrcNjM7lnp4Yn//vDsXBy+QAcepfGBtI3azkS1LtEn5lCUiau4azYcoijz4zmmu+qeXePrgIF+9eimPfGGbZhd72W707ATSXSdHuffVE3zsssVsXlKd1+/Y2FzJ2gXlvO+iBp788nbu/vhGzfTWM+G0mqhwmPPqYMuJlK8fHyEUVV4U9KscMiNTpqMCWxRFRkMxqgrQiFqzoJxOb5BgHu/J2fSkg50K3cEGaaGkJxeRaCJJLJHCrXKBLQj5LyZ+vqeB/oCNbzy+lO6x+b9TD+yrp9Ie5+q2kcxtppBUYOcqEQFJJjIUspBMQdeogzZPWJKIRMKQzO/zeM4W2PmcHOXt4kKmOMq010kdXjV12F3eIIIgaYcLxeJqJ6984wr+5w83F7RzXggEQUg7iSh/j1466qW91pXpul2/uoE+X4S9c9hRjQSj9Pki53VE+ky01bro+JtrNSvWPE4rsWSKgIoX77noGQ1z231v89UH9rKkxsXjX9rGF69s19SxKBOXPkWHHYkn+fqv99FYbufPrl+e9++wmY08/IVt3PXR9Swvkkd7U4U9k4iphJ1HvXhc0oD2q1kE58zGgD+iaky6TLndrJvOZyCaIJ4UqdJYIgJSZLooSg5KanF6tDgdbJB02Hp5H2FqTLr6O6NSNLyyc+uJURsHBtx8YOUQBgH+9LFlDARm/7ydGLXxZk8Fv7N6EItpsmEid7CTOYTMyMhhMz0+G7GkgbbqMAmHVNOYwvm5iZ2zBXY+AwTDAWm7WOutr5modlqodJjpVNFJpMsboqnCrroecD6aCmx/VEhaPMqt+iZiSd46OcrlS2syt121og6zUeCJOdxEDqat6i60DjagqbxAHtIa1VgmkkyJ3PfqCa79wU7eOTnKX39gFQ/84ebMrpWWZArsKa/xn585StdwiDtvWaPJhbUYNObhhX1qJMTJkTCfvXwJLquJF44oS2qLxJOMhmI0nOcSkbG0taXWQ44gdbBB3UHHt0+OYTUZijJrVWY36SpoRm5IaiE9dNvMiuuxxw7VYDKkuGNjL9+/4QgTcQNfe2wZo+GZj/OBffVYTUk+sPLM764p6CdhdyIac399ctiMPODYVi11sCF/L+xzt8CemO7BnC2yTrEYHWxBEGivc6sqETnuDZ53XeRi0+Jx0jM2QVyB5+4bJ0aIJVLsmFJglzvMbG3z8PiB2WUickT6qgvEQaRQZOLSNRp0jMST/O/ePm758Wv89f92sKmliqe/cjm3bWnWxPN6JuTXKJ/b3u0e4+6Xu/jopoVsa9dGelMMpLAZZR1sWbZ15Yo6diz18NyhIUXXkCG/9DfWqoPty+Pali37T/vm9eYfKWCBXe2y0lRhn3OHLxd+9XYPj+zt446tLQX7Dk5FbxIRucOsdpIjQLndpOg7GU0IPH3Mw/aWMSrsCZZUT/Dd648yHDLz9ceXEYye2TAcDZt49lg11y4dodx25jC3Eg9smVpXjPGImY4hF2ZDikUVEZLpDrYxz0HHc7bAjiVTdCqUWcg6xWKsbGHSqk+Nk6goipwYDrGkgPrrC4EWj5NkSqRnNHcd9ktHvFhNBja1VJ1x+/tWN9AzOpHpVJ/NwT4fi6ocGQvEEuowU3c3X5Ipkdc6h/nTB/ay8W+f5Yu/eJdBf4Qf/N467rv9EtXj0OfDajJSZjMxHIwSiSf52q/3UV9m4y/et6Kgx6E1jRU2AtGEoi7vS0eHWVhlp7nawRXL6xgKRGf9Ls7FZMiMNgV2IiUSnsENRi0G/RFuvecNbr/vLXzh2f+OhexgA6xbqM6g456ecb750AG2tXn402uWqnBkuVNm089OBEAoJhXYWuxkXbOyno5+P290jcx/5ym81FVFIGrixhWT1p+r6kN8+9pOTo3Z+PMn24nEJ0vU3x6oI5ES+NCa6WYBppBfkf4aoCbtJPJmdznNVROYjGKpgw3wzKFBRY+THQWqi+AiAlKB7ZuITxtIUsKAP0I4lix1sFWmWbbqG8ldJrLzmJfLWqunSXauWVWHySDw2CwykQO9/gtOf10IMh1sFQrsQ/1+vvP4IbZ+93luvedNnjwwwPWr6/n5py/llW9cwc3rmwoW9nQ2ctjMXc8do3MoyHduWZMJgjhfWJWWT72Wo346lkjx+vFhdrTXIAgC71lWgyDA84dzl4n0p/3xtXIRAe0s3kRR5C8fOkA0kSIQSXDPK12z3reQHWyQZCI9oxOM5HFdHA5G+aP/eofaMis//Oj6otnFlulISw9SiiNoIxG59dJFeFxW7nruWE6Pe/RQDU1lEdY3nlnEblzg55tXdtEx6OJbzywhnhSYiBt4pKOWrc3jLCg/6/MhiphCARIK9Ncw6YXd57fRVi011ESzhaTFeuEW2HazkWc7lBXYw8EoDotRk1CLbGhPB7DsPKp8yEZGtugrZMjMhUBr+u8p/32zpWc0TJc3dIY8RKbCYWHzkuoZ3UR84Tjdo+FMAVFCPeQCQemFu3MowL88f4zrfrCT6//fy/zHKydY3VTGv9y6nl3fvIrvf2gtW5Z4ij6P4HFZ2X1qnJ/s7OJDGxacMQNwvnBZazU1bisP5ehj/c6pMUKxZOZv4nFZWbuggucUFNiD6Q52vUYdbNCuwH7iwABPdwzylauXcsNFDdz7yglGQzMvPAvdwV6zIB04o3DQMZ5M8fn/3s1YOMZPPraByiLMWMmU282EYklFEkMtCGiowbaZjXz28lZeOz7C2ydHs3rMyTEb+wfc3LjCy0z9iMtbx/jqjpO81VPB3z3fyuOHPfijJj48Q/faOtSHkEoRr1DmkiQX2ABLqid3rJMO14UrESmzmXm3Zxyvgtjc4WC0KBZ9MhsWV7K6qYxvPLiPX77VnddzdXmlD0Cpg60ulU4L5XZzzoOOO9NJd5cvnVn3+r6LGjg5Ep4WC3wwneB4UUl/rTpWkxG3zZTpyM2HKIoc6PXx/acOc+U/vshV/7STf3j6KA6Lkb+5aRVv/Z+ruOe2S7hxTWPBB4vnosZlZcAfweOy8M0bVxb7cDTBaBB4/5pGXjjsnVPecDY7j3kxGYQzrAqvXF7LXgXXkH5fBKfFqMnugJYF9lgoxl89fIDVTWV8alsLX76qnXA8yU92Hp/x/qOhGFaTAYelMJ/xixaUIwiwT2HgzN8/fog3T4zy3Q+uKXqjoiytdS50hPhsZIYcNdBgA/z+pYvxuCxZd7Hl4cZrl83eZHzf8mH+aHM3L3VV8aPXF7GiNsjq+ukFb3nHbpIWK6FF7YqOXZaIAJkONqiT5njOFthuuwlRhBcUdCCkArt4q1ub2cgvP7OZbW0e/uw3+/mnp48o1mMf94ZwWozUqRjZW0KixePMWSKy86iXpgo7S2ZZ8Fyzsg6DAE8cOFMmIkekr7pAEhwLjcdlnTGEBaSCOhCJs+vkKH/7aAfbv/cCN/7wFf7tpS7qymx8+6ZVvPkXV/Kbz23l45ubC9bRy5Wa9ND23//ORee1jv/m9Y3Ekqlp36G52HnUy8WLK88oiq9YUQvAizm6ifSPRzTpXsNkMp4WBfa3H+tgPBzne7esxWQ00F7n5qa1jdz/2qkZFxkjISkmvVCSJ5fVxJIalyId9m/fPc19r57kE1tbuHl9kwZHlxvy+6gXmYiWEhEAu8XIp7e38vKx4XmHZ2MJgaeOetjWPE6lfe4FyIfXDPKxi/tIiQIfXddFHxv0AAAgAElEQVQ/rdttCvhw9BwnsHQNolnZOc9qEqX0RmBJ9eSwZsLhwhTOr8A+Z72b7GYj5eU2nj00yIcvWZjTY/vHI0VPHHRZTdxz20b+z2/3c9fznfSOR/juLRdhzlEz1jUcoqXGWTTd5/lMi8fJmzkMbsSTKV7rHOHGtQ2zvh/VLiuXtVbz2P5+vnL10sz99vf6aSy3UV3EnZXzmWqnhXdOjfGlX77LeDiObyKOfyLO+IT038mUtMC1GA1sa/fwx1e0c9XKOt0W0zNx+5Zm1i+q4MoVdcU+FE25qKmcVo+Th/b08pFNi+a9vzc9zPi1a8+MiV/ZUEZ9mY3nDw/xoY3ZXUNGQzFeOurlhjUNio59PrTqYL94ZIjf7O7li1e0nZGY+qWrlvK/+/r58YvH+av3n7nrMZYusAvJmgXl7Dw6jCiKWV/TDvT6+LMH93NpSxV//r78/d7VQGupT67IAT5ODWWxH9u8mJ/s7OL/PXeM+z+xadb7vXSiMj3cmN3C9o6Nvdyw3Eude/oOZNmhdwEB//J1Sg8bkLywneYkLuvkcHHS6cYYmUBIJhTZ/8E5XGADXLWyjgd2nSYST2a9Vftu9xhdwyFu39qs7cFlgdlo4M5b1tBYYecHzx5jKBDhR79/cU5bj13eIBcvqtTwKC9cWjxOfvtub9afrz094wSiCXa0z619vf6iBv7yoQMcGwqyNK3HP9jrY3VJHqIZl7VW859vnGJPzzjldjPldjMLKu2Z/65wmGmqcLBjqeecHQxs9jgzw7nnM4IgcNO6Jn7w3FH6fROZMKfZeDkj2zrzeykIAu9dXssje3qJJVJZBQH99LWTTMST/OGOVuUvYA7KHep3PoPRBP/ntwdYUuPkC1e0nfGzFo+TD65v4r/ePMWnd7Sc8bccKUKBvXZBBb/Z3Uu/L0JjFk48o6EYf/if71DltPCvv39xzg0qrch0sHVi1ReMJqRYcw3nRBwWE5/e3sqdTx7m3e4x1s9Sl2SGG5uy6w4LAjMW10IsirvzIKHmpSSd+TVMb1o1RDJ15t9GdhIxhoIkypSFoOnj06iQq1bUMRFP8trx7IcF73v1JG6riVsuXqDhkWWPIAh8+aqlfO931/D68RE+/JM3GPBlF6QQiSfpHZ8oaET6hURLjk4iLx3xYjQIbGmb23f42lV1CAI8nnYTCUTidA2HSgW2hvzptcvY+61reOlr7+WRL2zjPz95Kf9y68X83e9cxNevW85ndizhhjUN52xxfaFx07pGRBEe2dM37313HvVS7bSwsmG6/OrK5bWEYkneOjH/cFYomuBnr53k6pV1mUF1tXFZTBgEdTuf33/yMH2+Cb73u2uwmqY3Cv74ynZEUeRfX+g84/axcHE62JBd4EwimeKLv9iNNxjl3/5gQ1Hnqs6mzCYvlPShwQ5GEgUJm/rY5sVUOMyzarFPjdnY11/GDSu85Fvru48dwBCP4Vu5Pr8nAm5cMcxNq7xn3DaZ5qh80PGcLrAvba3CZTXxTEd2Ww0DvgiP7+/nw5cs1F2y2Yc3LuTe2y+heyTEB3/0KkcH51/dnRgOIYrMqvctkR+ZAjvLQcedx7ysX1gxr/611m1jU3NVpsCWBx5LFn0lSmRHs8fJuoUVPDRPgZ1Kibx8bJgdS2tm7N5taavGYjJkZdf3i7e68U3E+dx7lig+7vkwGATKVExzfPvkKPe/cYrbNjezYXHVjPdZWOXgwxsX8j9v93B6bHLIazRY+AJ7RUMZJoOQVeDMnU8e5tXOEf725tWsXaisw6gVupOIxBKaDThOxWWVutgvHPHOuEh6ND3ceN0cw41ZkUpRdmgPkdomYp76/J5rFpKZDrZyHfY5XWBbTcZ0ItcgqdT8Q4L//eYpkqLIbZubtT84BexYWsOvPruZRErklh+/xjun5u6qyBZypQ62NjR7nOmBxIF5h1BHglH29/pmtOebifdd1MDRwSCdQ4FMguOFGJFeooRSblrXyKF+/5zNiIN9fkZCMXbM4urjsJjYsqSa5w4PzvkdjyaS3P1yF5tbq2fd+laLcruZ8RwcUmYjEk/yjQf30Vhun6Y/P5svXNGGIAj88Dmpix1LpAhEE1Q5Cltg28xGVjSUzdvB/uVb3dz98gk+vnkxH85SP19IyuxSMasbiUgkodmA49l8fPNiyu3Tu9ixhIGnj3rYmsVw43w4ujsxh/z4Vl6c1/PMRcKRDpvJY9DxnC6wQZKJDAWimSJlNiLxJD9/s5urVtSxqNpRoKPLnVWN5fzmc1vwuKx88me7MjZ8MyH/rOUC0F0WA5fVxBevaOfhPX3c9+rJOe/7SucwokjWBfZ1q6VV9xP7BzjY66PWbaVWg+CKEiXOV25c04jRIPDQu7N7Ysu2mdvnmIu4cnktp0bCdM2xU/Xb3b0M+qP8kYbda5lylTrYP3z+GF3eEN/54EXz7tg2lNu5ddMifr37NCeHQ4yF0x7YRXDbWrOgnH09vlmbZq92DvPNhw5w+dIa/kqndpR2sxGzUdCNi0goWrgC220z86ltLTx7aIgDU+qyl09KXtbvX+Gd49HZUd6xm7irnPBCbWYhAESzOR02c4FKRADeu6wWgwDPzpPq+MjePkZCMe7Y0lyYA8uDBZUOfnbHJoyCwO33vT1rQEbXcIjGclvRAnMuBL50ZTvXrKzj7x4/xCvHZt/Weumol0qHOWsf67oyGxsXV/L4gQEO9JUGHEuUyJUat5WtbR4e3tM3azH20lEvqxrL5tTnvne5ZNc3m+VrMiXyk51drG4qY3v73PMVaqBGgX2wz8e/vdTF725YkPWi/3PvXYLZKHDXc8cyqaeF7mCDNOgYiCY4McPsS+dQgM/+1zssqXHxL7cWL6lxPgRB0FVcerCABTbAbVubKbOZzuhiP3a4kcayCOub/Hk9t8U7gM3bj3/FOjBo+/4nnO4LVyICUiDIxuYqnpkj1VEURX766kmW1bnPCBrQM4uqHdxz20aGAhE+df8uIvHktPt0eYOlgBmNMRgE/un31rGkxsnnf76bUzOc9FMpkZ1Hh9nWXpNTmt/1FzVwqN/PsaEgq0v+1yVK5MzN6xrpHZ/gne7p3ruBSJzdp8bmTbRcUOlgWZ2b5w7NXGA/eWCAE8MhPveetoLYoeYbs51MiXzjwX1UOix884YVWT+u1m3j45ubeWhPL7vS8sRi2FSuWTjzoONoKMYnfroLq8nAf9y+UfcDyWV2M36dBM0ECigRAWnI8xPbWni6Y5COPj/d4zb2DVRyowrDjeUdu0mZLQTaV6tzsHOQdLgv3CFHmatX1HF4IHDGgMZU3joxSke/n9u3Np9TftHrF1Xyg99bz56ecb78yz1ndGlEUaTLGyrprwuAy2rino9fgiDAp+/flfEUlTk04Gc4GGVHjt0tWSYiirCq1MEuUSJnrllVj81smFEm8trxERIpMasO7hUrann75Og0zawoivzoxU5aPU6uXaXNMNXZ5NvB/vmbpzjQ6+db719JRY4d6D/c0YrNbOSfnjkKFKfAbqtxYTcb2Tsl0TGaSPKZ+3cx6I9w98c3sqBSvzJPmXwXSmoSKtCQ41Tu2NqC2yp1sR89VINRSHHt0vyGG42hAM5TRwm0r0Y0a//ZTDhdeaU5nhcF9lUrpWCF2ToQ9716kgqHmZvXFT/hKVeuW13PN29YyZMHB/j7xw9lbvcGogSiCVpL+uuCsKjawb/eejHHvSH+5H/OXOzsPCqdNObrlJ1NU4Wddenp91JEeokSueOymrh6ZT2P7e8nlkid8bOdR704LcascgKuXF5LIiXy8tEzC4CXjw1zsM/PH17emtPuVD7IBbaSdN+RYJTvP3WELUuquVFBGE61y8odW5szQ5bFKLBNRgOrmyYHHUVR5Bu/3seuU2P844fXaj5kqhZlNpMuJCKiKBbMpm8q5XYzd2xt5smDAzx6qJatzcNUOfLr6Jcd3gMgyUMKQNLhxhidQEgoO+7zosBu8ThZUuOcUYd9eizM0x0DfHTTIuyW7MJo9MYnt7Vw+5Zm7nnlBD977SQgRaQDJYlIAdna5uGbN6zgmY5BfjBFW7bzqJfl9W5FQ4qf2t7CVSvqaNAoerlEifOdm9c1Mh6Os/Po5PCUKIq8dNTLljZPVgEy6xdVUuEw89zhM68hP3qxk/oyW0Hjt8vtZhIpkXBsuixwPu588jDhWJK/uWmV4t3aT29vxW01IQjk3AFXizULKjjY5yeeTHHXc508tKePr127jBvXNBbleJQgSUSKX2BHEykSKbGgEhGZT2xrwWU1MhE3csOy+T3r50KIx3Af3U94URsJV2EaUol0gI1RoUzkvCiwQepiv9E1Mu0D/Z+vn0IQBD522eIiHZk6/OWNK7l6ZR1//b8HeaZjkK5h6Q1fUuTI9wuN27c086ENC7jruWM8sb+fUDTBrlOjOXevZW5c08g9t208p6RLJUroiR1La6h0mHloz6RM5MRwiNNjE1kP+BkNAu9ZWsOLR7wk07tTu7vHeKNrlE9tb5kxoEUrlHoov3NqjF/tOs0nt7XQVqs8CKfCYeFr1y1je44zJWqyZkE50USKf3j6CP/87FFuuXiBpv7jWlBuN+siaEaWNLoLLBEB6bP0k2W7+ZX7O2w2H5r/AXPg6uzAGItqas13NnKao1KZyPlTYK+oI54Uz+hihGMJfvFWN9etqs8qdlXPGA0Cd31kPRc1lfPFX+zm8f392MwGGkrWbgVFEAT+9ndWs35RBV/51V7ue/UE8aSouMAuUaJEfpiNBm5Y08CzhwYzxYR8Hbh8Dnu+s7liRR2joRh709KEH71wnAqHmY9uWqT+Qc+BkgI7mRL51iMHqCuz8sUr2/M+ho9vbub+T2zK+3mUsnaBJJ37yUtdbGqp4u8/uPqca0KU2SQNthKpj5oE04OWziK5jW1tq2GD4RiLnvlfGh7/JY7u49LgUS6IIuWH3iXiqSdak7v0SSn5emGfNwX2xYsqqXSYeXaKm8hv3+3FH0lw+9bm4h2YitgtRu657RI8Liuvdo7Q4nHNmE5WQlusJiM/+YMNlNlN/MPTR7GbjWxoPjd0gSVKnI/cvK6JSDzFUwcGAMmer8XjzCnz4PJ0x/b5Q0McHQzw7KFBbtvcXBTtKkC/byLrx/z8rW4O9Pr55g0riyIFUJvF1Q6qnRaaqx385A82FHQHQS3K7CZiyRTRs2YDCo286Cz0kGOGTZ+m55ZP4r1kC8aJEHUvPELTw/fjOnYQktnJoBw9XZgD4/hXXgwFXGglZYmIQi/s86bANhoErlhex/OHh4gnUxlrvtVNZWxcfP4UPzVuKz+94xLK7WZWNCjfBiyRH7VlNv79YxuxmAxsbas+Jy8AJUqcL2xYXMmCSjsP7eklmkjyRtdozq4+5Q4zGxZX8tzhIf7txePYzUZuL0JuwsoGybf7K7/ay+4Z7AfPZiQY5ftPHlY82KhHBEHgvz51KQ98dguVRRi0VAN5oVRsJ5FMgV3EhZdoNuNbtorTv3MHQ9uvRzQYqXntaRb+5l7KDr6DEI/N+fiyQ7tJON2EFue/O5MLoslM0mpTLBE595e6U7h6ZS0P7j7NrpNjJFIpjg0F+ccPrT3ntpbmo63WzTNf2YHdXCrqisnahRU89LmtVDr17cdaosT5jiAI3LSukR+/eJwnDwwwEU9mrb+eypXLa/nOE4c5Ohjgts3NRSnuKp0WfvNHW/jYvW9y691v8OPf35AJw5mJ7z15hHAsyV9/QPlgox5Z0XBuZwOU2SalPsVM6Q3poMDOYDAQal1OqGUZ9r5TlB/YRfWunVS98/IMnenJ/xdSSUY3bNc8WGYmEg63YomIDv7i6rG9vQaL0cBzhwY5MRzC47Jw49rzY0V/NrXukvZaD6wsBcSUKKELbl7XxL++cJxvP3oIs1HgstbcQ8WuXCEV2AYBPr2jRYOjzI5F1Q5+/dkt3PHTt/jU/bv43i1ruGXDgmn32909xv/s6uEzO1ppryvtaOqJMrmDXWQnkaJLRGZCEJhoamaiqRnL8ACOni4EMS2lycizp+R+GE34l60t+GGCJBNRKhHR0V88f5xWE1vaqnloTy8joRhfvKK9tHVfokSJEhcA7XVuVjaU0dHvZ8uSakXa6SU1LlY2lLGxuZKG8uIOxte4rfzi05fx2f96h68+sJeRUJTP7Jh00kimRP7qYWmw8Y9VGGwsoS5K3WByYcgf4dXjw9y0tmnWeaxAREcd7BmIeeqJeQoT4qSEhMON1duv6LH6/IvnwVUr6njxiBezUeAPLi3s9HeJEiVKlCgeN69vpKPfr0geApLU5NEvblP5qJTjtpm59/ZL+Mqv9vL3jx/GG4jy59evwGAQ+EV6sPGuj67XbfF0IVOW7hhrZdU34IvwkX9/nZMjYUwGA+9fO7NHuK4kIucgCacbYzSi6LHnzZCjzJUrJK3aDRc1FFX3VKJEiRIlCsvvbljI9avruWmd8kASg0HQlTuT1WTkhx9Zz+1bmrn75RN89YG9DPkjfP+pI2xureb958lg4/mGlhKRAV+Ej979BsPBGIurHXz/qSPTkkxlgtEEggCOczRor9jITiJKOO+WNA3ldn56xyWl6OkSJUqUuMCoclr48R9sKPZhqI7BIPCt96+kxm3l+08d4fnDQ4SiibwSG0toS2bIMaxugT3oj3Dr3W8w5I9w/ycvJRCJc/t9b/Pfb57ijq3T5waC0QQui6n0OVGI7IWthPOuwAZ4z7LZJ65LlChRokSJcw1BEPj8e9uodlr4i9/u59OlwUZdYzEZsJuNvHVylPtePUEkniKaSJ7573iStjpX1n7rQ/4IH/33Nxj0R7j/k5vYsLgSURTZ2lbNXc8d45YNCzKFvUwwktDXgOM5hpzmqITSX71EiRIlSpQ4R/jIpkVcsaKWGpe12IdSYh4WVzt4+dgwLx8bztxmMRqwmgxYzUYsRoHfvNvLva+c4ItXtPPRTYuwmGZW7g75I3zkbqm4/tknNrFhcRUgLbz+/PoV3PjDV/i3F4/z9euWn/G4YDRR8LCk84mkoyQRKVGiRIkSJS4ISjat5wa//dxWfBNxrCYDNrMRi8mA8Sx9/+7uMe584jDfeuQg97zSxVevXsYH1jaeMQcwFJA01wM+qbje2Fx1xnOsbirn5nWN/McrJ/jY5sVnOOAEo4nSgOM8iGKSeHwIs7l+mpRGNJlIWu2AP+fnPe+GHEuUKFGiRIkSJYqN3WKkvtxGpdOC3WKcVlwDXLyokl9+5jJ+9olNuK1mvvw/e3jfXS/zwuEhRFHEG4hy691v0u+L8NM7NnHJWcW1zFevWYYowj8/c/SM20sF9tykUjEikZOkUhFEcWa9fELhoGPpr16iRIkSJUqUKFEkBEHg8qU1bG/z8Oj+fv7x6SPc8dO32dRcxWg4Rt/4BPfdfgmbWmYurgEWVjn4+ObF3PvqCT6xrYXl9VIIWiiaoK604zEjyWSQeNxLff3tBAJvEYsNYjBMT29VOuhY6mCXKFGiRIkSJUoUGYNB4ANrG3nmTy7n2zevpms4RO/YBPfefgmXZpFM+oUr2nBZTdz5xOHMbaUhx5mJx0dIJHwsWPBVqqquxGZbRDI5MeN9kwoHHUt/9RIlSpQoUaJECZ1gMRn42GWL+d2LFxCIxrPW3Fc4LHz+vW1854nDvHZ8mC1LPARKEpFpxGL9GAwOmpv/EptNCiS0WBYCsRnv71+xDng5599T6mCXKFGiRIkSJUroDLvFmPNA621bmmmqsPPdJw6TSomESgV2BlEUiUa7sVgaaW7+q0xxDWCxeJitJI6Xzy7NmYtSgV2iRIkSJUqUKHEeYDMb+eo1S9l32scD7/SQEinZ9AGimCAaPYHLtYFFi76B2Vx5xs/N5vklOLlSKrBLlChRokSJEiXOE25e18SKhjLufPIIwAWvwRbFJJHIKaqrP0BT02cxGqfvCphMVUAKURRV+72lArtEiRIlSpQoUeI8wWAQ+PPrlzMakjTF7gu8g51MBnE6l1NTcwuCYJzxPgaDGZOpmlQqotrvnbfAFgThXkEQhgRBODDltipBEJ4RBOFY+t+V6dsFQRDuEgShUxCEfYIgXDzlMbel739MEITbpty+QRCE/enH3CWc7fL9/9u7/yBJ6/rA4+/PdPf07OzsLjDswsIuCxsXEU1EIBu8U0PMlUG0DpJ4USq5kJPTXNSol3h3JlhnDsuqmOTinbmox5V7kisCoSKJ5soIBH/gVSk/oihsUIJyBjgEFFhA2B1m+nN/9DOxWabnR/fT83Q371dV13Y/v/rz3f5+Zz7z9Pf5PJIkSVq1V5y8lZfvORpwikirdZDJyeOedROZwzWbx9NqLV1JpBerOYP9ceCcw5a9G7g+M/cA1xevAV4N7CkebwY+Au2EHHgv8BPAXuC9i0l5sc2bOvY7/L0kSZK0Bhe/5gXs3rqRk4/p/Xbf4yCznWCvZGpqF63Wk6W974oJdmbeADx82OLzgMuK55cB53cs/5Ns+zJwRERsB34GuC4zH87MR4DrgHOKdZsz88vZnvjyJx3HkiRJUg9OOXYzn/3Ns9k1u7HqUCoWq7qIsZ2EL5T2rr3OwT4mM+8vnn8XOKZ4fjxwT8d29xbLllt+7xLLlxQRb46IWyLiloceeqjH0CVJkvTcENTrR6y4VaPRvVRfL/o+UnHmubzLLpd/r0sz88zMPHPr1q3r8ZaSJEkaWbnKBHt2KKqIPFBM76D498Fi+X3Azo7tdhTLllu+Y4nlkiRJUs8WzwHX61tW3LZe30LEBJnlTBPpNcH+FLBYCeRC4JMdy3+5qCZyFnCgmEpyDfCqiDiyuLjxVcA1xbrHIuKsonrIL3ccS5IkSepJ5hy12hYmJhorbhsxweTksaVVElmxdktEXAGcDRwdEffSrgbyu8BVEXER8B3gF4rNPw2cC9wFPAn8K4DMfDgi3gfcXGx3SWYuXjj5FtqVSjYAf108JEmSpJ61WgdpNLatevtmcwdPPHEbtVr/lVdWTLAz84Iuq356iW0TeGuX4+wD9i2x/BbgRSvFIUmSJK1Wuwb2savefmpqF48/flMp7+2dHCVJkjR2Mg/RbHYtTvcsk5PHUFbdDhNsSZIkjZ1MaDSOWvX27XrZ5dxQ3ARbkiRJYydidTWwF9Xrs3gGW5IkSVrGWhLsWm0jEVO0Wk/3/b4m2JIkSRormUlma00JdkTQbB5XSqk+E2xJkiSNlcw56vXNq6qB3anZ3Emr9WTf72+CLUmSpLGy1hrYi6amTqDVOtT3+5tgS5Ikaay0WofWVAN7UaOxlYj+02MTbEmSJI2VVusgzeZxa96vXaqvfybYkiRJGjNJo3H0mvdqNGbJXKB9c/LemWBLkiRprERMrKmCyKKJiSb1+hFkzvX1/ibYkiRJGju9JNgAzebxLCz0V0nEBFuSJElj44c1sLf0tH+zeULftbBNsCVJkjQ2Mp+mVpthYmKyp/2npnaQ2d/dHE2wJUmSNDZarYNMTq69Bvaien2WiOgrBhNsSZIkjY12gr295/0bjaPps4iICbYkSZIGZ37+AK3Wwb5L361WO8Feew3sRY3GkURAZqvnY9R73lOSJElaxuzsa3jssZs5ePBbzM09QESQmUxMTDIxMUOttrGUOyd2ioDJybXXwP7h/jUaja20Wgep1aZ7OoYJtiRJkgZi8+a9bN68F4CFhR8wN/cAc3Pf5amn7uKpp+7i4MF7qNU20WgcVeK7Rs8l+hY1mzt48slvmmBLkiRpeNVqG9mwYTcbNuxmy5Z/AsBjj93Iffd9tOQEu/ca2Iumpk7k8cdvpdHobX/nYEuSJKkSU1O7i/nO5czPbtfAXui5Bvaiycljgd5jMsGWJElSJRqNo6nXj6TVOljK8do1sDcxMdHsM67+SvWZYEuSJKkSEcHMzEuYn3+klOO1K4hs7fs4jcYsnsGWJEnSSNq48UeB+VKO1U6wj+37OLXaZiLqZPYWlwm2JEmSKrNhw0nF3On+52H3WwN7UUQwObmdhYWnetrfBFuSJEmVqde30Gwex8LCE30fKyJLmSIC0GzupNUywZYkSdII2rTpDBYWHi3hSLW+S/Qtmpo6gUwTbEmSJI2g6ekX0M9FhT+UpSXYjcY2oLdKIibYkiRJqtTU1IkAZLZ6PkZ7DneLWq2/GtiL2pVETLAlSZI0gmq1DWzY8CMsLDzW8zEy55mYmKZWmyolpkZjtueE3wRbkiRJlZuZOYP5+d4T7HYFkW2lxVOrTVOrbSRi7fmyCbYkSZIqNz19Mn3cPLG0Gtidms3jiFj7PBETbEmSJFWu2dxJRK3nm7uUVQP7mTGd0NN+JtiSJEmq3MREg+npU5mf761cX0SLRqOcGtiLms2dPe1ngi1JkqShMDNzOgsLP+hx74nSSvQtmpw8mkzWfKWjCbYkSZKGwvT08+i1NB5QeoJdr8/SaplgS5IkaURNTm6nVttAqzW3pv0Wa2CXnWC3S/WZYEuSJGlERUwwM3Ma8/OPrGm/smtgL5qYaDA/z9Nr3q/UKCRJkqQ+zMy8mMyDa9qn1TpY+gWOiw4c4Ptr3ccEW5IkSUNjamo3mVFM+1idzPJrYC+an2fNdQNNsCVJkjQ0Go1ZGo2jaLWeWvU+g6iB3Q8TbEmSJA2NiGDTptPXNA87s1XqbdL7ZYItSZKkobJx4wvJXFj19hET1OtbBhjR2phgS5IkaahMTe0mItc0D7vsEn39MMGWJEnSUKnXNzE5uYOFhSdWtX1m+TWw+2GCLUmSpKGzadOZLCw8uuJ27RrYU0xMlFsDux8m2JIkSRo609PPB1aeItKuILKNiN5vsV42E2xJkiQNnampE4Egc/k7lbcT7MHUwO6VCbYkSZKGTq02xYYNe5ifP7Dsdu0Ee/s6RbU6JtiSJEkaSps27WV+/vu0WnNdt8lcYHLymHWMamX1qgOQJEmSlnLkkWeTOceDD91FcAUAAAz/SURBVF5JvX7EkpVC2jWwh6eCCHgGW5IkSUMqYoLZ2XPYtes9ABw6dO+StbFNsCVJkqQ1mJ5+HieddAkbN76QQ4fufsaUkWGrgQ0m2JIkSRoB9fpmdux4O9u2vZ65ufuYnz9Q1MBuDlUNbDDBliRJ0oiIqDE7+xp27boYWODgwbuHrgY2mGBLkiRpxExPn8xJJ72PmZnTaTZ3VR3Os1hFRJIkSSOnXt/Czp3/lsynqw7lWYbmDHZEnBMR34yIuyLi3VXHI0mSpOEWMcHERLPqMJ5lKBLsiKgBfwy8GjgVuCAiTq02KkmSJGnthiLBBvYCd2XmtzNzDrgSOK/imCRJkqQ1G5YE+3jgno7X9xbLniEi3hwRt0TELQ899NC6BSdJkiSt1rAk2KuSmZdm5pmZeebWrVurDkeSJEl6lmFJsO8Ddna83lEskyRJkkbKsCTYNwN7IuKkiJgE3gB8quKYJEmSpDUbijrYmTkfEW8DrgFqwL7M3F9xWJIkSdKaDUWCDZCZnwY+XXUckiRJUj+GZYqIJEmSNBZMsCVJkqQSmWBLkiRJJTLBliRJkkoUmVl1DD2JiKeA5SqNbAEODPH6YYjBNgxHDCcA/9DH/mXEUPX6YYjBNgxHDM+FNqw05tcjBj8H2zAq64chhhdm5oZl1j9bZo7kA3hohfWXDvP6YYjBNgxHDP325SFpwzh8DrZhCGJ4jrRh2TE/JDE+Fz4H2zAC64chhtWM2cMfozxF5NEV1v/VkK8fhhhsw3DE0G9fLiOGqtcPQwy2YThieC60YaUxvx4x+DnYhlFZPwwxrGbMPsMoTxG5JTPPrDoOqV/2Zem5xTEvjZZexuwon8G+tOoApJLYl6XnFse8NFrWPGZH9gy2JEmSNIxG+Qz20IiIfRHxYETc3rHsdyLivoi4tXicW2WM/YqInRHxuYj4u4jYHxHvKJb/fkR8IyK+HhF/ERFHVB1rr5Zp44sj4ksRcVtE/FVEbK461n5ExDkR8c2IuCsi3l0s+3hE3N3RX0+rOs5+dBmTY9NXoWsbx62vLjkmi3W/Xnye+yPi96qMs19dxuTlxbLbi8+6UXWc/ejSxldGxFeKNl4WEfWq4+zHUmOyWD4WfXWZ35HvK36u3hoR10bEcVXHOhTWelWkjyWvLn0FcDpwe8ey3wHeVXVsJbZxO3B68XwTcCdwKvAqoF4s/wDwgapjHUAbbwZ+slj+RuB9VcfaRxtrwLeA3cAk8LWijR8HXld1fCW2c6kxOTZ9dZk2jk1fLdrQbUz+FPA3QLNYt63qWPtoY7cxeS4QxeMK4NeqjnUAbbwHOLnY5hLgoqpj7bOdS43Jceqr3cbj5o5t3g58tOpYh+HhGewSZOYNwMNVxzFImXl/Zn6leP44cAdwfGZem5nzxWZfBnZUFWO/urUROBm4odjsOuDnq4mwFHuBuzLz25k5B1wJnFdxTKVbakyOU1+Frj93xqmvLjcmfw343cw8VKx7sLoo+7bkmMzMT2cBuInR7q9LtfHngbnMvLPYZhz661Jjcmz66jJ5wGMdm20ERnrucURMRcRNEfG14kz9fyqWnxQRNxbfwvxZREwudxwT7MF6W/G1yb6IOLLqYMoSEScCLwFuPGzVG4G/Xu94BuGwNu7nh0novwB2VhNVKY6nfdZo0b3FMoD3F/31gxHRXP/Q1tXY9NXDjFNffYbDxuTJwMuLX3ZfiIgfrzK2Pi03JimmhvxL4DPrHFeZlmrjsUA9IhYrM7yOMeqvHcapr/6jw/OAiHh/RNwD/CLwH6uLrBSHgFdm5ouB04BzIuIs2t98fjAznwc8Aly03EFMsAfnI8CP0P5w7gf+c7XhlCMiZoBPAO/s/Ks1Ii4G5oHLq4qtLEu08Y3AWyLib2l/LTZXZXwD8lvAKcCPA0cB/6HacAZnnPrqEsayry4xJuu0++lZwL8DroqIqDDEQfowcENmfrHqQEqWwBuAD0bETcDjwEK1IQ3E2PXVpfKAzLw4M3fS/rn6tirj61fxxdETxctG8UjglcCfF8svA85f7jgm2AOSmQ9k5kJmtoD/QfsrspFWnEn5BHB5Zl7dsfxXgNcCv1h8nTmylmpjZn4jM1+VmWfQngv5rSpj7NN9PPMs0Q7gvuKrvyy+xvyfjEF/Xco49dWljFlfBbr+3LkXuLroszcBLeDoqmLs05JjEiAi3gtsBX6jgrjK1O3nzpcy8+WZuZf21KY7l9x7tI1TX+2aB3S4nBGf6gMQEbWIuBV4kPb0pW8Bj3ZMM3zGN01LMcEekIjY3vHyZ4Hbu207Coq/uD8G3JGZf9ix/Bzg3wP/PDOfrCq+MizTxm3FvxPAe4CPVhNhKW4G9hRzySZpn0H61GJ/Lf4PzmfE++tSxqmvdjNmfbXrmAT+kvbFY0TEybQvnPve+kdYim5j8l8DPwNcUJyoGWXd2rjYX5u0vzUb6f7axdj01WV+R+7p2Ow84BvrHVvZihOkp9H+Y3Av7W9412SkS+IMi4i4AjgbODoi7gXeC5wd7VJnCfxf4FcrC7Ac/5T2PMDbir/qAH4b+BDQBK4rvvX6cmb+m2pC7Fu3Nu6JiLcWr6+mfYZ3JGXmfES8DbiG9pX9+zJzf0R8NiK20q5YcCswqp8h0HVM/hbj01e7tXFmXPpqoduY3AfsK8qhzQEXjuo3EsuMya8B3wG+VPTXqzPzkgpD7dkybfz9iHgt7ZN9H8nMz1YaaJ+6jMmx6at0H48XRcTzaZ+d/w4j/vujU2Y+GhGfA14KHBER9eIs9j9+09SNN5qRJEmSgOJk09NFcr0BuJb2BY4XAp/IzCsj4qPA1zPzw12PY4ItSZIkQUT8GO2LGGu0v125KjMviYjdtEtMHgV8FfilxfKLSx7HBFuSJEkqjxc5SpIkSSUywZYkSZJKZIItSZIklcgEW5IkSSqRCbYkSZJUIhNsSZIkqUQm2JIkSVKJTLAlSZKkEplgS5IkSSUywZYkSZJKZIItSZIklcgEW5IkSSqRCbYkSZJUIhNsSZIkqUQm2NKARcT5EZERcUrVsUhaHxFxcUTsj4ivR8StEfETVcckaf2YYEuDdwHwf4p/JY25iHgp8Frg9Mz8MeCfAfdUG5Wk9WSCLQ1QRMwALwMuAt5QLDs7Iv53xzb/LSJ+pXh+bkR8IyL+NiI+1LmdpJGxHfheZh4CyMzvZeb/i4gzIuILxfi+JiK2A0TE5yPivxZnum+PiL2VRi+pbybY0mCdB3wmM+8Evh8RZ3TbMCKmgP8OvDozzwC2rlOMksp1LbAzIu6MiA9HxE9GRAP4I+B1xfjeB7y/Y5/pzDwNeEuxTtIIM8GWBusC4Mri+ZUsP03kFODbmXl38fqKQQYmaTAy8wngDODNwEPAnwG/CrwIuC4ibgXeA+zo2O2KYt8bgM0RccS6Bi2pVPWqA5DGVUQcBbwS+NGISKAGJPBJnvnH7VQF4UkaoMxcAD4PfD4ibgPeCuzPzJd222WF15JGiGewpcF5HfC/MnNXZp6YmTuBu2mPu1MjolmcpfrpYvtvArsj4sTi9evXO2BJ/YuI50fEno5FpwF3AFuLCyCJiEZEvLBjm9cXy18GHMjMA+sWsKTSeQZbGpwLgA8ctuwTtC92vAq4nXbC/VWAzHwqIt4CfCYifgDcvI6xSirPDPBHxR/Q88BdtKeLXAp8KCK20P79+1+A/cU+ByPiq0ADeOP6hyypTJHpt1DSsIiImcx8IiIC+GPg7zPzg1XHJWlwIuLzwLsy85aqY5FUDqeISMPlTcUFUPuBLbSrikiSpBHiGWxJkiSpRJ7BliRJkkpkgi2VLCJ2RsTnIuLvImJ/RLyjWH5URFwXEX9f/HtksfyUiPhSRByKiHcddqx3FHd22x8R76yiPZIkaW1MsKXyzQO/mZmnAmcBb42IU4F3A9dn5h7g+uI1wMPA24E/6DxIRLwIeBOwF3gx8NqIeN76NEGSJPXKBFsqWWben5lfKZ4/Trv+7fG0b5t+WbHZZcD5xTYPZubNwNOHHeoFwI2Z+WRmzgNfAH5uHZogSZL6YIItDVBx05iXADcCx2Tm/cWq7wLHrLD77cDLI2I2IqaBc4GdAwpVkiSVxBvNSAMSETO0byzzzsx8rF3aui0zs7h9eleZeUdEfAC4FvgBcCuwMMCQJUlSCTyDLQ1ARDRoJ9eXZ+bVxeIHImJ7sX478OBKx8nMj2XmGZn5CuAR4M5BxSxJksphgi2VrLgL48eAOzLzDztWfQq4sHh+IfDJVRxrW/HvCbTnX/9pudFKkqSyeaMZqWQR8TLgi8BtQKtY/Nu052FfBZwAfAf4hcx8OCKOBW4BNhfbPwGcWkwr+SIwS/sCyN/IzOvXtTGSJGnNTLAlSZKkEjlFRJIkSSqRCbYkSZJUIhNsSZIkqUQm2JIkSVKJTLAlSZKkEplgS5IkSSUywZYkSZJK9P8B6yZ5uKvXSowAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 87\n",
      "RMSE: 8356.881688180623\n",
      "MAE: 7453.349084821428\n",
      "Target Mean: 41728.84428571429\n",
      "                  y_pred   y_label\n",
      "2019-09-24  36762.671875  34817.70\n",
      "2019-09-25  37347.226562  33837.11\n",
      "2019-09-26  38581.914062  32969.10\n",
      "2019-09-27  45389.429688  36843.10\n",
      "2019-09-28  58944.835938  67866.62\n",
      "2019-09-29  53907.312500  39937.69\n",
      "2019-09-30  36162.785156  45830.59\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.99 s, sys: 32.1 ms, total: 2.02 s\n",
      "Wall time: 2.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "show_metrics( sample_sites, target_quantile='0.5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_new_features.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
